{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T. Tarantola, D. Kumaran, P. Dayan, & B. De Martino. (in press) Prior preferences beneficially influence social and non-social learning. <it>Nature Communications</it>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Extraction & Exclusion Tests: Pilot study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as ss\n",
    "from scipy.optimize import curve_fit\n",
    "import pylab as pl\n",
    "import math\n",
    "import seaborn as sns\n",
    "import rpy2\n",
    "import pystan\n",
    "from pystan.external.pymc import plots\n",
    "import pickle\n",
    "\n",
    "% matplotlib inline\n",
    "pd.options.display.max_rows = 999 # Set the maximum display to 999 rows so the entire dataframe is visible in the notebook\n",
    "pd.options.display.max_columns = 999 # Same for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data extraction (behavioral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "First, we import and concatenate the CSV files that PsychoPy generates for each experimental session. We put this in our data frame, called \"data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'../data/social_pilot/raw_data' # This is the folder that all data CSV files are saved in\n",
    "allFiles = glob.glob(path + '/*.csv')\n",
    "data = pd.DataFrame()\n",
    "list = []\n",
    "for files in allFiles: # Read all CSV files in the \"path\" folder\n",
    "    df = pd.read_csv(files, index_col=None, header=0)\n",
    "    list.append(df)\n",
    "data = pd.concat(list) # Concatenate all CSV files into one big data frame called \"data\"\n",
    "\n",
    "# Replace dots in variable names with underscores, to make it easier for pandas to handle\n",
    "data.rename(columns=lambda x: x.replace('.', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and create new variable columns in the data frame\n",
    "We sort the data first by participant, then participant's experimental session (there might be more than one if the task crashed, etc), the image pair, the rest block it was presented during, and lastly the order of presentation within that block.\n",
    "\n",
    "We then index the data frame by this new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = data.sort(['participant','session','img_correct','block_loop_thisN','outcome_loop_thisN']) # Sort the data\n",
    "data.index = range(1,len(data)+1) # Re-do the index so it conforms to the sorted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bid and choice tasks\n",
    "First, create two variables to explicitly indicate the participant's chosen and unchosen items in the binary choice task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'key_resp_choice1_keys']=='left':\n",
    "        data.loc[x,'chosen']=data.loc[x,'choice_left']\n",
    "        data.loc[x,'unchosen']=data.loc[x,'choice_right']\n",
    "    elif data.loc[x,'key_resp_choice1_keys']=='right':\n",
    "        data.loc[x,'chosen']=data.loc[x,'choice_right']\n",
    "        data.loc[x,'unchosen']=data.loc[x,'choice_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the z-scores for each bid, by participant, using the first and second bid task as separate populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bid_means = data.groupby(['participant']).bdm_bid1_response.mean() # Calculate each participant's mean bid\n",
    "bid_sds = data.groupby(['participant']).bdm_bid1_response.std(ddof=0) # Calculate each participant's standard deviation of their bids\n",
    "\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    p = data.loc[x,'participant'] # Variable for the participant\n",
    "    p_mean = bid_means[p] # Variable for that participant's mean bid\n",
    "    p_sd = bid_sds[p] # That participant's bid SD\n",
    "    bid = data.loc[x,'bdm_bid1_response'] # If that row is from the bid task, variable for that bid\n",
    "    data.loc[x,'bdm_bid_response_zscore'] = (bid - p_mean)/p_sd # Add a new variable to the dataframe with that bid's z-score at the participant level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the item familiarity and consumption quesitonnaire data, including their within-participant z-scores, into the BDM task rows. \n",
    "\n",
    "The value labels are:\n",
    "\n",
    "Familiarity: \"How familiar are you with this item?\"\n",
    "\n",
    "    1 = Not at all\n",
    "    2 = Somewhat\n",
    "    3 = Very\n",
    "\n",
    "Consumption: \"How often have you consumed this item?\"\n",
    "\n",
    "    1 = Never\n",
    "    2 = Sometimes\n",
    "    3 = Frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then move the BDM bid data, and their z-scores, into the binary choice rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'chosen']): # ... if there is a value in 'chosen' indicating that row is from the choice task\n",
    "        bidmatch_all = data[data.loc[x,'chosen']==data.bdm_img] # find all BDM rows in the dataset that match that chosen item\n",
    "        bidmatch_participant = bidmatch_all[data['participant']==data.loc[x,'participant']] # find the subset of bids from the same participant\n",
    "        bidmatch_participant_notnull = bidmatch_participant[bidmatch_participant['bdm_bid1_response'].notnull()] # from those data, pick the BDM task\n",
    "        bidmatch_participant_notnull_index = bidmatch_participant_notnull['bdm_bid1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'chosen_bid'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid1_response'] # define 'chosen_bid' on the choice row as the bid for that item\n",
    "        data.loc[x,'chosen_bid_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid_response_zscore'] # define 'chosen_bid_zscore' on the choice row as the participant's z-score for the bid for that item from the same (first/last) part of the experiment\n",
    "        \n",
    "# Do the same for the unchosen items in each choice\n",
    "for x in range(1,len(data)+1):\n",
    "    if not pd.isnull(data.loc[x,'unchosen']):\n",
    "        bidmatch_all = data[data.loc[x,'unchosen']==data.bdm_img]\n",
    "        bidmatch_participant = bidmatch_all[data['participant']==data.loc[x,'participant']]\n",
    "        bidmatch_participant_notnull = bidmatch_participant[bidmatch_participant['bdm_bid1_response'].notnull()]\n",
    "        bidmatch_participant_notnull_index = bidmatch_participant_notnull['bdm_bid1_response'].idxmax()\n",
    "        data.loc[x,'unchosen_bid'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid1_response']\n",
    "        data.loc[x,'unchosen_bid_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid_response_zscore']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a variable ('choice_dv') for the difference in bids between the chosen and unchosen items in each pair, and a variable ('choice_dv_zscore') for the difference between the bids' z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['choice_dv'] = data['chosen_bid'] - data['unchosen_bid'] # Difference between the bid amounts\n",
    "data['choice_dv_zscore'] = data['chosen_bid_zscore'] - data['unchosen_bid_zscore'] # Difference between the z-scores of the items' bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate similar variables, but for the difference between the left and right choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[data['chosen']==data['choice_left'],'choice_dv_left_minus_right'] = data[data['chosen']==data['choice_left']]['choice_dv']\n",
    "data.loc[data['chosen']==data['choice_right'],'choice_dv_left_minus_right'] = -data[data['chosen']==data['choice_right']]['choice_dv']\n",
    "\n",
    "data.loc[data['chosen']==data['choice_left'],'choice_dv_zscore_left_minus_right'] = data[data['chosen']==data['choice_left']]['choice_dv_zscore']\n",
    "data.loc[data['chosen']==data['choice_right'],'choice_dv_zscore_left_minus_right'] = -data[data['chosen']==data['choice_right']]['choice_dv_zscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dummy variable indicating whether the participant chose the item on the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['chosen']==data['choice_left'],'left_chosen'] = 1\n",
    "data.loc[data['chosen']==data['choice_right'],'left_chosen'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the z-scores for the choice confidence ratings, by participant, by task (first or second choice task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_means = data.groupby(['participant']).confidence_rating1_response.mean() # Calculate each participant's mean confidence rating (from 1 to 6) during the choice task\n",
    "conf_sds = data.groupby(['participant']).confidence_rating1_response.std(ddof=0) # Calculate each participant's standard deviation of their confidence rating in the choice task\n",
    "\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    p = data.loc[x,'participant'] # Variable for the participant\n",
    "    p_mean = conf_means[p] # Variable for that participant's mean confidence in the choice task\n",
    "    p_sd = conf_sds[p] # That participant's confidence SD for the choice task\n",
    "    conf = data.loc[x,'confidence_rating1_response'] # If that row is from the choice task, variable for that confidence rating\n",
    "    data.loc[x,'confidence_rating_response_zscore'] = (conf - p_mean)/p_sd # Add a new variable to the dataframe with that confidence rating's z-score at the participant level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable for the z-scores, by participant and by choice task, for the response times in each choice task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "choice_rt_means = data.groupby(['participant']).key_resp_choice1_rt.mean()\n",
    "choice_rt_sds = data.groupby(['participant']).key_resp_choice1_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = choice_rt_means[p]\n",
    "    p_sd = choice_rt_sds[p]\n",
    "    rt = data.loc[x,'key_resp_choice1_rt']\n",
    "    data.loc[x,'key_resp_choice_rt_zscore'] = (rt - p_mean)/p_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Learning task\n",
    "Now we create a variable \"pair_rep\" to indicate how many times each image pair has been presented so far in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_infer = data[data['img_correct'].notnull()] # Subset of \"data\" where 'img_correct' has a value\n",
    "data_infer = data_infer[data_infer['practice_loop_thisRepN']!=0] # Subset of \"data_infer\" that does NOT include practice trials\n",
    "data_infer['pair_rep'] = range(1,31) * (len(data_infer)/30) # Note: Change range and denominator if number of item presentations differs from 30\n",
    "data['pair_rep'] = data_infer['pair_rep'] # Populate main data frame with this new variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate a variable \"response_correct\" to indicate whether the subject responded correctly on each given trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create series variables from the sorted dataframe for easy handling in the loop below\n",
    "arr_img_correct = data['img_correct']\n",
    "arr_img_left = data['img_left']\n",
    "arr_img_right = data['img_right']\n",
    "arr_infer_resp = data['infer_resp_keys']\n",
    "\n",
    "# Generate a variable indicating whether the response was correct on each given trial\n",
    "for x in range(1,len(data)+1): \n",
    "    if arr_img_correct[x]==arr_img_left[x] and arr_infer_resp[x]=='left':\n",
    "        data.at[x,'response_correct'] = 1\n",
    "    elif arr_img_correct[x]==arr_img_left[x] and arr_infer_resp[x]=='right':\n",
    "        data.at[x,'response_correct'] = 0\n",
    "    elif arr_img_correct[x]==arr_img_right[x] and arr_infer_resp[x]=='right':\n",
    "        data.at[x,'response_correct'] = 1\n",
    "    elif arr_img_correct[x]==arr_img_right[x] and arr_infer_resp[x]=='left':\n",
    "        data.at[x,'response_correct'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a variable \"feedback_correct\" to indicate whether the box appeared around the correct (=1) or incorrect (=0) item after the response was collected on that trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if pd.isnull(data.loc[x,'practice_loop_thisRepN']): # If the row is NOT part of the learning practice block\n",
    "        if data.loc[x,'set_outcome_outcm_img']==data.loc[x,'img_correct']:\n",
    "            data.at[x,'feedback_correct'] = 1\n",
    "        elif data.loc[x,'set_outcome_outcm_img']==data.loc[x,'img_wrong']:\n",
    "            data.at[x,'feedback_correct'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a variable \"reward\" to indicate whether the outcome yellow box on a particular trial matched the participant's response on that trial. So for example, if the participant chose the correct item, and then the yellow box was displayed around the correct item, that reward would be coded as 1 for that trial. Similarly, if the participant chose the wrong item, but the yellow box then also appeared around the wrong item, the reward would also be coded as 1.\n",
    "\n",
    "If, however, the participant chose a different item from the one the yellow box then displays around (e.g. the participant chose the correct item but the box displays around the wrong item, or vice versa), the reward is coded as 0 for that trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if pd.isnull(data.loc[x,'practice_loop_thisRepN']): # If the row is not part of the inference practice block\n",
    "        if data.loc[x,'response_correct']==data.loc[x,'feedback_correct']:\n",
    "            data.at[x,'reward'] = 1\n",
    "        elif data.loc[x,'response_correct']!=data.loc[x,'feedback_correct']:\n",
    "            data.at[x,'reward'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the number of correct feedback boxes (where the yellow box appeared around the correct item) seen so far for that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # If in the main inference task (not the practice block)\n",
    "        part = data.loc[x,'participant']\n",
    "        itm = data.loc[x,'img_correct']\n",
    "        pair = data.loc[x,'pair_rep']\n",
    "        data_part = data[data['participant']==part]\n",
    "        data_part_itm = data_part[data_part['img_correct']==itm]\n",
    "        feedbck_corr_sum = data_part_itm[data_part_itm['pair_rep']<pair].feedback_correct.sum() # Sum of the correct feedback (yellow boxes around the correct answer) of trials in that item for that participant with lower pair_rep number than the current row\n",
    "        data.loc[x,'feedback_correct_sum'] = feedbck_corr_sum \n",
    "        data.loc[x,'feedback_wrong_sum'] = (pair - 1) - feedbck_corr_sum # Subtract to get the number of wrong feedback up until that point (yellow boxes around the wrong answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable for the difference between the number of correct and wrong feedback boxes displayed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['feedback_correct_sum_diff'] = data['feedback_correct_sum'] - data['feedback_wrong_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the trial number, and the number of trials (presentation of other item pairs) between the current and last presentation of that item pair (interference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the trial number, for all three blocks combined\n",
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'block_loop_thisN']==0:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'outcome_loop_thisN']\n",
    "    elif data.loc[x,'block_loop_thisN']==1:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'outcome_loop_thisN'] + 200\n",
    "    elif data.loc[x,'block_loop_thisN']==2:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'outcome_loop_thisN'] + 400\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'pair_rep'] > 1:\n",
    "        data.loc[x,'interference'] = data.loc[x,'learning_trial'] - data.loc[x-1,'learning_trial'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the z-scores, by participant, for their reaction times in the inference task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_means = data.groupby(['participant']).infer_resp_rt.mean()\n",
    "rt_sds = data.groupby(['participant']).infer_resp_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = rt_means[p]\n",
    "    p_sd = rt_sds[p]\n",
    "    rt = data.loc[x,'infer_resp_rt']\n",
    "    data.loc[x,'infer_resp_rt_zscore'] = (rt - p_mean)/p_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, move the participant's item bids into new variables aligned with the inference task. These will be signed to indicate congruency with the choice being inferred; the participant's bid for the incorrect item is subtracted from the bid for the correct item to create a correct_bid_dv variable. Strongly negative values for this variable, therefore, indicate a strong preference in the opposite direction as the choice being inferred. Strongly positive values indicate strong congruency with the choice being inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # ... if there is a value in 'img_correct' indicating that row is from the inference task, and it is not in the practice block\n",
    "        bid_inf_all = data[data.loc[x,'img_correct']==data.bdm_img] # find all BDM rows in the dataset that match that correct item\n",
    "        bid_inf_participant = bid_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of bids from the same participant\n",
    "        bid_inf_participant_notnull = bid_inf_participant[bid_inf_participant['bdm_bid1_response'].notnull()] # from those data, pick the BDM task\n",
    "        bid_inf_participant_notnull_index = bid_inf_participant_notnull['bdm_bid1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'correct_bid'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'bdm_bid1_response'] # define 'correct_bid' on the inference row as the bid for that item\n",
    "        data.loc[x,'correct_bid_zscore'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'bdm_bid_response_zscore'] # and add a variable for that participant's zscore of the bid for the correct item\n",
    "        \n",
    "# Do the same for the incorrect items in each inference trial\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_wrong']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']):\n",
    "        bid_infwr_all = data[data.loc[x,'img_wrong']==data.bdm_img] \n",
    "        bid_infwr_participant = bid_infwr_all[data['participant']==data.loc[x,'participant']] \n",
    "        bid_infwr_participant_notnull = bid_infwr_participant[bid_infwr_participant['bdm_bid1_response'].notnull()] \n",
    "        bid_infwr_participant_notnull_index = bid_infwr_participant_notnull['bdm_bid1_response'].idxmax() \n",
    "        data.loc[x,'wrong_bid'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'bdm_bid1_response']\n",
    "        data.loc[x,'wrong_bid_zscore'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'bdm_bid_response_zscore']\n",
    "        \n",
    "# Define congruency variables for each BDM task:\n",
    "data['inf_bid_dv']=data['correct_bid'] - data['wrong_bid'] # Difference in absolute bid amounts from the bid task\n",
    "data['inf_bid_dv_zscore']=data['correct_bid_zscore'] - data['wrong_bid_zscore'] # Difference in bid amount z-scores from the bid task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was the correct answer in the learning task pair chosen by the participant in the choice task? Create variables that indicate the number of times it was chosen (each pair was presented in the choice task twice; 0=never chosen; 1=chosen once but not chosen the second time; 2=chosen twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_data = pd.DataFrame(data.groupby('participant').chosen.value_counts()) # The number of times each item was chosen in the choice task, grouped by participant\n",
    "chosen_data.columns = ['number'] # Give the column with this number a name\n",
    "chosen_data.index.names = ['participant','item'] # Name the hierarchical index of this dataframe\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # If the row is part of the inference task, and not part of the practice block...\n",
    "        part = data.loc[x,'participant'] # The participant\n",
    "        itm = data.loc[x,'img_correct'] # The chosen item (correct answer) they're trying to learn\n",
    "        if not chosen_data.xs((part,itm), level=('participant','item')).values: # If the correct answer was not chosen by the participant at least once during the first choice task\n",
    "            data.loc[x,'choice_correct_congruence'] = 0 # ...the choice congruence score is 0\n",
    "        else: # Otherwise, it's the number of times that item was chosen in the choice task (either 1 or 2)\n",
    "            data.loc[x,'choice_correct_congruence'] = chosen_data.number.xs((part,itm), level=('participant','item')).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the choice confidence ratings, their within-participant (grouped by first and second choice task) z-scores, and response times and their z-scores, into the inference task rows. Since each participant indicated their choice in each item pair twice (flipping side of the screen once), there are 4 variables stored (each of these confidence ratings and their z-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # ... if there is a value in 'img_correct' indicating that row is from the inference task, and it is not in the practice block\n",
    "    # CONFIDENCE \n",
    "    # Get the confidence ratings from the choice task, from the trials where the correct item appears on the LEFT   \n",
    "        conf_left_inf_all = data[data.loc[x,'img_correct']==data.choice_left] # find all choice rows in the dataset that match that correct item, where the correct item was shown on the LEFT\n",
    "        conf_left_inf_participant = conf_left_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of confidence ratings from the same participant\n",
    "        conf_left_inf_participant_notnull = conf_left_inf_participant[conf_left_inf_participant['confidence_rating1_response'].notnull()] # from those data, pick the choice task\n",
    "        conf_left_inf_participant_notnull_index = conf_left_inf_participant_notnull['confidence_rating1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'conf_correct_on_left'] = conf_left_inf_participant_notnull.loc[conf_left_inf_participant_notnull_index,'confidence_rating1_response'] # define 'conf_correct_on_left' on the inference row as the confidence rating for that item where the correct item was displayed on the LEFT\n",
    "        data.loc[x,'conf_correct_on_left_zscore'] = conf_left_inf_participant_notnull.loc[conf_left_inf_participant_notnull_index,'confidence_rating_response_zscore'] # and add a variable for that participant's zscore of the confidence rating for the correct item from the choice task\n",
    "    # Get the confidence ratings from the choice task, where the correct item appears on the RIGHT\n",
    "        conf_right_inf_all = data[data.loc[x,'img_correct']==data.choice_right] # find all choice rows in the dataset that match that correct item, where the correct item was shown on the RIGHT\n",
    "        conf_right_inf_participant = conf_right_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of confidence ratings from the same participant\n",
    "        conf_right_inf_participant_notnull = conf_right_inf_participant[conf_right_inf_participant['confidence_rating1_response'].notnull()] # from those data, pick the choice task\n",
    "        conf_right_inf_participant_notnull_index = conf_right_inf_participant_notnull['confidence_rating1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'conf_correct_on_right'] = conf_right_inf_participant_notnull.loc[conf_right_inf_participant_notnull_index,'confidence_rating1_response'] # define 'conf1_correct_on_right' on the inference row as the confidence rating for that item where the correct item was displayed on the RIGHT\n",
    "        data.loc[x,'conf_correct_on_right_zscore'] = conf_right_inf_participant_notnull.loc[conf_right_inf_participant_notnull_index,'confidence_rating_response_zscore'] # and add a variable for that participant's zscore of the confidence rating for the correct item from the choice task\n",
    "   \n",
    "\n",
    "    # CHOICE RESPONSE TIMES\n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the LEFT   \n",
    "        chc_left_inf_all = data[data.loc[x,'img_correct']==data.choice_left] \n",
    "        chc_left_inf_participant = chc_left_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_left_inf_participant_notnull = chc_left_inf_participant[chc_left_inf_participant['key_resp_choice1_rt'].notnull()] \n",
    "        chc_left_inf_participant_notnull_index = chc_left_inf_participant_notnull['key_resp_choice1_rt'].idxmax()\n",
    "        data.loc[x,'chc_correct_on_left_rt'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice1_rt'] \n",
    "        data.loc[x,'chc_correct_on_left_rt_zscore'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice_rt_zscore'] \n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the RIGHT   \n",
    "        chc_right_inf_all = data[data.loc[x,'img_correct']==data.choice_right] \n",
    "        chc_right_inf_participant = chc_right_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_right_inf_participant_notnull = chc_right_inf_participant[chc_right_inf_participant['key_resp_choice1_rt'].notnull()] \n",
    "        chc_right_inf_participant_notnull_index = chc_right_inf_participant_notnull['key_resp_choice1_rt'].idxmax()\n",
    "        data.loc[x,'chc_correct_on_right_rt'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice1_rt'] \n",
    "        data.loc[x,'chc_correct_on_right_rt_zscore'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice_rt_zscore'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean confidence response time z-scores of the two presentations in the choice task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['conf_mean_zscore'] = (data['conf_correct_on_left_zscore'] + data['conf_correct_on_right_zscore'])/2\n",
    "data['chc_rt_mean_zscore'] = (data['chc_correct_on_left_rt_zscore'] + data['chc_correct_on_right_rt_zscore'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two more dummy variables indicating whether the participant chose the left choice on the first presentation of that pair, and the right choice on the second presentation of that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[((data['left_chosen']==1) & (data['choice_presentation']==1)),'left_chosen_firstpres'] = 1\n",
    "data.loc[((data['left_chosen']==0) & (data['choice_presentation']==1)),'left_chosen_firstpres'] = 0\n",
    "data.loc[((data['left_chosen']==1) & (data['choice_presentation']==2)),'right_chosen_secondpres'] = 0\n",
    "data.loc[((data['left_chosen']==0) & (data['choice_presentation']==2)),'right_chosen_secondpres'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dummy variable to indicate whether the correct image in the learning task was displayed on the left side of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[(data['img_correct']==data['img_left']), 'correct_on_left'] = 1\n",
    "data.loc[(data['img_correct']==data['img_right']), 'correct_on_left'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a dummy variable to indicate whether the participant responded \"left\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['infer_resp_keys']=='left', 'infer_response_left'] = 1\n",
    "data.loc[data['infer_resp_keys']=='right', 'infer_response_left'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe as CSV and PKL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv(path_or_buf=r'../data/social_pilot/data_processed_social_pilot.csv')\n",
    "data.to_pickle(r'../data/social_pilot/data_processed_social_pilot.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exclusion criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same exclusion criteria that we kept for the eye tracking group:\n",
    "\n",
    "Participants’ data will be excluded if:\n",
    "\n",
    "1)\tThey indicate at any point before, during, or after testing that they do not meet the following eligibility criteria:\n",
    "a.\tAre at least 18 years old,\n",
    "b.\tAre proficient in English, and\n",
    "c.\tDo not suffer from any psychiatric or neurological disorder.\n",
    "\n",
    "2)\tThey end their participation before the conclusion of the study, including by asking to leave before the post-experiment wait period has ended, or by consuming food or non-water drink that was not purchased during the auction.\n",
    "\n",
    "3)\tThey indicate that they did not comply with the requirement to drink only water and refrain from eating for 3 hours before attending the session.\n",
    "\n",
    "4)\tTheir responses in the choice task are inconsistent to the extent that a response on the first presentation of an item pair does not significantly and positively predict their response during the second presentation of that item pair. This will be tested using a logistic regression analysis predicting the response during the second presentation of the item pairs, using the response during the first presentation of that pair as the independent variable. The regression coefficient weighting this variable must be greater than zero with a probability of more than 95%.\n",
    "\n",
    "5 & 6) Not used for eye tracking group\n",
    "\n",
    "7)\tIf their bids do not predict their choices. Specifically, participants will be excluded if the inverse temperature parameter for a participant is five or more times larger than the mean for the entire group. (See De Martino, Fleming, Garrett, and Dolan, 2012, Nature Neuroscience.)\n",
    "\n",
    "8)\tIf their mean performance on the learning task is not significantly above chance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criteria 1-3: Failure to abide by study requirements\n",
    "No participants met any of these criteria. (See participant log at 'recruitment/participant_log.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 4: Choice consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_choice_consistency(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['chosen'].notnull()]\n",
    "    data_subset['intercept'] = 1.0\n",
    "    logit = sm.Logit(data_subset['right_chosen_secondpres'], data_subset[['left_chosen_firstpres','intercept']])\n",
    "    result = logit.fit()\n",
    "    print subj, result.summary()\n",
    "\n",
    "def check_choice_consistency_linear(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['chosen'].notnull()]\n",
    "    data_subset['intercept'] = 1.0\n",
    "    x = np.array(data_subset['left_chosen_firstpres'])\n",
    "    y = np.array(data_subset['right_chosen_secondpres'])\n",
    "    slope, intercept, r_value, p_value, slope_std_error = ss.linregress(x, y)\n",
    "    return subj, slope, p_value\n",
    "\n",
    "for x in data['participant'].unique():\n",
    "    if check_choice_consistency_linear(x)[1]<0 or check_choice_consistency_linear(x)[2]>0.05:\n",
    "        print 'Exclude ',x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all participants, the first choice significantly predicts the second choice with greater than 95% probability. Because many participants showed perfect consistency, logistic regressions were impossible to estimate, so linear regressions were substituted. \n",
    "\n",
    "No participants would be excluded under this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent choices for participant  P1 1\n",
      "Number of inconsistent choices for participant  P10 1\n",
      "Number of inconsistent choices for participant  P11 1\n",
      "Number of inconsistent choices for participant  P12 0\n",
      "Number of inconsistent choices for participant  P2 0\n",
      "Number of inconsistent choices for participant  P3 1\n",
      "Number of inconsistent choices for participant  P4 2\n",
      "Number of inconsistent choices for participant  P5 0\n",
      "Number of inconsistent choices for participant  P6 2\n",
      "Number of inconsistent choices for participant  P7 20\n",
      "Number of inconsistent choices for participant  P8 0\n",
      "Number of inconsistent choices for participant  P9 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in data['participant'].unique():\n",
    "    print 'Number of inconsistent choices for participant ', x, len(data.loc[data['participant']==x, 'chosen'].unique())-21\n",
    "#data.groupby(['participant']).chosen.value_counts()\n",
    "len(data['chosen'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude participant P7 for having made perfectly inconsistent choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[data['participant']!='P7']\n",
    "data.reset_index(drop=True)\n",
    "data.to_csv(path_or_buf=r'../data/social_pilot/data_processed_social_pilot_wexclusions.csv')\n",
    "data.to_pickle(r'../data/social_pilot/data_processed_social_pilot_wexclusions.pkl')"
   ]
  }
 ],
 "metadata": {
  "gist_id": "56d54360661ad30ee0a0",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
