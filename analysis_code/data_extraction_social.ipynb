{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T. Tarantola, D. Kumaran, P. Dayan, & B. De Martino. (in press) Prior preferences beneficially influence social and non-social learning. <it>Nature Communications</it>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Extraction & Exclusion Tests: Social Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as ss\n",
    "from scipy.optimize import curve_fit\n",
    "import pylab as pl\n",
    "import math\n",
    "import seaborn as sns\n",
    "import rpy2\n",
    "import pystan\n",
    "from pystan.external.pymc import plots\n",
    "import pickle\n",
    "\n",
    "% matplotlib inline\n",
    "pd.options.display.max_rows = 999 # Set the maximum display to 999 rows so the entire dataframe is visible in the notebook\n",
    "pd.options.display.max_columns = 999 # Same for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data extraction (behavioral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "First, we import and concatenate the CSV files that PsychoPy generates for each experimental session. We put this in our data frame, called \"data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'../data/social/raw_data' # This is the folder that all data CSV files are saved in\n",
    "allFiles = glob.glob(path + '/*.csv')\n",
    "data = pd.DataFrame()\n",
    "list = []\n",
    "for files in allFiles: # Read all CSV files in the \"path\" folder\n",
    "    df = pd.read_csv(files, index_col=None, header=0)\n",
    "    list.append(df)\n",
    "data = pd.concat(list) # Concatenate all CSV files into one big data frame called \"data\"\n",
    "\n",
    "# Replace dots in variable names with underscores, to make it easier for pandas to handle\n",
    "data.rename(columns=lambda x: x.replace('.', '_'), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import the item familiarity/consumption data, which was entered by hand based on participants' pen-and-paper survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fam = pd.read_csv('../data/social/familiarity/familiarity_data_social.csv', index_col=0, header=None) # Import the CSV file\n",
    "fam.index.name = 'participant' # Name the index of the data frame 'participant'\n",
    "item_idx = fam.iloc[0] # Extract the name of each item to use as a column index later\n",
    "rating_idx = fam.iloc[1] # Do the same for 'familiarity' and 'consumed' rating labels\n",
    "fam.columns = [pd.Index(item_idx, name='item'),pd.Index(rating_idx, name='rating')] # Specify a hierarchical column index\n",
    "fam = fam.iloc[2:] # Remove empty cells\n",
    "fam = fam.stack('item') # Stack the data frame by item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and create new variable columns in the data frame\n",
    "We sort the data first by participant, then participant's experimental session (there might be more than one if the task crashed, etc), the image pair, the rest block it was presented during, and lastly the order of presentation within that block.\n",
    "\n",
    "We then index the data frame by this new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = data.sort(['participant','session','img_correct','block_loop_thisN','trial_loop_thisN']) # Sort the data\n",
    "data.index = range(1,len(data)+1) # Re-do the index so it conforms to the sorted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bid and choice tasks\n",
    "First, create two variables to explicitly indicate the participant's chosen and unchosen items in the binary choice task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'key_resp_choice_keys']=='left':\n",
    "        data.loc[x,'chosen']=data.loc[x,'choice_left']\n",
    "        data.loc[x,'unchosen']=data.loc[x,'choice_right']\n",
    "    elif data.loc[x,'key_resp_choice_keys']=='right':\n",
    "        data.loc[x,'chosen']=data.loc[x,'choice_right']\n",
    "        data.loc[x,'unchosen']=data.loc[x,'choice_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the z-scores for each bid, by participant, using the first and second bid task as separate populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bid_means = data.groupby(['participant']).bdm_bid1_response.mean() # Calculate each participant's mean bid\n",
    "bid_sds = data.groupby(['participant']).bdm_bid1_response.std(ddof=0) # Calculate each participant's standard deviation of their bids\n",
    "\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    p = data.loc[x,'participant'] # Variable for the participant\n",
    "    p_mean = bid_means[p] # Variable for that participant's mean bid\n",
    "    p_sd = bid_sds[p] # That participant's bid SD\n",
    "    bid = data.loc[x,'bdm_bid1_response'] # If that row is from the bid task, variable for that bid\n",
    "    data.loc[x,'bdm_bid_response_zscore'] = (bid - p_mean)/p_sd # Add a new variable to the dataframe with that bid's z-score at the participant level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the item familiarity and consumption quesitonnaire data, including their within-participant z-scores, into the BDM task rows. \n",
    "\n",
    "The value labels are:\n",
    "\n",
    "Familiarity: \"How familiar are you with this item?\"\n",
    "\n",
    "    1 = Not at all\n",
    "    2 = Somewhat\n",
    "    3 = Very\n",
    "\n",
    "Consumption: \"How often have you consumed this item?\"\n",
    "\n",
    "    1 = Never\n",
    "    2 = Sometimes\n",
    "    3 = Frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if not pd.isnull(data.loc[x,'bdm_img']): # If the row is part of either BDM task\n",
    "        p = data.loc[x,'participant']\n",
    "        itm = data.loc[x,'bdm_img']\n",
    "        data.loc[x,'familiarity'] = fam.ix[p,itm]['familiarity'] # Merge familiarity rating from familiarity data frame into main data frame for that participant and BDM item\n",
    "        data.loc[x,'consumed'] = fam.ix[p,itm]['consumed'] # Do the same for consumption ratings\n",
    "# Convert new variables into floats\n",
    "data['familiarity'] = data['familiarity'].astype(float)\n",
    "data['consumed'] = data['consumed'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate familiarity and consumed z-scores within participant\n",
    "fam_means = data.groupby(['participant']).familiarity.mean()\n",
    "fam_sds = data.groupby(['participant']).familiarity.std(ddof=0)\n",
    "cons_means = data.groupby(['participant']).consumed.mean()\n",
    "cons_sds = data.groupby(['participant']).consumed.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean_fam = fam_means[p]\n",
    "    p_mean_cons = cons_means[p]\n",
    "    p_sd_fam = fam_sds[p]\n",
    "    p_sd_cons = cons_sds[p]\n",
    "    fam = data.loc[x,'familiarity']\n",
    "    cons = data.loc[x,'consumed']\n",
    "    data.loc[x,'familiarity_zscore'] = (fam - p_mean_fam)/p_sd_fam\n",
    "    data.loc[x,'consumed_zscore'] = (cons - p_mean_cons)/p_sd_cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then move the BDM bid and familiarity/consumption data, including their respective z-scores, into the binary choice rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'chosen']): # ... if there is a value in 'chosen' indicating that row is from the choice task\n",
    "        bidmatch_all = data[data.loc[x,'chosen']==data.bdm_img] # find all BDM rows in the dataset that match that chosen item\n",
    "        bidmatch_participant = bidmatch_all[data['participant']==data.loc[x,'participant']] # find the subset of bids from the same participant\n",
    "        bidmatch_participant_notnull = bidmatch_participant[bidmatch_participant['bdm_bid1_response'].notnull()] # from those data, pick the BDM task\n",
    "        bidmatch_participant_notnull_index = bidmatch_participant_notnull['bdm_bid1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'chosen_bid'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid1_response'] # define 'chosen_bid' on the choice row as the bid for that item\n",
    "        data.loc[x,'chosen_bid_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid_response_zscore'] # define 'chosen_bid_zscore' on the choice row as the participant's z-score for the bid for that item from the same (first/last) part of the experiment\n",
    "        data.loc[x,'chosen_familiarity'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'familiarity']\n",
    "        data.loc[x,'chosen_familiarity_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'familiarity_zscore']\n",
    "        data.loc[x,'chosen_consumed'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'consumed']\n",
    "        data.loc[x,'chosen_consumed_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'consumed_zscore']\n",
    "\n",
    "# Do the same for the unchosen items in each choice\n",
    "for x in range(1,len(data)+1):\n",
    "    if not pd.isnull(data.loc[x,'unchosen']):\n",
    "        bidmatch_all = data[data.loc[x,'unchosen']==data.bdm_img]\n",
    "        bidmatch_participant = bidmatch_all[data['participant']==data.loc[x,'participant']]\n",
    "        bidmatch_participant_notnull = bidmatch_participant[bidmatch_participant['bdm_bid1_response'].notnull()]\n",
    "        bidmatch_participant_notnull_index = bidmatch_participant_notnull['bdm_bid1_response'].idxmax()\n",
    "        data.loc[x,'unchosen_bid'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid1_response']\n",
    "        data.loc[x,'unchosen_bid_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'bdm_bid_response_zscore']\n",
    "        data.loc[x,'unchosen_familiarity'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'familiarity']\n",
    "        data.loc[x,'unchosen_familiarity_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'familiarity_zscore']\n",
    "        data.loc[x,'unchosen_consumed'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'consumed']\n",
    "        data.loc[x,'unchosen_consumed_zscore'] = bidmatch_participant_notnull.loc[bidmatch_participant_notnull_index,'consumed_zscore']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a variable ('choice_dv') for the difference in bids between the chosen and unchosen items in each pair, and a variable ('choice_dv_zscore') for the difference between the bids' z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['choice_dv'] = data['chosen_bid'] - data['unchosen_bid'] # Difference between the bid amounts\n",
    "data['choice_dv_zscore'] = data['chosen_bid_zscore'] - data['unchosen_bid_zscore'] # Difference between the z-scores of the items' bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate similar variables, but for the difference between the left and right choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[data['chosen']==data['choice_left'],'choice_dv_left_minus_right'] = data[data['chosen']==data['choice_left']]['choice_dv']\n",
    "data.loc[data['chosen']==data['choice_right'],'choice_dv_left_minus_right'] = -data[data['chosen']==data['choice_right']]['choice_dv']\n",
    "\n",
    "data.loc[data['chosen']==data['choice_left'],'choice_dv_zscore_left_minus_right'] = data[data['chosen']==data['choice_left']]['choice_dv_zscore']\n",
    "data.loc[data['chosen']==data['choice_right'],'choice_dv_zscore_left_minus_right'] = -data[data['chosen']==data['choice_right']]['choice_dv_zscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dummy variable indicating whether the participant chose the item on the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['chosen']==data['choice_left'],'left_chosen'] = 1\n",
    "data.loc[data['chosen']==data['choice_right'],'left_chosen'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the z-scores for the choice confidence ratings, by participant, by task (first or second choice task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf_means = data.groupby(['participant']).confidence_rating1_response.mean() # Calculate each participant's mean confidence rating (from 1 to 6) during the choice task\n",
    "conf_sds = data.groupby(['participant']).confidence_rating1_response.std(ddof=0) # Calculate each participant's standard deviation of their confidence rating in the choice task\n",
    "\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    p = data.loc[x,'participant'] # Variable for the participant\n",
    "    p_mean = conf_means[p] # Variable for that participant's mean confidence in the choice task\n",
    "    p_sd = conf_sds[p] # That participant's confidence SD for the choice task\n",
    "    conf = data.loc[x,'confidence_rating1_response'] # If that row is from the choice task, variable for that confidence rating\n",
    "    data.loc[x,'confidence_rating_response_zscore'] = (conf - p_mean)/p_sd # Add a new variable to the dataframe with that confidence rating's z-score at the participant level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable for the z-scores, by participant and by choice task, for the response times in each choice task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choice_rt_means = data.groupby(['participant']).key_resp_choice_rt.mean()\n",
    "choice_rt_sds = data.groupby(['participant']).key_resp_choice_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = choice_rt_means[p]\n",
    "    p_sd = choice_rt_sds[p]\n",
    "    rt = data.loc[x,'key_resp_choice_rt']\n",
    "    data.loc[x,'key_resp_choice_rt_zscore'] = (rt - p_mean)/p_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Learning task\n",
    "Now we create a variable \"pair_rep\" to indicate how many times each image pair has been presented so far in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_infer = data[data['img_correct'].notnull()] # Subset of \"data\" where 'img_correct' has a value\n",
    "data_infer = data_infer[data_infer['practice_loop_thisRepN']!=0] # Subset of \"data_infer\" that does NOT include practice trials\n",
    "data_infer['pair_rep'] = range(1,31) * (len(data_infer)/30) # Note: Change range and denominator if number of item presentations differs from 30\n",
    "data['pair_rep'] = data_infer['pair_rep'] # Populate main data frame with this new variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate a variable \"response_correct\" to indicate whether the subject responded correctly on each given trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create series variables from the sorted dataframe for easy handling in the loop below\n",
    "arr_img_correct = data['img_correct']\n",
    "arr_img_left = data['img_left']\n",
    "arr_img_right = data['img_right']\n",
    "arr_infer_resp = data['infer_resp_keys']\n",
    "\n",
    "# Generate a variable indicating whether the response was correct on each given trial\n",
    "for x in range(1,len(data)+1): \n",
    "    if arr_img_correct[x]==arr_img_left[x] and arr_infer_resp[x]=='left':\n",
    "        data.at[x,'response_correct'] = 1\n",
    "    elif arr_img_correct[x]==arr_img_left[x] and arr_infer_resp[x]=='right':\n",
    "        data.at[x,'response_correct'] = 0\n",
    "    elif arr_img_correct[x]==arr_img_right[x] and arr_infer_resp[x]=='right':\n",
    "        data.at[x,'response_correct'] = 1\n",
    "    elif arr_img_correct[x]==arr_img_right[x] and arr_infer_resp[x]=='left':\n",
    "        data.at[x,'response_correct'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a variable \"feedback_correct\" to indicate whether the box appeared around the correct (=1) or incorrect (=0) item after the response was collected on that trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if pd.isnull(data.loc[x,'practice_loop_thisRepN']): # If the row is NOT part of the learning practice block\n",
    "        if data.loc[x,'set_feedback_feedback_img']==data.loc[x,'img_correct']:\n",
    "            data.at[x,'feedback_correct'] = 1\n",
    "        elif data.loc[x,'set_feedback_feedback_img']==data.loc[x,'img_wrong']:\n",
    "            data.at[x,'feedback_correct'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a variable \"reward\" to indicate whether the outcome yellow box on a particular trial matched the participant's response on that trial. So for example, if the participant chose the correct item, and then the yellow box was displayed around the correct item, that reward would be coded as 1 for that trial. Similarly, if the participant chose the wrong item, but the yellow box then also appeared around the wrong item, the reward would also be coded as 1.\n",
    "\n",
    "If, however, the participant chose a different item from the one the yellow box then displays around (e.g. the participant chose the correct item but the box displays around the wrong item, or vice versa), the reward is coded as 0 for that trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if pd.isnull(data.loc[x,'practice_loop_thisRepN']): # If the row is not part of the inference practice block\n",
    "        if data.loc[x,'response_correct']==data.loc[x,'feedback_correct']:\n",
    "            data.at[x,'reward'] = 1\n",
    "        elif data.loc[x,'response_correct']!=data.loc[x,'feedback_correct']:\n",
    "            data.at[x,'reward'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the number of correct feedback boxes (where the yellow box appeared around the correct item) seen so far for that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1):\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # If in the main inference task (not the practice block)\n",
    "        part = data.loc[x,'participant']\n",
    "        itm = data.loc[x,'img_correct']\n",
    "        pair = data.loc[x,'pair_rep']\n",
    "        data_part = data[data['participant']==part]\n",
    "        data_part_itm = data_part[data_part['img_correct']==itm]\n",
    "        feedbck_corr_sum = data_part_itm[data_part_itm['pair_rep']<pair].feedback_correct.sum() # Sum of the correct feedback (yellow boxes around the correct answer) of trials in that item for that participant with lower pair_rep number than the current row\n",
    "        data.loc[x,'feedback_correct_sum'] = feedbck_corr_sum \n",
    "        data.loc[x,'feedback_wrong_sum'] = (pair - 1) - feedbck_corr_sum # Subtract to get the number of wrong feedback up until that point (yellow boxes around the wrong answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable for the difference between the number of correct and wrong feedback boxes displayed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['feedback_correct_sum_diff'] = data['feedback_correct_sum'] - data['feedback_wrong_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the trial number, and the number of trials (presentation of other item pairs) between the current and last presentation of that item pair (interference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the trial number, for all three blocks combined\n",
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'block_loop_thisN']==0:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'trial_loop_thisN']\n",
    "    elif data.loc[x,'block_loop_thisN']==1:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'trial_loop_thisN'] + 200\n",
    "    elif data.loc[x,'block_loop_thisN']==2:\n",
    "        data.loc[x,'learning_trial'] = data.loc[x,'trial_loop_thisN'] + 400\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    if data.loc[x,'pair_rep'] > 1:\n",
    "        data.loc[x,'interference'] = data.loc[x,'learning_trial'] - data.loc[x-1,'learning_trial'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the z-scores, by participant, for their reaction times in the inference task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_means = data.groupby(['participant']).infer_resp_rt.mean()\n",
    "rt_sds = data.groupby(['participant']).infer_resp_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = rt_means[p]\n",
    "    p_sd = rt_sds[p]\n",
    "    rt = data.loc[x,'infer_resp_rt']\n",
    "    data.loc[x,'infer_resp_rt_zscore'] = (rt - p_mean)/p_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, move the participant's item bids into new variables aligned with the inference task. These will be signed to indicate congruency with the choice being inferred; the participant's bid for the incorrect item is subtracted from the bid for the correct item to create a correct_bid_dv variable. Strongly negative values for this variable, therefore, indicate a strong preference in the opposite direction as the choice being inferred. Strongly positive values indicate strong congruency with the choice being inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # ... if there is a value in 'img_correct' indicating that row is from the inference task, and it is not in the practice block\n",
    "        bid_inf_all = data[data.loc[x,'img_correct']==data.bdm_img] # find all BDM rows in the dataset that match that correct item\n",
    "        bid_inf_participant = bid_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of bids from the same participant\n",
    "        bid_inf_participant_notnull = bid_inf_participant[bid_inf_participant['bdm_bid1_response'].notnull()] # from those data, pick the BDM task\n",
    "        bid_inf_participant_notnull_index = bid_inf_participant_notnull['bdm_bid1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'correct_bid'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'bdm_bid1_response'] # define 'correct_bid' on the inference row as the bid for that item\n",
    "        data.loc[x,'correct_bid_zscore'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'bdm_bid_response_zscore'] # and add a variable for that participant's zscore of the bid for the correct item\n",
    "        data.loc[x,'correct_familiarity'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'familiarity'] # and add a variable for that participant's familiarity with that item\n",
    "        data.loc[x,'correct_familiarity_zscore'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'familiarity_zscore'] # and add a variable for that participant's familiarity z-score\n",
    "        data.loc[x,'correct_consumed'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'consumed'] # and add a variable for that participant's past consumption of that item\n",
    "        data.loc[x,'correct_consumed_zscore'] = bid_inf_participant_notnull.loc[bid_inf_participant_notnull_index,'consumed_zscore'] # and add a variable for that participant's item consumption zscore\n",
    "\n",
    "# Do the same for the incorrect items in each inference trial\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_wrong']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']):\n",
    "        bid_infwr_all = data[data.loc[x,'img_wrong']==data.bdm_img] \n",
    "        bid_infwr_participant = bid_infwr_all[data['participant']==data.loc[x,'participant']] \n",
    "        bid_infwr_participant_notnull = bid_infwr_participant[bid_infwr_participant['bdm_bid1_response'].notnull()] \n",
    "        bid_infwr_participant_notnull_index = bid_infwr_participant_notnull['bdm_bid1_response'].idxmax() \n",
    "        data.loc[x,'wrong_bid'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'bdm_bid1_response']\n",
    "        data.loc[x,'wrong_bid_zscore'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'bdm_bid_response_zscore']\n",
    "        data.loc[x,'wrong_familiarity'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'familiarity'] # and add a variable for that participant's familiarity with that item\n",
    "        data.loc[x,'wrong_familiarity_zscore'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'familiarity_zscore'] # and add a variable for that participant's familiarity z-score\n",
    "        data.loc[x,'wrong_consumed'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'consumed'] # and add a variable for that participant's past consumption of that item\n",
    "        data.loc[x,'wrong_consumed_zscore'] = bid_infwr_participant_notnull.loc[bid_infwr_participant_notnull_index,'consumed_zscore'] # and add a variable for that participant's item consumption zscore\n",
    "\n",
    "# Define congruency variables for each BDM task:\n",
    "data['inf_bid_dv']=data['correct_bid'] - data['wrong_bid'] # Difference in absolute bid amounts from the bid task\n",
    "data['inf_bid_dv_zscore']=data['correct_bid_zscore'] - data['wrong_bid_zscore'] # Difference in bid amount z-scores from the bid task\n",
    "\n",
    "# Define familiarity and consumption rating z-score differences for each item\n",
    "data['familiarity_dv_zscore']=data['correct_familiarity_zscore'] - data['wrong_familiarity_zscore']\n",
    "data['consumed_dv_zscore']=data['correct_consumed_zscore'] - data['wrong_consumed_zscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was the correct answer in the learning task pair chosen by the participant in the choice task? Create variables that indicate the number of times it was chosen (each pair was presented in the choice task twice; 0=never chosen; 1=chosen once but not chosen the second time; 2=chosen twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_data = pd.DataFrame(data.groupby('participant').chosen.value_counts()) # The number of times each item was chosen in the choice task, grouped by participant\n",
    "chosen_data.columns = ['number'] # Give the column with this number a name\n",
    "chosen_data.index.names = ['participant','item'] # Name the hierarchical index of this dataframe\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # If the row is part of the inference task, and not part of the practice block...\n",
    "        part = data.loc[x,'participant'] # The participant\n",
    "        itm = data.loc[x,'img_correct'] # The chosen item (correct answer) they're trying to learn\n",
    "        if not chosen_data.xs((part,itm), level=('participant','item')).values: # If the correct answer was not chosen by the participant at least once during the first choice task\n",
    "            data.loc[x,'choice_correct_congruence'] = 0 # ...the choice congruence score is 0\n",
    "        else: # Otherwise, it's the number of times that item was chosen in the choice task (either 1 or 2)\n",
    "            data.loc[x,'choice_correct_congruence'] = chosen_data.number.xs((part,itm), level=('participant','item')).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the choice confidence ratings, their within-participant (grouped by first and second choice task) z-scores, and response times and their z-scores, into the inference task rows. Since each participant indicated their choice in each item pair twice (flipping side of the screen once), there are 4 variables stored (each of these confidence ratings and their z-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # ... if there is a value in 'img_correct' indicating that row is from the inference task, and it is not in the practice block\n",
    "    # CONFIDENCE \n",
    "    # Get the confidence ratings from the choice task, from the trials where the correct item appears on the LEFT   \n",
    "        conf_left_inf_all = data[data.loc[x,'img_correct']==data.choice_left] # find all choice rows in the dataset that match that correct item, where the correct item was shown on the LEFT\n",
    "        conf_left_inf_participant = conf_left_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of confidence ratings from the same participant\n",
    "        conf_left_inf_participant_notnull = conf_left_inf_participant[conf_left_inf_participant['confidence_rating1_response'].notnull()] # from those data, pick the choice task\n",
    "        conf_left_inf_participant_notnull_index = conf_left_inf_participant_notnull['confidence_rating1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'conf_correct_on_left'] = conf_left_inf_participant_notnull.loc[conf_left_inf_participant_notnull_index,'confidence_rating1_response'] # define 'conf_correct_on_left' on the inference row as the confidence rating for that item where the correct item was displayed on the LEFT\n",
    "        data.loc[x,'conf_correct_on_left_zscore'] = conf_left_inf_participant_notnull.loc[conf_left_inf_participant_notnull_index,'confidence_rating_response_zscore'] # and add a variable for that participant's zscore of the confidence rating for the correct item from the choice task\n",
    "    # Get the confidence ratings from the choice task, where the correct item appears on the RIGHT\n",
    "        conf_right_inf_all = data[data.loc[x,'img_correct']==data.choice_right] # find all choice rows in the dataset that match that correct item, where the correct item was shown on the RIGHT\n",
    "        conf_right_inf_participant = conf_right_inf_all[data['participant']==data.loc[x,'participant']] # find the subset of confidence ratings from the same participant\n",
    "        conf_right_inf_participant_notnull = conf_right_inf_participant[conf_right_inf_participant['confidence_rating1_response'].notnull()] # from those data, pick the choice task\n",
    "        conf_right_inf_participant_notnull_index = conf_right_inf_participant_notnull['confidence_rating1_response'].idxmax() # find the maximum to define as a single value index\n",
    "        data.loc[x,'conf_correct_on_right'] = conf_right_inf_participant_notnull.loc[conf_right_inf_participant_notnull_index,'confidence_rating1_response'] # define 'conf1_correct_on_right' on the inference row as the confidence rating for that item where the correct item was displayed on the RIGHT\n",
    "        data.loc[x,'conf_correct_on_right_zscore'] = conf_right_inf_participant_notnull.loc[conf_right_inf_participant_notnull_index,'confidence_rating_response_zscore'] # and add a variable for that participant's zscore of the confidence rating for the correct item from the choice task\n",
    "   \n",
    "\n",
    "    # CHOICE RESPONSE TIMES\n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the LEFT   \n",
    "        chc_left_inf_all = data[data.loc[x,'img_correct']==data.choice_left] \n",
    "        chc_left_inf_participant = chc_left_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_left_inf_participant_notnull = chc_left_inf_participant[chc_left_inf_participant['key_resp_choice_rt'].notnull()] \n",
    "        chc_left_inf_participant_notnull_index = chc_left_inf_participant_notnull['key_resp_choice_rt'].idxmax()\n",
    "        data.loc[x,'chc_correct_on_left_rt'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice_rt'] \n",
    "        data.loc[x,'chc_correct_on_left_rt_zscore'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice_rt_zscore'] \n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the RIGHT   \n",
    "        chc_right_inf_all = data[data.loc[x,'img_correct']==data.choice_right] \n",
    "        chc_right_inf_participant = chc_right_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_right_inf_participant_notnull = chc_right_inf_participant[chc_right_inf_participant['key_resp_choice_rt'].notnull()] \n",
    "        chc_right_inf_participant_notnull_index = chc_right_inf_participant_notnull['key_resp_choice_rt'].idxmax()\n",
    "        data.loc[x,'chc_correct_on_right_rt'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice_rt'] \n",
    "        data.loc[x,'chc_correct_on_right_rt_zscore'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice_rt_zscore'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean confidence and response time z-scores of the two presentations in the choice task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['conf_mean_zscore'] = (data['conf_correct_on_left_zscore'] + data['conf_correct_on_right_zscore'])/2\n",
    "data['chc_rt_mean_zscore'] = (data['chc_correct_on_left_rt_zscore'] + data['chc_correct_on_right_rt_zscore'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable \"choice_presentation\" to indicate, for the choice trials, whether it is the first (1) or second (2) presentation of that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['pairID'] = np.nan # Set up a temporary variable to identify each unique item pair in the choice task\n",
    "\n",
    "for x in data['participant'].unique(): # For each participant...\n",
    "    \n",
    "    right_choices=[] # Variable to keep track of choice stimuli displayed on the right side of the screen\n",
    "    pair_counter = 1 # Counter to keep track of how many time that item pair has been displayed so far in the choice task\n",
    "\n",
    "    for trial in data.loc[((data['choice_left'].notnull()) & (data['participant']==x)), 'binary_thisN']: # Within the choice task for that participant, for each trial...\n",
    "        if data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'choice_left'].any() in right_choices: # If the left choice has already been displayed on the right,\n",
    "            data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'pairID'] = data.loc[((data['choice_right']==data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'choice_left'].get_values()[0]) & (data['participant']==x)), 'pairID'].get_values()[0] # then assign it the same pairID\n",
    "            data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'choice_presentation'] = 2 # And set the 'choice_presentation' number to 2\n",
    "        else:\n",
    "            data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'pairID'] = pair_counter # Otherwise, assign the next available pairID\n",
    "            data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'choice_presentation'] = 1 # Set the choice presentation number to 1\n",
    "            pair_counter += 1 # Increase the pairID counter\n",
    "            right_choices.append(data.loc[((data['binary_thisN']==trial) & (data['participant']==x)), 'choice_right'].get_values()[0]) # And add the choice on the right to our list\n",
    "\n",
    "#data = data.drop('pairID',1) # When finished, drop the pair ID column from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two more dummy variables indicating whether the participant chose the left choice on the first presentation of that pair, and the right choice on the second presentation of that pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[((data['left_chosen']==1) & (data['choice_presentation']==1)),'left_chosen_firstpres'] = 1\n",
    "data.loc[((data['left_chosen']==0) & (data['choice_presentation']==1)),'left_chosen_firstpres'] = 0\n",
    "data.loc[((data['left_chosen']==1) & (data['choice_presentation']==2)),'right_chosen_secondpres'] = 0\n",
    "data.loc[((data['left_chosen']==0) & (data['choice_presentation']==2)),'right_chosen_secondpres'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in data['participant'].unique(): # For each participant...\n",
    "    for y in data.loc[((data['choice_left'].notnull()) & (data['participant']==x)), 'pairID']:\n",
    "        data.loc[((data['pairID']==y) & (data['participant']==x) & (data['choice_presentation']==2)), 'left_chosen_firstpres'] = data.loc[((data['pairID']==y) & (data['participant']==x) & (data['choice_presentation']==1)), 'left_chosen_firstpres'].get_values()[0]\n",
    "        data.loc[((data['pairID']==y) & (data['participant']==x) & (data['choice_presentation']==1)), 'right_chosen_secondpres'] = data.loc[((data['pairID']==y) & (data['participant']==x) & (data['choice_presentation']==2)), 'right_chosen_secondpres'].get_values()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dummy variable to indicate whether the correct image in the learning task was displayed on the left side of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[(data['img_correct']==data['img_left']), 'correct_on_left'] = 1\n",
    "data.loc[(data['img_correct']==data['img_right']), 'correct_on_left'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a dummy variable to indicate whether the participant responded \"left\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['infer_resp_keys']=='left', 'infer_response_left'] = 1\n",
    "data.loc[data['infer_resp_keys']=='right', 'infer_response_left'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe as CSV and PKL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(path_or_buf=r'../data/social/data_processed_social.csv')\n",
    "data.to_pickle(r'../data/social/data_processed_social.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##A priori participant exclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the following a priori exclusion criteria for participants (see 'analysis_code/exclusion_criteria.docx'):\n",
    "\n",
    "Participants’ data will be excluded if:\n",
    "\n",
    "1)\tThey indicate at any point before, during, or after testing that they do not meet the following eligibility criteria:\n",
    "a.\tAre at least 18 years old,\n",
    "b.\tAre proficient in English, and\n",
    "c.\tDo not suffer from any psychiatric or neurological disorder.\n",
    "\n",
    "2)\tThey end their participation before the conclusion of the study, including by asking to leave before the post-experiment wait period has ended, or by consuming food or non-water drink that was not purchased during the auction.\n",
    "\n",
    "3)\tThey indicate that they did not comply with the requirement to drink only water and refrain from eating for 3 hours before attending the session.\n",
    "\n",
    "4)\tTheir responses in the choice task are inconsistent to the extent that a response on the first presentation of an item pair does not significantly and positively predict their response during the second presentation of that item pair. This will be tested using a logistic regression analysis predicting the response during the second presentation of the item pairs, using the response during the first presentation of that pair as the independent variable. The regression coefficient weighting this variable must be greater than zero with a probability of more than 95%.\n",
    "\n",
    "5)\tThey use a very narrow range of the confidence scale. Specifically, if one standard deviation of a subject’s scale use represents less than 16% of the total range of the scale. (See De Martino, Fleming, Garrett, and Dolan, 2012, Nature Neuroscience.)\n",
    "\n",
    "6)\tIf their bids or confidence ratings can be significantly predicted by the randomly jittered starting point of the scale. This will be determined by two linear regression analyses predicting the confidence and bid responses separately, using the starting point as the independent variable.  A participant will be excluded if the coefficient weighting the starting point is significantly different from zero with a probability of more than 95% in either of these analyses. \n",
    "\n",
    "7)\tIf their bids do not predict their choices. Specifically, participants will be excluded if the inverse temperature parameter for a participant is five or more times larger than the mean for the entire group. (See De Martino, Fleming, Garrett, and Dolan, 2012, Nature Neuroscience.)\n",
    "\n",
    "8)\tIf their mean performance on the learning task is not significantly above chance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criteria 1-3: Failure to abide by study requirements\n",
    "No participants met any of these criteria. (See participant log at 'recruitment/participant_log.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 4: Choice consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_choice_consistency(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['chosen'].notnull()]\n",
    "    data_subset['intercept'] = 1.0\n",
    "    logit = sm.Logit(data_subset['right_chosen_secondpres'], data_subset[['left_chosen_firstpres','intercept']])\n",
    "    result = logit.fit()\n",
    "    print subj, result.summary()\n",
    "\n",
    "def check_choice_consistency_linear(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['chosen'].notnull()]\n",
    "    data_subset['intercept'] = 1.0\n",
    "    x = np.array(data_subset['left_chosen_firstpres'])\n",
    "    y = np.array(data_subset['right_chosen_secondpres'])\n",
    "    slope, intercept, r_value, p_value, slope_std_error = ss.linregress(x, y)\n",
    "    return subj, slope, p_value\n",
    "\n",
    "for x in data['participant'].unique():\n",
    "    if check_choice_consistency_linear(x)[1]<0 or check_choice_consistency_linear(x)[2]>0.05:\n",
    "        print 'Exclude ',x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all participants, the first choice significantly predicts the second choice with greater than 95% probability. Because many participants showed perfect consistency, logistic regressions were impossible to estimate, so linear regressions were substituted. \n",
    "\n",
    "No participants would be excluded under this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent choices for participant  E1 0\n",
      "Number of inconsistent choices for participant  E10 0\n",
      "Number of inconsistent choices for participant  E11 0\n",
      "Number of inconsistent choices for participant  E12 0\n",
      "Number of inconsistent choices for participant  E13 2\n",
      "Number of inconsistent choices for participant  E14 0\n",
      "Number of inconsistent choices for participant  E15 0\n",
      "Number of inconsistent choices for participant  E16 4\n",
      "Number of inconsistent choices for participant  E17 0\n",
      "Number of inconsistent choices for participant  E18 1\n",
      "Number of inconsistent choices for participant  E19 0\n",
      "Number of inconsistent choices for participant  E2 1\n",
      "Number of inconsistent choices for participant  E20 1\n",
      "Number of inconsistent choices for participant  E21 0\n",
      "Number of inconsistent choices for participant  E22 0\n",
      "Number of inconsistent choices for participant  E23 0\n",
      "Number of inconsistent choices for participant  E24 0\n",
      "Number of inconsistent choices for participant  E25 0\n",
      "Number of inconsistent choices for participant  E26 0\n",
      "Number of inconsistent choices for participant  E27 1\n",
      "Number of inconsistent choices for participant  E28 0\n",
      "Number of inconsistent choices for participant  E29 0\n",
      "Number of inconsistent choices for participant  E3 0\n",
      "Number of inconsistent choices for participant  E30 0\n",
      "Number of inconsistent choices for participant  E31 3\n",
      "Number of inconsistent choices for participant  E32 0\n",
      "Number of inconsistent choices for participant  E33 0\n",
      "Number of inconsistent choices for participant  E4 2\n",
      "Number of inconsistent choices for participant  E5 0\n",
      "Number of inconsistent choices for participant  E6 0\n",
      "Number of inconsistent choices for participant  E7 0\n",
      "Number of inconsistent choices for participant  E8 1\n",
      "Number of inconsistent choices for participant  E9 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in data['participant'].unique():\n",
    "    print 'Number of inconsistent choices for participant ', x, len(data.loc[data['participant']==x, 'chosen'].unique())-21\n",
    "#data.groupby(['participant']).chosen.value_counts()\n",
    "len(data['chosen'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 5: Use of confidence scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check to see whether each participant used an appropriate range of the scale (pre-determined to be one standard deviation of 16%, or 0.8 scale units, after De Martino, Fleming, Garrett, and Dolan, 2012, Nature Neuroscience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant\n",
       "E1     1.036433\n",
       "E10    1.447444\n",
       "E11    0.793710\n",
       "E12    1.218852\n",
       "E13    0.991350\n",
       "E14    1.002868\n",
       "E15    0.659351\n",
       "E16    1.080483\n",
       "E17    1.260516\n",
       "E18    0.715258\n",
       "E19    0.593922\n",
       "E2     1.110304\n",
       "E20    1.191123\n",
       "E21    1.208139\n",
       "E22    1.460274\n",
       "E23    0.749062\n",
       "E24    1.285085\n",
       "E25    0.553963\n",
       "E26    1.217128\n",
       "E27    1.815625\n",
       "E28    1.214650\n",
       "E29    1.562490\n",
       "E3     1.242676\n",
       "E30    0.882822\n",
       "E31    0.978455\n",
       "E32    1.223599\n",
       "E33    1.092428\n",
       "E4     1.545510\n",
       "E5     1.066243\n",
       "E6     1.451715\n",
       "E7     0.826680\n",
       "E8     1.885444\n",
       "E9     1.339475\n",
       "Name: confidence_rating1_response, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['participant']).confidence_rating1_response.std(ddof=0) #< 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this criterion, we would exclude participants E11, E15, E18, E19, E23, and E25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 6: Bids or confidence ratings predicted by jittered starting points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run regression analyses to determine whether a participant's bid or confidence responses were significantly predicted by the jittered starting point of the scale marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_jitter_effect_bids(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['bdm_bid1_response'].notnull()]\n",
    "    x = np.array(data_subset['bdm_marker_start'])\n",
    "    y = np.array(data_subset['bdm_bid1_response'])\n",
    "    slope, intercept, r_value, p_value, slope_std_error = ss.linregress(x, y)\n",
    "    #plt.scatter(x, y)\n",
    "    #plt.show()\n",
    "    return subj, p_value, r_value, slope\n",
    "\n",
    "for x in data['participant'].unique():\n",
    "    if check_jitter_effect_bids(x)[1] <0.05:\n",
    "        print check_jitter_effect_bids(x)[0], check_jitter_effect_bids(x)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No participant meets this criterion for the bid scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant E18 , p= 0.0044210737297 , r= 0.440744269817 , slope= 0.194255511376\n",
      "Participant E25 , p= 0.00122567551752 , r= 0.493101277099 , slope= 0.243148869476\n",
      "Participant E33 , p= 0.022980736332 , r= -0.358824737619 , slope= 0.128755192328\n",
      "Participant E5 , p= 0.00685621220024 , r= -0.420793513205 , slope= 0.177067180755\n",
      "Participant E6 , p= 0.00258766973022 , r= -0.463604614747 , slope= 0.214929238815\n"
     ]
    }
   ],
   "source": [
    "def check_jitter_effect_confidence(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['confidence_rating1_response'].notnull()]\n",
    "    x = np.array(data_subset['confidence_marker_start'])\n",
    "    y = np.array(data_subset['confidence_rating1_response'])\n",
    "    slope, intercept, r_value, p_value, slope_std_error = ss.linregress(x, y)\n",
    "    #plt.scatter(x, y)\n",
    "    #plt.show()\n",
    "    return subj, p_value, r_value, slope\n",
    "\n",
    "def check_jitter_effect_confidence_plot(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['confidence_rating1_response'].notnull()]\n",
    "    x = np.array(data_subset['confidence_marker_start'])\n",
    "    y = np.array(data_subset['confidence_rating1_response'])\n",
    "    slope, intercept, r_value, p_value, slope_std_error = ss.linregress(x, y)\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "for x in data['participant'].unique():\n",
    "    if check_jitter_effect_confidence(x)[1] <0.05:\n",
    "        print 'Participant',check_jitter_effect_confidence(x)[0], ', p=',check_jitter_effect_confidence(x)[1], ', r=',check_jitter_effect_confidence(x)[2], ', slope=',check_jitter_effect_confidence(x)[2]**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants E5, E6, E18, E25, and E33 would be excluded under this criterion for the confidence scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEJCAYAAACT/UyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110bfbad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_jitter_effect_confidence_plot_resid(subj):\n",
    "    #Data\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['confidence_rating1_response'].notnull()]\n",
    "    x = np.array(data_subset['confidence_marker_start'])\n",
    "    y = np.array(data_subset['confidence_rating1_response'])\n",
    "\n",
    "    #Model\n",
    "    Fofx = lambda x,a,b: a*x+b\n",
    "    #Best fit parameters\n",
    "    p, cov = curve_fit(Fofx,x,y)\n",
    "\n",
    "    #PLOT\n",
    "    fig1 = plt.figure(1)\n",
    "    #Plot Data-model\n",
    "    frame1=fig1.add_axes((.1,.3,.8,.6))\n",
    "    #xstart, ystart, xend, yend [units are fraction of the image frame, from bottom left corner]\n",
    "    plt.plot(x,y,'.b') #Noisy data\n",
    "    plt.plot(x,Fofx(x,*p),'-r') #Best fit model\n",
    "    frame1.set_xticklabels([]) #Remove x-tic labels for the first frame\n",
    "    plt.grid()\n",
    "\n",
    "    #Residual plot\n",
    "    difference = Fofx(x,*p) - y\n",
    "    frame2=fig1.add_axes((.1,.1,.8,.2))        \n",
    "    plt.hist(difference)\n",
    "    plt.grid()\n",
    "check_jitter_effect_confidence_plot_resid('E6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEJCAYAAAB2T0usAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fe94690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_jitter_effect_confidence_plot_resid('E33')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 7: Bids do not predict choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690545\n",
      "         Iterations 4\n",
      "E25                            Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            left_chosen   No. Observations:                   40\n",
      "Model:                          Logit   Df Residuals:                       38\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 29 Jun 2017   Pseudo R-squ.:                0.003754\n",
      "Time:                        15:22:26   Log-Likelihood:                -27.622\n",
      "converged:                       True   LL-Null:                       -27.726\n",
      "                                        LLR p-value:                    0.6482\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------------\n",
      "choice_dv_left_minus_right    -0.2607      0.573     -0.455      0.649        -1.384     0.862\n",
      "intercept                   1.944e-17      0.317   6.13e-17      1.000        -0.621     0.621\n",
      "==============================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691581\n",
      "         Iterations 3\n",
      "E30                            Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            left_chosen   No. Observations:                   40\n",
      "Model:                          Logit   Df Residuals:                       38\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 29 Jun 2017   Pseudo R-squ.:                0.002260\n",
      "Time:                        15:22:26   Log-Likelihood:                -27.663\n",
      "converged:                       True   LL-Null:                       -27.726\n",
      "                                        LLR p-value:                    0.7233\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------------\n",
      "choice_dv_left_minus_right    -0.3137      0.887     -0.353      0.724        -2.053     1.426\n",
      "intercept                  -8.648e-17      0.317  -2.73e-16      1.000        -0.621     0.621\n",
      "==============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_bid_predicting_choice(subj):\n",
    "    data_subset = data[data['participant']==subj]\n",
    "    data_subset = data_subset[data_subset['chosen'].notnull()]\n",
    "    data_subset['intercept'] = 1.0\n",
    "    logit = sm.Logit(data_subset['left_chosen'], data_subset[['choice_dv_left_minus_right','intercept']])\n",
    "    result = logit.fit()\n",
    "    print subj, result.summary()\n",
    "\n",
    "# for x in data['participant'].unique():\n",
    "#     check_bid_predicting_choice(x)\n",
    "\n",
    "check_bid_predicting_choice('E25'), check_bid_predicting_choice('E30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two subjects (E6 and E28) could not be estimated using logistic regression because their choices were perfectly consistent and in line with their bids. Excluding these two participants, the mean coefficient is 5.217. To be included, participants' individual coefficients must be 20% of this (1.0434) or higher (after De Martino, Fleming, Garrett, and Dolan, 2012, Nature Neuroscience). Two participants (E25 and E30) failed to meet this criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Criterion 8: Learning performance not significantly above chance\n",
    "All participants completed 600 learning trials. From the cumulative density of the binomial distribution, in order to perform above chance with 95% certainty, they would need to get at least 320 answers correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in data['participant'].unique():\n",
    "    data_subset = data[data['participant']==x]\n",
    "    data_subset = data_subset[data_subset['correct_counter'].notnull()]\n",
    "    performance = int(data_subset['correct_counter'].mean()) # The number of answers correct\n",
    "    \n",
    "    # If the cumulative density of the binomial distribution with 'performance' flips in 600 trials is less than 95%, print the participant to be excluded\n",
    "    if ss.binom.cdf(performance,600,0.5) < 0.95:\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All participants performed significantly above chance level, and therefore none are excluded on this basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exclusion Summary and Criteria Adjustment\n",
    "Under these criteria, we would exclude a total of 10 participants.\n",
    "\n",
    "| Participant |                      | Exclusion Criterion      |                          |\n",
    "|-------------|----------------------|--------------------------|--------------------------|\n",
    "|             | 5 (confidence scale) | 6 (scale starting point) | 7 (bids predict choices) |\n",
    "| E5          |                      | X                        |                          |\n",
    "| E6          |                      | X                        |                          |\n",
    "| E11         | X                    |                          |                          |\n",
    "| E15         | X                    |                          |                          |\n",
    "| E18         | X                    | X                        |                          |\n",
    "| E19         | X                    |                          |                          |\n",
    "| E23         | X                    |                          |                          |\n",
    "| E25         | X                    | X                        | X                        |\n",
    "| E30         |                      |                          | X                        |\n",
    "| E33         |                      | X                        |                          |\n",
    "\n",
    "We worry that these criteria may be too strict, as they would exclude 10 out of 33 participants. We decided, therefore, to eliminate criteria 5 and 6 for two reasons: (1) the choice confidence analyses are not central to the study; and (2) these criteria may be unnecessarily strict given the analyses, which, unlike the De Martino et al. (2013) study on which they are based, only require some basic z-scored resolution. The decision to eliminate these criteria was made after data collection but before any further analysis was performed.\n",
    "\n",
    "As such, we exclude a total of two participants (E25 and E30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine and save dataframe with these participants excluded:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Response Time Exclusions\n",
    "Based on my notes taken during testing, before the data were analyzed, there are several trials with exaggerated response times. This was usually due to my asking participants to pause during a learning trial because the eye tracker had lost their eye, or to a participant pausing to ask a question during the choice task. We first figure out which exact trials these were based on my notes (which listed the approximate trial) and by looking for unusually high response times (with a participant-level z-score greater than 3) around the trial noted. We then exclude the response times from these trials' data. \n",
    "\n",
    "Participant E1: \"Lost eye data for some trials (around trial 394), exaggerated RT for one trial as a result of stopping to readjust camera\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>learning_trial</th>\n",
       "      <th>infer_resp_rt</th>\n",
       "      <th>infer_resp_rt_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>E1</td>\n",
       "      <td>392</td>\n",
       "      <td>121.530282</td>\n",
       "      <td>24.258728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant  learning_trial  infer_resp_rt  infer_resp_rt_zscore\n",
       "236          E1             392     121.530282             24.258728"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['infer_resp_rt_zscore']>3)&(data['participant']=='E1')][['participant','learning_trial','infer_resp_rt','infer_resp_rt_zscore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noted trial appears to be number 392 for participant E1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace exaggerated RT with missing value\n",
    "data.loc[236,'infer_resp_rt'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participant E3: \"Buzzed during choice task to ask if it was supposed to be done with eye tracking (on trial with sardines)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>choice_left</th>\n",
       "      <th>choice_right</th>\n",
       "      <th>key_resp_choice_rt</th>\n",
       "      <th>key_resp_choice_rt_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>E3</td>\n",
       "      <td>40-sardines.png</td>\n",
       "      <td>5-pineapple.png</td>\n",
       "      <td>27.282386</td>\n",
       "      <td>5.390538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant      choice_left     choice_right  key_resp_choice_rt  \\\n",
       "16246          E3  40-sardines.png  5-pineapple.png           27.282386   \n",
       "\n",
       "       key_resp_choice_rt_zscore  \n",
       "16246                   5.390538  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['participant']=='E3')&(data['key_resp_choice_rt_zscore']>3)][['participant','choice_left','choice_right','key_resp_choice_rt','key_resp_choice_rt_zscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[16246,'key_resp_choice_rt'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure it wasn't the other sardines choice trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>choice_left</th>\n",
       "      <th>choice_right</th>\n",
       "      <th>key_resp_choice_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16240</th>\n",
       "      <td>E3</td>\n",
       "      <td>5-pineapple.png</td>\n",
       "      <td>40-sardines.png</td>\n",
       "      <td>1.28338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant      choice_left     choice_right  key_resp_choice_rt\n",
       "16240          E3  5-pineapple.png  40-sardines.png             1.28338"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['participant']=='E3')&(data['choice_right']=='40-sardines.png')][['participant','choice_left','choice_right','key_resp_choice_rt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participant E21: \"Cursor on screen for part of first block; eye tracker lost eye around trials 42, 399-400, and 438. I asked participant to pause around these trials while I re-captured the eye.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>learning_trial</th>\n",
       "      <th>infer_resp_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9224</th>\n",
       "      <td>E21</td>\n",
       "      <td>399</td>\n",
       "      <td>7.950210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9569</th>\n",
       "      <td>E21</td>\n",
       "      <td>437</td>\n",
       "      <td>15.733126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>E21</td>\n",
       "      <td>41</td>\n",
       "      <td>19.599863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant  learning_trial  infer_resp_rt\n",
       "9224         E21             399       7.950210\n",
       "9569         E21             437      15.733126\n",
       "9607         E21              41      19.599863"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['participant']=='E21')&(data['infer_resp_rt_zscore']>3)][['participant','learning_trial','infer_resp_rt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[9224,'infer_resp_rt'] = np.nan\n",
    "data.loc[9569, 'infer_resp_rt'] = np.nan\n",
    "data.loc[9607, 'infer_resp_rt'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participant E31: \"...buzzed in middle of choice task to confirm that '6' is most confident on the confidence scale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>key_resp_choice_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17663</th>\n",
       "      <td>E31</td>\n",
       "      <td>30.566257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      participant  key_resp_choice_rt\n",
       "17663         E31           30.566257"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['participant']=='E31')&(data['key_resp_choice_rt_zscore']>3)][['participant','key_resp_choice_rt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[17663,'key_resp_choice_rt'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we recalculate the response time z-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "choice_rt_means = data.groupby(['participant']).key_resp_choice_rt.mean()\n",
    "choice_rt_sds = data.groupby(['participant']).key_resp_choice_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = choice_rt_means[p]\n",
    "    p_sd = choice_rt_sds[p]\n",
    "    rt = data.loc[x,'key_resp_choice_rt']\n",
    "    data.loc[x,'key_resp_choice_rt_zscore'] = (rt - p_mean)/p_sd\n",
    "    \n",
    "rt_means = data.groupby(['participant']).infer_resp_rt.mean()\n",
    "rt_sds = data.groupby(['participant']).infer_resp_rt.std(ddof=0)\n",
    "\n",
    "for x in range(1,len(data)+1):\n",
    "    p = data.loc[x,'participant']\n",
    "    p_mean = rt_means[p]\n",
    "    p_sd = rt_sds[p]\n",
    "    rt = data.loc[x,'infer_resp_rt']\n",
    "    data.loc[x,'infer_resp_rt_zscore'] = (rt - p_mean)/p_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And copy these new response times and their z-scores to the inference trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.chc_correct_on_left_rt = np.nan\n",
    "data.chc_correct_on_left_rt_zscore = np.nan\n",
    "data.chc_correct_on_right_rt = np.nan\n",
    "data.chc_correct_on_right_rt_zscore = np.nan\n",
    "\n",
    "for x in range(1,len(data)+1): # For all rows...\n",
    "    if not pd.isnull(data.loc[x,'img_correct']) and pd.isnull(data.loc[x,'practice_loop_thisTrialN']): # ... if there is a value in 'img_correct' indicating that row is from the inference task, and it is not in the practice block\n",
    "    # CHOICE RESPONSE TIMES\n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the LEFT   \n",
    "        chc_left_inf_all = data[data.loc[x,'img_correct']==data.choice_left] \n",
    "        chc_left_inf_participant = chc_left_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_left_inf_participant_notnull = chc_left_inf_participant[chc_left_inf_participant['key_resp_choice_rt'].notnull()] \n",
    "        if len(chc_left_inf_participant_notnull) > 0:\n",
    "            chc_left_inf_participant_notnull_index = chc_left_inf_participant_notnull['key_resp_choice_rt'].idxmax()\n",
    "            data.loc[x,'chc_correct_on_left_rt'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice_rt'] \n",
    "            data.loc[x,'chc_correct_on_left_rt_zscore'] = chc_left_inf_participant_notnull.loc[chc_left_inf_participant_notnull_index,'key_resp_choice_rt_zscore'] \n",
    "        else:\n",
    "            data.loc[x,'chc_correct_on_left_rt'] = np.nan\n",
    "            data.loc[x,'chc_correct_on_left_rt_zscore'] = np.nan\n",
    "    # Get the choice response tims from the choice task, from the trials where the correct item appears on the RIGHT   \n",
    "        chc_right_inf_all = data[data.loc[x,'img_correct']==data.choice_right] \n",
    "        chc_right_inf_participant = chc_right_inf_all[data['participant']==data.loc[x,'participant']]\n",
    "        chc_right_inf_participant_notnull = chc_right_inf_participant[chc_right_inf_participant['key_resp_choice_rt'].notnull()] \n",
    "        if len(chc_right_inf_participant_notnull) > 0:\n",
    "            chc_right_inf_participant_notnull_index = chc_right_inf_participant_notnull['key_resp_choice_rt'].idxmax()\n",
    "            data.loc[x,'chc_correct_on_right_rt'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice_rt'] \n",
    "            data.loc[x,'chc_correct_on_right_rt_zscore'] = chc_right_inf_participant_notnull.loc[chc_right_inf_participant_notnull_index,'key_resp_choice_rt_zscore']\n",
    "        else:\n",
    "            data.loc[x,'chc_correct_on_right_rt'] = 0\n",
    "            data.loc[x,'chc_correct_on_right_rt_zscore'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[data['participant']!='E25']\n",
    "data = data[data['participant']!='E30']\n",
    "data.reset_index(drop=True)\n",
    "data.to_csv(path_or_buf=r'../data/social/data_processed_social_wexclusions.csv')\n",
    "data.to_pickle(r'../data/social/data_processed_social_wexclusions.pkl')"
   ]
  }
 ],
 "metadata": {
  "gist_id": "56d54360661ad30ee0a0",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
