ccopy_reg
_reconstructor
p1
(cpsychopy.data
ExperimentHandler
p2
c__builtin__
object
p3
NtRp4
(dp5
S'originPath'
p6
NsS'dataFileName'
p7
Vdata/P6_infer_design1_2014_Oct_17_1031
p8
sS'runtimeInfo'
p9
NsS'name'
p10
S'infer_design1'
p11
sS'dataNames'
p12
(lp13
S'instr_main_resp.keys'
p14
aS'instr_main_resp.rt'
p15
aS'instr_bdm1_resp.keys'
p16
aS'instr_bdm1_resp.rt'
p17
aS'bdm_bid1.response'
p18
aS'bdm_bid1.rt'
p19
aS'instr_choice1_resp.keys'
p20
aS'instr_choice1_resp.rt'
p21
aS'key_resp_choice1.keys'
p22
aS'key_resp_choice1.rt'
p23
aS'confidence_rating1.response'
p24
aS'confidence_rating1.rt'
p25
aS'instr_infer_intro_resp.keys'
p26
aS'instr_infer_intro_resp.rt'
p27
aS'instr_infer_practice_resp.keys'
p28
aS'instr_infer_practice_resp.rt'
p29
aS'set_outcome.outcm_img'
p30
aS'instr_infer_resp.keys'
p31
aS'instr_infer_resp.rt'
p32
aS'infer_resp.keys'
p33
aS'infer_resp.rt'
p34
aS'rest_prompt_resp.keys'
p35
aS'rest_prompt_resp.rt'
p36
aS'correct_counter'
p37
aS'incorrect_counter'
p38
aS'instr_bdm2_resp.keys'
p39
aS'instr_bdm2_resp.rt'
p40
aS'bdm_bid2.response'
p41
aS'bdm_bid2.rt'
p42
aS'instr_choice2_resp.keys'
p43
aS'instr_choice2_resp.rt'
p44
aS'key_resp_choice2.keys'
p45
aS'key_resp_choice2.rt'
p46
aS'confidence_rating2.response'
p47
aS'confidence_rating2.rt'
p48
aS'auction.win_item'
p49
aS'auction.price'
p50
aS'auction.bid'
p51
aS'auction.rand_itm_img'
p52
aS'score.base'
p53
aS'score.rwrd'
p54
aS'score.loss'
p55
aS'score.final_pymt'
p56
asS'autoLog'
p57
I01
sS'extraInfo'
p58
(dp59
S'date'
p60
V2014_Oct_17_1031
p61
sS'frameRate'
p62
cnumpy.core.multiarray
scalar
p63
(cnumpy
dtype
p64
(S'f8'
I0
I1
tRp65
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x1a\xd1p\x06\x1f\xc5R@'
tRp66
sS'expName'
p67
g11
sVsession
p68
V001
p69
sVparticipant
p70
VP6
p71
ssS'loopsUnfinished'
p72
(lp73
sS'saveWideText'
p74
I01
sS'thisEntry'
p75
(dp76
sS'version'
p77
S''
sS'_paramNamesSoFar'
p78
(lp79
Vbdm_img
p80
aS'choice_left'
p81
aS'choice_right'
p82
aS'img_correct'
p83
aS'img_left'
p84
aS'img_wrong'
p85
aS'img_right'
p86
asS'entries'
p87
(lp88
(dp89
g68
g69
sg67
g11
sg70
g71
sg15
F1107.2265977938532
sg60
g61
sg14
S'space'
p90
sg62
g66
sa(dp91
g16
S'space'
p92
sg60
g61
sg67
g11
sg70
g71
sg68
g69
sg17
F7.2324401565019798
sg62
g66
sa(dp93
g68
g69
sg19
F7.2220000000000004
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p94
I0
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p95
g63
(g64
(S'i4'
I0
I1
tRp96
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x07\x00\x00\x00'
tRp97
sS'bdm_loop1.thisRepN'
p98
I0
sS'bdm_loop1.thisTrialN'
p99
I0
sg60
g61
sg80
V8-liquorice_catherine_wheels.png
p100
sa(dp101
g68
g69
sg19
F17.131
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p102
I1
sg18
F0.51999999999999913
sg67
g11
sS'bdm_loop1.thisIndex'
p103
g63
(g96
S'\x1d\x00\x00\x00'
tRp104
sS'bdm_loop1.thisRepN'
p105
I0
sS'bdm_loop1.thisTrialN'
p106
I1
sg60
g61
sg80
V40-sardines.png
p107
sa(dp108
g68
g69
sg19
F8.0869999999999997
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p109
I2
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p110
g63
(g96
S'\x14\x00\x00\x00'
tRp111
sS'bdm_loop1.thisRepN'
p112
I0
sS'bdm_loop1.thisTrialN'
p113
I2
sg60
g61
sg80
V27-hartleys_raspberries_jelly.png
p114
sa(dp115
g68
g69
sg19
F5.8230000000000004
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p116
I3
sg18
F0.51999999999999913
sg67
g11
sS'bdm_loop1.thisIndex'
p117
g63
(g96
S'\x05\x00\x00\x00'
tRp118
sS'bdm_loop1.thisRepN'
p119
I0
sS'bdm_loop1.thisTrialN'
p120
I3
sg60
g61
sg80
V6-sour_patch_kids.png
p121
sa(dp122
g68
g69
sg19
F9.6989999999999998
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p123
I4
sg18
F0.99999999999999956
sg67
g11
sS'bdm_loop1.thisIndex'
p124
g63
(g96
S'\x1f\x00\x00\x00'
tRp125
sS'bdm_loop1.thisRepN'
p126
I0
sS'bdm_loop1.thisTrialN'
p127
I4
sg60
g61
sg80
V42-mrkipling_lemon_slices.png
p128
sa(dp129
g68
g69
sg19
F2.04
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p130
I5
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p131
g63
(g96
S'\x02\x00\x00\x00'
tRp132
sS'bdm_loop1.thisRepN'
p133
I0
sS'bdm_loop1.thisTrialN'
p134
I5
sg60
g61
sg80
V3-dole_fruit_snack.png
p135
sa(dp136
g68
g69
sg19
F2.5329999999999999
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p137
I6
sg18
F0.13999999999999896
sg67
g11
sS'bdm_loop1.thisIndex'
p138
g63
(g96
S'#\x00\x00\x00'
tRp139
sS'bdm_loop1.thisRepN'
p140
I0
sS'bdm_loop1.thisTrialN'
p141
I6
sg60
g61
sg80
V46-pistachios.png
p142
sa(dp143
g68
g69
sg19
F7.6479999999999997
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p144
I7
sg18
F0.45999999999999908
sg67
g11
sS'bdm_loop1.thisIndex'
p145
g63
(g96
S'&\x00\x00\x00'
tRp146
sS'bdm_loop1.thisRepN'
p147
I0
sS'bdm_loop1.thisTrialN'
p148
I7
sg60
g61
sg80
V50-polo.png
p149
sa(dp150
g68
g69
sg19
F8.9930000000000003
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p151
I8
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p152
g63
(g96
S'\x00\x00\x00\x00'
tRp153
sS'bdm_loop1.thisRepN'
p154
I0
sS'bdm_loop1.thisTrialN'
p155
I8
sg60
g61
sg80
V1-smarties_cookies.png
p156
sa(dp157
g68
g69
sg19
F4.7309999999999999
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p158
I9
sg18
F0.63999999999999924
sg67
g11
sS'bdm_loop1.thisIndex'
p159
g63
(g96
S'\x19\x00\x00\x00'
tRp160
sS'bdm_loop1.thisRepN'
p161
I0
sS'bdm_loop1.thisTrialN'
p162
I9
sg60
g61
sg80
V34-hula_hoops_bbq_beef.png
p163
sa(dp164
g68
g69
sg19
F2.5600000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p165
I10
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p166
g63
(g96
S"'\x00\x00\x00"
tRp167
sS'bdm_loop1.thisRepN'
p168
I0
sS'bdm_loop1.thisTrialN'
p169
I10
sg60
g61
sg80
V51-mars.png
p170
sa(dp171
g68
g69
sg19
F2.3069999999999999
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p172
I11
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p173
g63
(g96
S'\x1e\x00\x00\x00'
tRp174
sS'bdm_loop1.thisRepN'
p175
I0
sS'bdm_loop1.thisTrialN'
p176
I11
sg60
g61
sg80
V41-peanuts.png
p177
sa(dp178
g68
g69
sg19
F2.1070000000000002
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p179
I12
sg18
F0.21999999999999892
sg67
g11
sS'bdm_loop1.thisIndex'
p180
g63
(g96
S'%\x00\x00\x00'
tRp181
sS'bdm_loop1.thisRepN'
p182
I0
sS'bdm_loop1.thisTrialN'
p183
I12
sg60
g61
sg80
V49-yorkie.png
p184
sa(dp185
g68
g69
sg19
F4.1319999999999997
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p186
I13
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p187
g63
(g96
S'\x1a\x00\x00\x00'
tRp188
sS'bdm_loop1.thisRepN'
p189
I0
sS'bdm_loop1.thisTrialN'
p190
I13
sg60
g61
sg80
V35-sultanas.png
p191
sa(dp192
g68
g69
sg19
F2.214
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p193
I14
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p194
g63
(g96
S'\x03\x00\x00\x00'
tRp195
sS'bdm_loop1.thisRepN'
p196
I0
sS'bdm_loop1.thisTrialN'
p197
I14
sg60
g61
sg80
V4-corn.png
p198
sa(dp199
g68
g69
sg19
F2.6800000000000002
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p200
I15
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p201
g63
(g96
S'\x0e\x00\x00\x00'
tRp202
sS'bdm_loop1.thisRepN'
p203
I0
sS'bdm_loop1.thisTrialN'
p204
I15
sg60
g61
sg80
V20-fruit_pastilles.png
p205
sa(dp206
g68
g69
sg19
F8.0340000000000007
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p207
I16
sg18
F0.73999999999999932
sg67
g11
sS'bdm_loop1.thisIndex'
p208
g63
(g96
S'\x17\x00\x00\x00'
tRp209
sS'bdm_loop1.thisRepN'
p210
I0
sS'bdm_loop1.thisTrialN'
p211
I16
sg60
g61
sg80
V31-foxs_golden_biscuits.png
p212
sa(dp213
g68
g69
sg19
F4.3049999999999997
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p214
I17
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p215
g63
(g96
S'\x16\x00\x00\x00'
tRp216
sS'bdm_loop1.thisRepN'
p217
I0
sS'bdm_loop1.thisTrialN'
p218
I17
sg60
g61
sg80
V30-spaghetti_hoops.png
p219
sa(dp220
g68
g69
sg19
F10.298
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p221
I18
sg18
F0.65999999999999925
sg67
g11
sS'bdm_loop1.thisIndex'
p222
g63
(g96
S'\x01\x00\x00\x00'
tRp223
sS'bdm_loop1.thisRepN'
p224
I0
sS'bdm_loop1.thisTrialN'
p225
I18
sg60
g61
sg80
V2-steamed_puddings.png
p226
sa(dp227
g68
g69
sg19
F9.6720000000000006
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p228
I19
sg18
F0.77999999999999936
sg67
g11
sS'bdm_loop1.thisIndex'
p229
g63
(g96
S' \x00\x00\x00'
tRp230
sS'bdm_loop1.thisRepN'
p231
I0
sS'bdm_loop1.thisTrialN'
p232
I19
sg60
g61
sg80
V43-mrporky_pork_crackles.png
p233
sa(dp234
g68
g69
sg19
F4.0650000000000004
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p235
I20
sg18
F0.45999999999999908
sg67
g11
sS'bdm_loop1.thisIndex'
p236
g63
(g96
S'\x1c\x00\x00\x00'
tRp237
sS'bdm_loop1.thisRepN'
p238
I0
sS'bdm_loop1.thisTrialN'
p239
I20
sg60
g61
sg80
V38-maltesers.png
p240
sa(dp241
g68
g69
sg19
F1.841
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p242
I21
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p243
g63
(g96
S'\x08\x00\x00\x00'
tRp244
sS'bdm_loop1.thisRepN'
p245
I0
sS'bdm_loop1.thisTrialN'
p246
I21
sg60
g61
sg80
V10-bounty.png
p247
sa(dp248
g68
g69
sg19
F2.8260000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p249
I22
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p250
g63
(g96
S'\x18\x00\x00\x00'
tRp251
sS'bdm_loop1.thisRepN'
p252
I0
sS'bdm_loop1.thisTrialN'
p253
I22
sg60
g61
sg80
V33-ambrosia_rice.png
p254
sa(dp255
g68
g69
sg19
F1.4810000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p256
I23
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p257
g63
(g96
S'\x15\x00\x00\x00'
tRp258
sS'bdm_loop1.thisRepN'
p259
I0
sS'bdm_loop1.thisTrialN'
p260
I23
sg60
g61
sg80
V29-beans.png
p261
sa(dp262
g68
g69
sg19
F2.0270000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p263
I24
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p264
g63
(g96
S'\r\x00\x00\x00'
tRp265
sS'bdm_loop1.thisRepN'
p266
I0
sS'bdm_loop1.thisTrialN'
p267
I24
sg60
g61
sg80
V19-caramello.png
p268
sa(dp269
g68
g69
sg19
F1.494
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p270
I25
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p271
g63
(g96
S'\x11\x00\x00\x00'
tRp272
sS'bdm_loop1.thisRepN'
p273
I0
sS'bdm_loop1.thisTrialN'
p274
I25
sg60
g61
sg80
V23-crunchie.png
p275
sa(dp276
g68
g69
sg19
F3.8119999999999998
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p277
I26
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p278
g63
(g96
S'"\x00\x00\x00'
tRp279
sS'bdm_loop1.thisRepN'
p280
I0
sS'bdm_loop1.thisTrialN'
p281
I26
sg60
g61
sg80
V45-chewy_nougat.png
p282
sa(dp283
g68
g69
sg19
F3.2770000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p284
I27
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p285
g63
(g96
S'$\x00\x00\x00'
tRp286
sS'bdm_loop1.thisRepN'
p287
I0
sS'bdm_loop1.thisTrialN'
p288
I27
sg60
g61
sg80
V48-twix.png
p289
sa(dp290
g68
g69
sg19
F6.556
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p291
I28
sg18
F0.51999999999999913
sg67
g11
sS'bdm_loop1.thisIndex'
p292
g63
(g96
S'\x0b\x00\x00\x00'
tRp293
sS'bdm_loop1.thisRepN'
p294
I0
sS'bdm_loop1.thisTrialN'
p295
I28
sg60
g61
sg80
V17-jacobs_mini_cheddars.png
p296
sa(dp297
g68
g69
sg19
F6.5419999999999998
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p298
I29
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p299
g63
(g96
S'!\x00\x00\x00'
tRp300
sS'bdm_loop1.thisRepN'
p301
I0
sS'bdm_loop1.thisTrialN'
p302
I29
sg60
g61
sg80
V44-crunch.png
p303
sa(dp304
g68
g69
sg19
F3.452
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p305
I30
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p306
g63
(g96
S'\x0f\x00\x00\x00'
tRp307
sS'bdm_loop1.thisRepN'
p308
I0
sS'bdm_loop1.thisTrialN'
p309
I30
sg60
g61
sg80
V21-nakd_banana_crunch.png
p310
sa(dp311
g68
g69
sg19
F4.5039999999999996
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p312
I31
sg18
F0.51999999999999913
sg67
g11
sS'bdm_loop1.thisIndex'
p313
g63
(g96
S'\t\x00\x00\x00'
tRp314
sS'bdm_loop1.thisRepN'
p315
I0
sS'bdm_loop1.thisTrialN'
p316
I31
sg60
g61
sg80
V13-mccoys_steak_crisps.png
p317
sa(dp318
g68
g69
sg19
F4.8380000000000001
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p319
I32
sg18
F0.51999999999999913
sg67
g11
sS'bdm_loop1.thisIndex'
p320
g63
(g96
S'\x1b\x00\x00\x00'
tRp321
sS'bdm_loop1.thisRepN'
p322
I0
sS'bdm_loop1.thisTrialN'
p323
I32
sg60
g61
sg80
V36-fig_rolls.png
p324
sa(dp325
g68
g69
sg19
F1.548
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p326
I33
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p327
g63
(g96
S'\x10\x00\x00\x00'
tRp328
sS'bdm_loop1.thisRepN'
p329
I0
sS'bdm_loop1.thisTrialN'
p330
I33
sg60
g61
sg80
V22-daim.png
p331
sa(dp332
g68
g69
sg19
F2.5329999999999999
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p333
I34
sg18
F0.75999999999999934
sg67
g11
sS'bdm_loop1.thisIndex'
p334
g63
(g96
S'\x13\x00\x00\x00'
tRp335
sS'bdm_loop1.thisRepN'
p336
I0
sS'bdm_loop1.thisTrialN'
p337
I34
sg60
g61
sg80
V26-walkers_smoky_bacon.png
p338
sa(dp339
g68
g69
sg19
F2.4129999999999998
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p340
I35
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p341
g63
(g96
S'\x0c\x00\x00\x00'
tRp342
sS'bdm_loop1.thisRepN'
p343
I0
sS'bdm_loop1.thisTrialN'
p344
I35
sg60
g61
sg80
V18-mms.png
p345
sa(dp346
g68
g69
sg19
F1.375
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p347
I36
sg18
F0.53999999999999915
sg67
g11
sS'bdm_loop1.thisIndex'
p348
g63
(g96
S'\n\x00\x00\x00'
tRp349
sS'bdm_loop1.thisRepN'
p350
I0
sS'bdm_loop1.thisTrialN'
p351
I36
sg60
g61
sg80
V16-skips_prawn.png
p352
sa(dp353
g68
g69
sg19
F1.508
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p354
I37
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p355
g63
(g96
S'\x12\x00\x00\x00'
tRp356
sS'bdm_loop1.thisRepN'
p357
I0
sS'bdm_loop1.thisTrialN'
p358
I37
sg60
g61
sg80
V25-kitkat.png
p359
sa(dp360
g68
g69
sg19
F1.494
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p361
I38
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p362
g63
(g96
S'\x04\x00\x00\x00'
tRp363
sS'bdm_loop1.thisRepN'
p364
I0
sS'bdm_loop1.thisTrialN'
p365
I38
sg60
g61
sg80
V5-pineapple.png
p366
sa(dp367
g68
g69
sg19
F2.0139999999999998
sg70
g71
sg62
g66
sS'bdm_loop1.thisN'
p368
I39
sg18
F0
sg67
g11
sS'bdm_loop1.thisIndex'
p369
g63
(g96
S'\x06\x00\x00\x00'
tRp370
sS'bdm_loop1.thisRepN'
p371
I0
sS'bdm_loop1.thisTrialN'
p372
I39
sg60
g61
sg80
V7-olives.png
p373
sa(dp374
g68
g69
sg67
g11
sg70
g71
sg21
F2.5042277719658159
sg60
g61
sg20
S'space'
p375
sg62
g66
sa(dp376
g68
g69
sg22
S'left'
p377
sS'binary1.thisTrialN'
p378
I0
sS'binary1.thisRepN'
p379
I0
sg62
g66
sg24
F1
sg23
F3.0900597701656807
sg82
V13-mccoys_steak_crisps.png
p380
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p381
g63
(g96
S'\x00\x00\x00\x00'
tRp382
sg60
g61
sg81
V3-dole_fruit_snack.png
p383
sS'binary1.thisN'
p384
I0
sg25
F15.919
sa(dp385
g68
g69
sg22
S'left'
p386
sS'binary1.thisTrialN'
p387
I1
sS'binary1.thisRepN'
p388
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.5717497614914464
sg82
V44-crunch.png
p389
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p390
g63
(g96
S'\x01\x00\x00\x00'
tRp391
sg60
g61
sg81
V26-walkers_smoky_bacon.png
p392
sS'binary1.thisN'
p393
I1
sg25
F6.383
sa(dp394
g68
g69
sg22
S'left'
p395
sS'binary1.thisTrialN'
p396
I2
sS'binary1.thisRepN'
p397
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F3.4361825315791066
sg82
V20-fruit_pastilles.png
p398
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p399
g63
(g96
S'\x02\x00\x00\x00'
tRp400
sg60
g61
sg81
V2-steamed_puddings.png
p401
sS'binary1.thisN'
p402
I2
sg25
F1.2949999999999999
sa(dp403
g68
g69
sg22
S'left'
p404
sS'binary1.thisTrialN'
p405
I3
sS'binary1.thisRepN'
p406
I0
sg62
g66
sg24
F3.5
sg23
F4.2887484303173551
sg82
V49-yorkie.png
p407
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p408
g63
(g96
S'\x03\x00\x00\x00'
tRp409
sg60
g61
sg81
V35-sultanas.png
p410
sS'binary1.thisN'
p411
I3
sg25
F0.749
sa(dp412
g68
g69
sg22
S'right'
p413
sS'binary1.thisTrialN'
p414
I4
sS'binary1.thisRepN'
p415
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F4.9147941987048398
sg82
V30-spaghetti_hoops.png
p416
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p417
g63
(g96
S'\x04\x00\x00\x00'
tRp418
sg60
g61
sg81
V19-caramello.png
p419
sS'binary1.thisN'
p420
I4
sg25
F0.80200000000000005
sa(dp421
g68
g69
sg22
S'left'
p422
sS'binary1.thisTrialN'
p423
I5
sS'binary1.thisRepN'
p424
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.91911290401549195
sg82
V29-beans.png
p425
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p426
g63
(g96
S'\x05\x00\x00\x00'
tRp427
sg60
g61
sg81
V46-pistachios.png
p428
sS'binary1.thisN'
p429
I5
sg25
F0.749
sa(dp430
g68
g69
sg22
S'left'
p431
sS'binary1.thisTrialN'
p432
I6
sS'binary1.thisRepN'
p433
I0
sg62
g66
sg24
F3.7999999999999998
sg23
F4.4486271299847431
sg82
V42-mrkipling_lemon_slices.png
p434
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p435
g63
(g96
S'\x06\x00\x00\x00'
tRp436
sg60
g61
sg81
V16-skips_prawn.png
p437
sS'binary1.thisN'
p438
I6
sg25
F2.9060000000000001
sa(dp439
g68
g69
sg22
S'right'
p440
sS'binary1.thisTrialN'
p441
I7
sS'binary1.thisRepN'
p442
I0
sg62
g66
sg24
F4.3000000000000007
sg23
F1.7049189212593774
sg82
V35-sultanas.png
p443
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p444
g63
(g96
S'\x07\x00\x00\x00'
tRp445
sg60
g61
sg81
V49-yorkie.png
p446
sS'binary1.thisN'
p447
I7
sg25
F1.548
sa(dp448
g68
g69
sg22
S'left'
p449
sS'binary1.thisTrialN'
p450
I8
sS'binary1.thisRepN'
p451
I0
sg62
g66
sg24
F4.8000000000000007
sg23
F1.3985931172828714
sg82
V22-daim.png
p452
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p453
g63
(g96
S'\x08\x00\x00\x00'
tRp454
sg60
g61
sg81
V7-olives.png
p455
sS'binary1.thisN'
p456
I8
sg25
F1.641
sa(dp457
g68
g69
sg22
S'right'
p458
sS'binary1.thisTrialN'
p459
I9
sS'binary1.thisRepN'
p460
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F2.1710921360117936
sg82
V31-foxs_golden_biscuits.png
p461
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p462
g63
(g96
S'\t\x00\x00\x00'
tRp463
sg60
g61
sg81
V25-kitkat.png
p464
sS'binary1.thisN'
p465
I9
sg25
F1.0149999999999999
sa(dp466
g68
g69
sg22
S'left'
p467
sS'binary1.thisTrialN'
p468
I10
sS'binary1.thisRepN'
p469
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F5.2078152390859032
sg82
V36-fig_rolls.png
p470
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p471
g63
(g96
S'\n\x00\x00\x00'
tRp472
sg60
g61
sg81
V34-hula_hoops_bbq_beef.png
p473
sS'binary1.thisN'
p474
I10
sg25
F0.77500000000000002
sa(dp475
g68
g69
sg22
S'right'
p476
sS'binary1.thisTrialN'
p477
I11
sS'binary1.thisRepN'
p478
I0
sg62
g66
sg24
F3.5
sg23
F4.9947001644050033
sg82
V23-crunchie.png
p479
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p480
g63
(g96
S'\x0b\x00\x00\x00'
tRp481
sg60
g61
sg81
V33-ambrosia_rice.png
p482
sS'binary1.thisN'
p483
I11
sg25
F1.2949999999999999
sa(dp484
g68
g69
sg22
S'left'
p485
sS'binary1.thisTrialN'
p486
I12
sS'binary1.thisRepN'
p487
I0
sg62
g66
sg24
F3.8000000000000003
sg23
F4.5684979515554005
sg82
V21-nakd_banana_crunch.png
p488
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p489
g63
(g96
S'\x0c\x00\x00\x00'
tRp490
sg60
g61
sg81
V1-smarties_cookies.png
p491
sS'binary1.thisN'
p492
I12
sg25
F1.494
sa(dp493
g68
g69
sg22
S'left'
p494
sS'binary1.thisTrialN'
p495
I13
sS'binary1.thisRepN'
p496
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.2920359989875578
sg82
V10-bounty.png
p497
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p498
g63
(g96
S'\r\x00\x00\x00'
tRp499
sg60
g61
sg81
V4-corn.png
p500
sS'binary1.thisN'
p501
I13
sg25
F0.81499999999999995
sa(dp502
g68
g69
sg22
S'left'
p503
sS'binary1.thisTrialN'
p504
I14
sS'binary1.thisRepN'
p505
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.77252472032159858
sg82
V8-liquorice_catherine_wheels.png
p506
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p507
g63
(g96
S'\x0e\x00\x00\x00'
tRp508
sg60
g61
sg81
V17-jacobs_mini_cheddars.png
p509
sS'binary1.thisN'
p510
I14
sg25
F0.54900000000000004
sa(dp511
g68
g69
sg22
S'left'
p512
sS'binary1.thisTrialN'
p513
I15
sS'binary1.thisRepN'
p514
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.3320033691434219
sg82
V45-chewy_nougat.png
p515
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p516
g63
(g96
S'\x0f\x00\x00\x00'
tRp517
sg60
g61
sg81
V41-peanuts.png
p518
sS'binary1.thisN'
p519
I15
sg25
F0.52200000000000002
sa(dp520
g68
g69
sg22
S'right'
p521
sS'binary1.thisTrialN'
p522
I16
sS'binary1.thisRepN'
p523
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.77260629493321176
sg82
V26-walkers_smoky_bacon.png
p524
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p525
g63
(g96
S'\x10\x00\x00\x00'
tRp526
sg60
g61
sg81
V44-crunch.png
p527
sS'binary1.thisN'
p528
I16
sg25
F0.46899999999999997
sa(dp529
g68
g69
sg22
S'left'
p530
sS'binary1.thisTrialN'
p531
I17
sS'binary1.thisRepN'
p532
I0
sg62
g66
sg24
F4
sg23
F8.2178693102050602
sg82
V51-mars.png
p533
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p534
g63
(g96
S'\x11\x00\x00\x00'
tRp535
sg60
g61
sg81
V27-hartleys_raspberries_jelly.png
p536
sS'binary1.thisN'
p537
I17
sg25
F1.175
sa(dp538
g68
g69
sg22
S'left'
p539
sS'binary1.thisTrialN'
p540
I18
sS'binary1.thisRepN'
p541
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.81256360794577631
sg82
V18-mms.png
p542
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p543
g63
(g96
S'\x12\x00\x00\x00'
tRp544
sg60
g61
sg81
V43-mrporky_pork_crackles.png
p545
sS'binary1.thisN'
p546
I18
sg25
F0.77500000000000002
sa(dp547
g68
g69
sg22
S'right'
p548
sS'binary1.thisTrialN'
p549
I19
sS'binary1.thisRepN'
p550
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F6.2333522835997428
sg82
V16-skips_prawn.png
p551
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p552
g63
(g96
S'\x13\x00\x00\x00'
tRp553
sg60
g61
sg81
V42-mrkipling_lemon_slices.png
p554
sS'binary1.thisN'
p555
I19
sg25
F0.68200000000000005
sa(dp556
g68
g69
sg22
S'right'
p557
sS'binary1.thisTrialN'
p558
I20
sS'binary1.thisRepN'
p559
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.87917849894256506
sg82
V43-mrporky_pork_crackles.png
p560
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p561
g63
(g96
S'\x14\x00\x00\x00'
tRp562
sg60
g61
sg81
V18-mms.png
p563
sS'binary1.thisN'
p564
I20
sg25
F0.66900000000000004
sa(dp565
g68
g69
sg22
S'right'
p566
sS'binary1.thisTrialN'
p567
I21
sS'binary1.thisRepN'
p568
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.98570544580252317
sg82
V4-corn.png
p569
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p570
g63
(g96
S'\x15\x00\x00\x00'
tRp571
sg60
g61
sg81
V10-bounty.png
p572
sS'binary1.thisN'
p573
I21
sg25
F0.46899999999999997
sa(dp574
g68
g69
sg22
S'left'
p575
sS'binary1.thisTrialN'
p576
I22
sS'binary1.thisRepN'
p577
I0
sg62
g66
sg24
F4.9000000000000012
sg23
F3.9691469167173636
sg82
V6-sour_patch_kids.png
p578
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p579
g63
(g96
S'\x16\x00\x00\x00'
tRp580
sg60
g61
sg81
V38-maltesers.png
p581
sS'binary1.thisN'
p582
I22
sg25
F0.629
sa(dp583
g68
g69
sg22
S'left'
p584
sS'binary1.thisTrialN'
p585
I23
sS'binary1.thisRepN'
p586
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.77260098699662194
sg82
V5-pineapple.png
p587
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p588
g63
(g96
S'\x17\x00\x00\x00'
tRp589
sg60
g61
sg81
V40-sardines.png
p590
sS'binary1.thisN'
p591
I23
sg25
F0.53500000000000003
sa(dp592
g68
g69
sg22
S'right'
p593
sS'binary1.thisTrialN'
p594
I24
sS'binary1.thisRepN'
p595
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F2.2776445050985785
sg82
V17-jacobs_mini_cheddars.png
p596
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p597
g63
(g96
S'\x18\x00\x00\x00'
tRp598
sg60
g61
sg81
V8-liquorice_catherine_wheels.png
p599
sS'binary1.thisN'
p600
I24
sg25
F0.94799999999999995
sa(dp601
g68
g69
sg22
S'right'
p602
sS'binary1.thisTrialN'
p603
I25
sS'binary1.thisRepN'
p604
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.0523119558492908
sg82
V2-steamed_puddings.png
p605
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p606
g63
(g96
S'\x19\x00\x00\x00'
tRp607
sg60
g61
sg81
V20-fruit_pastilles.png
p608
sS'binary1.thisN'
p609
I25
sg25
F1.2010000000000001
sa(dp610
g68
g69
sg22
S'right'
p611
sS'binary1.thisTrialN'
p612
I26
sS'binary1.thisRepN'
p613
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.6250394952439819
sg82
V48-twix.png
p614
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p615
g63
(g96
S'\x1a\x00\x00\x00'
tRp616
sg60
g61
sg81
V50-polo.png
p617
sS'binary1.thisN'
p618
I26
sg25
F0.42899999999999999
sa(dp619
g68
g69
sg22
S'left'
p620
sS'binary1.thisTrialN'
p621
I27
sS'binary1.thisRepN'
p622
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.1189072912911797
sg82
V19-caramello.png
p623
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p624
g63
(g96
S'\x1b\x00\x00\x00'
tRp625
sg60
g61
sg81
V30-spaghetti_hoops.png
p626
sS'binary1.thisN'
p627
I27
sg25
F0.495
sa(dp628
g68
g69
sg22
S'left'
p629
sS'binary1.thisTrialN'
p630
I28
sS'binary1.thisRepN'
p631
I0
sg62
g66
sg24
F4.9000000000000012
sg23
F2.9435844499785162
sg82
V25-kitkat.png
p632
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p633
g63
(g96
S'\x1c\x00\x00\x00'
tRp634
sg60
g61
sg81
V31-foxs_golden_biscuits.png
p635
sS'binary1.thisN'
p636
I28
sg25
F0.82799999999999996
sa(dp637
g68
g69
sg22
S'right'
p638
sS'binary1.thisTrialN'
p639
I29
sS'binary1.thisRepN'
p640
I0
sg62
g66
sg24
F5.1000000000000005
sg23
F2.3442295040294994
sg82
V46-pistachios.png
p641
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p642
g63
(g96
S'\x1d\x00\x00\x00'
tRp643
sg60
g61
sg81
V29-beans.png
p644
sS'binary1.thisN'
p645
I29
sg25
F1.3080000000000001
sa(dp646
g68
g69
sg22
S'left'
p647
sS'binary1.thisTrialN'
p648
I30
sS'binary1.thisRepN'
p649
I0
sg62
g66
sg24
F4
sg23
F1.6383389509010158
sg82
V27-hartleys_raspberries_jelly.png
p650
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p651
g63
(g96
S'\x1e\x00\x00\x00'
tRp652
sg60
g61
sg81
V51-mars.png
p653
sS'binary1.thisN'
p654
I30
sg25
F1.4410000000000001
sa(dp655
g68
g69
sg22
S'left'
p656
sS'binary1.thisTrialN'
p657
I31
sS'binary1.thisRepN'
p658
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.81256416667383746
sg82
V50-polo.png
p659
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p660
g63
(g96
S'\x1f\x00\x00\x00'
tRp661
sg60
g61
sg81
V48-twix.png
p662
sS'binary1.thisN'
p663
I31
sg25
F0.46899999999999997
sa(dp664
g68
g69
sg22
S'right'
p665
sS'binary1.thisTrialN'
p666
I32
sS'binary1.thisRepN'
p667
I0
sg62
g66
sg24
F2.8999999999999995
sg23
F2.983550702672801
sg82
V7-olives.png
p668
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p669
g63
(g96
S' \x00\x00\x00'
tRp670
sg60
g61
sg81
V22-daim.png
p671
sS'binary1.thisN'
p672
I32
sg25
F1.8939999999999999
sa(dp673
g68
g69
sg22
S'right'
p674
sS'binary1.thisTrialN'
p675
I33
sS'binary1.thisRepN'
p676
I0
sg62
g66
sg24
F4.9000000000000012
sg23
F1.3850944742971478
sg82
V38-maltesers.png
p677
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p678
g63
(g96
S'!\x00\x00\x00'
tRp679
sg60
g61
sg81
V6-sour_patch_kids.png
p680
sS'binary1.thisN'
p681
I33
sg25
F0.52200000000000002
sa(dp682
g68
g69
sg22
S'left'
p683
sS'binary1.thisTrialN'
p684
I34
sS'binary1.thisRepN'
p685
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.61277480797252792
sg82
V3-dole_fruit_snack.png
p686
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p687
g63
(g96
S'"\x00\x00\x00'
tRp688
sg60
g61
sg81
V13-mccoys_steak_crisps.png
p689
sS'binary1.thisN'
p690
I34
sg25
F0.64200000000000002
sa(dp691
g68
g69
sg22
S'right'
p692
sS'binary1.thisTrialN'
p693
I35
sS'binary1.thisRepN'
p694
I0
sg62
g66
sg24
F4.5
sg23
F2.1444507612013695
sg82
V1-smarties_cookies.png
p695
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p696
g63
(g96
S'#\x00\x00\x00'
tRp697
sg60
g61
sg81
V21-nakd_banana_crunch.png
p698
sS'binary1.thisN'
p699
I35
sg25
F1.2809999999999999
sa(dp700
g68
g69
sg22
S'right'
p701
sS'binary1.thisTrialN'
p702
I36
sS'binary1.thisRepN'
p703
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F1.2121085221715475
sg82
V34-hula_hoops_bbq_beef.png
p704
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p705
g63
(g96
S'$\x00\x00\x00'
tRp706
sg60
g61
sg81
V36-fig_rolls.png
p707
sS'binary1.thisN'
p708
I36
sg25
F0.496
sa(dp709
g68
g69
sg22
S'right'
p710
sS'binary1.thisTrialN'
p711
I37
sS'binary1.thisRepN'
p712
I0
sg62
g66
sg24
F5.0000000000000009
sg23
F7.1788051274688769
sg82
V41-peanuts.png
p713
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p714
g63
(g96
S'%\x00\x00\x00'
tRp715
sg60
g61
sg81
V45-chewy_nougat.png
p716
sS'binary1.thisN'
p717
I37
sg25
F1.161
sa(dp718
g68
g69
sg22
S'right'
p719
sS'binary1.thisTrialN'
p720
I38
sS'binary1.thisRepN'
p721
I0
sg62
g66
sg24
F5.9999999999999973
sg23
F0.85253237492543121
sg82
V40-sardines.png
p722
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p723
g63
(g96
S'&\x00\x00\x00'
tRp724
sg60
g61
sg81
V5-pineapple.png
p725
sS'binary1.thisN'
p726
I38
sg25
F0.48199999999999998
sa(dp727
g68
g69
sg22
S'left'
p728
sS'binary1.thisTrialN'
p729
I39
sS'binary1.thisRepN'
p730
I0
sg62
g66
sg24
F5.3999999999999995
sg23
F1.2520839939152211
sg82
V33-ambrosia_rice.png
p731
sg70
g71
sg67
g11
sS'binary1.thisIndex'
p732
g63
(g96
S"'\x00\x00\x00"
tRp733
sg60
g61
sg81
V23-crunchie.png
p734
sS'binary1.thisN'
p735
I39
sg25
F0.88200000000000001
sa(dp736
g68
g69
sg27
F253.24572927564805
sg67
g11
sg70
g71
sg26
S'space'
p737
sg60
g61
sg62
g66
sa(dp738
g68
g69
sg67
g11
sg70
g71
sg29
F4.7018506542026444
sg60
g61
sg28
S'space'
p739
sg62
g66
sa(dp740
g68
g69
sg83
V11-snickers.png
p741
sg84
V54-frubes_yogurt.png
p742
sg70
g71
sS'practice_loop.thisN'
p743
I0
sS'practice_loop.thisTrialN'
p744
I0
sg62
g66
sS'practice_loop.thisRepN'
p745
I0
sg30
V54-frubes_yogurt.png
p746
sg67
g11
sg85
g746
sg60
g61
sS'practice_loop.thisIndex'
p747
g63
(g96
S'\x00\x00\x00\x00'
tRp748
sg86
V11-snickers.png
p749
sa(dp750
g68
g69
sg83
V37-nakd_cashew_cookie.png
p751
sg84
V9-yu_mango_pieces.png
p752
sg70
g71
sS'practice_loop.thisN'
p753
I1
sS'practice_loop.thisTrialN'
p754
I1
sg62
g66
sS'practice_loop.thisRepN'
p755
I0
sg30
g751
sg67
g11
sg85
V9-yu_mango_pieces.png
p756
sg60
g61
sS'practice_loop.thisIndex'
p757
g63
(g96
S'\x01\x00\x00\x00'
tRp758
sg86
V37-nakd_cashew_cookie.png
p759
sa(dp760
g68
g69
sg83
V15-walnut_whip.png
p761
sg84
V28-maple_pecan.png
p762
sg70
g71
sS'practice_loop.thisN'
p763
I2
sS'practice_loop.thisTrialN'
p764
I2
sg62
g66
sS'practice_loop.thisRepN'
p765
I0
sg30
V28-maple_pecan.png
p766
sg67
g11
sg85
g766
sg60
g61
sS'practice_loop.thisIndex'
p767
g63
(g96
S'\x02\x00\x00\x00'
tRp768
sg86
V15-walnut_whip.png
p769
sa(dp770
g68
g69
sg83
V37-nakd_cashew_cookie.png
p771
sg84
V37-nakd_cashew_cookie.png
p772
sg70
g71
sS'practice_loop.thisN'
p773
I3
sS'practice_loop.thisTrialN'
p774
I3
sg62
g66
sS'practice_loop.thisRepN'
p775
I0
sg30
g771
sg67
g11
sg85
V9-yu_mango_pieces.png
p776
sg60
g61
sS'practice_loop.thisIndex'
p777
g63
(g96
S'\x03\x00\x00\x00'
tRp778
sg86
V9-yu_mango_pieces.png
p779
sa(dp780
g68
g69
sg83
V12-topic.png
p781
sg84
V39-mackerel.png
p782
sg70
g71
sS'practice_loop.thisN'
p783
I4
sS'practice_loop.thisTrialN'
p784
I4
sg62
g66
sS'practice_loop.thisRepN'
p785
I0
sg30
g781
sg67
g11
sg85
V39-mackerel.png
p786
sg60
g61
sS'practice_loop.thisIndex'
p787
g63
(g96
S'\x04\x00\x00\x00'
tRp788
sg86
V12-topic.png
p789
sa(dp790
g68
g69
sg83
V52-aero_mousse.png
p791
sg84
V14-discos_salt_vinegar.png
p792
sg70
g71
sS'practice_loop.thisN'
p793
I5
sS'practice_loop.thisTrialN'
p794
I5
sg62
g66
sS'practice_loop.thisRepN'
p795
I0
sg30
V14-discos_salt_vinegar.png
p796
sg67
g11
sg85
g796
sg60
g61
sS'practice_loop.thisIndex'
p797
g63
(g96
S'\x05\x00\x00\x00'
tRp798
sg86
V52-aero_mousse.png
p799
sa(dp800
g68
g69
sg83
V53-cheestrings.png
p801
sg84
V47-picnic.png
p802
sg70
g71
sS'practice_loop.thisN'
p803
I6
sS'practice_loop.thisTrialN'
p804
I6
sg62
g66
sS'practice_loop.thisRepN'
p805
I0
sg30
g801
sg67
g11
sg85
V47-picnic.png
p806
sg60
g61
sS'practice_loop.thisIndex'
p807
g63
(g96
S'\x06\x00\x00\x00'
tRp808
sg86
V53-cheestrings.png
p809
sa(dp810
g68
g69
sg83
V15-walnut_whip.png
p811
sg84
V15-walnut_whip.png
p812
sg70
g71
sS'practice_loop.thisN'
p813
I7
sS'practice_loop.thisTrialN'
p814
I7
sg62
g66
sS'practice_loop.thisRepN'
p815
I0
sg30
g811
sg67
g11
sg85
V28-maple_pecan.png
p816
sg60
g61
sS'practice_loop.thisIndex'
p817
g63
(g96
S'\x07\x00\x00\x00'
tRp818
sg86
V28-maple_pecan.png
p819
sa(dp820
g68
g69
sg83
V52-aero_mousse.png
p821
sg84
V52-aero_mousse.png
p822
sg70
g71
sS'practice_loop.thisN'
p823
I8
sS'practice_loop.thisTrialN'
p824
I8
sg62
g66
sS'practice_loop.thisRepN'
p825
I0
sg30
g821
sg67
g11
sg85
V14-discos_salt_vinegar.png
p826
sg60
g61
sS'practice_loop.thisIndex'
p827
g63
(g96
S'\x08\x00\x00\x00'
tRp828
sg86
V14-discos_salt_vinegar.png
p829
sa(dp830
g68
g69
sg83
V32-hovis_crackers.png
p831
sg84
V24-food_doctor_apple_walnut_bar.png
p832
sg70
g71
sS'practice_loop.thisN'
p833
I9
sS'practice_loop.thisTrialN'
p834
I9
sg62
g66
sS'practice_loop.thisRepN'
p835
I0
sg30
g831
sg67
g11
sg85
V24-food_doctor_apple_walnut_bar.png
p836
sg60
g61
sS'practice_loop.thisIndex'
p837
g63
(g96
S'\t\x00\x00\x00'
tRp838
sg86
V32-hovis_crackers.png
p839
sa(dp840
g68
g69
sg83
V11-snickers.png
p841
sg84
V11-snickers.png
p842
sg70
g71
sS'practice_loop.thisN'
p843
I10
sS'practice_loop.thisTrialN'
p844
I10
sg62
g66
sS'practice_loop.thisRepN'
p845
I0
sg30
g841
sg67
g11
sg85
V54-frubes_yogurt.png
p846
sg60
g61
sS'practice_loop.thisIndex'
p847
g63
(g96
S'\n\x00\x00\x00'
tRp848
sg86
V54-frubes_yogurt.png
p849
sa(dp850
g68
g69
sg83
V12-topic.png
p851
sg84
V12-topic.png
p852
sg70
g71
sS'practice_loop.thisN'
p853
I11
sS'practice_loop.thisTrialN'
p854
I11
sg62
g66
sS'practice_loop.thisRepN'
p855
I0
sg30
g851
sg67
g11
sg85
V39-mackerel.png
p856
sg60
g61
sS'practice_loop.thisIndex'
p857
g63
(g96
S'\x0b\x00\x00\x00'
tRp858
sg86
V39-mackerel.png
p859
sa(dp860
g68
g69
sg83
V32-hovis_crackers.png
p861
sg84
V32-hovis_crackers.png
p862
sg70
g71
sS'practice_loop.thisN'
p863
I12
sS'practice_loop.thisTrialN'
p864
I12
sg62
g66
sS'practice_loop.thisRepN'
p865
I0
sg30
V24-food_doctor_apple_walnut_bar.png
p866
sg67
g11
sg85
g866
sg60
g61
sS'practice_loop.thisIndex'
p867
g63
(g96
S'\x0c\x00\x00\x00'
tRp868
sg86
V24-food_doctor_apple_walnut_bar.png
p869
sa(dp870
g68
g69
sg83
V53-cheestrings.png
p871
sg84
V53-cheestrings.png
p872
sg70
g71
sS'practice_loop.thisN'
p873
I13
sS'practice_loop.thisTrialN'
p874
I13
sg62
g66
sS'practice_loop.thisRepN'
p875
I0
sg30
V47-picnic.png
p876
sg67
g11
sg85
g876
sg60
g61
sS'practice_loop.thisIndex'
p877
g63
(g96
S'\r\x00\x00\x00'
tRp878
sg86
V47-picnic.png
p879
sa(dp880
g68
g69
sg67
g11
sg70
g71
sg32
F6.313441233452977
sg60
g61
sg62
g66
sg31
S'space'
p881
sa(dp882
S'block_loop.thisRepN'
p883
I0
sS'img_correct'
p884
V46-pistachios.png
p885
sS'img_left'
p886
V46-pistachios.png
p887
sg70
g71
sS'outcome_loop.thisRepN'
p888
I0
sS'block_loop.thisIndex'
p889
g63
(g96
S'\x00\x00\x00\x00'
tRp890
sS'outcome_loop.thisN'
p891
I0
sS'outcome_loop.thisTrialN'
p892
I0
sg62
g66
sg33
S'left'
p893
sS'block_loop.thisN'
p894
I0
sS'outcome_loop.thisIndex'
p895
g63
(g96
S'\x00\x00\x00\x00'
tRp896
sg30
g885
sg67
g11
sg68
g69
sS'img_wrong'
p897
V29-beans.png
p898
sS'block_loop.thisTrial'
p899
Nsg60
g61
sS'block_loop.thisTrialN'
p900
I0
sg34
F1.6383738715394429
sS'img_right'
p901
V29-beans.png
p902
sa(dp903
S'block_loop.thisRepN'
p904
I0
sg884
V13-mccoys_steak_crisps.png
p905
sg886
V3-dole_fruit_snack.png
p906
sg70
g71
sS'outcome_loop.thisRepN'
p907
I0
sS'block_loop.thisIndex'
p908
g890
sS'outcome_loop.thisN'
p909
I1
sS'outcome_loop.thisTrialN'
p910
I1
sg62
g66
sg33
S'right'
p911
sS'block_loop.thisN'
p912
I0
sS'outcome_loop.thisIndex'
p913
g63
(g96
S'\x01\x00\x00\x00'
tRp914
sg30
g905
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p915
sS'block_loop.thisTrial'
p916
Nsg60
g61
sS'block_loop.thisTrialN'
p917
I0
sg34
F0.9058036705791892
sg901
V13-mccoys_steak_crisps.png
p918
sa(dp919
S'block_loop.thisRepN'
p920
I0
sg884
V48-twix.png
p921
sg886
V50-polo.png
p922
sg70
g71
sS'outcome_loop.thisRepN'
p923
I0
sS'block_loop.thisIndex'
p924
g890
sS'outcome_loop.thisN'
p925
I2
sS'outcome_loop.thisTrialN'
p926
I2
sg62
g66
sg33
S'right'
p927
sS'block_loop.thisN'
p928
I0
sS'outcome_loop.thisIndex'
p929
g63
(g96
S'\x02\x00\x00\x00'
tRp930
sg30
V50-polo.png
p931
sg67
g11
sg68
g69
sg897
g931
sS'block_loop.thisTrial'
p932
Nsg60
g61
sS'block_loop.thisTrialN'
p933
I0
sg34
F1.3186673166565015
sg901
V48-twix.png
p934
sa(dp935
S'block_loop.thisRepN'
p936
I0
sg884
V36-fig_rolls.png
p937
sg886
V36-fig_rolls.png
p938
sg70
g71
sS'outcome_loop.thisRepN'
p939
I0
sS'block_loop.thisIndex'
p940
g890
sS'outcome_loop.thisN'
p941
I3
sS'outcome_loop.thisTrialN'
p942
I3
sg62
g66
sg33
S'right'
p943
sS'block_loop.thisN'
p944
I0
sS'outcome_loop.thisIndex'
p945
g63
(g96
S'\x03\x00\x00\x00'
tRp946
sg30
g937
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p947
sS'block_loop.thisTrial'
p948
Nsg60
g61
sS'block_loop.thisTrialN'
p949
I0
sg34
F0.7992387300619157
sg901
V34-hula_hoops_bbq_beef.png
p950
sa(dp951
S'block_loop.thisRepN'
p952
I0
sg884
V48-twix.png
p953
sg886
V48-twix.png
p954
sg70
g71
sS'outcome_loop.thisRepN'
p955
I0
sS'block_loop.thisIndex'
p956
g890
sS'outcome_loop.thisN'
p957
I4
sS'outcome_loop.thisTrialN'
p958
I4
sg62
g66
sg33
S'right'
p959
sS'block_loop.thisN'
p960
I0
sS'outcome_loop.thisIndex'
p961
g63
(g96
S'\x04\x00\x00\x00'
tRp962
sg30
V50-polo.png
p963
sg67
g11
sg68
g69
sg897
g963
sS'block_loop.thisTrial'
p964
Nsg60
g61
sS'block_loop.thisTrialN'
p965
I0
sg34
F2.6638860525581549
sg901
V50-polo.png
p966
sa(dp967
S'block_loop.thisRepN'
p968
I0
sg884
V51-mars.png
p969
sg886
V27-hartleys_raspberries_jelly.png
p970
sg70
g71
sS'outcome_loop.thisRepN'
p971
I0
sS'block_loop.thisIndex'
p972
g890
sS'outcome_loop.thisN'
p973
I5
sS'outcome_loop.thisTrialN'
p974
I5
sg62
g66
sg33
S'right'
p975
sS'block_loop.thisN'
p976
I0
sS'outcome_loop.thisIndex'
p977
g63
(g96
S'\x05\x00\x00\x00'
tRp978
sg30
g969
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p979
sS'block_loop.thisTrial'
p980
Nsg60
g61
sS'block_loop.thisTrialN'
p981
I0
sg34
F1.2920538783564552
sg901
V51-mars.png
p982
sa(dp983
S'block_loop.thisRepN'
p984
I0
sg884
V33-ambrosia_rice.png
p985
sg886
V33-ambrosia_rice.png
p986
sg70
g71
sS'outcome_loop.thisRepN'
p987
I0
sS'block_loop.thisIndex'
p988
g890
sS'outcome_loop.thisN'
p989
I6
sS'outcome_loop.thisTrialN'
p990
I6
sg62
g66
sg33
S'right'
p991
sS'block_loop.thisN'
p992
I0
sS'outcome_loop.thisIndex'
p993
g63
(g96
S'\x06\x00\x00\x00'
tRp994
sg30
V23-crunchie.png
p995
sg67
g11
sg68
g69
sg897
g995
sS'block_loop.thisTrial'
p996
Nsg60
g61
sS'block_loop.thisTrialN'
p997
I0
sg34
F1.0789499782804342
sg901
V23-crunchie.png
p998
sa(dp999
S'block_loop.thisRepN'
p1000
I0
sg884
V36-fig_rolls.png
p1001
sg886
V34-hula_hoops_bbq_beef.png
p1002
sg70
g71
sS'outcome_loop.thisRepN'
p1003
I0
sS'block_loop.thisIndex'
p1004
g890
sS'outcome_loop.thisN'
p1005
I7
sS'outcome_loop.thisTrialN'
p1006
I7
sg62
g66
sg33
S'right'
p1007
sS'block_loop.thisN'
p1008
I0
sS'outcome_loop.thisIndex'
p1009
g63
(g96
S'\x07\x00\x00\x00'
tRp1010
sg30
V34-hula_hoops_bbq_beef.png
p1011
sg67
g11
sg68
g69
sg897
g1011
sS'block_loop.thisTrial'
p1012
Nsg60
g61
sS'block_loop.thisTrialN'
p1013
I0
sg34
F1.5051681149416254
sg901
V36-fig_rolls.png
p1014
sa(dp1015
S'block_loop.thisRepN'
p1016
I0
sg884
V26-walkers_smoky_bacon.png
p1017
sg886
V44-crunch.png
p1018
sg70
g71
sS'outcome_loop.thisRepN'
p1019
I0
sS'block_loop.thisIndex'
p1020
g890
sS'outcome_loop.thisN'
p1021
I8
sS'outcome_loop.thisTrialN'
p1022
I8
sg62
g66
sg33
S'right'
p1023
sS'block_loop.thisN'
p1024
I0
sS'outcome_loop.thisIndex'
p1025
g63
(g96
S'\x08\x00\x00\x00'
tRp1026
sg30
g1017
sg67
g11
sg68
g69
sg897
V44-crunch.png
p1027
sS'block_loop.thisTrial'
p1028
Nsg60
g61
sS'block_loop.thisTrialN'
p1029
I0
sg34
F0.81256640159517701
sg901
V26-walkers_smoky_bacon.png
p1030
sa(dp1031
S'block_loop.thisRepN'
p1032
I0
sg884
V7-olives.png
p1033
sg886
V22-daim.png
p1034
sg70
g71
sS'outcome_loop.thisRepN'
p1035
I0
sS'block_loop.thisIndex'
p1036
g890
sS'outcome_loop.thisN'
p1037
I9
sS'outcome_loop.thisTrialN'
p1038
I9
sg62
g66
sg33
S'left'
p1039
sS'block_loop.thisN'
p1040
I0
sS'outcome_loop.thisIndex'
p1041
g63
(g96
S'\t\x00\x00\x00'
tRp1042
sg30
g1033
sg67
g11
sg68
g69
sg897
V22-daim.png
p1043
sS'block_loop.thisTrial'
p1044
Nsg60
g61
sS'block_loop.thisTrialN'
p1045
I0
sg34
F1.1855059791123495
sg901
V7-olives.png
p1046
sa(dp1047
S'block_loop.thisRepN'
p1048
I0
sg884
V26-walkers_smoky_bacon.png
p1049
sg886
V44-crunch.png
p1050
sg70
g71
sS'outcome_loop.thisRepN'
p1051
I0
sS'block_loop.thisIndex'
p1052
g890
sS'outcome_loop.thisN'
p1053
I10
sS'outcome_loop.thisTrialN'
p1054
I10
sg62
g66
sg33
S'right'
p1055
sS'block_loop.thisN'
p1056
I0
sS'outcome_loop.thisIndex'
p1057
g63
(g96
S'\n\x00\x00\x00'
tRp1058
sg30
V44-crunch.png
p1059
sg67
g11
sg68
g69
sg897
g1059
sS'block_loop.thisTrial'
p1060
Nsg60
g61
sS'block_loop.thisTrialN'
p1061
I0
sg34
F0.94576740898628486
sg901
V26-walkers_smoky_bacon.png
p1062
sa(dp1063
S'block_loop.thisRepN'
p1064
I0
sg884
V4-corn.png
p1065
sg886
V4-corn.png
p1066
sg70
g71
sS'outcome_loop.thisRepN'
p1067
I0
sS'block_loop.thisIndex'
p1068
g890
sS'outcome_loop.thisN'
p1069
I11
sS'outcome_loop.thisTrialN'
p1070
I11
sg62
g66
sg33
S'right'
p1071
sS'block_loop.thisN'
p1072
I0
sS'outcome_loop.thisIndex'
p1073
g63
(g96
S'\x0b\x00\x00\x00'
tRp1074
sg30
g1065
sg67
g11
sg68
g69
sg897
V10-bounty.png
p1075
sS'block_loop.thisTrial'
p1076
Nsg60
g61
sS'block_loop.thisTrialN'
p1077
I0
sg34
F2.0645297097817092
sg901
V10-bounty.png
p1078
sa(dp1079
S'block_loop.thisRepN'
p1080
I0
sg884
V6-sour_patch_kids.png
p1081
sg886
V6-sour_patch_kids.png
p1082
sg70
g71
sS'outcome_loop.thisRepN'
p1083
I0
sS'block_loop.thisIndex'
p1084
g890
sS'outcome_loop.thisN'
p1085
I12
sS'outcome_loop.thisTrialN'
p1086
I12
sg62
g66
sg33
S'right'
p1087
sS'block_loop.thisN'
p1088
I0
sS'outcome_loop.thisIndex'
p1089
g63
(g96
S'\x0c\x00\x00\x00'
tRp1090
sg30
g1081
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p1091
sS'block_loop.thisTrial'
p1092
Nsg60
g61
sS'block_loop.thisTrialN'
p1093
I0
sg34
F1.5717335583158274
sg901
V38-maltesers.png
p1094
sa(dp1095
S'block_loop.thisRepN'
p1096
I0
sg884
V19-caramello.png
p1097
sg886
V30-spaghetti_hoops.png
p1098
sg70
g71
sS'outcome_loop.thisRepN'
p1099
I0
sS'block_loop.thisIndex'
p1100
g890
sS'outcome_loop.thisN'
p1101
I13
sS'outcome_loop.thisTrialN'
p1102
I13
sg62
g66
sg33
S'right'
p1103
sS'block_loop.thisN'
p1104
I0
sS'outcome_loop.thisIndex'
p1105
g63
(g96
S'\r\x00\x00\x00'
tRp1106
sg30
g1097
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p1107
sS'block_loop.thisTrial'
p1108
Nsg60
g61
sS'block_loop.thisTrialN'
p1109
I0
sg34
F1.7981589838927903
sg901
V19-caramello.png
p1110
sa(dp1111
S'block_loop.thisRepN'
p1112
I0
sg884
V49-yorkie.png
p1113
sg886
V35-sultanas.png
p1114
sg70
g71
sS'outcome_loop.thisRepN'
p1115
I0
sS'block_loop.thisIndex'
p1116
g890
sS'outcome_loop.thisN'
p1117
I14
sS'outcome_loop.thisTrialN'
p1118
I14
sg62
g66
sg33
S'right'
p1119
sS'block_loop.thisN'
p1120
I0
sS'outcome_loop.thisIndex'
p1121
g63
(g96
S'\x0e\x00\x00\x00'
tRp1122
sg30
g1113
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p1123
sS'block_loop.thisTrial'
p1124
Nsg60
g61
sS'block_loop.thisTrialN'
p1125
I0
sg34
F1.9446845898000902
sg901
V49-yorkie.png
p1126
sa(dp1127
S'block_loop.thisRepN'
p1128
I0
sg884
V45-chewy_nougat.png
p1129
sg886
V45-chewy_nougat.png
p1130
sg70
g71
sS'outcome_loop.thisRepN'
p1131
I0
sS'block_loop.thisIndex'
p1132
g890
sS'outcome_loop.thisN'
p1133
I15
sS'outcome_loop.thisTrialN'
p1134
I15
sg62
g66
sg33
S'left'
p1135
sS'block_loop.thisN'
p1136
I0
sS'outcome_loop.thisIndex'
p1137
g63
(g96
S'\x0f\x00\x00\x00'
tRp1138
sg30
g1129
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p1139
sS'block_loop.thisTrial'
p1140
Nsg60
g61
sS'block_loop.thisTrialN'
p1141
I0
sg34
F1.9047130291710346
sg901
V41-peanuts.png
p1142
sa(dp1143
S'block_loop.thisRepN'
p1144
I0
sg884
V31-foxs_golden_biscuits.png
p1145
sg886
V25-kitkat.png
p1146
sg70
g71
sS'outcome_loop.thisRepN'
p1147
I0
sS'block_loop.thisIndex'
p1148
g890
sS'outcome_loop.thisN'
p1149
I16
sS'outcome_loop.thisTrialN'
p1150
I16
sg62
g66
sg33
S'left'
p1151
sS'block_loop.thisN'
p1152
I0
sS'outcome_loop.thisIndex'
p1153
g63
(g96
S'\x10\x00\x00\x00'
tRp1154
sg30
g1145
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p1155
sS'block_loop.thisTrial'
p1156
Nsg60
g61
sS'block_loop.thisTrialN'
p1157
I0
sg34
F1.7715299011470051
sg901
V31-foxs_golden_biscuits.png
p1158
sa(dp1159
S'block_loop.thisRepN'
p1160
I0
sg884
V19-caramello.png
p1161
sg886
V19-caramello.png
p1162
sg70
g71
sS'outcome_loop.thisRepN'
p1163
I0
sS'block_loop.thisIndex'
p1164
g890
sS'outcome_loop.thisN'
p1165
I17
sS'outcome_loop.thisTrialN'
p1166
I17
sg62
g66
sg33
S'left'
p1167
sS'block_loop.thisN'
p1168
I0
sS'outcome_loop.thisIndex'
p1169
g63
(g96
S'\x11\x00\x00\x00'
tRp1170
sg30
V30-spaghetti_hoops.png
p1171
sg67
g11
sg68
g69
sg897
g1171
sS'block_loop.thisTrial'
p1172
Nsg60
g61
sS'block_loop.thisTrialN'
p1173
I0
sg34
F0.89248354190385726
sg901
V30-spaghetti_hoops.png
p1174
sa(dp1175
S'block_loop.thisRepN'
p1176
I0
sg884
V13-mccoys_steak_crisps.png
p1177
sg886
V13-mccoys_steak_crisps.png
p1178
sg70
g71
sS'outcome_loop.thisRepN'
p1179
I0
sS'block_loop.thisIndex'
p1180
g890
sS'outcome_loop.thisN'
p1181
I18
sS'outcome_loop.thisTrialN'
p1182
I18
sg62
g66
sg33
S'left'
p1183
sS'block_loop.thisN'
p1184
I0
sS'outcome_loop.thisIndex'
p1185
g63
(g96
S'\x12\x00\x00\x00'
tRp1186
sg30
g1177
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p1187
sS'block_loop.thisTrial'
p1188
Nsg60
g61
sS'block_loop.thisTrialN'
p1189
I0
sg34
F0.98572304580557102
sg901
V3-dole_fruit_snack.png
p1190
sa(dp1191
S'block_loop.thisRepN'
p1192
I0
sg884
V1-smarties_cookies.png
p1193
sg886
V1-smarties_cookies.png
p1194
sg70
g71
sS'outcome_loop.thisRepN'
p1195
I0
sS'block_loop.thisIndex'
p1196
g890
sS'outcome_loop.thisN'
p1197
I19
sS'outcome_loop.thisTrialN'
p1198
I19
sg62
g66
sg33
S'left'
p1199
sS'block_loop.thisN'
p1200
I0
sS'outcome_loop.thisIndex'
p1201
g63
(g96
S'\x13\x00\x00\x00'
tRp1202
sg30
V21-nakd_banana_crunch.png
p1203
sg67
g11
sg68
g69
sg897
g1203
sS'block_loop.thisTrial'
p1204
Nsg60
g61
sS'block_loop.thisTrialN'
p1205
I0
sg34
F2.3708708788399235
sg901
V21-nakd_banana_crunch.png
p1206
sa(dp1207
S'block_loop.thisRepN'
p1208
I0
sg884
V48-twix.png
p1209
sg886
V50-polo.png
p1210
sg70
g71
sS'outcome_loop.thisRepN'
p1211
I0
sS'block_loop.thisIndex'
p1212
g890
sS'outcome_loop.thisN'
p1213
I20
sS'outcome_loop.thisTrialN'
p1214
I20
sg62
g66
sg33
S'left'
p1215
sS'block_loop.thisN'
p1216
I0
sS'outcome_loop.thisIndex'
p1217
g63
(g96
S'\x14\x00\x00\x00'
tRp1218
sg30
g1209
sg67
g11
sg68
g69
sg897
V50-polo.png
p1219
sS'block_loop.thisTrial'
p1220
Nsg60
g61
sS'block_loop.thisTrialN'
p1221
I0
sg34
F1.6783077178806707
sg901
V48-twix.png
p1222
sa(dp1223
S'block_loop.thisRepN'
p1224
I0
sg884
V42-mrkipling_lemon_slices.png
p1225
sg886
V42-mrkipling_lemon_slices.png
p1226
sg70
g71
sS'outcome_loop.thisRepN'
p1227
I0
sS'block_loop.thisIndex'
p1228
g890
sS'outcome_loop.thisN'
p1229
I21
sS'outcome_loop.thisTrialN'
p1230
I21
sg62
g66
sg33
S'left'
p1231
sS'block_loop.thisN'
p1232
I0
sS'outcome_loop.thisIndex'
p1233
g63
(g96
S'\x15\x00\x00\x00'
tRp1234
sg30
g1225
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p1235
sS'block_loop.thisTrial'
p1236
Nsg60
g61
sS'block_loop.thisTrialN'
p1237
I0
sg34
F2.091181700467132
sg901
V16-skips_prawn.png
p1238
sa(dp1239
S'block_loop.thisRepN'
p1240
I0
sg884
V36-fig_rolls.png
p1241
sg886
V36-fig_rolls.png
p1242
sg70
g71
sS'outcome_loop.thisRepN'
p1243
I0
sS'block_loop.thisIndex'
p1244
g890
sS'outcome_loop.thisN'
p1245
I22
sS'outcome_loop.thisTrialN'
p1246
I22
sg62
g66
sg33
S'left'
p1247
sS'block_loop.thisN'
p1248
I0
sS'outcome_loop.thisIndex'
p1249
g63
(g96
S'\x16\x00\x00\x00'
tRp1250
sg30
g1241
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p1251
sS'block_loop.thisTrial'
p1252
Nsg60
g61
sS'block_loop.thisTrialN'
p1253
I0
sg34
F4.6217362821244024
sg901
V34-hula_hoops_bbq_beef.png
p1254
sa(dp1255
S'block_loop.thisRepN'
p1256
I0
sg884
V46-pistachios.png
p1257
sg886
V29-beans.png
p1258
sg70
g71
sS'outcome_loop.thisRepN'
p1259
I0
sS'block_loop.thisIndex'
p1260
g890
sS'outcome_loop.thisN'
p1261
I23
sS'outcome_loop.thisTrialN'
p1262
I23
sg62
g66
sg33
S'right'
p1263
sS'block_loop.thisN'
p1264
I0
sS'outcome_loop.thisIndex'
p1265
g63
(g96
S'\x17\x00\x00\x00'
tRp1266
sg30
g1257
sg67
g11
sg68
g69
sg897
V29-beans.png
p1267
sS'block_loop.thisTrial'
p1268
Nsg60
g61
sS'block_loop.thisTrialN'
p1269
I0
sg34
F1.971310599530625
sg901
V46-pistachios.png
p1270
sa(dp1271
S'block_loop.thisRepN'
p1272
I0
sg884
V43-mrporky_pork_crackles.png
p1273
sg886
V43-mrporky_pork_crackles.png
p1274
sg70
g71
sS'outcome_loop.thisRepN'
p1275
I0
sS'block_loop.thisIndex'
p1276
g890
sS'outcome_loop.thisN'
p1277
I24
sS'outcome_loop.thisTrialN'
p1278
I24
sg62
g66
sg33
S'left'
p1279
sS'block_loop.thisN'
p1280
I0
sS'outcome_loop.thisIndex'
p1281
g63
(g96
S'\x18\x00\x00\x00'
tRp1282
sg30
g1273
sg67
g11
sg68
g69
sg897
V18-mms.png
p1283
sS'block_loop.thisTrial'
p1284
Nsg60
g61
sS'block_loop.thisTrialN'
p1285
I0
sg34
F1.6916141576657537
sg901
V18-mms.png
p1286
sa(dp1287
S'block_loop.thisRepN'
p1288
I0
sg884
V4-corn.png
p1289
sg886
V4-corn.png
p1290
sg70
g71
sS'outcome_loop.thisRepN'
p1291
I0
sS'block_loop.thisIndex'
p1292
g890
sS'outcome_loop.thisN'
p1293
I25
sS'outcome_loop.thisTrialN'
p1294
I25
sg62
g66
sg33
S'left'
p1295
sS'block_loop.thisN'
p1296
I0
sS'outcome_loop.thisIndex'
p1297
g63
(g96
S'\x19\x00\x00\x00'
tRp1298
sg30
g1289
sg67
g11
sg68
g69
sg897
V10-bounty.png
p1299
sS'block_loop.thisTrial'
p1300
Nsg60
g61
sS'block_loop.thisTrialN'
p1301
I0
sg34
F0.86584104963003483
sg901
V10-bounty.png
p1302
sa(dp1303
S'block_loop.thisRepN'
p1304
I0
sg884
V42-mrkipling_lemon_slices.png
p1305
sg886
V42-mrkipling_lemon_slices.png
p1306
sg70
g71
sS'outcome_loop.thisRepN'
p1307
I0
sS'block_loop.thisIndex'
p1308
g890
sS'outcome_loop.thisN'
p1309
I26
sS'outcome_loop.thisTrialN'
p1310
I26
sg62
g66
sg33
S'right'
p1311
sS'block_loop.thisN'
p1312
I0
sS'outcome_loop.thisIndex'
p1313
g63
(g96
S'\x1a\x00\x00\x00'
tRp1314
sg30
g1305
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p1315
sS'block_loop.thisTrial'
p1316
Nsg60
g61
sS'block_loop.thisTrialN'
p1317
I0
sg34
F5.3276829876413103
sg901
V16-skips_prawn.png
p1318
sa(dp1319
S'block_loop.thisRepN'
p1320
I0
sg884
V33-ambrosia_rice.png
p1321
sg886
V23-crunchie.png
p1322
sg70
g71
sS'outcome_loop.thisRepN'
p1323
I0
sS'block_loop.thisIndex'
p1324
g890
sS'outcome_loop.thisN'
p1325
I27
sS'outcome_loop.thisTrialN'
p1326
I27
sg62
g66
sg33
S'left'
p1327
sS'block_loop.thisN'
p1328
I0
sS'outcome_loop.thisIndex'
p1329
g63
(g96
S'\x1b\x00\x00\x00'
tRp1330
sg30
V23-crunchie.png
p1331
sg67
g11
sg68
g69
sg897
g1331
sS'block_loop.thisTrial'
p1332
Nsg60
g61
sS'block_loop.thisTrialN'
p1333
I0
sg34
F0.86584691629832378
sg901
V33-ambrosia_rice.png
p1334
sa(dp1335
S'block_loop.thisRepN'
p1336
I0
sg884
V6-sour_patch_kids.png
p1337
sg886
V6-sour_patch_kids.png
p1338
sg70
g71
sS'outcome_loop.thisRepN'
p1339
I0
sS'block_loop.thisIndex'
p1340
g890
sS'outcome_loop.thisN'
p1341
I28
sS'outcome_loop.thisTrialN'
p1342
I28
sg62
g66
sg33
S'right'
p1343
sS'block_loop.thisN'
p1344
I0
sS'outcome_loop.thisIndex'
p1345
g63
(g96
S'\x1c\x00\x00\x00'
tRp1346
sg30
g1337
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p1347
sS'block_loop.thisTrial'
p1348
Nsg60
g61
sS'block_loop.thisTrialN'
p1349
I0
sg34
F2.6905374845118786
sg901
V38-maltesers.png
p1350
sa(dp1351
S'block_loop.thisRepN'
p1352
I0
sg884
V33-ambrosia_rice.png
p1353
sg886
V23-crunchie.png
p1354
sg70
g71
sS'outcome_loop.thisRepN'
p1355
I0
sS'block_loop.thisIndex'
p1356
g890
sS'outcome_loop.thisN'
p1357
I29
sS'outcome_loop.thisTrialN'
p1358
I29
sg62
g66
sg33
S'left'
p1359
sS'block_loop.thisN'
p1360
I0
sS'outcome_loop.thisIndex'
p1361
g63
(g96
S'\x1d\x00\x00\x00'
tRp1362
sg30
g1353
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p1363
sS'block_loop.thisTrial'
p1364
Nsg60
g61
sS'block_loop.thisTrialN'
p1365
I0
sg34
F0.77260797112467117
sg901
V33-ambrosia_rice.png
p1366
sa(dp1367
S'block_loop.thisRepN'
p1368
I0
sg884
V48-twix.png
p1369
sg886
V48-twix.png
p1370
sg70
g71
sS'outcome_loop.thisRepN'
p1371
I0
sS'block_loop.thisIndex'
p1372
g890
sS'outcome_loop.thisN'
p1373
I30
sS'outcome_loop.thisTrialN'
p1374
I30
sg62
g66
sg33
S'right'
p1375
sS'block_loop.thisN'
p1376
I0
sS'outcome_loop.thisIndex'
p1377
g63
(g96
S'\x1e\x00\x00\x00'
tRp1378
sg30
g1369
sg67
g11
sg68
g69
sg897
V50-polo.png
p1379
sS'block_loop.thisTrial'
p1380
Nsg60
g61
sS'block_loop.thisTrialN'
p1381
I0
sg34
F1.0256786826248572
sg901
V50-polo.png
p1382
sa(dp1383
S'block_loop.thisRepN'
p1384
I0
sg884
V36-fig_rolls.png
p1385
sg886
V34-hula_hoops_bbq_beef.png
p1386
sg70
g71
sS'outcome_loop.thisRepN'
p1387
I0
sS'block_loop.thisIndex'
p1388
g890
sS'outcome_loop.thisN'
p1389
I31
sS'outcome_loop.thisTrialN'
p1390
I31
sg62
g66
sg33
S'right'
p1391
sS'block_loop.thisN'
p1392
I0
sS'outcome_loop.thisIndex'
p1393
g63
(g96
S'\x1f\x00\x00\x00'
tRp1394
sg30
V34-hula_hoops_bbq_beef.png
p1395
sg67
g11
sg68
g69
sg897
g1395
sS'block_loop.thisTrial'
p1396
Nsg60
g61
sS'block_loop.thisTrialN'
p1397
I0
sg34
F0.83920274783486093
sg901
V36-fig_rolls.png
p1398
sa(dp1399
S'block_loop.thisRepN'
p1400
I0
sg884
V48-twix.png
p1401
sg886
V48-twix.png
p1402
sg70
g71
sS'outcome_loop.thisRepN'
p1403
I0
sS'block_loop.thisIndex'
p1404
g890
sS'outcome_loop.thisN'
p1405
I32
sS'outcome_loop.thisTrialN'
p1406
I32
sg62
g66
sg33
S'right'
p1407
sS'block_loop.thisN'
p1408
I0
sS'outcome_loop.thisIndex'
p1409
g63
(g96
S' \x00\x00\x00'
tRp1410
sg30
g1401
sg67
g11
sg68
g69
sg897
V50-polo.png
p1411
sS'block_loop.thisTrial'
p1412
Nsg60
g61
sS'block_loop.thisTrialN'
p1413
I0
sg34
F1.7715212408274965
sg901
V50-polo.png
p1414
sa(dp1415
S'block_loop.thisRepN'
p1416
I0
sg884
V19-caramello.png
p1417
sg886
V19-caramello.png
p1418
sg70
g71
sS'outcome_loop.thisRepN'
p1419
I0
sS'block_loop.thisIndex'
p1420
g890
sS'outcome_loop.thisN'
p1421
I33
sS'outcome_loop.thisTrialN'
p1422
I33
sg62
g66
sg33
S'left'
p1423
sS'block_loop.thisN'
p1424
I0
sS'outcome_loop.thisIndex'
p1425
g63
(g96
S'!\x00\x00\x00'
tRp1426
sg30
V30-spaghetti_hoops.png
p1427
sg67
g11
sg68
g69
sg897
g1427
sS'block_loop.thisTrial'
p1428
Nsg60
g61
sS'block_loop.thisTrialN'
p1429
I0
sg34
F1.1189031008143502
sg901
V30-spaghetti_hoops.png
p1430
sa(dp1431
S'block_loop.thisRepN'
p1432
I0
sg884
V20-fruit_pastilles.png
p1433
sg886
V20-fruit_pastilles.png
p1434
sg70
g71
sS'outcome_loop.thisRepN'
p1435
I0
sS'block_loop.thisIndex'
p1436
g890
sS'outcome_loop.thisN'
p1437
I34
sS'outcome_loop.thisTrialN'
p1438
I34
sg62
g66
sg33
S'right'
p1439
sS'block_loop.thisN'
p1440
I0
sS'outcome_loop.thisIndex'
p1441
g63
(g96
S'"\x00\x00\x00'
tRp1442
sg30
g1433
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p1443
sS'block_loop.thisTrial'
p1444
Nsg60
g61
sS'block_loop.thisTrialN'
p1445
I0
sg34
F3.0900810019156779
sg901
V2-steamed_puddings.png
p1446
sa(dp1447
S'block_loop.thisRepN'
p1448
I0
sg884
V49-yorkie.png
p1449
sg886
V35-sultanas.png
p1450
sg70
g71
sS'outcome_loop.thisRepN'
p1451
I0
sS'block_loop.thisIndex'
p1452
g890
sS'outcome_loop.thisN'
p1453
I35
sS'outcome_loop.thisTrialN'
p1454
I35
sg62
g66
sg33
S'right'
p1455
sS'block_loop.thisN'
p1456
I0
sS'outcome_loop.thisIndex'
p1457
g63
(g96
S'#\x00\x00\x00'
tRp1458
sg30
g1449
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p1459
sS'block_loop.thisTrial'
p1460
Nsg60
g61
sS'block_loop.thisTrialN'
p1461
I0
sg34
F1.1854886584751512
sg901
V49-yorkie.png
p1462
sa(dp1463
S'block_loop.thisRepN'
p1464
I0
sg884
V26-walkers_smoky_bacon.png
p1465
sg886
V44-crunch.png
p1466
sg70
g71
sS'outcome_loop.thisRepN'
p1467
I0
sS'block_loop.thisIndex'
p1468
g890
sS'outcome_loop.thisN'
p1469
I36
sS'outcome_loop.thisTrialN'
p1470
I36
sg62
g66
sg33
S'right'
p1471
sS'block_loop.thisN'
p1472
I0
sS'outcome_loop.thisIndex'
p1473
g63
(g96
S'$\x00\x00\x00'
tRp1474
sg30
g1465
sg67
g11
sg68
g69
sg897
V44-crunch.png
p1475
sS'block_loop.thisTrial'
p1476
Nsg60
g61
sS'block_loop.thisTrialN'
p1477
I0
sg34
F0.82588764773026924
sg901
V26-walkers_smoky_bacon.png
p1478
sa(dp1479
S'block_loop.thisRepN'
p1480
I0
sg884
V46-pistachios.png
p1481
sg886
V46-pistachios.png
p1482
sg70
g71
sS'outcome_loop.thisRepN'
p1483
I0
sS'block_loop.thisIndex'
p1484
g890
sS'outcome_loop.thisN'
p1485
I37
sS'outcome_loop.thisTrialN'
p1486
I37
sg62
g66
sg33
S'left'
p1487
sS'block_loop.thisN'
p1488
I0
sS'outcome_loop.thisIndex'
p1489
g63
(g96
S'%\x00\x00\x00'
tRp1490
sg30
g1481
sg67
g11
sg68
g69
sg897
V29-beans.png
p1491
sS'block_loop.thisTrial'
p1492
Nsg60
g61
sS'block_loop.thisTrialN'
p1493
I0
sg34
F1.4918471481705637
sg901
V29-beans.png
p1494
sa(dp1495
S'block_loop.thisRepN'
p1496
I0
sg884
V17-jacobs_mini_cheddars.png
p1497
sg886
V17-jacobs_mini_cheddars.png
p1498
sg70
g71
sS'outcome_loop.thisRepN'
p1499
I0
sS'block_loop.thisIndex'
p1500
g890
sS'outcome_loop.thisN'
p1501
I38
sS'outcome_loop.thisTrialN'
p1502
I38
sg62
g66
sg33
S'left'
p1503
sS'block_loop.thisN'
p1504
I0
sS'outcome_loop.thisIndex'
p1505
g63
(g96
S'&\x00\x00\x00'
tRp1506
sg30
g1497
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p1507
sS'block_loop.thisTrial'
p1508
Nsg60
g61
sS'block_loop.thisTrialN'
p1509
I0
sg34
F0.81257115080370568
sg901
V8-liquorice_catherine_wheels.png
p1510
sa(dp1511
S'block_loop.thisRepN'
p1512
I0
sg884
V20-fruit_pastilles.png
p1513
sg886
V20-fruit_pastilles.png
p1514
sg70
g71
sS'outcome_loop.thisRepN'
p1515
I0
sS'block_loop.thisIndex'
p1516
g890
sS'outcome_loop.thisN'
p1517
I39
sS'outcome_loop.thisTrialN'
p1518
I39
sg62
g66
sg33
S'left'
p1519
sS'block_loop.thisN'
p1520
I0
sS'outcome_loop.thisIndex'
p1521
g63
(g96
S"'\x00\x00\x00"
tRp1522
sg30
g1513
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p1523
sS'block_loop.thisTrial'
p1524
Nsg60
g61
sS'block_loop.thisTrialN'
p1525
I0
sg34
F2.5040537274981034
sg901
V2-steamed_puddings.png
p1526
sa(dp1527
S'block_loop.thisRepN'
p1528
I0
sg884
V19-caramello.png
p1529
sg886
V30-spaghetti_hoops.png
p1530
sg70
g71
sS'outcome_loop.thisRepN'
p1531
I0
sS'block_loop.thisIndex'
p1532
g890
sS'outcome_loop.thisN'
p1533
I40
sS'outcome_loop.thisTrialN'
p1534
I40
sg62
g66
sg33
S'left'
p1535
sS'block_loop.thisN'
p1536
I0
sS'outcome_loop.thisIndex'
p1537
g63
(g96
S'(\x00\x00\x00'
tRp1538
sg30
g1529
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p1539
sS'block_loop.thisTrial'
p1540
Nsg60
g61
sS'block_loop.thisTrialN'
p1541
I0
sg34
F1.6383241445491876
sg901
V19-caramello.png
p1542
sa(dp1543
S'block_loop.thisRepN'
p1544
I0
sg884
V43-mrporky_pork_crackles.png
p1545
sg886
V43-mrporky_pork_crackles.png
p1546
sg70
g71
sS'outcome_loop.thisRepN'
p1547
I0
sS'block_loop.thisIndex'
p1548
g890
sS'outcome_loop.thisN'
p1549
I41
sS'outcome_loop.thisTrialN'
p1550
I41
sg62
g66
sg33
S'left'
p1551
sS'block_loop.thisN'
p1552
I0
sS'outcome_loop.thisIndex'
p1553
g63
(g96
S')\x00\x00\x00'
tRp1554
sg30
g1545
sg67
g11
sg68
g69
sg897
V18-mms.png
p1555
sS'block_loop.thisTrial'
p1556
Nsg60
g61
sS'block_loop.thisTrialN'
p1557
I0
sg34
F1.1188991897015512
sg901
V18-mms.png
p1558
sa(dp1559
S'block_loop.thisRepN'
p1560
I0
sg884
V31-foxs_golden_biscuits.png
p1561
sg886
V31-foxs_golden_biscuits.png
p1562
sg70
g71
sS'outcome_loop.thisRepN'
p1563
I0
sS'block_loop.thisIndex'
p1564
g890
sS'outcome_loop.thisN'
p1565
I42
sS'outcome_loop.thisTrialN'
p1566
I42
sg62
g66
sg33
S'left'
p1567
sS'block_loop.thisN'
p1568
I0
sS'outcome_loop.thisIndex'
p1569
g63
(g96
S'*\x00\x00\x00'
tRp1570
sg30
g1561
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p1571
sS'block_loop.thisTrial'
p1572
Nsg60
g61
sS'block_loop.thisTrialN'
p1573
I0
sg34
F1.5318066961026489
sg901
V25-kitkat.png
p1574
sa(dp1575
S'block_loop.thisRepN'
p1576
I0
sg884
V43-mrporky_pork_crackles.png
p1577
sg886
V18-mms.png
p1578
sg70
g71
sS'outcome_loop.thisRepN'
p1579
I0
sS'block_loop.thisIndex'
p1580
g890
sS'outcome_loop.thisN'
p1581
I43
sS'outcome_loop.thisTrialN'
p1582
I43
sg62
g66
sg33
S'right'
p1583
sS'block_loop.thisN'
p1584
I0
sS'outcome_loop.thisIndex'
p1585
g63
(g96
S'+\x00\x00\x00'
tRp1586
sg30
V18-mms.png
p1587
sg67
g11
sg68
g69
sg897
g1587
sS'block_loop.thisTrial'
p1588
Nsg60
g61
sS'block_loop.thisTrialN'
p1589
I0
sg34
F0.93243219459509419
sg901
V43-mrporky_pork_crackles.png
p1590
sa(dp1591
S'block_loop.thisRepN'
p1592
I0
sg884
V31-foxs_golden_biscuits.png
p1593
sg886
V31-foxs_golden_biscuits.png
p1594
sg70
g71
sS'outcome_loop.thisRepN'
p1595
I0
sS'block_loop.thisIndex'
p1596
g890
sS'outcome_loop.thisN'
p1597
I44
sS'outcome_loop.thisTrialN'
p1598
I44
sg62
g66
sg33
S'left'
p1599
sS'block_loop.thisN'
p1600
I0
sS'outcome_loop.thisIndex'
p1601
g63
(g96
S',\x00\x00\x00'
tRp1602
sg30
g1593
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p1603
sS'block_loop.thisTrial'
p1604
Nsg60
g61
sS'block_loop.thisTrialN'
p1605
I0
sg34
F0.9457534407320054
sg901
V25-kitkat.png
p1606
sa(dp1607
S'block_loop.thisRepN'
p1608
I0
sg884
V26-walkers_smoky_bacon.png
p1609
sg886
V26-walkers_smoky_bacon.png
p1610
sg70
g71
sS'outcome_loop.thisRepN'
p1611
I0
sS'block_loop.thisIndex'
p1612
g890
sS'outcome_loop.thisN'
p1613
I45
sS'outcome_loop.thisTrialN'
p1614
I45
sg62
g66
sg33
S'left'
p1615
sS'block_loop.thisN'
p1616
I0
sS'outcome_loop.thisIndex'
p1617
g63
(g96
S'-\x00\x00\x00'
tRp1618
sg30
g1609
sg67
g11
sg68
g69
sg897
V44-crunch.png
p1619
sS'block_loop.thisTrial'
p1620
Nsg60
g61
sS'block_loop.thisTrialN'
p1621
I0
sg34
F1.1055910737268277
sg901
V44-crunch.png
p1622
sa(dp1623
S'block_loop.thisRepN'
p1624
I0
sg884
V7-olives.png
p1625
sg886
V7-olives.png
p1626
sg70
g71
sS'outcome_loop.thisRepN'
p1627
I0
sS'block_loop.thisIndex'
p1628
g890
sS'outcome_loop.thisN'
p1629
I46
sS'outcome_loop.thisTrialN'
p1630
I46
sg62
g66
sg33
S'left'
p1631
sS'block_loop.thisN'
p1632
I0
sS'outcome_loop.thisIndex'
p1633
g63
(g96
S'.\x00\x00\x00'
tRp1634
sg30
g1625
sg67
g11
sg68
g69
sg897
V22-daim.png
p1635
sS'block_loop.thisTrial'
p1636
Nsg60
g61
sS'block_loop.thisTrialN'
p1637
I0
sg34
F1.0389909890782292
sg901
V22-daim.png
p1638
sa(dp1639
S'block_loop.thisRepN'
p1640
I0
sg884
V6-sour_patch_kids.png
p1641
sg886
V6-sour_patch_kids.png
p1642
sg70
g71
sS'outcome_loop.thisRepN'
p1643
I0
sS'block_loop.thisIndex'
p1644
g890
sS'outcome_loop.thisN'
p1645
I47
sS'outcome_loop.thisTrialN'
p1646
I47
sg62
g66
sg33
S'left'
p1647
sS'block_loop.thisN'
p1648
I0
sS'outcome_loop.thisIndex'
p1649
g63
(g96
S'/\x00\x00\x00'
tRp1650
sg30
V38-maltesers.png
p1651
sg67
g11
sg68
g69
sg897
g1651
sS'block_loop.thisTrial'
p1652
Nsg60
g61
sS'block_loop.thisTrialN'
p1653
I0
sg34
F3.0501273206500628
sg901
V38-maltesers.png
p1654
sa(dp1655
S'block_loop.thisRepN'
p1656
I0
sg884
V17-jacobs_mini_cheddars.png
p1657
sg886
V17-jacobs_mini_cheddars.png
p1658
sg70
g71
sS'outcome_loop.thisRepN'
p1659
I0
sS'block_loop.thisIndex'
p1660
g890
sS'outcome_loop.thisN'
p1661
I48
sS'outcome_loop.thisTrialN'
p1662
I48
sg62
g66
sg33
S'left'
p1663
sS'block_loop.thisN'
p1664
I0
sS'outcome_loop.thisIndex'
p1665
g63
(g96
S'0\x00\x00\x00'
tRp1666
sg30
V8-liquorice_catherine_wheels.png
p1667
sg67
g11
sg68
g69
sg897
g1667
sS'block_loop.thisTrial'
p1668
Nsg60
g61
sS'block_loop.thisTrialN'
p1669
I0
sg34
F0.86585529725198285
sg901
V8-liquorice_catherine_wheels.png
p1670
sa(dp1671
S'block_loop.thisRepN'
p1672
I0
sg884
V20-fruit_pastilles.png
p1673
sg886
V2-steamed_puddings.png
p1674
sg70
g71
sS'outcome_loop.thisRepN'
p1675
I0
sS'block_loop.thisIndex'
p1676
g890
sS'outcome_loop.thisN'
p1677
I49
sS'outcome_loop.thisTrialN'
p1678
I49
sg62
g66
sg33
S'left'
p1679
sS'block_loop.thisN'
p1680
I0
sS'outcome_loop.thisIndex'
p1681
g63
(g96
S'1\x00\x00\x00'
tRp1682
sg30
g1673
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p1683
sS'block_loop.thisTrial'
p1684
Nsg60
g61
sS'block_loop.thisTrialN'
p1685
I0
sg34
F2.9302713054312335
sg901
V20-fruit_pastilles.png
p1686
sa(dp1687
S'block_loop.thisRepN'
p1688
I0
sg884
V46-pistachios.png
p1689
sg886
V29-beans.png
p1690
sg70
g71
sS'outcome_loop.thisRepN'
p1691
I0
sS'block_loop.thisIndex'
p1692
g890
sS'outcome_loop.thisN'
p1693
I50
sS'outcome_loop.thisTrialN'
p1694
I50
sg62
g66
sg33
S'right'
p1695
sS'block_loop.thisN'
p1696
I0
sS'outcome_loop.thisIndex'
p1697
g63
(g96
S'2\x00\x00\x00'
tRp1698
sg30
g1689
sg67
g11
sg68
g69
sg897
V29-beans.png
p1699
sS'block_loop.thisTrial'
p1700
Nsg60
g61
sS'block_loop.thisTrialN'
p1701
I0
sg34
F3.0900972050912969
sg901
V46-pistachios.png
p1702
sa(dp1703
S'block_loop.thisRepN'
p1704
I0
sg884
V4-corn.png
p1705
sg886
V10-bounty.png
p1706
sg70
g71
sS'outcome_loop.thisRepN'
p1707
I0
sS'block_loop.thisIndex'
p1708
g890
sS'outcome_loop.thisN'
p1709
I51
sS'outcome_loop.thisTrialN'
p1710
I51
sg62
g66
sg33
S'left'
p1711
sS'block_loop.thisN'
p1712
I0
sS'outcome_loop.thisIndex'
p1713
g63
(g96
S'3\x00\x00\x00'
tRp1714
sg30
g1705
sg67
g11
sg68
g69
sg897
V10-bounty.png
p1715
sS'block_loop.thisTrial'
p1716
Nsg60
g61
sS'block_loop.thisTrialN'
p1717
I0
sg34
F1.4518814542079781
sg901
V4-corn.png
p1718
sa(dp1719
S'block_loop.thisRepN'
p1720
I0
sg884
V43-mrporky_pork_crackles.png
p1721
sg886
V18-mms.png
p1722
sg70
g71
sS'outcome_loop.thisRepN'
p1723
I0
sS'block_loop.thisIndex'
p1724
g890
sS'outcome_loop.thisN'
p1725
I52
sS'outcome_loop.thisTrialN'
p1726
I52
sg62
g66
sg33
S'right'
p1727
sS'block_loop.thisN'
p1728
I0
sS'outcome_loop.thisIndex'
p1729
g63
(g96
S'4\x00\x00\x00'
tRp1730
sg30
g1721
sg67
g11
sg68
g69
sg897
V18-mms.png
p1731
sS'block_loop.thisTrial'
p1732
Nsg60
g61
sS'block_loop.thisTrialN'
p1733
I0
sg34
F1.957986001014433
sg901
V43-mrporky_pork_crackles.png
p1734
sa(dp1735
S'block_loop.thisRepN'
p1736
I0
sg884
V6-sour_patch_kids.png
p1737
sg886
V6-sour_patch_kids.png
p1738
sg70
g71
sS'outcome_loop.thisRepN'
p1739
I0
sS'block_loop.thisIndex'
p1740
g890
sS'outcome_loop.thisN'
p1741
I53
sS'outcome_loop.thisTrialN'
p1742
I53
sg62
g66
sg33
S'right'
p1743
sS'block_loop.thisN'
p1744
I0
sS'outcome_loop.thisIndex'
p1745
g63
(g96
S'5\x00\x00\x00'
tRp1746
sg30
V38-maltesers.png
p1747
sg67
g11
sg68
g69
sg897
g1747
sS'block_loop.thisTrial'
p1748
Nsg60
g61
sS'block_loop.thisTrialN'
p1749
I0
sg34
F2.6505787746755232
sg901
V38-maltesers.png
p1750
sa(dp1751
S'block_loop.thisRepN'
p1752
I0
sg884
V5-pineapple.png
p1753
sg886
V5-pineapple.png
p1754
sg70
g71
sS'outcome_loop.thisRepN'
p1755
I0
sS'block_loop.thisIndex'
p1756
g890
sS'outcome_loop.thisN'
p1757
I54
sS'outcome_loop.thisTrialN'
p1758
I54
sg62
g66
sg33
S'right'
p1759
sS'block_loop.thisN'
p1760
I0
sS'outcome_loop.thisIndex'
p1761
g63
(g96
S'6\x00\x00\x00'
tRp1762
sg30
g1753
sg67
g11
sg68
g69
sg897
V40-sardines.png
p1763
sS'block_loop.thisTrial'
p1764
Nsg60
g61
sS'block_loop.thisTrialN'
p1765
I0
sg34
F1.7714963773341879
sg901
V40-sardines.png
p1766
sa(dp1767
S'block_loop.thisRepN'
p1768
I0
sg884
V51-mars.png
p1769
sg886
V27-hartleys_raspberries_jelly.png
p1770
sg70
g71
sS'outcome_loop.thisRepN'
p1771
I0
sS'block_loop.thisIndex'
p1772
g890
sS'outcome_loop.thisN'
p1773
I55
sS'outcome_loop.thisTrialN'
p1774
I55
sg62
g66
sg33
S'right'
p1775
sS'block_loop.thisN'
p1776
I0
sS'outcome_loop.thisIndex'
p1777
g63
(g96
S'7\x00\x00\x00'
tRp1778
sg30
V27-hartleys_raspberries_jelly.png
p1779
sg67
g11
sg68
g69
sg897
g1779
sS'block_loop.thisTrial'
p1780
Nsg60
g61
sS'block_loop.thisTrialN'
p1781
I0
sg34
F1.5850693314368982
sg901
V51-mars.png
p1782
sa(dp1783
S'block_loop.thisRepN'
p1784
I0
sg884
V49-yorkie.png
p1785
sg886
V49-yorkie.png
p1786
sg70
g71
sS'outcome_loop.thisRepN'
p1787
I0
sS'block_loop.thisIndex'
p1788
g890
sS'outcome_loop.thisN'
p1789
I56
sS'outcome_loop.thisTrialN'
p1790
I56
sg62
g66
sg33
S'left'
p1791
sS'block_loop.thisN'
p1792
I0
sS'outcome_loop.thisIndex'
p1793
g63
(g96
S'8\x00\x00\x00'
tRp1794
sg30
g1785
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p1795
sS'block_loop.thisTrial'
p1796
Nsg60
g61
sS'block_loop.thisTrialN'
p1797
I0
sg34
F1.0123470999806159
sg901
V35-sultanas.png
p1798
sa(dp1799
S'block_loop.thisRepN'
p1800
I0
sg884
V7-olives.png
p1801
sg886
V7-olives.png
p1802
sg70
g71
sS'outcome_loop.thisRepN'
p1803
I0
sS'block_loop.thisIndex'
p1804
g890
sS'outcome_loop.thisN'
p1805
I57
sS'outcome_loop.thisTrialN'
p1806
I57
sg62
g66
sg33
S'left'
p1807
sS'block_loop.thisN'
p1808
I0
sS'outcome_loop.thisIndex'
p1809
g63
(g96
S'9\x00\x00\x00'
tRp1810
sg30
g1801
sg67
g11
sg68
g69
sg897
V22-daim.png
p1811
sS'block_loop.thisTrial'
p1812
Nsg60
g61
sS'block_loop.thisTrialN'
p1813
I0
sg34
F1.7448952310969617
sg901
V22-daim.png
p1814
sa(dp1815
S'block_loop.thisRepN'
p1816
I0
sg884
V46-pistachios.png
p1817
sg886
V29-beans.png
p1818
sg70
g71
sS'outcome_loop.thisRepN'
p1819
I0
sS'block_loop.thisIndex'
p1820
g890
sS'outcome_loop.thisN'
p1821
I58
sS'outcome_loop.thisTrialN'
p1822
I58
sg62
g66
sg33
S'right'
p1823
sS'block_loop.thisN'
p1824
I0
sS'outcome_loop.thisIndex'
p1825
g63
(g96
S':\x00\x00\x00'
tRp1826
sg30
g1817
sg67
g11
sg68
g69
sg897
V29-beans.png
p1827
sS'block_loop.thisTrial'
p1828
Nsg60
g61
sS'block_loop.thisTrialN'
p1829
I0
sg34
F1.5850704488984775
sg901
V46-pistachios.png
p1830
sa(dp1831
S'block_loop.thisRepN'
p1832
I0
sg884
V36-fig_rolls.png
p1833
sg886
V36-fig_rolls.png
p1834
sg70
g71
sS'outcome_loop.thisRepN'
p1835
I0
sS'block_loop.thisIndex'
p1836
g890
sS'outcome_loop.thisN'
p1837
I59
sS'outcome_loop.thisTrialN'
p1838
I59
sg62
g66
sg33
S'left'
p1839
sS'block_loop.thisN'
p1840
I0
sS'outcome_loop.thisIndex'
p1841
g63
(g96
S';\x00\x00\x00'
tRp1842
sg30
V34-hula_hoops_bbq_beef.png
p1843
sg67
g11
sg68
g69
sg897
g1843
sS'block_loop.thisTrial'
p1844
Nsg60
g61
sS'block_loop.thisTrialN'
p1845
I0
sg34
F0.79906105384907278
sg901
V34-hula_hoops_bbq_beef.png
p1846
sa(dp1847
S'block_loop.thisRepN'
p1848
I0
sg884
V49-yorkie.png
p1849
sg886
V49-yorkie.png
p1850
sg70
g71
sS'outcome_loop.thisRepN'
p1851
I0
sS'block_loop.thisIndex'
p1852
g890
sS'outcome_loop.thisN'
p1853
I60
sS'outcome_loop.thisTrialN'
p1854
I60
sg62
g66
sg33
S'left'
p1855
sS'block_loop.thisN'
p1856
I0
sS'outcome_loop.thisIndex'
p1857
g63
(g96
S'<\x00\x00\x00'
tRp1858
sg30
g1849
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p1859
sS'block_loop.thisTrial'
p1860
Nsg60
g61
sS'block_loop.thisTrialN'
p1861
I0
sg34
F0.73265596605233441
sg901
V35-sultanas.png
p1862
sa(dp1863
S'block_loop.thisRepN'
p1864
I0
sg884
V1-smarties_cookies.png
p1865
sg886
V21-nakd_banana_crunch.png
p1866
sg70
g71
sS'outcome_loop.thisRepN'
p1867
I0
sS'block_loop.thisIndex'
p1868
g890
sS'outcome_loop.thisN'
p1869
I61
sS'outcome_loop.thisTrialN'
p1870
I61
sg62
g66
sg33
S'right'
p1871
sS'block_loop.thisN'
p1872
I0
sS'outcome_loop.thisIndex'
p1873
g63
(g96
S'=\x00\x00\x00'
tRp1874
sg30
g1865
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p1875
sS'block_loop.thisTrial'
p1876
Nsg60
g61
sS'block_loop.thisTrialN'
p1877
I0
sg34
F3.0901050273150759
sg901
V1-smarties_cookies.png
p1878
sa(dp1879
S'block_loop.thisRepN'
p1880
I0
sg884
V20-fruit_pastilles.png
p1881
sg886
V2-steamed_puddings.png
p1882
sg70
g71
sS'outcome_loop.thisRepN'
p1883
I0
sS'block_loop.thisIndex'
p1884
g890
sS'outcome_loop.thisN'
p1885
I62
sS'outcome_loop.thisTrialN'
p1886
I62
sg62
g66
sg33
S'left'
p1887
sS'block_loop.thisN'
p1888
I0
sS'outcome_loop.thisIndex'
p1889
g63
(g96
S'>\x00\x00\x00'
tRp1890
sg30
g1881
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p1891
sS'block_loop.thisTrial'
p1892
Nsg60
g61
sS'block_loop.thisTrialN'
p1893
I0
sg34
F14.171412009069172
sg901
V20-fruit_pastilles.png
p1894
sa(dp1895
S'block_loop.thisRepN'
p1896
I0
sg884
V36-fig_rolls.png
p1897
sg886
V36-fig_rolls.png
p1898
sg70
g71
sS'outcome_loop.thisRepN'
p1899
I0
sS'block_loop.thisIndex'
p1900
g890
sS'outcome_loop.thisN'
p1901
I63
sS'outcome_loop.thisTrialN'
p1902
I63
sg62
g66
sg33
S'left'
p1903
sS'block_loop.thisN'
p1904
I0
sS'outcome_loop.thisIndex'
p1905
g63
(g96
S'?\x00\x00\x00'
tRp1906
sg30
g1897
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p1907
sS'block_loop.thisTrial'
p1908
Nsg60
g61
sS'block_loop.thisTrialN'
p1909
I0
sg34
F4.1156529670679447
sg901
V34-hula_hoops_bbq_beef.png
p1910
sa(dp1911
S'block_loop.thisRepN'
p1912
I0
sg884
V26-walkers_smoky_bacon.png
p1913
sg886
V26-walkers_smoky_bacon.png
p1914
sg70
g71
sS'outcome_loop.thisRepN'
p1915
I0
sS'block_loop.thisIndex'
p1916
g890
sS'outcome_loop.thisN'
p1917
I64
sS'outcome_loop.thisTrialN'
p1918
I64
sg62
g66
sg33
S'left'
p1919
sS'block_loop.thisN'
p1920
I0
sS'outcome_loop.thisIndex'
p1921
g63
(g96
S'@\x00\x00\x00'
tRp1922
sg30
g1913
sg67
g11
sg68
g69
sg897
V44-crunch.png
p1923
sS'block_loop.thisTrial'
p1924
Nsg60
g61
sS'block_loop.thisTrialN'
p1925
I0
sg34
F0.79924375863447494
sg901
V44-crunch.png
p1926
sa(dp1927
S'block_loop.thisRepN'
p1928
I0
sg884
V49-yorkie.png
p1929
sg886
V49-yorkie.png
p1930
sg70
g71
sS'outcome_loop.thisRepN'
p1931
I0
sS'block_loop.thisIndex'
p1932
g890
sS'outcome_loop.thisN'
p1933
I65
sS'outcome_loop.thisTrialN'
p1934
I65
sg62
g66
sg33
S'left'
p1935
sS'block_loop.thisN'
p1936
I0
sS'outcome_loop.thisIndex'
p1937
g63
(g96
S'A\x00\x00\x00'
tRp1938
sg30
g1929
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p1939
sS'block_loop.thisTrial'
p1940
Nsg60
g61
sS'block_loop.thisTrialN'
p1941
I0
sg34
F0.78591636646524421
sg901
V35-sultanas.png
p1942
sa(dp1943
S'block_loop.thisRepN'
p1944
I0
sg884
V31-foxs_golden_biscuits.png
p1945
sg886
V25-kitkat.png
p1946
sg70
g71
sS'outcome_loop.thisRepN'
p1947
I0
sS'block_loop.thisIndex'
p1948
g890
sS'outcome_loop.thisN'
p1949
I66
sS'outcome_loop.thisTrialN'
p1950
I66
sg62
g66
sg33
S'right'
p1951
sS'block_loop.thisN'
p1952
I0
sS'outcome_loop.thisIndex'
p1953
g63
(g96
S'B\x00\x00\x00'
tRp1954
sg30
g1945
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p1955
sS'block_loop.thisTrial'
p1956
Nsg60
g61
sS'block_loop.thisTrialN'
p1957
I0
sg34
F1.0256602445297176
sg901
V31-foxs_golden_biscuits.png
p1958
sa(dp1959
S'block_loop.thisRepN'
p1960
I0
sg884
V51-mars.png
p1961
sg886
V51-mars.png
p1962
sg70
g71
sS'outcome_loop.thisRepN'
p1963
I0
sS'block_loop.thisIndex'
p1964
g890
sS'outcome_loop.thisN'
p1965
I67
sS'outcome_loop.thisTrialN'
p1966
I67
sg62
g66
sg33
S'left'
p1967
sS'block_loop.thisN'
p1968
I0
sS'outcome_loop.thisIndex'
p1969
g63
(g96
S'C\x00\x00\x00'
tRp1970
sg30
V27-hartleys_raspberries_jelly.png
p1971
sg67
g11
sg68
g69
sg897
g1971
sS'block_loop.thisTrial'
p1972
Nsg60
g61
sS'block_loop.thisTrialN'
p1973
I0
sg34
F1.1856448235739663
sg901
V27-hartleys_raspberries_jelly.png
p1974
sa(dp1975
S'block_loop.thisRepN'
p1976
I0
sg884
V6-sour_patch_kids.png
p1977
sg886
V38-maltesers.png
p1978
sg70
g71
sS'outcome_loop.thisRepN'
p1979
I0
sS'block_loop.thisIndex'
p1980
g890
sS'outcome_loop.thisN'
p1981
I68
sS'outcome_loop.thisTrialN'
p1982
I68
sg62
g66
sg33
S'left'
p1983
sS'block_loop.thisN'
p1984
I0
sS'outcome_loop.thisIndex'
p1985
g63
(g96
S'D\x00\x00\x00'
tRp1986
sg30
g1977
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p1987
sS'block_loop.thisTrial'
p1988
Nsg60
g61
sS'block_loop.thisTrialN'
p1989
I0
sg34
F0.93244951523047348
sg901
V6-sour_patch_kids.png
p1990
sa(dp1991
S'block_loop.thisRepN'
p1992
I0
sg884
V42-mrkipling_lemon_slices.png
p1993
sg886
V16-skips_prawn.png
p1994
sg70
g71
sS'outcome_loop.thisRepN'
p1995
I0
sS'block_loop.thisIndex'
p1996
g890
sS'outcome_loop.thisN'
p1997
I69
sS'outcome_loop.thisTrialN'
p1998
I69
sg62
g66
sg33
S'left'
p1999
sS'block_loop.thisN'
p2000
I0
sS'outcome_loop.thisIndex'
p2001
g63
(g96
S'E\x00\x00\x00'
tRp2002
sg30
g1993
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p2003
sS'block_loop.thisTrial'
p2004
Nsg60
g61
sS'block_loop.thisTrialN'
p2005
I0
sg34
F1.5184625420261
sg901
V42-mrkipling_lemon_slices.png
p2006
sa(dp2007
S'block_loop.thisRepN'
p2008
I0
sg884
V46-pistachios.png
p2009
sg886
V46-pistachios.png
p2010
sg70
g71
sS'outcome_loop.thisRepN'
p2011
I0
sS'block_loop.thisIndex'
p2012
g890
sS'outcome_loop.thisN'
p2013
I70
sS'outcome_loop.thisTrialN'
p2014
I70
sg62
g66
sg33
S'left'
p2015
sS'block_loop.thisN'
p2016
I0
sS'outcome_loop.thisIndex'
p2017
g63
(g96
S'F\x00\x00\x00'
tRp2018
sg30
g2009
sg67
g11
sg68
g69
sg897
V29-beans.png
p2019
sS'block_loop.thisTrial'
p2020
Nsg60
g61
sS'block_loop.thisTrialN'
p2021
I0
sg34
F0.71932801515322353
sg901
V29-beans.png
p2022
sa(dp2023
S'block_loop.thisRepN'
p2024
I0
sg884
V26-walkers_smoky_bacon.png
p2025
sg886
V26-walkers_smoky_bacon.png
p2026
sg70
g71
sS'outcome_loop.thisRepN'
p2027
I0
sS'block_loop.thisIndex'
p2028
g890
sS'outcome_loop.thisN'
p2029
I71
sS'outcome_loop.thisTrialN'
p2030
I71
sg62
g66
sg33
S'left'
p2031
sS'block_loop.thisN'
p2032
I0
sS'outcome_loop.thisIndex'
p2033
g63
(g96
S'G\x00\x00\x00'
tRp2034
sg30
g2025
sg67
g11
sg68
g69
sg897
V44-crunch.png
p2035
sS'block_loop.thisTrial'
p2036
Nsg60
g61
sS'block_loop.thisTrialN'
p2037
I0
sg34
F0.59945719358074712
sg901
V44-crunch.png
p2038
sa(dp2039
S'block_loop.thisRepN'
p2040
I0
sg884
V51-mars.png
p2041
sg886
V27-hartleys_raspberries_jelly.png
p2042
sg70
g71
sS'outcome_loop.thisRepN'
p2043
I0
sS'block_loop.thisIndex'
p2044
g890
sS'outcome_loop.thisN'
p2045
I72
sS'outcome_loop.thisTrialN'
p2046
I72
sg62
g66
sg33
S'right'
p2047
sS'block_loop.thisN'
p2048
I0
sS'outcome_loop.thisIndex'
p2049
g63
(g96
S'H\x00\x00\x00'
tRp2050
sg30
g2041
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p2051
sS'block_loop.thisTrial'
p2052
Nsg60
g61
sS'block_loop.thisTrialN'
p2053
I0
sg34
F2.3575608073097101
sg901
V51-mars.png
p2054
sa(dp2055
S'block_loop.thisRepN'
p2056
I0
sg884
V17-jacobs_mini_cheddars.png
p2057
sg886
V8-liquorice_catherine_wheels.png
p2058
sg70
g71
sS'outcome_loop.thisRepN'
p2059
I0
sS'block_loop.thisIndex'
p2060
g890
sS'outcome_loop.thisN'
p2061
I73
sS'outcome_loop.thisTrialN'
p2062
I73
sg62
g66
sg33
S'right'
p2063
sS'block_loop.thisN'
p2064
I0
sS'outcome_loop.thisIndex'
p2065
g63
(g96
S'I\x00\x00\x00'
tRp2066
sg30
g2057
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2067
sS'block_loop.thisTrial'
p2068
Nsg60
g61
sS'block_loop.thisTrialN'
p2069
I0
sg34
F0.87916341322852531
sg901
V17-jacobs_mini_cheddars.png
p2070
sa(dp2071
S'block_loop.thisRepN'
p2072
I0
sg884
V33-ambrosia_rice.png
p2073
sg886
V33-ambrosia_rice.png
p2074
sg70
g71
sS'outcome_loop.thisRepN'
p2075
I0
sS'block_loop.thisIndex'
p2076
g890
sS'outcome_loop.thisN'
p2077
I74
sS'outcome_loop.thisTrialN'
p2078
I74
sg62
g66
sg33
S'left'
p2079
sS'block_loop.thisN'
p2080
I0
sS'outcome_loop.thisIndex'
p2081
g63
(g96
S'J\x00\x00\x00'
tRp2082
sg30
g2073
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p2083
sS'block_loop.thisTrial'
p2084
Nsg60
g61
sS'block_loop.thisTrialN'
p2085
I0
sg34
F1.1188949992247217
sg901
V23-crunchie.png
p2086
sa(dp2087
S'block_loop.thisRepN'
p2088
I0
sg884
V51-mars.png
p2089
sg886
V27-hartleys_raspberries_jelly.png
p2090
sg70
g71
sS'outcome_loop.thisRepN'
p2091
I0
sS'block_loop.thisIndex'
p2092
g890
sS'outcome_loop.thisN'
p2093
I75
sS'outcome_loop.thisTrialN'
p2094
I75
sg62
g66
sg33
S'right'
p2095
sS'block_loop.thisN'
p2096
I0
sS'outcome_loop.thisIndex'
p2097
g63
(g96
S'K\x00\x00\x00'
tRp2098
sg30
g2089
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p2099
sS'block_loop.thisTrial'
p2100
Nsg60
g61
sS'block_loop.thisTrialN'
p2101
I0
sg34
F0.99904177765711211
sg901
V51-mars.png
p2102
sa(dp2103
S'block_loop.thisRepN'
p2104
I0
sg884
V5-pineapple.png
p2105
sg886
V5-pineapple.png
p2106
sg70
g71
sS'outcome_loop.thisRepN'
p2107
I0
sS'block_loop.thisIndex'
p2108
g890
sS'outcome_loop.thisN'
p2109
I76
sS'outcome_loop.thisTrialN'
p2110
I76
sg62
g66
sg33
S'right'
p2111
sS'block_loop.thisN'
p2112
I0
sS'outcome_loop.thisIndex'
p2113
g63
(g96
S'L\x00\x00\x00'
tRp2114
sg30
g2105
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2115
sS'block_loop.thisTrial'
p2116
Nsg60
g61
sS'block_loop.thisTrialN'
p2117
I0
sg34
F2.5307023658024264
sg901
V40-sardines.png
p2118
sa(dp2119
S'block_loop.thisRepN'
p2120
I0
sg884
V45-chewy_nougat.png
p2121
sg886
V41-peanuts.png
p2122
sg70
g71
sS'outcome_loop.thisRepN'
p2123
I0
sS'block_loop.thisIndex'
p2124
g890
sS'outcome_loop.thisN'
p2125
I77
sS'outcome_loop.thisTrialN'
p2126
I77
sg62
g66
sg33
S'right'
p2127
sS'block_loop.thisN'
p2128
I0
sS'outcome_loop.thisIndex'
p2129
g63
(g96
S'M\x00\x00\x00'
tRp2130
sg30
g2121
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p2131
sS'block_loop.thisTrial'
p2132
Nsg60
g61
sS'block_loop.thisTrialN'
p2133
I0
sg34
F1.6117000903741427
sg901
V45-chewy_nougat.png
p2134
sa(dp2135
S'block_loop.thisRepN'
p2136
I0
sg884
V17-jacobs_mini_cheddars.png
p2137
sg886
V8-liquorice_catherine_wheels.png
p2138
sg70
g71
sS'outcome_loop.thisRepN'
p2139
I0
sS'block_loop.thisIndex'
p2140
g890
sS'outcome_loop.thisN'
p2141
I78
sS'outcome_loop.thisTrialN'
p2142
I78
sg62
g66
sg33
S'right'
p2143
sS'block_loop.thisN'
p2144
I0
sS'outcome_loop.thisIndex'
p2145
g63
(g96
S'N\x00\x00\x00'
tRp2146
sg30
g2137
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2147
sS'block_loop.thisTrial'
p2148
Nsg60
g61
sS'block_loop.thisTrialN'
p2149
I0
sg34
F0.81258204604273487
sg901
V17-jacobs_mini_cheddars.png
p2150
sa(dp2151
S'block_loop.thisRepN'
p2152
I0
sg884
V49-yorkie.png
p2153
sg886
V35-sultanas.png
p2154
sg70
g71
sS'outcome_loop.thisRepN'
p2155
I0
sS'block_loop.thisIndex'
p2156
g890
sS'outcome_loop.thisN'
p2157
I79
sS'outcome_loop.thisTrialN'
p2158
I79
sg62
g66
sg33
S'right'
p2159
sS'block_loop.thisN'
p2160
I0
sS'outcome_loop.thisIndex'
p2161
g63
(g96
S'O\x00\x00\x00'
tRp2162
sg30
g2153
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p2163
sS'block_loop.thisTrial'
p2164
Nsg60
g61
sS'block_loop.thisTrialN'
p2165
I0
sg34
F0.99904233638517326
sg901
V49-yorkie.png
p2166
sa(dp2167
S'block_loop.thisRepN'
p2168
I0
sg884
V36-fig_rolls.png
p2169
sg886
V34-hula_hoops_bbq_beef.png
p2170
sg70
g71
sS'outcome_loop.thisRepN'
p2171
I0
sS'block_loop.thisIndex'
p2172
g890
sS'outcome_loop.thisN'
p2173
I80
sS'outcome_loop.thisTrialN'
p2174
I80
sg62
g66
sg33
S'right'
p2175
sS'block_loop.thisN'
p2176
I0
sS'outcome_loop.thisIndex'
p2177
g63
(g96
S'P\x00\x00\x00'
tRp2178
sg30
g2169
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p2179
sS'block_loop.thisTrial'
p2180
Nsg60
g61
sS'block_loop.thisTrialN'
p2181
I0
sg34
F1.1455391676881845
sg901
V36-fig_rolls.png
p2182
sa(dp2183
S'block_loop.thisRepN'
p2184
I0
sg884
V20-fruit_pastilles.png
p2185
sg886
V2-steamed_puddings.png
p2186
sg70
g71
sS'outcome_loop.thisRepN'
p2187
I0
sS'block_loop.thisIndex'
p2188
g890
sS'outcome_loop.thisN'
p2189
I81
sS'outcome_loop.thisTrialN'
p2190
I81
sg62
g66
sg33
S'left'
p2191
sS'block_loop.thisN'
p2192
I0
sS'outcome_loop.thisIndex'
p2193
g63
(g96
S'Q\x00\x00\x00'
tRp2194
sg30
g2185
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p2195
sS'block_loop.thisTrial'
p2196
Nsg60
g61
sS'block_loop.thisTrialN'
p2197
I0
sg34
F4.6883601128065493
sg901
V20-fruit_pastilles.png
p2198
sa(dp2199
S'block_loop.thisRepN'
p2200
I0
sg884
V31-foxs_golden_biscuits.png
p2201
sg886
V31-foxs_golden_biscuits.png
p2202
sg70
g71
sS'outcome_loop.thisRepN'
p2203
I0
sS'block_loop.thisIndex'
p2204
g890
sS'outcome_loop.thisN'
p2205
I82
sS'outcome_loop.thisTrialN'
p2206
I82
sg62
g66
sg33
S'left'
p2207
sS'block_loop.thisN'
p2208
I0
sS'outcome_loop.thisIndex'
p2209
g63
(g96
S'R\x00\x00\x00'
tRp2210
sg30
V25-kitkat.png
p2211
sg67
g11
sg68
g69
sg897
g2211
sS'block_loop.thisTrial'
p2212
Nsg60
g61
sS'block_loop.thisTrialN'
p2213
I0
sg34
F2.4641128970306454
sg901
V25-kitkat.png
p2214
sa(dp2215
S'block_loop.thisRepN'
p2216
I0
sg884
V36-fig_rolls.png
p2217
sg886
V34-hula_hoops_bbq_beef.png
p2218
sg70
g71
sS'outcome_loop.thisRepN'
p2219
I0
sS'block_loop.thisIndex'
p2220
g890
sS'outcome_loop.thisN'
p2221
I83
sS'outcome_loop.thisTrialN'
p2222
I83
sg62
g66
sg33
S'right'
p2223
sS'block_loop.thisN'
p2224
I0
sS'outcome_loop.thisIndex'
p2225
g63
(g96
S'S\x00\x00\x00'
tRp2226
sg30
g2217
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p2227
sS'block_loop.thisTrial'
p2228
Nsg60
g61
sS'block_loop.thisTrialN'
p2229
I0
sg34
F0.99902138400284457
sg901
V36-fig_rolls.png
p2230
sa(dp2231
S'block_loop.thisRepN'
p2232
I0
sg884
V5-pineapple.png
p2233
sg886
V40-sardines.png
p2234
sg70
g71
sS'outcome_loop.thisRepN'
p2235
I0
sS'block_loop.thisIndex'
p2236
g890
sS'outcome_loop.thisN'
p2237
I84
sS'outcome_loop.thisTrialN'
p2238
I84
sg62
g66
sg33
S'right'
p2239
sS'block_loop.thisN'
p2240
I0
sS'outcome_loop.thisIndex'
p2241
g63
(g96
S'T\x00\x00\x00'
tRp2242
sg30
g2233
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2243
sS'block_loop.thisTrial'
p2244
Nsg60
g61
sS'block_loop.thisTrialN'
p2245
I0
sg34
F2.1842195027566049
sg901
V5-pineapple.png
p2246
sa(dp2247
S'block_loop.thisRepN'
p2248
I0
sg884
V7-olives.png
p2249
sg886
V22-daim.png
p2250
sg70
g71
sS'outcome_loop.thisRepN'
p2251
I0
sS'block_loop.thisIndex'
p2252
g890
sS'outcome_loop.thisN'
p2253
I85
sS'outcome_loop.thisTrialN'
p2254
I85
sg62
g66
sg33
S'right'
p2255
sS'block_loop.thisN'
p2256
I0
sS'outcome_loop.thisIndex'
p2257
g63
(g96
S'U\x00\x00\x00'
tRp2258
sg30
g2249
sg67
g11
sg68
g69
sg897
V22-daim.png
p2259
sS'block_loop.thisTrial'
p2260
Nsg60
g61
sS'block_loop.thisTrialN'
p2261
I0
sg34
F1.0791178767140082
sg901
V7-olives.png
p2262
sa(dp2263
S'block_loop.thisRepN'
p2264
I0
sg884
V43-mrporky_pork_crackles.png
p2265
sg886
V43-mrporky_pork_crackles.png
p2266
sg70
g71
sS'outcome_loop.thisRepN'
p2267
I0
sS'block_loop.thisIndex'
p2268
g890
sS'outcome_loop.thisN'
p2269
I86
sS'outcome_loop.thisTrialN'
p2270
I86
sg62
g66
sg33
S'left'
p2271
sS'block_loop.thisN'
p2272
I0
sS'outcome_loop.thisIndex'
p2273
g63
(g96
S'V\x00\x00\x00'
tRp2274
sg30
g2265
sg67
g11
sg68
g69
sg897
V18-mms.png
p2275
sS'block_loop.thisTrial'
p2276
Nsg60
g61
sS'block_loop.thisTrialN'
p2277
I0
sg34
F0.99903814590834372
sg901
V18-mms.png
p2278
sa(dp2279
S'block_loop.thisRepN'
p2280
I0
sg884
V1-smarties_cookies.png
p2281
sg886
V21-nakd_banana_crunch.png
p2282
sg70
g71
sS'outcome_loop.thisRepN'
p2283
I0
sS'block_loop.thisIndex'
p2284
g890
sS'outcome_loop.thisN'
p2285
I87
sS'outcome_loop.thisTrialN'
p2286
I87
sg62
g66
sg33
S'right'
p2287
sS'block_loop.thisN'
p2288
I0
sS'outcome_loop.thisIndex'
p2289
g63
(g96
S'W\x00\x00\x00'
tRp2290
sg30
g2281
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p2291
sS'block_loop.thisTrial'
p2292
Nsg60
g61
sS'block_loop.thisTrialN'
p2293
I0
sg34
F2.5839753376476438
sg901
V1-smarties_cookies.png
p2294
sa(dp2295
S'block_loop.thisRepN'
p2296
I0
sg884
V5-pineapple.png
p2297
sg886
V40-sardines.png
p2298
sg70
g71
sS'outcome_loop.thisRepN'
p2299
I0
sS'block_loop.thisIndex'
p2300
g890
sS'outcome_loop.thisN'
p2301
I88
sS'outcome_loop.thisTrialN'
p2302
I88
sg62
g66
sg33
S'right'
p2303
sS'block_loop.thisN'
p2304
I0
sS'outcome_loop.thisIndex'
p2305
g63
(g96
S'X\x00\x00\x00'
tRp2306
sg30
g2297
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2307
sS'block_loop.thisTrial'
p2308
Nsg60
g61
sS'block_loop.thisTrialN'
p2309
I0
sg34
F1.3320508612123376
sg901
V5-pineapple.png
p2310
sa(dp2311
S'block_loop.thisRepN'
p2312
I0
sg884
V33-ambrosia_rice.png
p2313
sg886
V23-crunchie.png
p2314
sg70
g71
sS'outcome_loop.thisRepN'
p2315
I0
sS'block_loop.thisIndex'
p2316
g890
sS'outcome_loop.thisN'
p2317
I89
sS'outcome_loop.thisTrialN'
p2318
I89
sg62
g66
sg33
S'left'
p2319
sS'block_loop.thisN'
p2320
I0
sS'outcome_loop.thisIndex'
p2321
g63
(g96
S'Y\x00\x00\x00'
tRp2322
sg30
g2313
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p2323
sS'block_loop.thisTrial'
p2324
Nsg60
g61
sS'block_loop.thisTrialN'
p2325
I0
sg34
F1.4252311397121957
sg901
V33-ambrosia_rice.png
p2326
sa(dp2327
S'block_loop.thisRepN'
p2328
I0
sg884
V7-olives.png
p2329
sg886
V7-olives.png
p2330
sg70
g71
sS'outcome_loop.thisRepN'
p2331
I0
sS'block_loop.thisIndex'
p2332
g890
sS'outcome_loop.thisN'
p2333
I90
sS'outcome_loop.thisTrialN'
p2334
I90
sg62
g66
sg33
S'left'
p2335
sS'block_loop.thisN'
p2336
I0
sS'outcome_loop.thisIndex'
p2337
g63
(g96
S'Z\x00\x00\x00'
tRp2338
sg30
g2329
sg67
g11
sg68
g69
sg897
V22-daim.png
p2339
sS'block_loop.thisTrial'
p2340
Nsg60
g61
sS'block_loop.thisTrialN'
p2341
I0
sg34
F0.75929957578409812
sg901
V22-daim.png
p2342
sa(dp2343
S'block_loop.thisRepN'
p2344
I0
sg884
V31-foxs_golden_biscuits.png
p2345
sg886
V25-kitkat.png
p2346
sg70
g71
sS'outcome_loop.thisRepN'
p2347
I0
sS'block_loop.thisIndex'
p2348
g890
sS'outcome_loop.thisN'
p2349
I91
sS'outcome_loop.thisTrialN'
p2350
I91
sg62
g66
sg33
S'right'
p2351
sS'block_loop.thisN'
p2352
I0
sS'outcome_loop.thisIndex'
p2353
g63
(g96
S'[\x00\x00\x00'
tRp2354
sg30
g2345
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p2355
sS'block_loop.thisTrial'
p2356
Nsg60
g61
sS'block_loop.thisTrialN'
p2357
I0
sg34
F1.5184899198084167
sg901
V31-foxs_golden_biscuits.png
p2358
sa(dp2359
S'block_loop.thisRepN'
p2360
I0
sg884
V42-mrkipling_lemon_slices.png
p2361
sg886
V42-mrkipling_lemon_slices.png
p2362
sg70
g71
sS'outcome_loop.thisRepN'
p2363
I0
sS'block_loop.thisIndex'
p2364
g890
sS'outcome_loop.thisN'
p2365
I92
sS'outcome_loop.thisTrialN'
p2366
I92
sg62
g66
sg33
S'left'
p2367
sS'block_loop.thisN'
p2368
I0
sS'outcome_loop.thisIndex'
p2369
g63
(g96
S'\\\x00\x00\x00'
tRp2370
sg30
g2361
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p2371
sS'block_loop.thisTrial'
p2372
Nsg60
g61
sS'block_loop.thisTrialN'
p2373
I0
sg34
F2.4241659205290489
sg901
V16-skips_prawn.png
p2374
sa(dp2375
S'block_loop.thisRepN'
p2376
I0
sg884
V6-sour_patch_kids.png
p2377
sg886
V6-sour_patch_kids.png
p2378
sg70
g71
sS'outcome_loop.thisRepN'
p2379
I0
sS'block_loop.thisIndex'
p2380
g890
sS'outcome_loop.thisN'
p2381
I93
sS'outcome_loop.thisTrialN'
p2382
I93
sg62
g66
sg33
S'right'
p2383
sS'block_loop.thisN'
p2384
I0
sS'outcome_loop.thisIndex'
p2385
g63
(g96
S']\x00\x00\x00'
tRp2386
sg30
g2377
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p2387
sS'block_loop.thisTrial'
p2388
Nsg60
g61
sS'block_loop.thisTrialN'
p2389
I0
sg34
F1.5184678499645088
sg901
V38-maltesers.png
p2390
sa(dp2391
S'block_loop.thisRepN'
p2392
I0
sg884
V36-fig_rolls.png
p2393
sg886
V36-fig_rolls.png
p2394
sg70
g71
sS'outcome_loop.thisRepN'
p2395
I0
sS'block_loop.thisIndex'
p2396
g890
sS'outcome_loop.thisN'
p2397
I94
sS'outcome_loop.thisTrialN'
p2398
I94
sg62
g66
sg33
S'left'
p2399
sS'block_loop.thisN'
p2400
I0
sS'outcome_loop.thisIndex'
p2401
g63
(g96
S'^\x00\x00\x00'
tRp2402
sg30
g2393
sg67
g11
sg68
g69
sg897
V34-hula_hoops_bbq_beef.png
p2403
sS'block_loop.thisTrial'
p2404
Nsg60
g61
sS'block_loop.thisTrialN'
p2405
I0
sg34
F0.67939807992479473
sg901
V34-hula_hoops_bbq_beef.png
p2406
sa(dp2407
S'block_loop.thisRepN'
p2408
I0
sg884
V4-corn.png
p2409
sg886
V10-bounty.png
p2410
sg70
g71
sS'outcome_loop.thisRepN'
p2411
I0
sS'block_loop.thisIndex'
p2412
g890
sS'outcome_loop.thisN'
p2413
I95
sS'outcome_loop.thisTrialN'
p2414
I95
sg62
g66
sg33
S'right'
p2415
sS'block_loop.thisN'
p2416
I0
sS'outcome_loop.thisIndex'
p2417
g63
(g96
S'_\x00\x00\x00'
tRp2418
sg30
g2409
sg67
g11
sg68
g69
sg897
V10-bounty.png
p2419
sS'block_loop.thisTrial'
p2420
Nsg60
g61
sS'block_loop.thisTrialN'
p2421
I0
sg34
F0.99903311733760347
sg901
V4-corn.png
p2422
sa(dp2423
S'block_loop.thisRepN'
p2424
I0
sg884
V45-chewy_nougat.png
p2425
sg886
V45-chewy_nougat.png
p2426
sg70
g71
sS'outcome_loop.thisRepN'
p2427
I0
sS'block_loop.thisIndex'
p2428
g890
sS'outcome_loop.thisN'
p2429
I96
sS'outcome_loop.thisTrialN'
p2430
I96
sg62
g66
sg33
S'left'
p2431
sS'block_loop.thisN'
p2432
I0
sS'outcome_loop.thisIndex'
p2433
g63
(g96
S'`\x00\x00\x00'
tRp2434
sg30
g2425
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p2435
sS'block_loop.thisTrial'
p2436
Nsg60
g61
sS'block_loop.thisTrialN'
p2437
I0
sg34
F2.3176227704916528
sg901
V41-peanuts.png
p2438
sa(dp2439
S'block_loop.thisRepN'
p2440
I0
sg884
V5-pineapple.png
p2441
sg886
V40-sardines.png
p2442
sg70
g71
sS'outcome_loop.thisRepN'
p2443
I0
sS'block_loop.thisIndex'
p2444
g890
sS'outcome_loop.thisN'
p2445
I97
sS'outcome_loop.thisTrialN'
p2446
I97
sg62
g66
sg33
S'right'
p2447
sS'block_loop.thisN'
p2448
I0
sS'outcome_loop.thisIndex'
p2449
g63
(g96
S'a\x00\x00\x00'
tRp2450
sg30
g2441
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2451
sS'block_loop.thisTrial'
p2452
Nsg60
g61
sS'block_loop.thisTrialN'
p2453
I0
sg34
F0.95907133448417881
sg901
V5-pineapple.png
p2454
sa(dp2455
S'block_loop.thisRepN'
p2456
I0
sg884
V19-caramello.png
p2457
sg886
V30-spaghetti_hoops.png
p2458
sg70
g71
sS'outcome_loop.thisRepN'
p2459
I0
sS'block_loop.thisIndex'
p2460
g890
sS'outcome_loop.thisN'
p2461
I98
sS'outcome_loop.thisTrialN'
p2462
I98
sg62
g66
sg33
S'left'
p2463
sS'block_loop.thisN'
p2464
I0
sS'outcome_loop.thisIndex'
p2465
g63
(g96
S'b\x00\x00\x00'
tRp2466
sg30
g2457
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p2467
sS'block_loop.thisTrial'
p2468
Nsg60
g61
sS'block_loop.thisTrialN'
p2469
I0
sg34
F2.7837563153989322
sg901
V19-caramello.png
p2470
sa(dp2471
S'block_loop.thisRepN'
p2472
I0
sg884
V5-pineapple.png
p2473
sg886
V5-pineapple.png
p2474
sg70
g71
sS'outcome_loop.thisRepN'
p2475
I0
sS'block_loop.thisIndex'
p2476
g890
sS'outcome_loop.thisN'
p2477
I99
sS'outcome_loop.thisTrialN'
p2478
I99
sg62
g66
sg33
S'left'
p2479
sS'block_loop.thisN'
p2480
I0
sS'outcome_loop.thisIndex'
p2481
g63
(g96
S'c\x00\x00\x00'
tRp2482
sg30
g2473
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2483
sS'block_loop.thisTrial'
p2484
Nsg60
g61
sS'block_loop.thisTrialN'
p2485
I0
sg34
F0.65273323844303377
sg901
V40-sardines.png
p2486
sa(dp2487
S'block_loop.thisRepN'
p2488
I0
sg884
V1-smarties_cookies.png
p2489
sg886
V1-smarties_cookies.png
p2490
sg70
g71
sS'outcome_loop.thisRepN'
p2491
I0
sS'block_loop.thisIndex'
p2492
g890
sS'outcome_loop.thisN'
p2493
I100
sS'outcome_loop.thisTrialN'
p2494
I100
sg62
g66
sg33
S'left'
p2495
sS'block_loop.thisN'
p2496
I0
sS'outcome_loop.thisIndex'
p2497
g63
(g96
S'd\x00\x00\x00'
tRp2498
sg30
g2489
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p2499
sS'block_loop.thisTrial'
p2500
Nsg60
g61
sS'block_loop.thisTrialN'
p2501
I0
sg34
F2.9433989515418943
sg901
V21-nakd_banana_crunch.png
p2502
sa(dp2503
S'block_loop.thisRepN'
p2504
I0
sg884
V20-fruit_pastilles.png
p2505
sg886
V20-fruit_pastilles.png
p2506
sg70
g71
sS'outcome_loop.thisRepN'
p2507
I0
sS'block_loop.thisIndex'
p2508
g890
sS'outcome_loop.thisN'
p2509
I101
sS'outcome_loop.thisTrialN'
p2510
I101
sg62
g66
sg33
S'left'
p2511
sS'block_loop.thisN'
p2512
I0
sS'outcome_loop.thisIndex'
p2513
g63
(g96
S'e\x00\x00\x00'
tRp2514
sg30
g2505
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p2515
sS'block_loop.thisTrial'
p2516
Nsg60
g61
sS'block_loop.thisTrialN'
p2517
I0
sg34
F7.085763414066605
sg901
V2-steamed_puddings.png
p2518
sa(dp2519
S'block_loop.thisRepN'
p2520
I0
sg884
V17-jacobs_mini_cheddars.png
p2521
sg886
V8-liquorice_catherine_wheels.png
p2522
sg70
g71
sS'outcome_loop.thisRepN'
p2523
I0
sS'block_loop.thisIndex'
p2524
g890
sS'outcome_loop.thisN'
p2525
I102
sS'outcome_loop.thisTrialN'
p2526
I102
sg62
g66
sg33
S'right'
p2527
sS'block_loop.thisN'
p2528
I0
sS'outcome_loop.thisIndex'
p2529
g63
(g96
S'f\x00\x00\x00'
tRp2530
sg30
g2521
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2531
sS'block_loop.thisTrial'
p2532
Nsg60
g61
sS'block_loop.thisTrialN'
p2533
I0
sg34
F2.4507533778742072
sg901
V17-jacobs_mini_cheddars.png
p2534
sa(dp2535
S'block_loop.thisRepN'
p2536
I0
sg884
V6-sour_patch_kids.png
p2537
sg886
V38-maltesers.png
p2538
sg70
g71
sS'outcome_loop.thisRepN'
p2539
I0
sS'block_loop.thisIndex'
p2540
g890
sS'outcome_loop.thisN'
p2541
I103
sS'outcome_loop.thisTrialN'
p2542
I103
sg62
g66
sg33
S'left'
p2543
sS'block_loop.thisN'
p2544
I0
sS'outcome_loop.thisIndex'
p2545
g63
(g96
S'g\x00\x00\x00'
tRp2546
sg30
g2537
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p2547
sS'block_loop.thisTrial'
p2548
Nsg60
g61
sS'block_loop.thisTrialN'
p2549
I0
sg34
F0.87915363544743741
sg901
V6-sour_patch_kids.png
p2550
sa(dp2551
S'block_loop.thisRepN'
p2552
I0
sg884
V42-mrkipling_lemon_slices.png
p2553
sg886
V16-skips_prawn.png
p2554
sg70
g71
sS'outcome_loop.thisRepN'
p2555
I0
sS'block_loop.thisIndex'
p2556
g890
sS'outcome_loop.thisN'
p2557
I104
sS'outcome_loop.thisTrialN'
p2558
I104
sg62
g66
sg33
S'right'
p2559
sS'block_loop.thisN'
p2560
I0
sS'outcome_loop.thisIndex'
p2561
g63
(g96
S'h\x00\x00\x00'
tRp2562
sg30
V16-skips_prawn.png
p2563
sg67
g11
sg68
g69
sg897
g2563
sS'block_loop.thisTrial'
p2564
Nsg60
g61
sS'block_loop.thisTrialN'
p2565
I0
sg34
F2.1045026672381937
sg901
V42-mrkipling_lemon_slices.png
p2566
sa(dp2567
S'block_loop.thisRepN'
p2568
I0
sg884
V4-corn.png
p2569
sg886
V4-corn.png
p2570
sg70
g71
sS'outcome_loop.thisRepN'
p2571
I0
sS'block_loop.thisIndex'
p2572
g890
sS'outcome_loop.thisN'
p2573
I105
sS'outcome_loop.thisTrialN'
p2574
I105
sg62
g66
sg33
S'left'
p2575
sS'block_loop.thisN'
p2576
I0
sS'outcome_loop.thisIndex'
p2577
g63
(g96
S'i\x00\x00\x00'
tRp2578
sg30
V10-bounty.png
p2579
sg67
g11
sg68
g69
sg897
g2579
sS'block_loop.thisTrial'
p2580
Nsg60
g61
sS'block_loop.thisTrialN'
p2581
I0
sg34
F3.1700081993658387
sg901
V10-bounty.png
p2582
sa(dp2583
S'block_loop.thisRepN'
p2584
I0
sg884
V17-jacobs_mini_cheddars.png
p2585
sg886
V8-liquorice_catherine_wheels.png
p2586
sg70
g71
sS'outcome_loop.thisRepN'
p2587
I0
sS'block_loop.thisIndex'
p2588
g890
sS'outcome_loop.thisN'
p2589
I106
sS'outcome_loop.thisTrialN'
p2590
I106
sg62
g66
sg33
S'right'
p2591
sS'block_loop.thisN'
p2592
I0
sS'outcome_loop.thisIndex'
p2593
g63
(g96
S'j\x00\x00\x00'
tRp2594
sg30
g2585
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2595
sS'block_loop.thisTrial'
p2596
Nsg60
g61
sS'block_loop.thisTrialN'
p2597
I0
sg34
F0.74596100900998863
sg901
V17-jacobs_mini_cheddars.png
p2598
sa(dp2599
S'block_loop.thisRepN'
p2600
I0
sg884
V51-mars.png
p2601
sg886
V51-mars.png
p2602
sg70
g71
sS'outcome_loop.thisRepN'
p2603
I0
sS'block_loop.thisIndex'
p2604
g890
sS'outcome_loop.thisN'
p2605
I107
sS'outcome_loop.thisTrialN'
p2606
I107
sg62
g66
sg33
S'left'
p2607
sS'block_loop.thisN'
p2608
I0
sS'outcome_loop.thisIndex'
p2609
g63
(g96
S'k\x00\x00\x00'
tRp2610
sg30
V27-hartleys_raspberries_jelly.png
p2611
sg67
g11
sg68
g69
sg897
g2611
sS'block_loop.thisTrial'
p2612
Nsg60
g61
sS'block_loop.thisTrialN'
p2613
I0
sg34
F3.2765650382934837
sg901
V27-hartleys_raspberries_jelly.png
p2614
sa(dp2615
S'block_loop.thisRepN'
p2616
I0
sg884
V20-fruit_pastilles.png
p2617
sg886
V20-fruit_pastilles.png
p2618
sg70
g71
sS'outcome_loop.thisRepN'
p2619
I0
sS'block_loop.thisIndex'
p2620
g890
sS'outcome_loop.thisN'
p2621
I108
sS'outcome_loop.thisTrialN'
p2622
I108
sg62
g66
sg33
S'left'
p2623
sS'block_loop.thisN'
p2624
I0
sS'outcome_loop.thisIndex'
p2625
g63
(g96
S'l\x00\x00\x00'
tRp2626
sg30
g2617
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p2627
sS'block_loop.thisTrial'
p2628
Nsg60
g61
sS'block_loop.thisTrialN'
p2629
I0
sg34
F1.0257923842273158
sg901
V2-steamed_puddings.png
p2630
sa(dp2631
S'block_loop.thisRepN'
p2632
I0
sg884
V6-sour_patch_kids.png
p2633
sg886
V38-maltesers.png
p2634
sg70
g71
sS'outcome_loop.thisRepN'
p2635
I0
sS'block_loop.thisIndex'
p2636
g890
sS'outcome_loop.thisN'
p2637
I109
sS'outcome_loop.thisTrialN'
p2638
I109
sg62
g66
sg33
S'left'
p2639
sS'block_loop.thisN'
p2640
I0
sS'outcome_loop.thisIndex'
p2641
g63
(g96
S'm\x00\x00\x00'
tRp2642
sg30
g2633
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p2643
sS'block_loop.thisTrial'
p2644
Nsg60
g61
sS'block_loop.thisTrialN'
p2645
I0
sg34
F1.3053689784592279
sg901
V6-sour_patch_kids.png
p2646
sa(dp2647
S'block_loop.thisRepN'
p2648
I0
sg884
V33-ambrosia_rice.png
p2649
sg886
V33-ambrosia_rice.png
p2650
sg70
g71
sS'outcome_loop.thisRepN'
p2651
I0
sS'block_loop.thisIndex'
p2652
g890
sS'outcome_loop.thisN'
p2653
I110
sS'outcome_loop.thisTrialN'
p2654
I110
sg62
g66
sg33
S'left'
p2655
sS'block_loop.thisN'
p2656
I0
sS'outcome_loop.thisIndex'
p2657
g63
(g96
S'n\x00\x00\x00'
tRp2658
sg30
g2649
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p2659
sS'block_loop.thisTrial'
p2660
Nsg60
g61
sS'block_loop.thisTrialN'
p2661
I0
sg34
F1.6914269830394915
sg901
V23-crunchie.png
p2662
sa(dp2663
S'block_loop.thisRepN'
p2664
I0
sg884
V31-foxs_golden_biscuits.png
p2665
sg886
V31-foxs_golden_biscuits.png
p2666
sg70
g71
sS'outcome_loop.thisRepN'
p2667
I0
sS'block_loop.thisIndex'
p2668
g890
sS'outcome_loop.thisN'
p2669
I111
sS'outcome_loop.thisTrialN'
p2670
I111
sg62
g66
sg33
S'left'
p2671
sS'block_loop.thisN'
p2672
I0
sS'outcome_loop.thisIndex'
p2673
g63
(g96
S'o\x00\x00\x00'
tRp2674
sg30
g2665
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p2675
sS'block_loop.thisTrial'
p2676
Nsg60
g61
sS'block_loop.thisTrialN'
p2677
I0
sg34
F1.1988149331828026
sg901
V25-kitkat.png
p2678
sa(dp2679
S'block_loop.thisRepN'
p2680
I0
sg884
V6-sour_patch_kids.png
p2681
sg886
V38-maltesers.png
p2682
sg70
g71
sS'outcome_loop.thisRepN'
p2683
I0
sS'block_loop.thisIndex'
p2684
g890
sS'outcome_loop.thisN'
p2685
I112
sS'outcome_loop.thisTrialN'
p2686
I112
sg62
g66
sg33
S'left'
p2687
sS'block_loop.thisN'
p2688
I0
sS'outcome_loop.thisIndex'
p2689
g63
(g96
S'p\x00\x00\x00'
tRp2690
sg30
g2681
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p2691
sS'block_loop.thisTrial'
p2692
Nsg60
g61
sS'block_loop.thisTrialN'
p2693
I0
sg34
F0.70597156901203562
sg901
V6-sour_patch_kids.png
p2694
sa(dp2695
S'block_loop.thisRepN'
p2696
I0
sg884
V36-fig_rolls.png
p2697
sg886
V34-hula_hoops_bbq_beef.png
p2698
sg70
g71
sS'outcome_loop.thisRepN'
p2699
I0
sS'block_loop.thisIndex'
p2700
g890
sS'outcome_loop.thisN'
p2701
I113
sS'outcome_loop.thisTrialN'
p2702
I113
sg62
g66
sg33
S'right'
p2703
sS'block_loop.thisN'
p2704
I0
sS'outcome_loop.thisIndex'
p2705
g63
(g96
S'q\x00\x00\x00'
tRp2706
sg30
V34-hula_hoops_bbq_beef.png
p2707
sg67
g11
sg68
g69
sg897
g2707
sS'block_loop.thisTrial'
p2708
Nsg60
g61
sS'block_loop.thisTrialN'
p2709
I0
sg34
F1.0922653577490564
sg901
V36-fig_rolls.png
p2710
sa(dp2711
S'block_loop.thisRepN'
p2712
I0
sg884
V4-corn.png
p2713
sg886
V10-bounty.png
p2714
sg70
g71
sS'outcome_loop.thisRepN'
p2715
I0
sS'block_loop.thisIndex'
p2716
g890
sS'outcome_loop.thisN'
p2717
I114
sS'outcome_loop.thisTrialN'
p2718
I114
sg62
g66
sg33
S'right'
p2719
sS'block_loop.thisN'
p2720
I0
sS'outcome_loop.thisIndex'
p2721
g63
(g96
S'r\x00\x00\x00'
tRp2722
sg30
g2713
sg67
g11
sg68
g69
sg897
V10-bounty.png
p2723
sS'block_loop.thisTrial'
p2724
Nsg60
g61
sS'block_loop.thisTrialN'
p2725
I0
sg34
F1.5717383075225371
sg901
V4-corn.png
p2726
sa(dp2727
S'block_loop.thisRepN'
p2728
I0
sg884
V19-caramello.png
p2729
sg886
V19-caramello.png
p2730
sg70
g71
sS'outcome_loop.thisRepN'
p2731
I0
sS'block_loop.thisIndex'
p2732
g890
sS'outcome_loop.thisN'
p2733
I115
sS'outcome_loop.thisTrialN'
p2734
I115
sg62
g66
sg33
S'right'
p2735
sS'block_loop.thisN'
p2736
I0
sS'outcome_loop.thisIndex'
p2737
g63
(g96
S's\x00\x00\x00'
tRp2738
sg30
V30-spaghetti_hoops.png
p2739
sg67
g11
sg68
g69
sg897
g2739
sS'block_loop.thisTrial'
p2740
Nsg60
g61
sS'block_loop.thisTrialN'
p2741
I0
sg34
F3.5562544960321247
sg901
V30-spaghetti_hoops.png
p2742
sa(dp2743
S'block_loop.thisRepN'
p2744
I0
sg884
V45-chewy_nougat.png
p2745
sg886
V41-peanuts.png
p2746
sg70
g71
sS'outcome_loop.thisRepN'
p2747
I0
sS'block_loop.thisIndex'
p2748
g890
sS'outcome_loop.thisN'
p2749
I116
sS'outcome_loop.thisTrialN'
p2750
I116
sg62
g66
sg33
S'right'
p2751
sS'block_loop.thisN'
p2752
I0
sS'outcome_loop.thisIndex'
p2753
g63
(g96
S't\x00\x00\x00'
tRp2754
sg30
V41-peanuts.png
p2755
sg67
g11
sg68
g69
sg897
g2755
sS'block_loop.thisTrial'
p2756
Nsg60
g61
sS'block_loop.thisTrialN'
p2757
I0
sg34
F1.1721894821839669
sg901
V45-chewy_nougat.png
p2758
sa(dp2759
S'block_loop.thisRepN'
p2760
I0
sg884
V13-mccoys_steak_crisps.png
p2761
sg886
V13-mccoys_steak_crisps.png
p2762
sg70
g71
sS'outcome_loop.thisRepN'
p2763
I0
sS'block_loop.thisIndex'
p2764
g890
sS'outcome_loop.thisN'
p2765
I117
sS'outcome_loop.thisTrialN'
p2766
I117
sg62
g66
sg33
S'left'
p2767
sS'block_loop.thisN'
p2768
I0
sS'outcome_loop.thisIndex'
p2769
g63
(g96
S'u\x00\x00\x00'
tRp2770
sg30
g2761
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p2771
sS'block_loop.thisTrial'
p2772
Nsg60
g61
sS'block_loop.thisTrialN'
p2773
I0
sg34
F0.85247594317115727
sg901
V3-dole_fruit_snack.png
p2774
sa(dp2775
S'block_loop.thisRepN'
p2776
I0
sg884
V46-pistachios.png
p2777
sg886
V46-pistachios.png
p2778
sg70
g71
sS'outcome_loop.thisRepN'
p2779
I0
sS'block_loop.thisIndex'
p2780
g890
sS'outcome_loop.thisN'
p2781
I118
sS'outcome_loop.thisTrialN'
p2782
I118
sg62
g66
sg33
S'left'
p2783
sS'block_loop.thisN'
p2784
I0
sS'outcome_loop.thisIndex'
p2785
g63
(g96
S'v\x00\x00\x00'
tRp2786
sg30
g2777
sg67
g11
sg68
g69
sg897
V29-beans.png
p2787
sS'block_loop.thisTrial'
p2788
Nsg60
g61
sS'block_loop.thisTrialN'
p2789
I0
sg34
F0.75929175356031919
sg901
V29-beans.png
p2790
sa(dp2791
S'block_loop.thisRepN'
p2792
I0
sg884
V13-mccoys_steak_crisps.png
p2793
sg886
V3-dole_fruit_snack.png
p2794
sg70
g71
sS'outcome_loop.thisRepN'
p2795
I0
sS'block_loop.thisIndex'
p2796
g890
sS'outcome_loop.thisN'
p2797
I119
sS'outcome_loop.thisTrialN'
p2798
I119
sg62
g66
sg33
S'right'
p2799
sS'block_loop.thisN'
p2800
I0
sS'outcome_loop.thisIndex'
p2801
g63
(g96
S'w\x00\x00\x00'
tRp2802
sg30
g2793
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p2803
sS'block_loop.thisTrial'
p2804
Nsg60
g61
sS'block_loop.thisTrialN'
p2805
I0
sg34
F0.90580534676882962
sg901
V13-mccoys_steak_crisps.png
p2806
sa(dp2807
S'block_loop.thisRepN'
p2808
I0
sg884
V33-ambrosia_rice.png
p2809
sg886
V23-crunchie.png
p2810
sg70
g71
sS'outcome_loop.thisRepN'
p2811
I0
sS'block_loop.thisIndex'
p2812
g890
sS'outcome_loop.thisN'
p2813
I120
sS'outcome_loop.thisTrialN'
p2814
I120
sg62
g66
sg33
S'right'
p2815
sS'block_loop.thisN'
p2816
I0
sS'outcome_loop.thisIndex'
p2817
g63
(g96
S'x\x00\x00\x00'
tRp2818
sg30
g2809
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p2819
sS'block_loop.thisTrial'
p2820
Nsg60
g61
sS'block_loop.thisTrialN'
p2821
I0
sg34
F1.5184681293285394
sg901
V33-ambrosia_rice.png
p2822
sa(dp2823
S'block_loop.thisRepN'
p2824
I0
sg884
V20-fruit_pastilles.png
p2825
sg886
V20-fruit_pastilles.png
p2826
sg70
g71
sS'outcome_loop.thisRepN'
p2827
I0
sS'block_loop.thisIndex'
p2828
g890
sS'outcome_loop.thisN'
p2829
I121
sS'outcome_loop.thisTrialN'
p2830
I121
sg62
g66
sg33
S'left'
p2831
sS'block_loop.thisN'
p2832
I0
sS'outcome_loop.thisIndex'
p2833
g63
(g96
S'y\x00\x00\x00'
tRp2834
sg30
g2825
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p2835
sS'block_loop.thisTrial'
p2836
Nsg60
g61
sS'block_loop.thisTrialN'
p2837
I0
sg34
F1.3853221568660956
sg901
V2-steamed_puddings.png
p2838
sa(dp2839
S'block_loop.thisRepN'
p2840
I0
sg884
V26-walkers_smoky_bacon.png
p2841
sg886
V44-crunch.png
p2842
sg70
g71
sS'outcome_loop.thisRepN'
p2843
I0
sS'block_loop.thisIndex'
p2844
g890
sS'outcome_loop.thisN'
p2845
I122
sS'outcome_loop.thisTrialN'
p2846
I122
sg62
g66
sg33
S'right'
p2847
sS'block_loop.thisN'
p2848
I0
sS'outcome_loop.thisIndex'
p2849
g63
(g96
S'z\x00\x00\x00'
tRp2850
sg30
g2841
sg67
g11
sg68
g69
sg897
V44-crunch.png
p2851
sS'block_loop.thisTrial'
p2852
Nsg60
g61
sS'block_loop.thisTrialN'
p2853
I0
sg34
F0.83914799227386538
sg901
V26-walkers_smoky_bacon.png
p2854
sa(dp2855
S'block_loop.thisRepN'
p2856
I0
sg884
V5-pineapple.png
p2857
sg886
V40-sardines.png
p2858
sg70
g71
sS'outcome_loop.thisRepN'
p2859
I0
sS'block_loop.thisIndex'
p2860
g890
sS'outcome_loop.thisN'
p2861
I123
sS'outcome_loop.thisTrialN'
p2862
I123
sg62
g66
sg33
S'right'
p2863
sS'block_loop.thisN'
p2864
I0
sS'outcome_loop.thisIndex'
p2865
g63
(g96
S'{\x00\x00\x00'
tRp2866
sg30
g2857
sg67
g11
sg68
g69
sg897
V40-sardines.png
p2867
sS'block_loop.thisTrial'
p2868
Nsg60
g61
sS'block_loop.thisTrialN'
p2869
I0
sg34
F1.0656276146819437
sg901
V5-pineapple.png
p2870
sa(dp2871
S'block_loop.thisRepN'
p2872
I0
sg884
V17-jacobs_mini_cheddars.png
p2873
sg886
V8-liquorice_catherine_wheels.png
p2874
sg70
g71
sS'outcome_loop.thisRepN'
p2875
I0
sS'block_loop.thisIndex'
p2876
g890
sS'outcome_loop.thisN'
p2877
I124
sS'outcome_loop.thisTrialN'
p2878
I124
sg62
g66
sg33
S'right'
p2879
sS'block_loop.thisN'
p2880
I0
sS'outcome_loop.thisIndex'
p2881
g63
(g96
S'|\x00\x00\x00'
tRp2882
sg30
g2873
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2883
sS'block_loop.thisTrial'
p2884
Nsg60
g61
sS'block_loop.thisTrialN'
p2885
I0
sg34
F0.67922068307598238
sg901
V17-jacobs_mini_cheddars.png
p2886
sa(dp2887
S'block_loop.thisRepN'
p2888
I0
sg884
V31-foxs_golden_biscuits.png
p2889
sg886
V25-kitkat.png
p2890
sg70
g71
sS'outcome_loop.thisRepN'
p2891
I0
sS'block_loop.thisIndex'
p2892
g890
sS'outcome_loop.thisN'
p2893
I125
sS'outcome_loop.thisTrialN'
p2894
I125
sg62
g66
sg33
S'right'
p2895
sS'block_loop.thisN'
p2896
I0
sS'outcome_loop.thisIndex'
p2897
g63
(g96
S'}\x00\x00\x00'
tRp2898
sg30
g2889
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p2899
sS'block_loop.thisTrial'
p2900
Nsg60
g61
sS'block_loop.thisTrialN'
p2901
I0
sg34
F1.3852808108294994
sg901
V31-foxs_golden_biscuits.png
p2902
sa(dp2903
S'block_loop.thisRepN'
p2904
I0
sg884
V4-corn.png
p2905
sg886
V10-bounty.png
p2906
sg70
g71
sS'outcome_loop.thisRepN'
p2907
I0
sS'block_loop.thisIndex'
p2908
g890
sS'outcome_loop.thisN'
p2909
I126
sS'outcome_loop.thisTrialN'
p2910
I126
sg62
g66
sg33
S'right'
p2911
sS'block_loop.thisN'
p2912
I0
sS'outcome_loop.thisIndex'
p2913
g63
(g96
S'~\x00\x00\x00'
tRp2914
sg30
g2905
sg67
g11
sg68
g69
sg897
V10-bounty.png
p2915
sS'block_loop.thisTrial'
p2916
Nsg60
g61
sS'block_loop.thisTrialN'
p2917
I0
sg34
F0.74593614551667997
sg901
V4-corn.png
p2918
sa(dp2919
S'block_loop.thisRepN'
p2920
I0
sg884
V43-mrporky_pork_crackles.png
p2921
sg886
V18-mms.png
p2922
sg70
g71
sS'outcome_loop.thisRepN'
p2923
I0
sS'block_loop.thisIndex'
p2924
g890
sS'outcome_loop.thisN'
p2925
I127
sS'outcome_loop.thisTrialN'
p2926
I127
sg62
g66
sg33
S'right'
p2927
sS'block_loop.thisN'
p2928
I0
sS'outcome_loop.thisIndex'
p2929
g63
(g96
S'\x7f\x00\x00\x00'
tRp2930
sg30
g2921
sg67
g11
sg68
g69
sg897
V18-mms.png
p2931
sS'block_loop.thisTrial'
p2932
Nsg60
g61
sS'block_loop.thisTrialN'
p2933
I0
sg34
F0.85251645111384278
sg901
V43-mrporky_pork_crackles.png
p2934
sa(dp2935
S'block_loop.thisRepN'
p2936
I0
sg884
V17-jacobs_mini_cheddars.png
p2937
sg886
V17-jacobs_mini_cheddars.png
p2938
sg70
g71
sS'outcome_loop.thisRepN'
p2939
I0
sS'block_loop.thisIndex'
p2940
g890
sS'outcome_loop.thisN'
p2941
I128
sS'outcome_loop.thisTrialN'
p2942
I128
sg62
g66
sg33
S'left'
p2943
sS'block_loop.thisN'
p2944
I0
sS'outcome_loop.thisIndex'
p2945
g63
(g96
S'\x80\x00\x00\x00'
tRp2946
sg30
g2937
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p2947
sS'block_loop.thisTrial'
p2948
Nsg60
g61
sS'block_loop.thisTrialN'
p2949
I0
sg34
F0.63942260818112118
sg901
V8-liquorice_catherine_wheels.png
p2950
sa(dp2951
S'block_loop.thisRepN'
p2952
I0
sg884
V42-mrkipling_lemon_slices.png
p2953
sg886
V42-mrkipling_lemon_slices.png
p2954
sg70
g71
sS'outcome_loop.thisRepN'
p2955
I0
sS'block_loop.thisIndex'
p2956
g890
sS'outcome_loop.thisN'
p2957
I129
sS'outcome_loop.thisTrialN'
p2958
I129
sg62
g66
sg33
S'left'
p2959
sS'block_loop.thisN'
p2960
I0
sS'outcome_loop.thisIndex'
p2961
g63
(g96
S'\x81\x00\x00\x00'
tRp2962
sg30
V16-skips_prawn.png
p2963
sg67
g11
sg68
g69
sg897
g2963
sS'block_loop.thisTrial'
p2964
Nsg60
g61
sS'block_loop.thisTrialN'
p2965
I0
sg34
F1.7315795722643088
sg901
V16-skips_prawn.png
p2966
sa(dp2967
S'block_loop.thisRepN'
p2968
I0
sg884
V7-olives.png
p2969
sg886
V7-olives.png
p2970
sg70
g71
sS'outcome_loop.thisRepN'
p2971
I0
sS'block_loop.thisIndex'
p2972
g890
sS'outcome_loop.thisN'
p2973
I130
sS'outcome_loop.thisTrialN'
p2974
I130
sg62
g66
sg33
S'left'
p2975
sS'block_loop.thisN'
p2976
I0
sS'outcome_loop.thisIndex'
p2977
g63
(g96
S'\x82\x00\x00\x00'
tRp2978
sg30
g2969
sg67
g11
sg68
g69
sg897
V22-daim.png
p2979
sS'block_loop.thisTrial'
p2980
Nsg60
g61
sS'block_loop.thisTrialN'
p2981
I0
sg34
F0.78593564265975147
sg901
V22-daim.png
p2982
sa(dp2983
S'block_loop.thisRepN'
p2984
I0
sg884
V45-chewy_nougat.png
p2985
sg886
V41-peanuts.png
p2986
sg70
g71
sS'outcome_loop.thisRepN'
p2987
I0
sS'block_loop.thisIndex'
p2988
g890
sS'outcome_loop.thisN'
p2989
I131
sS'outcome_loop.thisTrialN'
p2990
I131
sg62
g66
sg33
S'right'
p2991
sS'block_loop.thisN'
p2992
I0
sS'outcome_loop.thisIndex'
p2993
g63
(g96
S'\x83\x00\x00\x00'
tRp2994
sg30
g2985
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p2995
sS'block_loop.thisTrial'
p2996
Nsg60
g61
sS'block_loop.thisTrialN'
p2997
I0
sg34
F1.1187103388838295
sg901
V45-chewy_nougat.png
p2998
sa(dp2999
S'block_loop.thisRepN'
p3000
I0
sg884
V1-smarties_cookies.png
p3001
sg886
V1-smarties_cookies.png
p3002
sg70
g71
sS'outcome_loop.thisRepN'
p3003
I0
sS'block_loop.thisIndex'
p3004
g890
sS'outcome_loop.thisN'
p3005
I132
sS'outcome_loop.thisTrialN'
p3006
I132
sg62
g66
sg33
S'left'
p3007
sS'block_loop.thisN'
p3008
I0
sS'outcome_loop.thisIndex'
p3009
g63
(g96
S'\x84\x00\x00\x00'
tRp3010
sg30
g3001
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p3011
sS'block_loop.thisTrial'
p3012
Nsg60
g61
sS'block_loop.thisTrialN'
p3013
I0
sg34
F1.4916448878284427
sg901
V21-nakd_banana_crunch.png
p3014
sa(dp3015
S'block_loop.thisRepN'
p3016
I0
sg884
V19-caramello.png
p3017
sg886
V30-spaghetti_hoops.png
p3018
sg70
g71
sS'outcome_loop.thisRepN'
p3019
I0
sS'block_loop.thisIndex'
p3020
g890
sS'outcome_loop.thisN'
p3021
I133
sS'outcome_loop.thisTrialN'
p3022
I133
sg62
g66
sg33
S'left'
p3023
sS'block_loop.thisN'
p3024
I0
sS'outcome_loop.thisIndex'
p3025
g63
(g96
S'\x85\x00\x00\x00'
tRp3026
sg30
V30-spaghetti_hoops.png
p3027
sg67
g11
sg68
g69
sg897
g3027
sS'block_loop.thisTrial'
p3028
Nsg60
g61
sS'block_loop.thisTrialN'
p3029
I0
sg34
F1.4117202046636521
sg901
V19-caramello.png
p3030
sa(dp3031
S'block_loop.thisRepN'
p3032
I0
sg884
V33-ambrosia_rice.png
p3033
sg886
V33-ambrosia_rice.png
p3034
sg70
g71
sS'outcome_loop.thisRepN'
p3035
I0
sS'block_loop.thisIndex'
p3036
g890
sS'outcome_loop.thisN'
p3037
I134
sS'outcome_loop.thisTrialN'
p3038
I134
sg62
g66
sg33
S'left'
p3039
sS'block_loop.thisN'
p3040
I0
sS'outcome_loop.thisIndex'
p3041
g63
(g96
S'\x86\x00\x00\x00'
tRp3042
sg30
g3033
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p3043
sS'block_loop.thisTrial'
p3044
Nsg60
g61
sS'block_loop.thisTrialN'
p3045
I0
sg34
F0.82589379376440775
sg901
V23-crunchie.png
p3046
sa(dp3047
S'block_loop.thisRepN'
p3048
I0
sg884
V48-twix.png
p3049
sg886
V48-twix.png
p3050
sg70
g71
sS'outcome_loop.thisRepN'
p3051
I0
sS'block_loop.thisIndex'
p3052
g890
sS'outcome_loop.thisN'
p3053
I135
sS'outcome_loop.thisTrialN'
p3054
I135
sg62
g66
sg33
S'right'
p3055
sS'block_loop.thisN'
p3056
I0
sS'outcome_loop.thisIndex'
p3057
g63
(g96
S'\x87\x00\x00\x00'
tRp3058
sg30
g3049
sg67
g11
sg68
g69
sg897
V50-polo.png
p3059
sS'block_loop.thisTrial'
p3060
Nsg60
g61
sS'block_loop.thisTrialN'
p3061
I0
sg34
F1.957982089901634
sg901
V50-polo.png
p3062
sa(dp3063
S'block_loop.thisRepN'
p3064
I0
sg884
V19-caramello.png
p3065
sg886
V19-caramello.png
p3066
sg70
g71
sS'outcome_loop.thisRepN'
p3067
I0
sS'block_loop.thisIndex'
p3068
g890
sS'outcome_loop.thisN'
p3069
I136
sS'outcome_loop.thisTrialN'
p3070
I136
sg62
g66
sg33
S'right'
p3071
sS'block_loop.thisN'
p3072
I0
sS'outcome_loop.thisIndex'
p3073
g63
(g96
S'\x88\x00\x00\x00'
tRp3074
sg30
g3065
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p3075
sS'block_loop.thisTrial'
p3076
Nsg60
g61
sS'block_loop.thisTrialN'
p3077
I0
sg34
F2.0511411366514949
sg901
V30-spaghetti_hoops.png
p3078
sa(dp3079
S'block_loop.thisRepN'
p3080
I0
sg884
V45-chewy_nougat.png
p3081
sg886
V45-chewy_nougat.png
p3082
sg70
g71
sS'outcome_loop.thisRepN'
p3083
I0
sS'block_loop.thisIndex'
p3084
g890
sS'outcome_loop.thisN'
p3085
I137
sS'outcome_loop.thisTrialN'
p3086
I137
sg62
g66
sg33
S'left'
p3087
sS'block_loop.thisN'
p3088
I0
sS'outcome_loop.thisIndex'
p3089
g63
(g96
S'\x89\x00\x00\x00'
tRp3090
sg30
g3081
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p3091
sS'block_loop.thisTrial'
p3092
Nsg60
g61
sS'block_loop.thisTrialN'
p3093
I0
sg34
F0.89247460221849906
sg901
V41-peanuts.png
p3094
sa(dp3095
S'block_loop.thisRepN'
p3096
I0
sg884
V46-pistachios.png
p3097
sg886
V46-pistachios.png
p3098
sg70
g71
sS'outcome_loop.thisRepN'
p3099
I0
sS'block_loop.thisIndex'
p3100
g890
sS'outcome_loop.thisN'
p3101
I138
sS'outcome_loop.thisTrialN'
p3102
I138
sg62
g66
sg33
S'left'
p3103
sS'block_loop.thisN'
p3104
I0
sS'outcome_loop.thisIndex'
p3105
g63
(g96
S'\x8a\x00\x00\x00'
tRp3106
sg30
g3097
sg67
g11
sg68
g69
sg897
V29-beans.png
p3107
sS'block_loop.thisTrial'
p3108
Nsg60
g61
sS'block_loop.thisTrialN'
p3109
I0
sg34
F0.5994672507258656
sg901
V29-beans.png
p3110
sa(dp3111
S'block_loop.thisRepN'
p3112
I0
sg884
V49-yorkie.png
p3113
sg886
V49-yorkie.png
p3114
sg70
g71
sS'outcome_loop.thisRepN'
p3115
I0
sS'block_loop.thisIndex'
p3116
g890
sS'outcome_loop.thisN'
p3117
I139
sS'outcome_loop.thisTrialN'
p3118
I139
sg62
g66
sg33
S'left'
p3119
sS'block_loop.thisN'
p3120
I0
sS'outcome_loop.thisIndex'
p3121
g63
(g96
S'\x8b\x00\x00\x00'
tRp3122
sg30
g3113
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p3123
sS'block_loop.thisTrial'
p3124
Nsg60
g61
sS'block_loop.thisTrialN'
p3125
I0
sg34
F0.75929287102007947
sg901
V35-sultanas.png
p3126
sa(dp3127
S'block_loop.thisRepN'
p3128
I0
sg884
V31-foxs_golden_biscuits.png
p3129
sg886
V25-kitkat.png
p3130
sg70
g71
sS'outcome_loop.thisRepN'
p3131
I0
sS'block_loop.thisIndex'
p3132
g890
sS'outcome_loop.thisN'
p3133
I140
sS'outcome_loop.thisTrialN'
p3134
I140
sg62
g66
sg33
S'right'
p3135
sS'block_loop.thisN'
p3136
I0
sS'outcome_loop.thisIndex'
p3137
g63
(g96
S'\x8c\x00\x00\x00'
tRp3138
sg30
g3129
sg67
g11
sg68
g69
sg897
V25-kitkat.png
p3139
sS'block_loop.thisTrial'
p3140
Nsg60
g61
sS'block_loop.thisTrialN'
p3141
I0
sg34
F0.89248382126788783
sg901
V31-foxs_golden_biscuits.png
p3142
sa(dp3143
S'block_loop.thisRepN'
p3144
I0
sg884
V13-mccoys_steak_crisps.png
p3145
sg886
V3-dole_fruit_snack.png
p3146
sg70
g71
sS'outcome_loop.thisRepN'
p3147
I0
sS'block_loop.thisIndex'
p3148
g890
sS'outcome_loop.thisN'
p3149
I141
sS'outcome_loop.thisTrialN'
p3150
I141
sg62
g66
sg33
S'right'
p3151
sS'block_loop.thisN'
p3152
I0
sS'outcome_loop.thisIndex'
p3153
g63
(g96
S'\x8d\x00\x00\x00'
tRp3154
sg30
g3145
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p3155
sS'block_loop.thisTrial'
p3156
Nsg60
g61
sS'block_loop.thisTrialN'
p3157
I0
sg34
F4.3553934927494993
sg901
V13-mccoys_steak_crisps.png
p3158
sa(dp3159
S'block_loop.thisRepN'
p3160
I0
sg884
V45-chewy_nougat.png
p3161
sg886
V41-peanuts.png
p3162
sg70
g71
sS'outcome_loop.thisRepN'
p3163
I0
sS'block_loop.thisIndex'
p3164
g890
sS'outcome_loop.thisN'
p3165
I142
sS'outcome_loop.thisTrialN'
p3166
I142
sg62
g66
sg33
S'right'
p3167
sS'block_loop.thisN'
p3168
I0
sS'outcome_loop.thisIndex'
p3169
g63
(g96
S'\x8e\x00\x00\x00'
tRp3170
sg30
g3161
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p3171
sS'block_loop.thisTrial'
p3172
Nsg60
g61
sS'block_loop.thisTrialN'
p3173
I0
sg34
F1.2254585429163853
sg901
V45-chewy_nougat.png
p3174
sa(dp3175
S'block_loop.thisRepN'
p3176
I0
sg884
V51-mars.png
p3177
sg886
V51-mars.png
p3178
sg70
g71
sS'outcome_loop.thisRepN'
p3179
I0
sS'block_loop.thisIndex'
p3180
g890
sS'outcome_loop.thisN'
p3181
I143
sS'outcome_loop.thisTrialN'
p3182
I143
sg62
g66
sg33
S'right'
p3183
sS'block_loop.thisN'
p3184
I0
sS'outcome_loop.thisIndex'
p3185
g63
(g96
S'\x8f\x00\x00\x00'
tRp3186
sg30
g3177
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p3187
sS'block_loop.thisTrial'
p3188
Nsg60
g61
sS'block_loop.thisTrialN'
p3189
I0
sg34
F1.1722702187016694
sg901
V27-hartleys_raspberries_jelly.png
p3190
sa(dp3191
S'block_loop.thisRepN'
p3192
I0
sg884
V48-twix.png
p3193
sg886
V50-polo.png
p3194
sg70
g71
sS'outcome_loop.thisRepN'
p3195
I0
sS'block_loop.thisIndex'
p3196
g890
sS'outcome_loop.thisN'
p3197
I144
sS'outcome_loop.thisTrialN'
p3198
I144
sg62
g66
sg33
S'left'
p3199
sS'block_loop.thisN'
p3200
I0
sS'outcome_loop.thisIndex'
p3201
g63
(g96
S'\x90\x00\x00\x00'
tRp3202
sg30
g3193
sg67
g11
sg68
g69
sg897
V50-polo.png
p3203
sS'block_loop.thisTrial'
p3204
Nsg60
g61
sS'block_loop.thisTrialN'
p3205
I0
sg34
F0.82590161598818668
sg901
V48-twix.png
p3206
sa(dp3207
S'block_loop.thisRepN'
p3208
I0
sg884
V42-mrkipling_lemon_slices.png
p3209
sg886
V16-skips_prawn.png
p3210
sg70
g71
sS'outcome_loop.thisRepN'
p3211
I0
sS'block_loop.thisIndex'
p3212
g890
sS'outcome_loop.thisN'
p3213
I145
sS'outcome_loop.thisTrialN'
p3214
I145
sg62
g66
sg33
S'right'
p3215
sS'block_loop.thisN'
p3216
I0
sS'outcome_loop.thisIndex'
p3217
g63
(g96
S'\x91\x00\x00\x00'
tRp3218
sg30
g3209
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p3219
sS'block_loop.thisTrial'
p3220
Nsg60
g61
sS'block_loop.thisTrialN'
p3221
I0
sg34
F1.1189014246210718
sg901
V42-mrkipling_lemon_slices.png
p3222
sa(dp3223
S'block_loop.thisRepN'
p3224
I0
sg884
V4-corn.png
p3225
sg886
V4-corn.png
p3226
sg70
g71
sS'outcome_loop.thisRepN'
p3227
I0
sS'block_loop.thisIndex'
p3228
g890
sS'outcome_loop.thisN'
p3229
I146
sS'outcome_loop.thisTrialN'
p3230
I146
sg62
g66
sg33
S'left'
p3231
sS'block_loop.thisN'
p3232
I0
sS'outcome_loop.thisIndex'
p3233
g63
(g96
S'\x92\x00\x00\x00'
tRp3234
sg30
g3225
sg67
g11
sg68
g69
sg897
V10-bounty.png
p3235
sS'block_loop.thisTrial'
p3236
Nsg60
g61
sS'block_loop.thisTrialN'
p3237
I0
sg34
F0.75929650276884786
sg901
V10-bounty.png
p3238
sa(dp3239
S'block_loop.thisRepN'
p3240
I0
sg884
V26-walkers_smoky_bacon.png
p3241
sg886
V26-walkers_smoky_bacon.png
p3242
sg70
g71
sS'outcome_loop.thisRepN'
p3243
I0
sS'block_loop.thisIndex'
p3244
g890
sS'outcome_loop.thisN'
p3245
I147
sS'outcome_loop.thisTrialN'
p3246
I147
sg62
g66
sg33
S'left'
p3247
sS'block_loop.thisN'
p3248
I0
sS'outcome_loop.thisIndex'
p3249
g63
(g96
S'\x93\x00\x00\x00'
tRp3250
sg30
V44-crunch.png
p3251
sg67
g11
sg68
g69
sg897
g3251
sS'block_loop.thisTrial'
p3252
Nsg60
g61
sS'block_loop.thisTrialN'
p3253
I0
sg34
F0.58614572522492381
sg901
V44-crunch.png
p3254
sa(dp3255
S'block_loop.thisRepN'
p3256
I0
sg884
V48-twix.png
p3257
sg886
V50-polo.png
p3258
sg70
g71
sS'outcome_loop.thisRepN'
p3259
I0
sS'block_loop.thisIndex'
p3260
g890
sS'outcome_loop.thisN'
p3261
I148
sS'outcome_loop.thisTrialN'
p3262
I148
sg62
g66
sg33
S'left'
p3263
sS'block_loop.thisN'
p3264
I0
sS'outcome_loop.thisIndex'
p3265
g63
(g96
S'\x94\x00\x00\x00'
tRp3266
sg30
g3257
sg67
g11
sg68
g69
sg897
V50-polo.png
p3267
sS'block_loop.thisTrial'
p3268
Nsg60
g61
sS'block_loop.thisTrialN'
p3269
I0
sg34
F1.0922720625094371
sg901
V48-twix.png
p3270
sa(dp3271
S'block_loop.thisRepN'
p3272
I0
sg884
V26-walkers_smoky_bacon.png
p3273
sg886
V26-walkers_smoky_bacon.png
p3274
sg70
g71
sS'outcome_loop.thisRepN'
p3275
I0
sS'block_loop.thisIndex'
p3276
g890
sS'outcome_loop.thisN'
p3277
I149
sS'outcome_loop.thisTrialN'
p3278
I149
sg62
g66
sg33
S'left'
p3279
sS'block_loop.thisN'
p3280
I0
sS'outcome_loop.thisIndex'
p3281
g63
(g96
S'\x95\x00\x00\x00'
tRp3282
sg30
g3273
sg67
g11
sg68
g69
sg897
V44-crunch.png
p3283
sS'block_loop.thisTrial'
p3284
Nsg60
g61
sS'block_loop.thisTrialN'
p3285
I0
sg34
F0.70601934044680092
sg901
V44-crunch.png
p3286
sa(dp3287
S'block_loop.thisRepN'
p3288
I0
sg884
V5-pineapple.png
p3289
sg886
V5-pineapple.png
p3290
sg70
g71
sS'outcome_loop.thisRepN'
p3291
I0
sS'block_loop.thisIndex'
p3292
g890
sS'outcome_loop.thisN'
p3293
I150
sS'outcome_loop.thisTrialN'
p3294
I150
sg62
g66
sg33
S'left'
p3295
sS'block_loop.thisN'
p3296
I0
sS'outcome_loop.thisIndex'
p3297
g63
(g96
S'\x96\x00\x00\x00'
tRp3298
sg30
g3289
sg67
g11
sg68
g69
sg897
V40-sardines.png
p3299
sS'block_loop.thisTrial'
p3300
Nsg60
g61
sS'block_loop.thisTrialN'
p3301
I0
sg34
F0.79922755545703694
sg901
V40-sardines.png
p3302
sa(dp3303
S'block_loop.thisRepN'
p3304
I0
sg884
V45-chewy_nougat.png
p3305
sg886
V41-peanuts.png
p3306
sg70
g71
sS'outcome_loop.thisRepN'
p3307
I0
sS'block_loop.thisIndex'
p3308
g890
sS'outcome_loop.thisN'
p3309
I151
sS'outcome_loop.thisTrialN'
p3310
I151
sg62
g66
sg33
S'right'
p3311
sS'block_loop.thisN'
p3312
I0
sS'outcome_loop.thisIndex'
p3313
g63
(g96
S'\x97\x00\x00\x00'
tRp3314
sg30
g3305
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p3315
sS'block_loop.thisTrial'
p3316
Nsg60
g61
sS'block_loop.thisTrialN'
p3317
I0
sg34
F0.85251756857360306
sg901
V45-chewy_nougat.png
p3318
sa(dp3319
S'block_loop.thisRepN'
p3320
I0
sg884
V13-mccoys_steak_crisps.png
p3321
sg886
V3-dole_fruit_snack.png
p3322
sg70
g71
sS'outcome_loop.thisRepN'
p3323
I0
sS'block_loop.thisIndex'
p3324
g890
sS'outcome_loop.thisN'
p3325
I152
sS'outcome_loop.thisTrialN'
p3326
I152
sg62
g66
sg33
S'right'
p3327
sS'block_loop.thisN'
p3328
I0
sS'outcome_loop.thisIndex'
p3329
g63
(g96
S'\x98\x00\x00\x00'
tRp3330
sg30
g3321
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p3331
sS'block_loop.thisTrial'
p3332
Nsg60
g61
sS'block_loop.thisTrialN'
p3333
I0
sg34
F0.63942288754697074
sg901
V13-mccoys_steak_crisps.png
p3334
sa(dp3335
S'block_loop.thisRepN'
p3336
I0
sg884
V42-mrkipling_lemon_slices.png
p3337
sg886
V16-skips_prawn.png
p3338
sg70
g71
sS'outcome_loop.thisRepN'
p3339
I0
sS'block_loop.thisIndex'
p3340
g890
sS'outcome_loop.thisN'
p3341
I153
sS'outcome_loop.thisTrialN'
p3342
I153
sg62
g66
sg33
S'right'
p3343
sS'block_loop.thisN'
p3344
I0
sS'outcome_loop.thisIndex'
p3345
g63
(g96
S'\x99\x00\x00\x00'
tRp3346
sg30
V16-skips_prawn.png
p3347
sg67
g11
sg68
g69
sg897
g3347
sS'block_loop.thisTrial'
p3348
Nsg60
g61
sS'block_loop.thisTrialN'
p3349
I0
sg34
F1.0523111177553801
sg901
V42-mrkipling_lemon_slices.png
p3350
sa(dp3351
S'block_loop.thisRepN'
p3352
I0
sg884
V33-ambrosia_rice.png
p3353
sg886
V23-crunchie.png
p3354
sg70
g71
sS'outcome_loop.thisRepN'
p3355
I0
sS'block_loop.thisIndex'
p3356
g890
sS'outcome_loop.thisN'
p3357
I154
sS'outcome_loop.thisTrialN'
p3358
I154
sg62
g66
sg33
S'right'
p3359
sS'block_loop.thisN'
p3360
I0
sS'outcome_loop.thisIndex'
p3361
g63
(g96
S'\x9a\x00\x00\x00'
tRp3362
sg30
g3353
sg67
g11
sg68
g69
sg897
V23-crunchie.png
p3363
sS'block_loop.thisTrial'
p3364
Nsg60
g61
sS'block_loop.thisTrialN'
p3365
I0
sg34
F0.97241381236926827
sg901
V33-ambrosia_rice.png
p3366
sa(dp3367
S'block_loop.thisRepN'
p3368
I0
sg884
V17-jacobs_mini_cheddars.png
p3369
sg886
V17-jacobs_mini_cheddars.png
p3370
sg70
g71
sS'outcome_loop.thisRepN'
p3371
I0
sS'block_loop.thisIndex'
p3372
g890
sS'outcome_loop.thisN'
p3373
I155
sS'outcome_loop.thisTrialN'
p3374
I155
sg62
g66
sg33
S'left'
p3375
sS'block_loop.thisN'
p3376
I0
sS'outcome_loop.thisIndex'
p3377
g63
(g96
S'\x9b\x00\x00\x00'
tRp3378
sg30
g3369
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p3379
sS'block_loop.thisTrial'
p3380
Nsg60
g61
sS'block_loop.thisTrialN'
p3381
I0
sg34
F0.99901328241503506
sg901
V8-liquorice_catherine_wheels.png
p3382
sa(dp3383
S'block_loop.thisRepN'
p3384
I0
sg884
V26-walkers_smoky_bacon.png
p3385
sg886
V44-crunch.png
p3386
sg70
g71
sS'outcome_loop.thisRepN'
p3387
I0
sS'block_loop.thisIndex'
p3388
g890
sS'outcome_loop.thisN'
p3389
I156
sS'outcome_loop.thisTrialN'
p3390
I156
sg62
g66
sg33
S'right'
p3391
sS'block_loop.thisN'
p3392
I0
sS'outcome_loop.thisIndex'
p3393
g63
(g96
S'\x9c\x00\x00\x00'
tRp3394
sg30
g3385
sg67
g11
sg68
g69
sg897
V44-crunch.png
p3395
sS'block_loop.thisTrial'
p3396
Nsg60
g61
sS'block_loop.thisTrialN'
p3397
I0
sg34
F0.69270675462939835
sg901
V26-walkers_smoky_bacon.png
p3398
sa(dp3399
S'block_loop.thisRepN'
p3400
I0
sg884
V49-yorkie.png
p3401
sg886
V35-sultanas.png
p3402
sg70
g71
sS'outcome_loop.thisRepN'
p3403
I0
sS'block_loop.thisIndex'
p3404
g890
sS'outcome_loop.thisN'
p3405
I157
sS'outcome_loop.thisTrialN'
p3406
I157
sg62
g66
sg33
S'right'
p3407
sS'block_loop.thisN'
p3408
I0
sS'outcome_loop.thisIndex'
p3409
g63
(g96
S'\x9d\x00\x00\x00'
tRp3410
sg30
g3401
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p3411
sS'block_loop.thisTrial'
p3412
Nsg60
g61
sS'block_loop.thisTrialN'
p3413
I0
sg34
F0.91911821195026278
sg901
V49-yorkie.png
p3414
sa(dp3415
S'block_loop.thisRepN'
p3416
I0
sg884
V20-fruit_pastilles.png
p3417
sg886
V2-steamed_puddings.png
p3418
sg70
g71
sS'outcome_loop.thisRepN'
p3419
I0
sS'block_loop.thisIndex'
p3420
g890
sS'outcome_loop.thisN'
p3421
I158
sS'outcome_loop.thisTrialN'
p3422
I158
sg62
g66
sg33
S'right'
p3423
sS'block_loop.thisN'
p3424
I0
sS'outcome_loop.thisIndex'
p3425
g63
(g96
S'\x9e\x00\x00\x00'
tRp3426
sg30
g3417
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p3427
sS'block_loop.thisTrial'
p3428
Nsg60
g61
sS'block_loop.thisTrialN'
p3429
I0
sg34
F1.4252356095530558
sg901
V20-fruit_pastilles.png
p3430
sa(dp3431
S'block_loop.thisRepN'
p3432
I0
sg884
V4-corn.png
p3433
sg886
V10-bounty.png
p3434
sg70
g71
sS'outcome_loop.thisRepN'
p3435
I0
sS'block_loop.thisIndex'
p3436
g890
sS'outcome_loop.thisN'
p3437
I159
sS'outcome_loop.thisTrialN'
p3438
I159
sg62
g66
sg33
S'right'
p3439
sS'block_loop.thisN'
p3440
I0
sS'outcome_loop.thisIndex'
p3441
g63
(g96
S'\x9f\x00\x00\x00'
tRp3442
sg30
g3433
sg67
g11
sg68
g69
sg897
V10-bounty.png
p3443
sS'block_loop.thisTrial'
p3444
Nsg60
g61
sS'block_loop.thisTrialN'
p3445
I0
sg34
F0.82569069532473804
sg901
V4-corn.png
p3446
sa(dp3447
S'block_loop.thisRepN'
p3448
I0
sg884
V31-foxs_golden_biscuits.png
p3449
sg886
V31-foxs_golden_biscuits.png
p3450
sg70
g71
sS'outcome_loop.thisRepN'
p3451
I0
sS'block_loop.thisIndex'
p3452
g890
sS'outcome_loop.thisN'
p3453
I160
sS'outcome_loop.thisTrialN'
p3454
I160
sg62
g66
sg33
S'left'
p3455
sS'block_loop.thisN'
p3456
I0
sS'outcome_loop.thisIndex'
p3457
g63
(g96
S'\xa0\x00\x00\x00'
tRp3458
sg30
V25-kitkat.png
p3459
sg67
g11
sg68
g69
sg897
g3459
sS'block_loop.thisTrial'
p3460
Nsg60
g61
sS'block_loop.thisTrialN'
p3461
I0
sg34
F0.6527438543162134
sg901
V25-kitkat.png
p3462
sa(dp3463
S'block_loop.thisRepN'
p3464
I0
sg884
V13-mccoys_steak_crisps.png
p3465
sg886
V13-mccoys_steak_crisps.png
p3466
sg70
g71
sS'outcome_loop.thisRepN'
p3467
I0
sS'block_loop.thisIndex'
p3468
g890
sS'outcome_loop.thisN'
p3469
I161
sS'outcome_loop.thisTrialN'
p3470
I161
sg62
g66
sg33
S'left'
p3471
sS'block_loop.thisN'
p3472
I0
sS'outcome_loop.thisIndex'
p3473
g63
(g96
S'\xa1\x00\x00\x00'
tRp3474
sg30
g3465
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p3475
sS'block_loop.thisTrial'
p3476
Nsg60
g61
sS'block_loop.thisTrialN'
p3477
I0
sg34
F0.66605727822934568
sg901
V3-dole_fruit_snack.png
p3478
sa(dp3479
S'block_loop.thisRepN'
p3480
I0
sg884
V5-pineapple.png
p3481
sg886
V40-sardines.png
p3482
sg70
g71
sS'outcome_loop.thisRepN'
p3483
I0
sS'block_loop.thisIndex'
p3484
g890
sS'outcome_loop.thisN'
p3485
I162
sS'outcome_loop.thisTrialN'
p3486
I162
sg62
g66
sg33
S'left'
p3487
sS'block_loop.thisN'
p3488
I0
sS'outcome_loop.thisIndex'
p3489
g63
(g96
S'\xa2\x00\x00\x00'
tRp3490
sg30
g3481
sg67
g11
sg68
g69
sg897
V40-sardines.png
p3491
sS'block_loop.thisTrial'
p3492
Nsg60
g61
sS'block_loop.thisTrialN'
p3493
I0
sg34
F0.62610583188688906
sg901
V5-pineapple.png
p3494
sa(dp3495
S'block_loop.thisRepN'
p3496
I0
sg884
V46-pistachios.png
p3497
sg886
V29-beans.png
p3498
sg70
g71
sS'outcome_loop.thisRepN'
p3499
I0
sS'block_loop.thisIndex'
p3500
g890
sS'outcome_loop.thisN'
p3501
I163
sS'outcome_loop.thisTrialN'
p3502
I163
sg62
g66
sg33
S'right'
p3503
sS'block_loop.thisN'
p3504
I0
sS'outcome_loop.thisIndex'
p3505
g63
(g96
S'\xa3\x00\x00\x00'
tRp3506
sg30
g3497
sg67
g11
sg68
g69
sg897
V29-beans.png
p3507
sS'block_loop.thisTrial'
p3508
Nsg60
g61
sS'block_loop.thisTrialN'
p3509
I0
sg34
F0.86583657978917472
sg901
V46-pistachios.png
p3510
sa(dp3511
S'block_loop.thisRepN'
p3512
I0
sg884
V51-mars.png
p3513
sg886
V27-hartleys_raspberries_jelly.png
p3514
sg70
g71
sS'outcome_loop.thisRepN'
p3515
I0
sS'block_loop.thisIndex'
p3516
g890
sS'outcome_loop.thisN'
p3517
I164
sS'outcome_loop.thisTrialN'
p3518
I164
sg62
g66
sg33
S'left'
p3519
sS'block_loop.thisN'
p3520
I0
sS'outcome_loop.thisIndex'
p3521
g63
(g96
S'\xa4\x00\x00\x00'
tRp3522
sg30
g3513
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p3523
sS'block_loop.thisTrial'
p3524
Nsg60
g61
sS'block_loop.thisTrialN'
p3525
I0
sg34
F4.1687546880966693
sg901
V51-mars.png
p3526
sa(dp3527
S'block_loop.thisRepN'
p3528
I0
sg884
V43-mrporky_pork_crackles.png
p3529
sg886
V18-mms.png
p3530
sg70
g71
sS'outcome_loop.thisRepN'
p3531
I0
sS'block_loop.thisIndex'
p3532
g890
sS'outcome_loop.thisN'
p3533
I165
sS'outcome_loop.thisTrialN'
p3534
I165
sg62
g66
sg33
S'right'
p3535
sS'block_loop.thisN'
p3536
I0
sS'outcome_loop.thisIndex'
p3537
g63
(g96
S'\xa5\x00\x00\x00'
tRp3538
sg30
V18-mms.png
p3539
sg67
g11
sg68
g69
sg897
g3539
sS'block_loop.thisTrial'
p3540
Nsg60
g61
sS'block_loop.thisTrialN'
p3541
I0
sg34
F0.67940282912968541
sg901
V43-mrporky_pork_crackles.png
p3542
sa(dp3543
S'block_loop.thisRepN'
p3544
I0
sg884
V51-mars.png
p3545
sg886
V51-mars.png
p3546
sg70
g71
sS'outcome_loop.thisRepN'
p3547
I0
sS'block_loop.thisIndex'
p3548
g890
sS'outcome_loop.thisN'
p3549
I166
sS'outcome_loop.thisTrialN'
p3550
I166
sg62
g66
sg33
S'right'
p3551
sS'block_loop.thisN'
p3552
I0
sS'outcome_loop.thisIndex'
p3553
g63
(g96
S'\xa6\x00\x00\x00'
tRp3554
sg30
V27-hartleys_raspberries_jelly.png
p3555
sg67
g11
sg68
g69
sg897
g3555
sS'block_loop.thisTrial'
p3556
Nsg60
g61
sS'block_loop.thisTrialN'
p3557
I0
sg34
F2.0245793808990129
sg901
V27-hartleys_raspberries_jelly.png
p3558
sa(dp3559
S'block_loop.thisRepN'
p3560
I0
sg884
V48-twix.png
p3561
sg886
V48-twix.png
p3562
sg70
g71
sS'outcome_loop.thisRepN'
p3563
I0
sS'block_loop.thisIndex'
p3564
g890
sS'outcome_loop.thisN'
p3565
I167
sS'outcome_loop.thisTrialN'
p3566
I167
sg62
g66
sg33
S'left'
p3567
sS'block_loop.thisN'
p3568
I0
sS'outcome_loop.thisIndex'
p3569
g63
(g96
S'\xa7\x00\x00\x00'
tRp3570
sg30
g3561
sg67
g11
sg68
g69
sg897
V50-polo.png
p3571
sS'block_loop.thisTrial'
p3572
Nsg60
g61
sS'block_loop.thisTrialN'
p3573
I0
sg34
F1.3852805314654688
sg901
V50-polo.png
p3574
sa(dp3575
S'block_loop.thisRepN'
p3576
I0
sg884
V1-smarties_cookies.png
p3577
sg886
V21-nakd_banana_crunch.png
p3578
sg70
g71
sS'outcome_loop.thisRepN'
p3579
I0
sS'block_loop.thisIndex'
p3580
g890
sS'outcome_loop.thisN'
p3581
I168
sS'outcome_loop.thisTrialN'
p3582
I168
sg62
g66
sg33
S'right'
p3583
sS'block_loop.thisN'
p3584
I0
sS'outcome_loop.thisIndex'
p3585
g63
(g96
S'\xa8\x00\x00\x00'
tRp3586
sg30
g3577
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p3587
sS'block_loop.thisTrial'
p3588
Nsg60
g61
sS'block_loop.thisTrialN'
p3589
I0
sg34
F0.87916313386267575
sg901
V1-smarties_cookies.png
p3590
sa(dp3591
S'block_loop.thisRepN'
p3592
I0
sg884
V48-twix.png
p3593
sg886
V50-polo.png
p3594
sg70
g71
sS'outcome_loop.thisRepN'
p3595
I0
sS'block_loop.thisIndex'
p3596
g890
sS'outcome_loop.thisN'
p3597
I169
sS'outcome_loop.thisTrialN'
p3598
I169
sg62
g66
sg33
S'left'
p3599
sS'block_loop.thisN'
p3600
I0
sS'outcome_loop.thisIndex'
p3601
g63
(g96
S'\xa9\x00\x00\x00'
tRp3602
sg30
g3593
sg67
g11
sg68
g69
sg897
V50-polo.png
p3603
sS'block_loop.thisTrial'
p3604
Nsg60
g61
sS'block_loop.thisTrialN'
p3605
I0
sg34
F2.7571294675708486
sg901
V48-twix.png
p3606
sa(dp3607
S'block_loop.thisRepN'
p3608
I0
sg884
V42-mrkipling_lemon_slices.png
p3609
sg886
V16-skips_prawn.png
p3610
sg70
g71
sS'outcome_loop.thisRepN'
p3611
I0
sS'block_loop.thisIndex'
p3612
g890
sS'outcome_loop.thisN'
p3613
I170
sS'outcome_loop.thisTrialN'
p3614
I170
sg62
g66
sg33
S'right'
p3615
sS'block_loop.thisN'
p3616
I0
sS'outcome_loop.thisIndex'
p3617
g63
(g96
S'\xaa\x00\x00\x00'
tRp3618
sg30
g3609
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p3619
sS'block_loop.thisTrial'
p3620
Nsg60
g61
sS'block_loop.thisTrialN'
p3621
I0
sg34
F1.1988096252443938
sg901
V42-mrkipling_lemon_slices.png
p3622
sa(dp3623
S'block_loop.thisRepN'
p3624
I0
sg884
V1-smarties_cookies.png
p3625
sg886
V21-nakd_banana_crunch.png
p3626
sg70
g71
sS'outcome_loop.thisRepN'
p3627
I0
sS'block_loop.thisIndex'
p3628
g890
sS'outcome_loop.thisN'
p3629
I171
sS'outcome_loop.thisTrialN'
p3630
I171
sg62
g66
sg33
S'right'
p3631
sS'block_loop.thisN'
p3632
I0
sS'outcome_loop.thisIndex'
p3633
g63
(g96
S'\xab\x00\x00\x00'
tRp3634
sg30
g3625
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p3635
sS'block_loop.thisTrial'
p3636
Nsg60
g61
sS'block_loop.thisTrialN'
p3637
I0
sg34
F0.83920358593059063
sg901
V1-smarties_cookies.png
p3638
sa(dp3639
S'block_loop.thisRepN'
p3640
I0
sg884
V20-fruit_pastilles.png
p3641
sg886
V2-steamed_puddings.png
p3642
sg70
g71
sS'outcome_loop.thisRepN'
p3643
I0
sS'block_loop.thisIndex'
p3644
g890
sS'outcome_loop.thisN'
p3645
I172
sS'outcome_loop.thisTrialN'
p3646
I172
sg62
g66
sg33
S'right'
p3647
sS'block_loop.thisN'
p3648
I0
sS'outcome_loop.thisIndex'
p3649
g63
(g96
S'\xac\x00\x00\x00'
tRp3650
sg30
g3641
sg67
g11
sg68
g69
sg897
V2-steamed_puddings.png
p3651
sS'block_loop.thisTrial'
p3652
Nsg60
g61
sS'block_loop.thisTrialN'
p3653
I0
sg34
F2.4507746096223855
sg901
V20-fruit_pastilles.png
p3654
sa(dp3655
S'block_loop.thisRepN'
p3656
I0
sg884
V13-mccoys_steak_crisps.png
p3657
sg886
V13-mccoys_steak_crisps.png
p3658
sg70
g71
sS'outcome_loop.thisRepN'
p3659
I0
sS'block_loop.thisIndex'
p3660
g890
sS'outcome_loop.thisN'
p3661
I173
sS'outcome_loop.thisTrialN'
p3662
I173
sg62
g66
sg33
S'left'
p3663
sS'block_loop.thisN'
p3664
I0
sS'outcome_loop.thisIndex'
p3665
g63
(g96
S'\xad\x00\x00\x00'
tRp3666
sg30
g3657
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p3667
sS'block_loop.thisTrial'
p3668
Nsg60
g61
sS'block_loop.thisTrialN'
p3669
I0
sg34
F0.69278441813185054
sg901
V3-dole_fruit_snack.png
p3670
sa(dp3671
S'block_loop.thisRepN'
p3672
I0
sg884
V1-smarties_cookies.png
p3673
sg886
V1-smarties_cookies.png
p3674
sg70
g71
sS'outcome_loop.thisRepN'
p3675
I0
sS'block_loop.thisIndex'
p3676
g890
sS'outcome_loop.thisN'
p3677
I174
sS'outcome_loop.thisTrialN'
p3678
I174
sg62
g66
sg33
S'left'
p3679
sS'block_loop.thisN'
p3680
I0
sS'outcome_loop.thisIndex'
p3681
g63
(g96
S'\xae\x00\x00\x00'
tRp3682
sg30
g3673
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p3683
sS'block_loop.thisTrial'
p3684
Nsg60
g61
sS'block_loop.thisTrialN'
p3685
I0
sg34
F1.9713187011202535
sg901
V21-nakd_banana_crunch.png
p3686
sa(dp3687
S'block_loop.thisRepN'
p3688
I0
sg884
V19-caramello.png
p3689
sg886
V19-caramello.png
p3690
sg70
g71
sS'outcome_loop.thisRepN'
p3691
I0
sS'block_loop.thisIndex'
p3692
g890
sS'outcome_loop.thisN'
p3693
I175
sS'outcome_loop.thisTrialN'
p3694
I175
sg62
g66
sg33
S'right'
p3695
sS'block_loop.thisN'
p3696
I0
sS'outcome_loop.thisIndex'
p3697
g63
(g96
S'\xaf\x00\x00\x00'
tRp3698
sg30
g3689
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p3699
sS'block_loop.thisTrial'
p3700
Nsg60
g61
sS'block_loop.thisTrialN'
p3701
I0
sg34
F1.3053706546506874
sg901
V30-spaghetti_hoops.png
p3702
sa(dp3703
S'block_loop.thisRepN'
p3704
I0
sg884
V7-olives.png
p3705
sg886
V7-olives.png
p3706
sg70
g71
sS'outcome_loop.thisRepN'
p3707
I0
sS'block_loop.thisIndex'
p3708
g890
sS'outcome_loop.thisN'
p3709
I176
sS'outcome_loop.thisTrialN'
p3710
I176
sg62
g66
sg33
S'left'
p3711
sS'block_loop.thisN'
p3712
I0
sS'outcome_loop.thisIndex'
p3713
g63
(g96
S'\xb0\x00\x00\x00'
tRp3714
sg30
g3705
sg67
g11
sg68
g69
sg897
V22-daim.png
p3715
sS'block_loop.thisTrial'
p3716
Nsg60
g61
sS'block_loop.thisTrialN'
p3717
I0
sg34
F0.70595480710471747
sg901
V22-daim.png
p3718
sa(dp3719
S'block_loop.thisRepN'
p3720
I0
sg884
V45-chewy_nougat.png
p3721
sg886
V45-chewy_nougat.png
p3722
sg70
g71
sS'outcome_loop.thisRepN'
p3723
I0
sS'block_loop.thisIndex'
p3724
g890
sS'outcome_loop.thisN'
p3725
I177
sS'outcome_loop.thisTrialN'
p3726
I177
sg62
g66
sg33
S'left'
p3727
sS'block_loop.thisN'
p3728
I0
sS'outcome_loop.thisIndex'
p3729
g63
(g96
S'\xb1\x00\x00\x00'
tRp3730
sg30
g3721
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p3731
sS'block_loop.thisTrial'
p3732
Nsg60
g61
sS'block_loop.thisTrialN'
p3733
I0
sg34
F0.73265931843343424
sg901
V41-peanuts.png
p3734
sa(dp3735
S'block_loop.thisRepN'
p3736
I0
sg884
V6-sour_patch_kids.png
p3737
sg886
V38-maltesers.png
p3738
sg70
g71
sS'outcome_loop.thisRepN'
p3739
I0
sS'block_loop.thisIndex'
p3740
g890
sS'outcome_loop.thisN'
p3741
I178
sS'outcome_loop.thisTrialN'
p3742
I178
sg62
g66
sg33
S'left'
p3743
sS'block_loop.thisN'
p3744
I0
sS'outcome_loop.thisIndex'
p3745
g63
(g96
S'\xb2\x00\x00\x00'
tRp3746
sg30
g3737
sg67
g11
sg68
g69
sg897
V38-maltesers.png
p3747
sS'block_loop.thisTrial'
p3748
Nsg60
g61
sS'block_loop.thisTrialN'
p3749
I0
sg34
F0.81256444603968703
sg901
V6-sour_patch_kids.png
p3750
sa(dp3751
S'block_loop.thisRepN'
p3752
I0
sg884
V5-pineapple.png
p3753
sg886
V5-pineapple.png
p3754
sg70
g71
sS'outcome_loop.thisRepN'
p3755
I0
sS'block_loop.thisIndex'
p3756
g890
sS'outcome_loop.thisN'
p3757
I179
sS'outcome_loop.thisTrialN'
p3758
I179
sg62
g66
sg33
S'left'
p3759
sS'block_loop.thisN'
p3760
I0
sS'outcome_loop.thisIndex'
p3761
g63
(g96
S'\xb3\x00\x00\x00'
tRp3762
sg30
g3753
sg67
g11
sg68
g69
sg897
V40-sardines.png
p3763
sS'block_loop.thisTrial'
p3764
Nsg60
g61
sS'block_loop.thisTrialN'
p3765
I0
sg34
F0.71934282150505169
sg901
V40-sardines.png
p3766
sa(dp3767
S'block_loop.thisRepN'
p3768
I0
sg884
V19-caramello.png
p3769
sg886
V30-spaghetti_hoops.png
p3770
sg70
g71
sS'outcome_loop.thisRepN'
p3771
I0
sS'block_loop.thisIndex'
p3772
g890
sS'outcome_loop.thisN'
p3773
I180
sS'outcome_loop.thisTrialN'
p3774
I180
sg62
g66
sg33
S'right'
p3775
sS'block_loop.thisN'
p3776
I0
sS'outcome_loop.thisIndex'
p3777
g63
(g96
S'\xb4\x00\x00\x00'
tRp3778
sg30
g3769
sg67
g11
sg68
g69
sg897
V30-spaghetti_hoops.png
p3779
sS'block_loop.thisTrial'
p3780
Nsg60
g61
sS'block_loop.thisTrialN'
p3781
I0
sg34
F0.82587032709488994
sg901
V19-caramello.png
p3782
sa(dp3783
S'block_loop.thisRepN'
p3784
I0
sg884
V17-jacobs_mini_cheddars.png
p3785
sg886
V17-jacobs_mini_cheddars.png
p3786
sg70
g71
sS'outcome_loop.thisRepN'
p3787
I0
sS'block_loop.thisIndex'
p3788
g890
sS'outcome_loop.thisN'
p3789
I181
sS'outcome_loop.thisTrialN'
p3790
I181
sg62
g66
sg33
S'left'
p3791
sS'block_loop.thisN'
p3792
I0
sS'outcome_loop.thisIndex'
p3793
g63
(g96
S'\xb5\x00\x00\x00'
tRp3794
sg30
g3785
sg67
g11
sg68
g69
sg897
V8-liquorice_catherine_wheels.png
p3795
sS'block_loop.thisTrial'
p3796
Nsg60
g61
sS'block_loop.thisTrialN'
p3797
I0
sg34
F0.70600788647789159
sg901
V8-liquorice_catherine_wheels.png
p3798
sa(dp3799
S'block_loop.thisRepN'
p3800
I0
sg884
V43-mrporky_pork_crackles.png
p3801
sg886
V43-mrporky_pork_crackles.png
p3802
sg70
g71
sS'outcome_loop.thisRepN'
p3803
I0
sS'block_loop.thisIndex'
p3804
g890
sS'outcome_loop.thisN'
p3805
I182
sS'outcome_loop.thisTrialN'
p3806
I182
sg62
g66
sg33
S'left'
p3807
sS'block_loop.thisN'
p3808
I0
sS'outcome_loop.thisIndex'
p3809
g63
(g96
S'\xb6\x00\x00\x00'
tRp3810
sg30
g3801
sg67
g11
sg68
g69
sg897
V18-mms.png
p3811
sS'block_loop.thisTrial'
p3812
Nsg60
g61
sS'block_loop.thisTrialN'
p3813
I0
sg34
F0.63941757960856194
sg901
V18-mms.png
p3814
sa(dp3815
S'block_loop.thisRepN'
p3816
I0
sg884
V7-olives.png
p3817
sg886
V22-daim.png
p3818
sg70
g71
sS'outcome_loop.thisRepN'
p3819
I0
sS'block_loop.thisIndex'
p3820
g890
sS'outcome_loop.thisN'
p3821
I183
sS'outcome_loop.thisTrialN'
p3822
I183
sg62
g66
sg33
S'right'
p3823
sS'block_loop.thisN'
p3824
I0
sS'outcome_loop.thisIndex'
p3825
g63
(g96
S'\xb7\x00\x00\x00'
tRp3826
sg30
g3817
sg67
g11
sg68
g69
sg897
V22-daim.png
p3827
sS'block_loop.thisTrial'
p3828
Nsg60
g61
sS'block_loop.thisTrialN'
p3829
I0
sg34
F0.81256221111834748
sg901
V7-olives.png
p3830
sa(dp3831
S'block_loop.thisRepN'
p3832
I0
sg884
V51-mars.png
p3833
sg886
V51-mars.png
p3834
sg70
g71
sS'outcome_loop.thisRepN'
p3835
I0
sS'block_loop.thisIndex'
p3836
g890
sS'outcome_loop.thisN'
p3837
I184
sS'outcome_loop.thisTrialN'
p3838
I184
sg62
g66
sg33
S'right'
p3839
sS'block_loop.thisN'
p3840
I0
sS'outcome_loop.thisIndex'
p3841
g63
(g96
S'\xb8\x00\x00\x00'
tRp3842
sg30
g3833
sg67
g11
sg68
g69
sg897
V27-hartleys_raspberries_jelly.png
p3843
sS'block_loop.thisTrial'
p3844
Nsg60
g61
sS'block_loop.thisTrialN'
p3845
I0
sg34
F0.97239118379548017
sg901
V27-hartleys_raspberries_jelly.png
p3846
sa(dp3847
S'block_loop.thisRepN'
p3848
I0
sg884
V4-corn.png
p3849
sg886
V4-corn.png
p3850
sg70
g71
sS'outcome_loop.thisRepN'
p3851
I0
sS'block_loop.thisIndex'
p3852
g890
sS'outcome_loop.thisN'
p3853
I185
sS'outcome_loop.thisTrialN'
p3854
I185
sg62
g66
sg33
S'left'
p3855
sS'block_loop.thisN'
p3856
I0
sS'outcome_loop.thisIndex'
p3857
g63
(g96
S'\xb9\x00\x00\x00'
tRp3858
sg30
g3849
sg67
g11
sg68
g69
sg897
V10-bounty.png
p3859
sS'block_loop.thisTrial'
p3860
Nsg60
g61
sS'block_loop.thisTrialN'
p3861
I0
sg34
F0.74596771377400728
sg901
V10-bounty.png
p3862
sa(dp3863
S'block_loop.thisRepN'
p3864
I0
sg884
V43-mrporky_pork_crackles.png
p3865
sg886
V18-mms.png
p3866
sg70
g71
sS'outcome_loop.thisRepN'
p3867
I0
sS'block_loop.thisIndex'
p3868
g890
sS'outcome_loop.thisN'
p3869
I186
sS'outcome_loop.thisTrialN'
p3870
I186
sg62
g66
sg33
S'right'
p3871
sS'block_loop.thisN'
p3872
I0
sS'outcome_loop.thisIndex'
p3873
g63
(g96
S'\xba\x00\x00\x00'
tRp3874
sg30
V18-mms.png
p3875
sg67
g11
sg68
g69
sg897
g3875
sS'block_loop.thisTrial'
p3876
Nsg60
g61
sS'block_loop.thisTrialN'
p3877
I0
sg34
F0.49291320544944028
sg901
V43-mrporky_pork_crackles.png
p3878
sa(dp3879
S'block_loop.thisRepN'
p3880
I0
sg884
V49-yorkie.png
p3881
sg886
V49-yorkie.png
p3882
sg70
g71
sS'outcome_loop.thisRepN'
p3883
I0
sS'block_loop.thisIndex'
p3884
g890
sS'outcome_loop.thisN'
p3885
I187
sS'outcome_loop.thisTrialN'
p3886
I187
sg62
g66
sg33
S'left'
p3887
sS'block_loop.thisN'
p3888
I0
sS'outcome_loop.thisIndex'
p3889
g63
(g96
S'\xbb\x00\x00\x00'
tRp3890
sg30
g3881
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p3891
sS'block_loop.thisTrial'
p3892
Nsg60
g61
sS'block_loop.thisTrialN'
p3893
I0
sg34
F0.67939472754187591
sg901
V35-sultanas.png
p3894
sa(dp3895
S'block_loop.thisRepN'
p3896
I0
sg884
V42-mrkipling_lemon_slices.png
p3897
sg886
V42-mrkipling_lemon_slices.png
p3898
sg70
g71
sS'outcome_loop.thisRepN'
p3899
I0
sS'block_loop.thisIndex'
p3900
g890
sS'outcome_loop.thisN'
p3901
I188
sS'outcome_loop.thisTrialN'
p3902
I188
sg62
g66
sg33
S'left'
p3903
sS'block_loop.thisN'
p3904
I0
sS'outcome_loop.thisIndex'
p3905
g63
(g96
S'\xbc\x00\x00\x00'
tRp3906
sg30
g3897
sg67
g11
sg68
g69
sg897
V16-skips_prawn.png
p3907
sS'block_loop.thisTrial'
p3908
Nsg60
g61
sS'block_loop.thisTrialN'
p3909
I0
sg34
F0.77261523461856996
sg901
V16-skips_prawn.png
p3910
sa(dp3911
S'block_loop.thisRepN'
p3912
I0
sg884
V1-smarties_cookies.png
p3913
sg886
V1-smarties_cookies.png
p3914
sg70
g71
sS'outcome_loop.thisRepN'
p3915
I0
sS'block_loop.thisIndex'
p3916
g890
sS'outcome_loop.thisN'
p3917
I189
sS'outcome_loop.thisTrialN'
p3918
I189
sg62
g66
sg33
S'left'
p3919
sS'block_loop.thisN'
p3920
I0
sS'outcome_loop.thisIndex'
p3921
g63
(g96
S'\xbd\x00\x00\x00'
tRp3922
sg30
g3913
sg67
g11
sg68
g69
sg897
V21-nakd_banana_crunch.png
p3923
sS'block_loop.thisTrial'
p3924
Nsg60
g61
sS'block_loop.thisTrialN'
p3925
I0
sg34
F0.67937070214247797
sg901
V21-nakd_banana_crunch.png
p3926
sa(dp3927
S'block_loop.thisRepN'
p3928
I0
sg884
V33-ambrosia_rice.png
p3929
sg886
V33-ambrosia_rice.png
p3930
sg70
g71
sS'outcome_loop.thisRepN'
p3931
I0
sS'block_loop.thisIndex'
p3932
g890
sS'outcome_loop.thisN'
p3933
I190
sS'outcome_loop.thisTrialN'
p3934
I190
sg62
g66
sg33
S'left'
p3935
sS'block_loop.thisN'
p3936
I0
sS'outcome_loop.thisIndex'
p3937
g63
(g96
S'\xbe\x00\x00\x00'
tRp3938
sg30
V23-crunchie.png
p3939
sg67
g11
sg68
g69
sg897
g3939
sS'block_loop.thisTrial'
p3940
Nsg60
g61
sS'block_loop.thisTrialN'
p3941
I0
sg34
F0.62609270172652032
sg901
V23-crunchie.png
p3942
sa(dp3943
S'block_loop.thisRepN'
p3944
I0
sg884
V13-mccoys_steak_crisps.png
p3945
sg886
V3-dole_fruit_snack.png
p3946
sg70
g71
sS'outcome_loop.thisRepN'
p3947
I0
sS'block_loop.thisIndex'
p3948
g890
sS'outcome_loop.thisN'
p3949
I191
sS'outcome_loop.thisTrialN'
p3950
I191
sg62
g66
sg33
S'right'
p3951
sS'block_loop.thisN'
p3952
I0
sS'outcome_loop.thisIndex'
p3953
g63
(g96
S'\xbf\x00\x00\x00'
tRp3954
sg30
g3945
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p3955
sS'block_loop.thisTrial'
p3956
Nsg60
g61
sS'block_loop.thisTrialN'
p3957
I0
sg34
F0.7326713311340427
sg901
V13-mccoys_steak_crisps.png
p3958
sa(dp3959
S'block_loop.thisRepN'
p3960
I0
sg884
V49-yorkie.png
p3961
sg886
V35-sultanas.png
p3962
sg70
g71
sS'outcome_loop.thisRepN'
p3963
I0
sS'block_loop.thisIndex'
p3964
g890
sS'outcome_loop.thisN'
p3965
I192
sS'outcome_loop.thisTrialN'
p3966
I192
sg62
g66
sg33
S'right'
p3967
sS'block_loop.thisN'
p3968
I0
sS'outcome_loop.thisIndex'
p3969
g63
(g96
S'\xc0\x00\x00\x00'
tRp3970
sg30
g3961
sg67
g11
sg68
g69
sg897
V35-sultanas.png
p3971
sS'block_loop.thisTrial'
p3972
Nsg60
g61
sS'block_loop.thisTrialN'
p3973
I0
sg34
F0.93243554697619402
sg901
V49-yorkie.png
p3974
sa(dp3975
S'block_loop.thisRepN'
p3976
I0
sg884
V46-pistachios.png
p3977
sg886
V29-beans.png
p3978
sg70
g71
sS'outcome_loop.thisRepN'
p3979
I0
sS'block_loop.thisIndex'
p3980
g890
sS'outcome_loop.thisN'
p3981
I193
sS'outcome_loop.thisTrialN'
p3982
I193
sg62
g66
sg33
S'right'
p3983
sS'block_loop.thisN'
p3984
I0
sS'outcome_loop.thisIndex'
p3985
g63
(g96
S'\xc1\x00\x00\x00'
tRp3986
sg30
g3977
sg67
g11
sg68
g69
sg897
V29-beans.png
p3987
sS'block_loop.thisTrial'
p3988
Nsg60
g61
sS'block_loop.thisTrialN'
p3989
I0
sg34
F0.77261104413992143
sg901
V46-pistachios.png
p3990
sa(dp3991
S'block_loop.thisRepN'
p3992
I0
sg884
V43-mrporky_pork_crackles.png
p3993
sg886
V43-mrporky_pork_crackles.png
p3994
sg70
g71
sS'outcome_loop.thisRepN'
p3995
I0
sS'block_loop.thisIndex'
p3996
g890
sS'outcome_loop.thisN'
p3997
I194
sS'outcome_loop.thisTrialN'
p3998
I194
sg62
g66
sg33
S'left'
p3999
sS'block_loop.thisN'
p4000
I0
sS'outcome_loop.thisIndex'
p4001
g63
(g96
S'\xc2\x00\x00\x00'
tRp4002
sg30
g3993
sg67
g11
sg68
g69
sg897
V18-mms.png
p4003
sS'block_loop.thisTrial'
p4004
Nsg60
g61
sS'block_loop.thisTrialN'
p4005
I0
sg34
F0.69269111018365948
sg901
V18-mms.png
p4006
sa(dp4007
S'block_loop.thisRepN'
p4008
I0
sg884
V7-olives.png
p4009
sg886
V22-daim.png
p4010
sg70
g71
sS'outcome_loop.thisRepN'
p4011
I0
sS'block_loop.thisIndex'
p4012
g890
sS'outcome_loop.thisN'
p4013
I195
sS'outcome_loop.thisTrialN'
p4014
I195
sg62
g66
sg33
S'right'
p4015
sS'block_loop.thisN'
p4016
I0
sS'outcome_loop.thisIndex'
p4017
g63
(g96
S'\xc3\x00\x00\x00'
tRp4018
sg30
g4009
sg67
g11
sg68
g69
sg897
V22-daim.png
p4019
sS'block_loop.thisTrial'
p4020
Nsg60
g61
sS'block_loop.thisTrialN'
p4021
I0
sg34
F0.70602660394069972
sg901
V7-olives.png
p4022
sa(dp4023
S'block_loop.thisRepN'
p4024
I0
sg884
V45-chewy_nougat.png
p4025
sg886
V45-chewy_nougat.png
p4026
sg70
g71
sS'outcome_loop.thisRepN'
p4027
I0
sS'block_loop.thisIndex'
p4028
g890
sS'outcome_loop.thisN'
p4029
I196
sS'outcome_loop.thisTrialN'
p4030
I196
sg62
g66
sg33
S'left'
p4031
sS'block_loop.thisN'
p4032
I0
sS'outcome_loop.thisIndex'
p4033
g63
(g96
S'\xc4\x00\x00\x00'
tRp4034
sg30
g4025
sg67
g11
sg68
g69
sg897
V41-peanuts.png
p4035
sS'block_loop.thisTrial'
p4036
Nsg60
g61
sS'block_loop.thisTrialN'
p4037
I0
sg34
F0.61278542384570756
sg901
V41-peanuts.png
p4038
sa(dp4039
S'block_loop.thisRepN'
p4040
I0
sg884
V1-smarties_cookies.png
p4041
sg886
V21-nakd_banana_crunch.png
p4042
sg70
g71
sS'outcome_loop.thisRepN'
p4043
I0
sS'block_loop.thisIndex'
p4044
g890
sS'outcome_loop.thisN'
p4045
I197
sS'outcome_loop.thisTrialN'
p4046
I197
sg62
g66
sg33
S'right'
p4047
sS'block_loop.thisN'
p4048
I0
sS'outcome_loop.thisIndex'
p4049
g63
(g96
S'\xc5\x00\x00\x00'
tRp4050
sg30
V21-nakd_banana_crunch.png
p4051
sg67
g11
sg68
g69
sg897
g4051
sS'block_loop.thisTrial'
p4052
Nsg60
g61
sS'block_loop.thisTrialN'
p4053
I0
sg34
F1.3053692578232585
sg901
V1-smarties_cookies.png
p4054
sa(dp4055
S'block_loop.thisRepN'
p4056
I0
sg884
V13-mccoys_steak_crisps.png
p4057
sg886
V13-mccoys_steak_crisps.png
p4058
sg70
g71
sS'outcome_loop.thisRepN'
p4059
I0
sS'block_loop.thisIndex'
p4060
g890
sS'outcome_loop.thisN'
p4061
I198
sS'outcome_loop.thisTrialN'
p4062
I198
sg62
g66
sg33
S'left'
p4063
sS'block_loop.thisN'
p4064
I0
sS'outcome_loop.thisIndex'
p4065
g63
(g96
S'\xc6\x00\x00\x00'
tRp4066
sg30
g4057
sg67
g11
sg68
g69
sg897
V3-dole_fruit_snack.png
p4067
sS'block_loop.thisTrial'
p4068
Nsg60
g61
sS'block_loop.thisTrialN'
p4069
I0
sg34
F0.57281246638922312
sg901
V3-dole_fruit_snack.png
p4070
sa(dp4071
S'block_loop.thisRepN'
p4072
I0
sg884
V7-olives.png
p4073
sg886
V22-daim.png
p4074
sg70
g71
sS'outcome_loop.thisRepN'
p4075
I0
sS'block_loop.thisIndex'
p4076
g890
sS'outcome_loop.thisN'
p4077
I199
sS'outcome_loop.thisTrialN'
p4078
I199
sg62
g66
sg33
S'right'
p4079
sS'block_loop.thisN'
p4080
I0
sS'outcome_loop.thisIndex'
p4081
g63
(g96
S'\xc7\x00\x00\x00'
tRp4082
sg30
g4073
sg67
g11
sg68
g69
sg897
V22-daim.png
p4083
sS'block_loop.thisTrial'
p4084
Nsg60
g61
sS'block_loop.thisTrialN'
p4085
I0
sg34
F0.70613723252608906
sg901
V7-olives.png
p4086
sa(dp4087
S'block_loop.thisRepN'
p4088
I0
sg67
g11
sg36
F1.3588140392130299
sg70
g71
sS'block_loop.thisIndex'
p4089
g890
sg62
g66
sS'block_loop.thisN'
p4090
I0
sg35
S'space'
p4091
sg68
g69
sS'block_loop.thisTrial'
p4092
Nsg60
g61
sS'block_loop.thisTrialN'
p4093
I0
sa(dp4094
S'block_loop.thisRepN'
p4095
I1
sS'img_correct'
p4096
V20-fruit_pastilles.png
p4097
sS'img_left'
p4098
V20-fruit_pastilles.png
p4099
sg70
g71
sS'outcome_loop.thisRepN'
p4100
I0
sS'block_loop.thisIndex'
p4101
g63
(g96
S'\x00\x00\x00\x00'
tRp4102
sS'outcome_loop.thisN'
p4103
I0
sS'outcome_loop.thisTrialN'
p4104
I0
sg62
g66
sg33
S'left'
p4105
sS'block_loop.thisN'
p4106
I1
sS'outcome_loop.thisIndex'
p4107
g63
(g96
S'\x00\x00\x00\x00'
tRp4108
sg30
g4097
sg67
g11
sg68
g69
sS'img_wrong'
p4109
V2-steamed_puddings.png
p4110
sS'block_loop.thisTrial'
p4111
Nsg60
g61
sS'block_loop.thisTrialN'
p4112
I0
sg34
F0.97237693617535115
sS'img_right'
p4113
V2-steamed_puddings.png
p4114
sa(dp4115
S'block_loop.thisRepN'
p4116
I1
sg4096
V45-chewy_nougat.png
p4117
sg4098
V45-chewy_nougat.png
p4118
sg70
g71
sS'outcome_loop.thisRepN'
p4119
I0
sS'block_loop.thisIndex'
p4120
g4102
sS'outcome_loop.thisN'
p4121
I1
sS'outcome_loop.thisTrialN'
p4122
I1
sg62
g66
sg33
S'left'
p4123
sS'block_loop.thisN'
p4124
I1
sS'outcome_loop.thisIndex'
p4125
g63
(g96
S'\x01\x00\x00\x00'
tRp4126
sg30
g4117
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p4127
sS'block_loop.thisTrial'
p4128
Nsg60
g61
sS'block_loop.thisTrialN'
p4129
I0
sg34
F0.87914721005108731
sg4113
V41-peanuts.png
p4130
sa(dp4131
S'block_loop.thisRepN'
p4132
I1
sg4096
V26-walkers_smoky_bacon.png
p4133
sg4098
V26-walkers_smoky_bacon.png
p4134
sg70
g71
sS'outcome_loop.thisRepN'
p4135
I0
sS'block_loop.thisIndex'
p4136
g4102
sS'outcome_loop.thisN'
p4137
I2
sS'outcome_loop.thisTrialN'
p4138
I2
sg62
g66
sg33
S'left'
p4139
sS'block_loop.thisN'
p4140
I1
sS'outcome_loop.thisIndex'
p4141
g63
(g96
S'\x02\x00\x00\x00'
tRp4142
sg30
g4133
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p4143
sS'block_loop.thisTrial'
p4144
Nsg60
g61
sS'block_loop.thisTrialN'
p4145
I0
sg34
F1.0523005018803815
sg4113
V44-crunch.png
p4146
sa(dp4147
S'block_loop.thisRepN'
p4148
I1
sg4096
V13-mccoys_steak_crisps.png
p4149
sg4098
V13-mccoys_steak_crisps.png
p4150
sg70
g71
sS'outcome_loop.thisRepN'
p4151
I0
sS'block_loop.thisIndex'
p4152
g4102
sS'outcome_loop.thisN'
p4153
I3
sS'outcome_loop.thisTrialN'
p4154
I3
sg62
g66
sg33
S'left'
p4155
sS'block_loop.thisN'
p4156
I1
sS'outcome_loop.thisIndex'
p4157
g63
(g96
S'\x03\x00\x00\x00'
tRp4158
sg30
g4149
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p4159
sS'block_loop.thisTrial'
p4160
Nsg60
g61
sS'block_loop.thisTrialN'
p4161
I0
sg34
F0.57282280289837217
sg4113
V3-dole_fruit_snack.png
p4162
sa(dp4163
S'block_loop.thisRepN'
p4164
I1
sg4096
V1-smarties_cookies.png
p4165
sg4098
V1-smarties_cookies.png
p4166
sg70
g71
sS'outcome_loop.thisRepN'
p4167
I0
sS'block_loop.thisIndex'
p4168
g4102
sS'outcome_loop.thisN'
p4169
I4
sS'outcome_loop.thisTrialN'
p4170
I4
sg62
g66
sg33
S'left'
p4171
sS'block_loop.thisN'
p4172
I1
sS'outcome_loop.thisIndex'
p4173
g63
(g96
S'\x04\x00\x00\x00'
tRp4174
sg30
g4165
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p4175
sS'block_loop.thisTrial'
p4176
Nsg60
g61
sS'block_loop.thisTrialN'
p4177
I0
sg34
F0.65274078129914415
sg4113
V21-nakd_banana_crunch.png
p4178
sa(dp4179
S'block_loop.thisRepN'
p4180
I1
sg4096
V51-mars.png
p4181
sg4098
V51-mars.png
p4182
sg70
g71
sS'outcome_loop.thisRepN'
p4183
I0
sS'block_loop.thisIndex'
p4184
g4102
sS'outcome_loop.thisN'
p4185
I5
sS'outcome_loop.thisTrialN'
p4186
I5
sg62
g66
sg33
S'right'
p4187
sS'block_loop.thisN'
p4188
I1
sS'outcome_loop.thisIndex'
p4189
g63
(g96
S'\x05\x00\x00\x00'
tRp4190
sg30
g4181
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p4191
sS'block_loop.thisTrial'
p4192
Nsg60
g61
sS'block_loop.thisTrialN'
p4193
I0
sg34
F0.83920610021596076
sg4113
V27-hartleys_raspberries_jelly.png
p4194
sa(dp4195
S'block_loop.thisRepN'
p4196
I1
sg4096
V43-mrporky_pork_crackles.png
p4197
sg4098
V43-mrporky_pork_crackles.png
p4198
sg70
g71
sS'outcome_loop.thisRepN'
p4199
I0
sS'block_loop.thisIndex'
p4200
g4102
sS'outcome_loop.thisN'
p4201
I6
sS'outcome_loop.thisTrialN'
p4202
I6
sg62
g66
sg33
S'left'
p4203
sS'block_loop.thisN'
p4204
I1
sS'outcome_loop.thisIndex'
p4205
g63
(g96
S'\x06\x00\x00\x00'
tRp4206
sg30
g4197
sg67
g11
sg68
g69
sg4109
V18-mms.png
p4207
sS'block_loop.thisTrial'
p4208
Nsg60
g61
sS'block_loop.thisTrialN'
p4209
I0
sg34
F0.59947032374111586
sg4113
V18-mms.png
p4210
sa(dp4211
S'block_loop.thisRepN'
p4212
I1
sg4096
V26-walkers_smoky_bacon.png
p4213
sg4098
V26-walkers_smoky_bacon.png
p4214
sg70
g71
sS'outcome_loop.thisRepN'
p4215
I0
sS'block_loop.thisIndex'
p4216
g4102
sS'outcome_loop.thisN'
p4217
I7
sS'outcome_loop.thisTrialN'
p4218
I7
sg62
g66
sg33
S'left'
p4219
sS'block_loop.thisN'
p4220
I1
sS'outcome_loop.thisIndex'
p4221
g63
(g96
S'\x07\x00\x00\x00'
tRp4222
sg30
g4213
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p4223
sS'block_loop.thisTrial'
p4224
Nsg60
g61
sS'block_loop.thisTrialN'
p4225
I0
sg34
F0.67937964182601718
sg4113
V44-crunch.png
p4226
sa(dp4227
S'block_loop.thisRepN'
p4228
I1
sg4096
V31-foxs_golden_biscuits.png
p4229
sg4098
V31-foxs_golden_biscuits.png
p4230
sg70
g71
sS'outcome_loop.thisRepN'
p4231
I0
sS'block_loop.thisIndex'
p4232
g4102
sS'outcome_loop.thisN'
p4233
I8
sS'outcome_loop.thisTrialN'
p4234
I8
sg62
g66
sg33
S'left'
p4235
sS'block_loop.thisN'
p4236
I1
sS'outcome_loop.thisIndex'
p4237
g63
(g96
S'\x08\x00\x00\x00'
tRp4238
sg30
V25-kitkat.png
p4239
sg67
g11
sg68
g69
sg4109
g4239
sS'block_loop.thisTrial'
p4240
Nsg60
g61
sS'block_loop.thisTrialN'
p4241
I0
sg34
F0.65273882574365416
sg4113
V25-kitkat.png
p4242
sa(dp4243
S'block_loop.thisRepN'
p4244
I1
sg4096
V17-jacobs_mini_cheddars.png
p4245
sg4098
V17-jacobs_mini_cheddars.png
p4246
sg70
g71
sS'outcome_loop.thisRepN'
p4247
I0
sS'block_loop.thisIndex'
p4248
g4102
sS'outcome_loop.thisN'
p4249
I9
sS'outcome_loop.thisTrialN'
p4250
I9
sg62
g66
sg33
S'left'
p4251
sS'block_loop.thisN'
p4252
I1
sS'outcome_loop.thisIndex'
p4253
g63
(g96
S'\t\x00\x00\x00'
tRp4254
sg30
g4245
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p4255
sS'block_loop.thisTrial'
p4256
Nsg60
g61
sS'block_loop.thisTrialN'
p4257
I0
sg34
F0.55950211549316009
sg4113
V8-liquorice_catherine_wheels.png
p4258
sa(dp4259
S'block_loop.thisRepN'
p4260
I1
sg4096
V5-pineapple.png
p4261
sg4098
V5-pineapple.png
p4262
sg70
g71
sS'outcome_loop.thisRepN'
p4263
I0
sS'block_loop.thisIndex'
p4264
g4102
sS'outcome_loop.thisN'
p4265
I10
sS'outcome_loop.thisTrialN'
p4266
I10
sg62
g66
sg33
S'left'
p4267
sS'block_loop.thisN'
p4268
I1
sS'outcome_loop.thisIndex'
p4269
g63
(g96
S'\n\x00\x00\x00'
tRp4270
sg30
g4261
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p4271
sS'block_loop.thisTrial'
p4272
Nsg60
g61
sS'block_loop.thisTrialN'
p4273
I0
sg34
F0.95907273131160764
sg4113
V40-sardines.png
p4274
sa(dp4275
S'block_loop.thisRepN'
p4276
I1
sg4096
V43-mrporky_pork_crackles.png
p4277
sg4098
V43-mrporky_pork_crackles.png
p4278
sg70
g71
sS'outcome_loop.thisRepN'
p4279
I0
sS'block_loop.thisIndex'
p4280
g4102
sS'outcome_loop.thisN'
p4281
I11
sS'outcome_loop.thisTrialN'
p4282
I11
sg62
g66
sg33
S'left'
p4283
sS'block_loop.thisN'
p4284
I1
sS'outcome_loop.thisIndex'
p4285
g63
(g96
S'\x0b\x00\x00\x00'
tRp4286
sg30
g4277
sg67
g11
sg68
g69
sg4109
V18-mms.png
p4287
sS'block_loop.thisTrial'
p4288
Nsg60
g61
sS'block_loop.thisTrialN'
p4289
I0
sg34
F0.5461878534842981
sg4113
V18-mms.png
p4290
sa(dp4291
S'block_loop.thisRepN'
p4292
I1
sg4096
V17-jacobs_mini_cheddars.png
p4293
sg4098
V8-liquorice_catherine_wheels.png
p4294
sg70
g71
sS'outcome_loop.thisRepN'
p4295
I0
sS'block_loop.thisIndex'
p4296
g4102
sS'outcome_loop.thisN'
p4297
I12
sS'outcome_loop.thisTrialN'
p4298
I12
sg62
g66
sg33
S'right'
p4299
sS'block_loop.thisN'
p4300
I1
sS'outcome_loop.thisIndex'
p4301
g63
(g96
S'\x0c\x00\x00\x00'
tRp4302
sg30
g4293
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p4303
sS'block_loop.thisTrial'
p4304
Nsg60
g61
sS'block_loop.thisTrialN'
p4305
I0
sg34
F0.63941618278295209
sg4113
V17-jacobs_mini_cheddars.png
p4306
sa(dp4307
S'block_loop.thisRepN'
p4308
I1
sg4096
V42-mrkipling_lemon_slices.png
p4309
sg4098
V16-skips_prawn.png
p4310
sg70
g71
sS'outcome_loop.thisRepN'
p4311
I0
sS'block_loop.thisIndex'
p4312
g4102
sS'outcome_loop.thisN'
p4313
I13
sS'outcome_loop.thisTrialN'
p4314
I13
sg62
g66
sg33
S'right'
p4315
sS'block_loop.thisN'
p4316
I1
sS'outcome_loop.thisIndex'
p4317
g63
(g96
S'\r\x00\x00\x00'
tRp4318
sg30
g4309
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p4319
sS'block_loop.thisTrial'
p4320
Nsg60
g61
sS'block_loop.thisTrialN'
p4321
I0
sg34
F0.82587367947598977
sg4113
V42-mrkipling_lemon_slices.png
p4322
sa(dp4323
S'block_loop.thisRepN'
p4324
I1
sg4096
V6-sour_patch_kids.png
p4325
sg4098
V6-sour_patch_kids.png
p4326
sg70
g71
sS'outcome_loop.thisRepN'
p4327
I0
sS'block_loop.thisIndex'
p4328
g4102
sS'outcome_loop.thisN'
p4329
I14
sS'outcome_loop.thisTrialN'
p4330
I14
sg62
g66
sg33
S'right'
p4331
sS'block_loop.thisN'
p4332
I1
sS'outcome_loop.thisIndex'
p4333
g63
(g96
S'\x0e\x00\x00\x00'
tRp4334
sg30
g4325
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p4335
sS'block_loop.thisTrial'
p4336
Nsg60
g61
sS'block_loop.thisTrialN'
p4337
I0
sg34
F0.90580394994503877
sg4113
V38-maltesers.png
p4338
sa(dp4339
S'block_loop.thisRepN'
p4340
I1
sg4096
V19-caramello.png
p4341
sg4098
V19-caramello.png
p4342
sg70
g71
sS'outcome_loop.thisRepN'
p4343
I0
sS'block_loop.thisIndex'
p4344
g4102
sS'outcome_loop.thisN'
p4345
I15
sS'outcome_loop.thisTrialN'
p4346
I15
sg62
g66
sg33
S'left'
p4347
sS'block_loop.thisN'
p4348
I1
sS'outcome_loop.thisIndex'
p4349
g63
(g96
S'\x0f\x00\x00\x00'
tRp4350
sg30
g4341
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p4351
sS'block_loop.thisTrial'
p4352
Nsg60
g61
sS'block_loop.thisTrialN'
p4353
I0
sg34
F1.1721808218626393
sg4113
V30-spaghetti_hoops.png
p4354
sa(dp4355
S'block_loop.thisRepN'
p4356
I1
sg4096
V31-foxs_golden_biscuits.png
p4357
sg4098
V25-kitkat.png
p4358
sg70
g71
sS'outcome_loop.thisRepN'
p4359
I0
sS'block_loop.thisIndex'
p4360
g4102
sS'outcome_loop.thisN'
p4361
I16
sS'outcome_loop.thisTrialN'
p4362
I16
sg62
g66
sg33
S'right'
p4363
sS'block_loop.thisN'
p4364
I1
sS'outcome_loop.thisIndex'
p4365
g63
(g96
S'\x10\x00\x00\x00'
tRp4366
sg30
g4357
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p4367
sS'block_loop.thisTrial'
p4368
Nsg60
g61
sS'block_loop.thisTrialN'
p4369
I0
sg34
F1.438550430291798
sg4113
V31-foxs_golden_biscuits.png
p4370
sa(dp4371
S'block_loop.thisRepN'
p4372
I1
sg4096
V5-pineapple.png
p4373
sg4098
V5-pineapple.png
p4374
sg70
g71
sS'outcome_loop.thisRepN'
p4375
I0
sS'block_loop.thisIndex'
p4376
g4102
sS'outcome_loop.thisN'
p4377
I17
sS'outcome_loop.thisTrialN'
p4378
I17
sg62
g66
sg33
S'left'
p4379
sS'block_loop.thisN'
p4380
I1
sS'outcome_loop.thisIndex'
p4381
g63
(g96
S'\x11\x00\x00\x00'
tRp4382
sg30
V40-sardines.png
p4383
sg67
g11
sg68
g69
sg4109
g4383
sS'block_loop.thisTrial'
p4384
Nsg60
g61
sS'block_loop.thisTrialN'
p4385
I0
sg34
F0.82585775566440134
sg4113
V40-sardines.png
p4386
sa(dp4387
S'block_loop.thisRepN'
p4388
I1
sg4096
V17-jacobs_mini_cheddars.png
p4389
sg4098
V8-liquorice_catherine_wheels.png
p4390
sg70
g71
sS'outcome_loop.thisRepN'
p4391
I0
sS'block_loop.thisIndex'
p4392
g4102
sS'outcome_loop.thisN'
p4393
I18
sS'outcome_loop.thisTrialN'
p4394
I18
sg62
g66
sg33
S'right'
p4395
sS'block_loop.thisN'
p4396
I1
sS'outcome_loop.thisIndex'
p4397
g63
(g96
S'\x12\x00\x00\x00'
tRp4398
sg30
g4389
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p4399
sS'block_loop.thisTrial'
p4400
Nsg60
g61
sS'block_loop.thisTrialN'
p4401
I0
sg34
F0.67937908309613704
sg4113
V17-jacobs_mini_cheddars.png
p4402
sa(dp4403
S'block_loop.thisRepN'
p4404
I1
sg4096
V49-yorkie.png
p4405
sg4098
V49-yorkie.png
p4406
sg70
g71
sS'outcome_loop.thisRepN'
p4407
I0
sS'block_loop.thisIndex'
p4408
g4102
sS'outcome_loop.thisN'
p4409
I19
sS'outcome_loop.thisTrialN'
p4410
I19
sg62
g66
sg33
S'left'
p4411
sS'block_loop.thisN'
p4412
I1
sS'outcome_loop.thisIndex'
p4413
g63
(g96
S'\x13\x00\x00\x00'
tRp4414
sg30
g4405
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p4415
sS'block_loop.thisTrial'
p4416
Nsg60
g61
sS'block_loop.thisTrialN'
p4417
I0
sg34
F1.3985886474401923
sg4113
V35-sultanas.png
p4418
sa(dp4419
S'block_loop.thisRepN'
p4420
I1
sg4096
V17-jacobs_mini_cheddars.png
p4421
sg4098
V17-jacobs_mini_cheddars.png
p4422
sg70
g71
sS'outcome_loop.thisRepN'
p4423
I0
sS'block_loop.thisIndex'
p4424
g4102
sS'outcome_loop.thisN'
p4425
I20
sS'outcome_loop.thisTrialN'
p4426
I20
sg62
g66
sg33
S'left'
p4427
sS'block_loop.thisN'
p4428
I1
sS'outcome_loop.thisIndex'
p4429
g63
(g96
S'\x14\x00\x00\x00'
tRp4430
sg30
V8-liquorice_catherine_wheels.png
p4431
sg67
g11
sg68
g69
sg4109
g4431
sS'block_loop.thisTrial'
p4432
Nsg60
g61
sS'block_loop.thisTrialN'
p4433
I0
sg34
F0.62610806680640962
sg4113
V8-liquorice_catherine_wheels.png
p4434
sa(dp4435
S'block_loop.thisRepN'
p4436
I1
sg4096
V13-mccoys_steak_crisps.png
p4437
sg4098
V3-dole_fruit_snack.png
p4438
sg70
g71
sS'outcome_loop.thisRepN'
p4439
I0
sS'block_loop.thisIndex'
p4440
g4102
sS'outcome_loop.thisN'
p4441
I21
sS'outcome_loop.thisTrialN'
p4442
I21
sg62
g66
sg33
S'right'
p4443
sS'block_loop.thisN'
p4444
I1
sS'outcome_loop.thisIndex'
p4445
g63
(g96
S'\x15\x00\x00\x00'
tRp4446
sg30
g4437
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p4447
sS'block_loop.thisTrial'
p4448
Nsg60
g61
sS'block_loop.thisTrialN'
p4449
I0
sg34
F0.55950323295292037
sg4113
V13-mccoys_steak_crisps.png
p4450
sa(dp4451
S'block_loop.thisRepN'
p4452
I1
sg4096
V1-smarties_cookies.png
p4453
sg4098
V1-smarties_cookies.png
p4454
sg70
g71
sS'outcome_loop.thisRepN'
p4455
I0
sS'block_loop.thisIndex'
p4456
g4102
sS'outcome_loop.thisN'
p4457
I22
sS'outcome_loop.thisTrialN'
p4458
I22
sg62
g66
sg33
S'left'
p4459
sS'block_loop.thisN'
p4460
I1
sS'outcome_loop.thisIndex'
p4461
g63
(g96
S'\x16\x00\x00\x00'
tRp4462
sg30
g4453
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p4463
sS'block_loop.thisTrial'
p4464
Nsg60
g61
sS'block_loop.thisTrialN'
p4465
I0
sg34
F0.5861493569718732
sg4113
V21-nakd_banana_crunch.png
p4466
sa(dp4467
S'block_loop.thisRepN'
p4468
I1
sg4096
V20-fruit_pastilles.png
p4469
sg4098
V20-fruit_pastilles.png
p4470
sg70
g71
sS'outcome_loop.thisRepN'
p4471
I0
sS'block_loop.thisIndex'
p4472
g4102
sS'outcome_loop.thisN'
p4473
I23
sS'outcome_loop.thisTrialN'
p4474
I23
sg62
g66
sg33
S'left'
p4475
sS'block_loop.thisN'
p4476
I1
sS'outcome_loop.thisIndex'
p4477
g63
(g96
S'\x17\x00\x00\x00'
tRp4478
sg30
g4469
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p4479
sS'block_loop.thisTrial'
p4480
Nsg60
g61
sS'block_loop.thisTrialN'
p4481
I0
sg34
F0.77260964731431159
sg4113
V2-steamed_puddings.png
p4482
sa(dp4483
S'block_loop.thisRepN'
p4484
I1
sg4096
V33-ambrosia_rice.png
p4485
sg4098
V23-crunchie.png
p4486
sg70
g71
sS'outcome_loop.thisRepN'
p4487
I0
sS'block_loop.thisIndex'
p4488
g4102
sS'outcome_loop.thisN'
p4489
I24
sS'outcome_loop.thisTrialN'
p4490
I24
sg62
g66
sg33
S'right'
p4491
sS'block_loop.thisN'
p4492
I1
sS'outcome_loop.thisIndex'
p4493
g63
(g96
S'\x18\x00\x00\x00'
tRp4494
sg30
V23-crunchie.png
p4495
sg67
g11
sg68
g69
sg4109
g4495
sS'block_loop.thisTrial'
p4496
Nsg60
g61
sS'block_loop.thisTrialN'
p4497
I0
sg34
F1.3985436696566467
sg4113
V33-ambrosia_rice.png
p4498
sa(dp4499
S'block_loop.thisRepN'
p4500
I1
sg4096
V7-olives.png
p4501
sg4098
V7-olives.png
p4502
sg70
g71
sS'outcome_loop.thisRepN'
p4503
I0
sS'block_loop.thisIndex'
p4504
g4102
sS'outcome_loop.thisN'
p4505
I25
sS'outcome_loop.thisTrialN'
p4506
I25
sg62
g66
sg33
S'left'
p4507
sS'block_loop.thisN'
p4508
I1
sS'outcome_loop.thisIndex'
p4509
g63
(g96
S'\x19\x00\x00\x00'
tRp4510
sg30
g4501
sg67
g11
sg68
g69
sg4109
V22-daim.png
p4511
sS'block_loop.thisTrial'
p4512
Nsg60
g61
sS'block_loop.thisTrialN'
p4513
I0
sg34
F0.71933388182151248
sg4113
V22-daim.png
p4514
sa(dp4515
S'block_loop.thisRepN'
p4516
I1
sg4096
V6-sour_patch_kids.png
p4517
sg4098
V6-sour_patch_kids.png
p4518
sg70
g71
sS'outcome_loop.thisRepN'
p4519
I0
sS'block_loop.thisIndex'
p4520
g4102
sS'outcome_loop.thisN'
p4521
I26
sS'outcome_loop.thisTrialN'
p4522
I26
sg62
g66
sg33
S'right'
p4523
sS'block_loop.thisN'
p4524
I1
sS'outcome_loop.thisIndex'
p4525
g63
(g96
S'\x1a\x00\x00\x00'
tRp4526
sg30
V38-maltesers.png
p4527
sg67
g11
sg68
g69
sg4109
g4527
sS'block_loop.thisTrial'
p4528
Nsg60
g61
sS'block_loop.thisTrialN'
p4529
I0
sg34
F0.77256494889661553
sg4113
V38-maltesers.png
p4530
sa(dp4531
S'block_loop.thisRepN'
p4532
I1
sg4096
V33-ambrosia_rice.png
p4533
sg4098
V23-crunchie.png
p4534
sg70
g71
sS'outcome_loop.thisRepN'
p4535
I0
sS'block_loop.thisIndex'
p4536
g4102
sS'outcome_loop.thisN'
p4537
I27
sS'outcome_loop.thisTrialN'
p4538
I27
sg62
g66
sg33
S'right'
p4539
sS'block_loop.thisN'
p4540
I1
sS'outcome_loop.thisIndex'
p4541
g63
(g96
S'\x1b\x00\x00\x00'
tRp4542
sg30
g4533
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p4543
sS'block_loop.thisTrial'
p4544
Nsg60
g61
sS'block_loop.thisTrialN'
p4545
I0
sg34
F0.73266714065539418
sg4113
V33-ambrosia_rice.png
p4546
sa(dp4547
S'block_loop.thisRepN'
p4548
I1
sg4096
V48-twix.png
p4549
sg4098
V48-twix.png
p4550
sg70
g71
sS'outcome_loop.thisRepN'
p4551
I0
sS'block_loop.thisIndex'
p4552
g4102
sS'outcome_loop.thisN'
p4553
I28
sS'outcome_loop.thisTrialN'
p4554
I28
sg62
g66
sg33
S'left'
p4555
sS'block_loop.thisN'
p4556
I1
sS'outcome_loop.thisIndex'
p4557
g63
(g96
S'\x1c\x00\x00\x00'
tRp4558
sg30
g4549
sg67
g11
sg68
g69
sg4109
V50-polo.png
p4559
sS'block_loop.thisTrial'
p4560
Nsg60
g61
sS'block_loop.thisTrialN'
p4561
I0
sg34
F1.4785172417159629
sg4113
V50-polo.png
p4562
sa(dp4563
S'block_loop.thisRepN'
p4564
I1
sg4096
V4-corn.png
p4565
sg4098
V4-corn.png
p4566
sg70
g71
sS'outcome_loop.thisRepN'
p4567
I0
sS'block_loop.thisIndex'
p4568
g4102
sS'outcome_loop.thisN'
p4569
I29
sS'outcome_loop.thisTrialN'
p4570
I29
sg62
g66
sg33
S'left'
p4571
sS'block_loop.thisN'
p4572
I1
sS'outcome_loop.thisIndex'
p4573
g63
(g96
S'\x1d\x00\x00\x00'
tRp4574
sg30
g4565
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p4575
sS'block_loop.thisTrial'
p4576
Nsg60
g61
sS'block_loop.thisTrialN'
p4577
I0
sg34
F0.85253488921080134
sg4113
V10-bounty.png
p4578
sa(dp4579
S'block_loop.thisRepN'
p4580
I1
sg4096
V46-pistachios.png
p4581
sg4098
V29-beans.png
p4582
sg70
g71
sS'outcome_loop.thisRepN'
p4583
I0
sS'block_loop.thisIndex'
p4584
g4102
sS'outcome_loop.thisN'
p4585
I30
sS'outcome_loop.thisTrialN'
p4586
I30
sg62
g66
sg33
S'right'
p4587
sS'block_loop.thisN'
p4588
I1
sS'outcome_loop.thisIndex'
p4589
g63
(g96
S'\x1e\x00\x00\x00'
tRp4590
sg30
g4581
sg67
g11
sg68
g69
sg4109
V29-beans.png
p4591
sS'block_loop.thisTrial'
p4592
Nsg60
g61
sS'block_loop.thisTrialN'
p4593
I0
sg34
F0.83921448117143882
sg4113
V46-pistachios.png
p4594
sa(dp4595
S'block_loop.thisRepN'
p4596
I1
sg4096
V42-mrkipling_lemon_slices.png
p4597
sg4098
V16-skips_prawn.png
p4598
sg70
g71
sS'outcome_loop.thisRepN'
p4599
I0
sS'block_loop.thisIndex'
p4600
g4102
sS'outcome_loop.thisN'
p4601
I31
sS'outcome_loop.thisTrialN'
p4602
I31
sg62
g66
sg33
S'right'
p4603
sS'block_loop.thisN'
p4604
I1
sS'outcome_loop.thisIndex'
p4605
g63
(g96
S'\x1f\x00\x00\x00'
tRp4606
sg30
g4597
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p4607
sS'block_loop.thisTrial'
p4608
Nsg60
g61
sS'block_loop.thisTrialN'
p4609
I0
sg34
F0.9457562343814061
sg4113
V42-mrkipling_lemon_slices.png
p4610
sa(dp4611
S'block_loop.thisRepN'
p4612
I1
sg4096
V7-olives.png
p4613
sg4098
V22-daim.png
p4614
sg70
g71
sS'outcome_loop.thisRepN'
p4615
I0
sS'block_loop.thisIndex'
p4616
g4102
sS'outcome_loop.thisN'
p4617
I32
sS'outcome_loop.thisTrialN'
p4618
I32
sg62
g66
sg33
S'right'
p4619
sS'block_loop.thisN'
p4620
I1
sS'outcome_loop.thisIndex'
p4621
g63
(g96
S' \x00\x00\x00'
tRp4622
sg30
g4613
sg67
g11
sg68
g69
sg4109
V22-daim.png
p4623
sS'block_loop.thisTrial'
p4624
Nsg60
g61
sS'block_loop.thisTrialN'
p4625
I0
sg34
F0.70599587377728312
sg4113
V7-olives.png
p4626
sa(dp4627
S'block_loop.thisRepN'
p4628
I1
sg4096
V33-ambrosia_rice.png
p4629
sg4098
V33-ambrosia_rice.png
p4630
sg70
g71
sS'outcome_loop.thisRepN'
p4631
I0
sS'block_loop.thisIndex'
p4632
g4102
sS'outcome_loop.thisN'
p4633
I33
sS'outcome_loop.thisTrialN'
p4634
I33
sg62
g66
sg33
S'left'
p4635
sS'block_loop.thisN'
p4636
I1
sS'outcome_loop.thisIndex'
p4637
g63
(g96
S'!\x00\x00\x00'
tRp4638
sg30
g4629
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p4639
sS'block_loop.thisTrial'
p4640
Nsg60
g61
sS'block_loop.thisTrialN'
p4641
I0
sg34
F0.65275111781011219
sg4113
V23-crunchie.png
p4642
sa(dp4643
S'block_loop.thisRepN'
p4644
I1
sg4096
V1-smarties_cookies.png
p4645
sg4098
V1-smarties_cookies.png
p4646
sg70
g71
sS'outcome_loop.thisRepN'
p4647
I0
sS'block_loop.thisIndex'
p4648
g4102
sS'outcome_loop.thisN'
p4649
I34
sS'outcome_loop.thisTrialN'
p4650
I34
sg62
g66
sg33
S'left'
p4651
sS'block_loop.thisN'
p4652
I1
sS'outcome_loop.thisIndex'
p4653
g63
(g96
S'"\x00\x00\x00'
tRp4654
sg30
g4645
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p4655
sS'block_loop.thisTrial'
p4656
Nsg60
g61
sS'block_loop.thisTrialN'
p4657
I0
sg34
F1.052312514579171
sg4113
V21-nakd_banana_crunch.png
p4658
sa(dp4659
S'block_loop.thisRepN'
p4660
I1
sg4096
V6-sour_patch_kids.png
p4661
sg4098
V38-maltesers.png
p4662
sg70
g71
sS'outcome_loop.thisRepN'
p4663
I0
sS'block_loop.thisIndex'
p4664
g4102
sS'outcome_loop.thisN'
p4665
I35
sS'outcome_loop.thisTrialN'
p4666
I35
sg62
g66
sg33
S'left'
p4667
sS'block_loop.thisN'
p4668
I1
sS'outcome_loop.thisIndex'
p4669
g63
(g96
S'#\x00\x00\x00'
tRp4670
sg30
g4661
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p4671
sS'block_loop.thisTrial'
p4672
Nsg60
g61
sS'block_loop.thisTrialN'
p4673
I0
sg34
F0.66610616712387127
sg4113
V6-sour_patch_kids.png
p4674
sa(dp4675
S'block_loop.thisRepN'
p4676
I1
sg4096
V43-mrporky_pork_crackles.png
p4677
sg4098
V43-mrporky_pork_crackles.png
p4678
sg70
g71
sS'outcome_loop.thisRepN'
p4679
I0
sS'block_loop.thisIndex'
p4680
g4102
sS'outcome_loop.thisN'
p4681
I36
sS'outcome_loop.thisTrialN'
p4682
I36
sg62
g66
sg33
S'left'
p4683
sS'block_loop.thisN'
p4684
I1
sS'outcome_loop.thisIndex'
p4685
g63
(g96
S'$\x00\x00\x00'
tRp4686
sg30
g4677
sg67
g11
sg68
g69
sg4109
V18-mms.png
p4687
sS'block_loop.thisTrial'
p4688
Nsg60
g61
sS'block_loop.thisTrialN'
p4689
I0
sg34
F0.58609096966210927
sg4113
V18-mms.png
p4690
sa(dp4691
S'block_loop.thisRepN'
p4692
I1
sg4096
V33-ambrosia_rice.png
p4693
sg4098
V23-crunchie.png
p4694
sg70
g71
sS'outcome_loop.thisRepN'
p4695
I0
sS'block_loop.thisIndex'
p4696
g4102
sS'outcome_loop.thisN'
p4697
I37
sS'outcome_loop.thisTrialN'
p4698
I37
sg62
g66
sg33
S'right'
p4699
sS'block_loop.thisN'
p4700
I1
sS'outcome_loop.thisIndex'
p4701
g63
(g96
S'%\x00\x00\x00'
tRp4702
sg30
g4693
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p4703
sS'block_loop.thisTrial'
p4704
Nsg60
g61
sS'block_loop.thisTrialN'
p4705
I0
sg34
F0.67938718468394654
sg4113
V33-ambrosia_rice.png
p4706
sa(dp4707
S'block_loop.thisRepN'
p4708
I1
sg4096
V19-caramello.png
p4709
sg4098
V19-caramello.png
p4710
sg70
g71
sS'outcome_loop.thisRepN'
p4711
I0
sS'block_loop.thisIndex'
p4712
g4102
sS'outcome_loop.thisN'
p4713
I38
sS'outcome_loop.thisTrialN'
p4714
I38
sg62
g66
sg33
S'left'
p4715
sS'block_loop.thisN'
p4716
I1
sS'outcome_loop.thisIndex'
p4717
g63
(g96
S'&\x00\x00\x00'
tRp4718
sg30
g4709
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p4719
sS'block_loop.thisTrial'
p4720
Nsg60
g61
sS'block_loop.thisTrialN'
p4721
I0
sg34
F0.86584719566417334
sg4113
V30-spaghetti_hoops.png
p4722
sa(dp4723
S'block_loop.thisRepN'
p4724
I1
sg4096
V49-yorkie.png
p4725
sg4098
V35-sultanas.png
p4726
sg70
g71
sS'outcome_loop.thisRepN'
p4727
I0
sS'block_loop.thisIndex'
p4728
g4102
sS'outcome_loop.thisN'
p4729
I39
sS'outcome_loop.thisTrialN'
p4730
I39
sg62
g66
sg33
S'right'
p4731
sS'block_loop.thisN'
p4732
I1
sS'outcome_loop.thisIndex'
p4733
g63
(g96
S"'\x00\x00\x00"
tRp4734
sg30
V35-sultanas.png
p4735
sg67
g11
sg68
g69
sg4109
g4735
sS'block_loop.thisTrial'
p4736
Nsg60
g61
sS'block_loop.thisTrialN'
p4737
I0
sg34
F1.2920460561344953
sg4113
V49-yorkie.png
p4738
sa(dp4739
S'block_loop.thisRepN'
p4740
I1
sg4096
V46-pistachios.png
p4741
sg4098
V29-beans.png
p4742
sg70
g71
sS'outcome_loop.thisRepN'
p4743
I0
sS'block_loop.thisIndex'
p4744
g4102
sS'outcome_loop.thisN'
p4745
I40
sS'outcome_loop.thisTrialN'
p4746
I40
sg62
g66
sg33
S'right'
p4747
sS'block_loop.thisN'
p4748
I1
sS'outcome_loop.thisIndex'
p4749
g63
(g96
S'(\x00\x00\x00'
tRp4750
sg30
g4741
sg67
g11
sg68
g69
sg4109
V29-beans.png
p4751
sS'block_loop.thisTrial'
p4752
Nsg60
g61
sS'block_loop.thisTrialN'
p4753
I0
sg34
F0.87908295607485343
sg4113
V46-pistachios.png
p4754
sa(dp4755
S'block_loop.thisRepN'
p4756
I1
sg4096
V1-smarties_cookies.png
p4757
sg4098
V21-nakd_banana_crunch.png
p4758
sg70
g71
sS'outcome_loop.thisRepN'
p4759
I0
sS'block_loop.thisIndex'
p4760
g4102
sS'outcome_loop.thisN'
p4761
I41
sS'outcome_loop.thisTrialN'
p4762
I41
sg62
g66
sg33
S'right'
p4763
sS'block_loop.thisN'
p4764
I1
sS'outcome_loop.thisIndex'
p4765
g63
(g96
S')\x00\x00\x00'
tRp4766
sg30
g4757
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p4767
sS'block_loop.thisTrial'
p4768
Nsg60
g61
sS'block_loop.thisTrialN'
p4769
I0
sg34
F0.9191170944905025
sg4113
V1-smarties_cookies.png
p4770
sa(dp4771
S'block_loop.thisRepN'
p4772
I1
sg4096
V5-pineapple.png
p4773
sg4098
V40-sardines.png
p4774
sg70
g71
sS'outcome_loop.thisRepN'
p4775
I0
sS'block_loop.thisIndex'
p4776
g4102
sS'outcome_loop.thisN'
p4777
I42
sS'outcome_loop.thisTrialN'
p4778
I42
sg62
g66
sg33
S'right'
p4779
sS'block_loop.thisN'
p4780
I1
sS'outcome_loop.thisIndex'
p4781
g63
(g96
S'*\x00\x00\x00'
tRp4782
sg30
g4773
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p4783
sS'block_loop.thisTrial'
p4784
Nsg60
g61
sS'block_loop.thisTrialN'
p4785
I0
sg34
F1.0522971494974627
sg4113
V5-pineapple.png
p4786
sa(dp4787
S'block_loop.thisRepN'
p4788
I1
sg4096
V13-mccoys_steak_crisps.png
p4789
sg4098
V3-dole_fruit_snack.png
p4790
sg70
g71
sS'outcome_loop.thisRepN'
p4791
I0
sS'block_loop.thisIndex'
p4792
g4102
sS'outcome_loop.thisN'
p4793
I43
sS'outcome_loop.thisTrialN'
p4794
I43
sg62
g66
sg33
S'right'
p4795
sS'block_loop.thisN'
p4796
I1
sS'outcome_loop.thisIndex'
p4797
g63
(g96
S'+\x00\x00\x00'
tRp4798
sg30
g4789
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p4799
sS'block_loop.thisTrial'
p4800
Nsg60
g61
sS'block_loop.thisTrialN'
p4801
I0
sg34
F1.0389834462202998
sg4113
V13-mccoys_steak_crisps.png
p4802
sa(dp4803
S'block_loop.thisRepN'
p4804
I1
sg4096
V46-pistachios.png
p4805
sg4098
V46-pistachios.png
p4806
sg70
g71
sS'outcome_loop.thisRepN'
p4807
I0
sS'block_loop.thisIndex'
p4808
g4102
sS'outcome_loop.thisN'
p4809
I44
sS'outcome_loop.thisTrialN'
p4810
I44
sg62
g66
sg33
S'left'
p4811
sS'block_loop.thisN'
p4812
I1
sS'outcome_loop.thisIndex'
p4813
g63
(g96
S',\x00\x00\x00'
tRp4814
sg30
g4805
sg67
g11
sg68
g69
sg4109
V29-beans.png
p4815
sS'block_loop.thisTrial'
p4816
Nsg60
g61
sS'block_loop.thisTrialN'
p4817
I0
sg34
F0.58615019506760291
sg4113
V29-beans.png
p4818
sa(dp4819
S'block_loop.thisRepN'
p4820
I1
sg4096
V31-foxs_golden_biscuits.png
p4821
sg4098
V25-kitkat.png
p4822
sg70
g71
sS'outcome_loop.thisRepN'
p4823
I0
sS'block_loop.thisIndex'
p4824
g4102
sS'outcome_loop.thisN'
p4825
I45
sS'outcome_loop.thisTrialN'
p4826
I45
sg62
g66
sg33
S'right'
p4827
sS'block_loop.thisN'
p4828
I1
sS'outcome_loop.thisIndex'
p4829
g63
(g96
S'-\x00\x00\x00'
tRp4830
sg30
g4821
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p4831
sS'block_loop.thisTrial'
p4832
Nsg60
g61
sS'block_loop.thisTrialN'
p4833
I0
sg34
F0.7459702280593774
sg4113
V31-foxs_golden_biscuits.png
p4834
sa(dp4835
S'block_loop.thisRepN'
p4836
I1
sg4096
V4-corn.png
p4837
sg4098
V4-corn.png
p4838
sg70
g71
sS'outcome_loop.thisRepN'
p4839
I0
sS'block_loop.thisIndex'
p4840
g4102
sS'outcome_loop.thisN'
p4841
I46
sS'outcome_loop.thisTrialN'
p4842
I46
sg62
g66
sg33
S'left'
p4843
sS'block_loop.thisN'
p4844
I1
sS'outcome_loop.thisIndex'
p4845
g63
(g96
S'.\x00\x00\x00'
tRp4846
sg30
g4837
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p4847
sS'block_loop.thisTrial'
p4848
Nsg60
g61
sS'block_loop.thisTrialN'
p4849
I0
sg34
F0.62610611125091964
sg4113
V10-bounty.png
p4850
sa(dp4851
S'block_loop.thisRepN'
p4852
I1
sg4096
V5-pineapple.png
p4853
sg4098
V40-sardines.png
p4854
sg70
g71
sS'outcome_loop.thisRepN'
p4855
I0
sS'block_loop.thisIndex'
p4856
g4102
sS'outcome_loop.thisN'
p4857
I47
sS'outcome_loop.thisTrialN'
p4858
I47
sg62
g66
sg33
S'right'
p4859
sS'block_loop.thisN'
p4860
I1
sS'outcome_loop.thisIndex'
p4861
g63
(g96
S'/\x00\x00\x00'
tRp4862
sg30
g4853
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p4863
sS'block_loop.thisTrial'
p4864
Nsg60
g61
sS'block_loop.thisTrialN'
p4865
I0
sg34
F0.87922263863038097
sg4113
V5-pineapple.png
p4866
sa(dp4867
S'block_loop.thisRepN'
p4868
I1
sg4096
V20-fruit_pastilles.png
p4869
sg4098
V2-steamed_puddings.png
p4870
sg70
g71
sS'outcome_loop.thisRepN'
p4871
I0
sS'block_loop.thisIndex'
p4872
g4102
sS'outcome_loop.thisN'
p4873
I48
sS'outcome_loop.thisTrialN'
p4874
I48
sg62
g66
sg33
S'right'
p4875
sS'block_loop.thisN'
p4876
I1
sS'outcome_loop.thisIndex'
p4877
g63
(g96
S'0\x00\x00\x00'
tRp4878
sg30
g4869
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p4879
sS'block_loop.thisTrial'
p4880
Nsg60
g61
sS'block_loop.thisTrialN'
p4881
I0
sg34
F1.3186407769699144
sg4113
V20-fruit_pastilles.png
p4882
sa(dp4883
S'block_loop.thisRepN'
p4884
I1
sg4096
V49-yorkie.png
p4885
sg4098
V49-yorkie.png
p4886
sg70
g71
sS'outcome_loop.thisRepN'
p4887
I0
sS'block_loop.thisIndex'
p4888
g4102
sS'outcome_loop.thisN'
p4889
I49
sS'outcome_loop.thisTrialN'
p4890
I49
sg62
g66
sg33
S'left'
p4891
sS'block_loop.thisN'
p4892
I1
sS'outcome_loop.thisIndex'
p4893
g63
(g96
S'1\x00\x00\x00'
tRp4894
sg30
g4885
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p4895
sS'block_loop.thisTrial'
p4896
Nsg60
g61
sS'block_loop.thisTrialN'
p4897
I0
sg34
F0.77261132350758999
sg4113
V35-sultanas.png
p4898
sa(dp4899
S'block_loop.thisRepN'
p4900
I1
sg4096
V4-corn.png
p4901
sg4098
V10-bounty.png
p4902
sg70
g71
sS'outcome_loop.thisRepN'
p4903
I0
sS'block_loop.thisIndex'
p4904
g4102
sS'outcome_loop.thisN'
p4905
I50
sS'outcome_loop.thisTrialN'
p4906
I50
sg62
g66
sg33
S'right'
p4907
sS'block_loop.thisN'
p4908
I1
sS'outcome_loop.thisIndex'
p4909
g63
(g96
S'2\x00\x00\x00'
tRp4910
sg30
g4901
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p4911
sS'block_loop.thisTrial'
p4912
Nsg60
g61
sS'block_loop.thisTrialN'
p4913
I0
sg34
F0.85252511143153242
sg4113
V4-corn.png
p4914
sa(dp4915
S'block_loop.thisRepN'
p4916
I1
sg4096
V1-smarties_cookies.png
p4917
sg4098
V21-nakd_banana_crunch.png
p4918
sg70
g71
sS'outcome_loop.thisRepN'
p4919
I0
sS'block_loop.thisIndex'
p4920
g4102
sS'outcome_loop.thisN'
p4921
I51
sS'outcome_loop.thisTrialN'
p4922
I51
sg62
g66
sg33
S'right'
p4923
sS'block_loop.thisN'
p4924
I1
sS'outcome_loop.thisIndex'
p4925
g63
(g96
S'3\x00\x00\x00'
tRp4926
sg30
g4917
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p4927
sS'block_loop.thisTrial'
p4928
Nsg60
g61
sS'block_loop.thisTrialN'
p4929
I0
sg34
F0.74597385980450781
sg4113
V1-smarties_cookies.png
p4930
sa(dp4931
S'block_loop.thisRepN'
p4932
I1
sg4096
V49-yorkie.png
p4933
sg4098
V49-yorkie.png
p4934
sg70
g71
sS'outcome_loop.thisRepN'
p4935
I0
sS'block_loop.thisIndex'
p4936
g4102
sS'outcome_loop.thisN'
p4937
I52
sS'outcome_loop.thisTrialN'
p4938
I52
sg62
g66
sg33
S'left'
p4939
sS'block_loop.thisN'
p4940
I1
sS'outcome_loop.thisIndex'
p4941
g63
(g96
S'4\x00\x00\x00'
tRp4942
sg30
g4933
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p4943
sS'block_loop.thisTrial'
p4944
Nsg60
g61
sS'block_loop.thisTrialN'
p4945
I0
sg34
F0.7060321912431391
sg4113
V35-sultanas.png
p4946
sa(dp4947
S'block_loop.thisRepN'
p4948
I1
sg4096
V6-sour_patch_kids.png
p4949
sg4098
V38-maltesers.png
p4950
sg70
g71
sS'outcome_loop.thisRepN'
p4951
I0
sS'block_loop.thisIndex'
p4952
g4102
sS'outcome_loop.thisN'
p4953
I53
sS'outcome_loop.thisTrialN'
p4954
I53
sg62
g66
sg33
S'left'
p4955
sS'block_loop.thisN'
p4956
I1
sS'outcome_loop.thisIndex'
p4957
g63
(g96
S'5\x00\x00\x00'
tRp4958
sg30
V38-maltesers.png
p4959
sg67
g11
sg68
g69
sg4109
g4959
sS'block_loop.thisTrial'
p4960
Nsg60
g61
sS'block_loop.thisTrialN'
p4961
I0
sg34
F0.785941788690252
sg4113
V6-sour_patch_kids.png
p4962
sa(dp4963
S'block_loop.thisRepN'
p4964
I1
sg4096
V17-jacobs_mini_cheddars.png
p4965
sg4098
V17-jacobs_mini_cheddars.png
p4966
sg70
g71
sS'outcome_loop.thisRepN'
p4967
I0
sS'block_loop.thisIndex'
p4968
g4102
sS'outcome_loop.thisN'
p4969
I54
sS'outcome_loop.thisTrialN'
p4970
I54
sg62
g66
sg33
S'left'
p4971
sS'block_loop.thisN'
p4972
I1
sS'outcome_loop.thisIndex'
p4973
g63
(g96
S'6\x00\x00\x00'
tRp4974
sg30
g4965
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p4975
sS'block_loop.thisTrial'
p4976
Nsg60
g61
sS'block_loop.thisTrialN'
p4977
I0
sg34
F0.69270004986719869
sg4113
V8-liquorice_catherine_wheels.png
p4978
sa(dp4979
S'block_loop.thisRepN'
p4980
I1
sg4096
V45-chewy_nougat.png
p4981
sg4098
V41-peanuts.png
p4982
sg70
g71
sS'outcome_loop.thisRepN'
p4983
I0
sS'block_loop.thisIndex'
p4984
g4102
sS'outcome_loop.thisN'
p4985
I55
sS'outcome_loop.thisTrialN'
p4986
I55
sg62
g66
sg33
S'right'
p4987
sS'block_loop.thisN'
p4988
I1
sS'outcome_loop.thisIndex'
p4989
g63
(g96
S'7\x00\x00\x00'
tRp4990
sg30
g4981
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p4991
sS'block_loop.thisTrial'
p4992
Nsg60
g61
sS'block_loop.thisTrialN'
p4993
I0
sg34
F0.93243359142070403
sg4113
V45-chewy_nougat.png
p4994
sa(dp4995
S'block_loop.thisRepN'
p4996
I1
sg4096
V42-mrkipling_lemon_slices.png
p4997
sg4098
V16-skips_prawn.png
p4998
sg70
g71
sS'outcome_loop.thisRepN'
p4999
I0
sS'block_loop.thisIndex'
p5000
g4102
sS'outcome_loop.thisN'
p5001
I56
sS'outcome_loop.thisTrialN'
p5002
I56
sg62
g66
sg33
S'right'
p5003
sS'block_loop.thisN'
p5004
I1
sS'outcome_loop.thisIndex'
p5005
g63
(g96
S'8\x00\x00\x00'
tRp5006
sg30
g4997
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p5007
sS'block_loop.thisTrial'
p5008
Nsg60
g61
sS'block_loop.thisTrialN'
p5009
I0
sg34
F0.77260908858625044
sg4113
V42-mrkipling_lemon_slices.png
p5010
sa(dp5011
S'block_loop.thisRepN'
p5012
I1
sg4096
V46-pistachios.png
p5013
sg4098
V29-beans.png
p5014
sg70
g71
sS'outcome_loop.thisRepN'
p5015
I0
sS'block_loop.thisIndex'
p5016
g4102
sS'outcome_loop.thisN'
p5017
I57
sS'outcome_loop.thisTrialN'
p5018
I57
sg62
g66
sg33
S'right'
p5019
sS'block_loop.thisN'
p5020
I1
sS'outcome_loop.thisIndex'
p5021
g63
(g96
S'9\x00\x00\x00'
tRp5022
sg30
g5013
sg67
g11
sg68
g69
sg4109
V29-beans.png
p5023
sS'block_loop.thisTrial'
p5024
Nsg60
g61
sS'block_loop.thisTrialN'
p5025
I0
sg34
F0.89248186571239785
sg4113
V46-pistachios.png
p5026
sa(dp5027
S'block_loop.thisRepN'
p5028
I1
sg4096
V5-pineapple.png
p5029
sg4098
V40-sardines.png
p5030
sg70
g71
sS'outcome_loop.thisRepN'
p5031
I0
sS'block_loop.thisIndex'
p5032
g4102
sS'outcome_loop.thisN'
p5033
I58
sS'outcome_loop.thisTrialN'
p5034
I58
sg62
g66
sg33
S'right'
p5035
sS'block_loop.thisN'
p5036
I1
sS'outcome_loop.thisIndex'
p5037
g63
(g96
S':\x00\x00\x00'
tRp5038
sg30
g5029
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p5039
sS'block_loop.thisTrial'
p5040
Nsg60
g61
sS'block_loop.thisTrialN'
p5041
I0
sg34
F0.91912407861855172
sg4113
V5-pineapple.png
p5042
sa(dp5043
S'block_loop.thisRepN'
p5044
I1
sg4096
V4-corn.png
p5045
sg4098
V10-bounty.png
p5046
sg70
g71
sS'outcome_loop.thisRepN'
p5047
I0
sS'block_loop.thisIndex'
p5048
g4102
sS'outcome_loop.thisN'
p5049
I59
sS'outcome_loop.thisTrialN'
p5050
I59
sg62
g66
sg33
S'right'
p5051
sS'block_loop.thisN'
p5052
I1
sS'outcome_loop.thisIndex'
p5053
g63
(g96
S';\x00\x00\x00'
tRp5054
sg30
g5045
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p5055
sS'block_loop.thisTrial'
p5056
Nsg60
g61
sS'block_loop.thisTrialN'
p5057
I0
sg34
F0.66605280838666658
sg4113
V4-corn.png
p5058
sa(dp5059
S'block_loop.thisRepN'
p5060
I1
sg4096
V43-mrporky_pork_crackles.png
p5061
sg4098
V43-mrporky_pork_crackles.png
p5062
sg70
g71
sS'outcome_loop.thisRepN'
p5063
I0
sS'block_loop.thisIndex'
p5064
g4102
sS'outcome_loop.thisN'
p5065
I60
sS'outcome_loop.thisTrialN'
p5066
I60
sg62
g66
sg33
S'left'
p5067
sS'block_loop.thisN'
p5068
I1
sS'outcome_loop.thisIndex'
p5069
g63
(g96
S'<\x00\x00\x00'
tRp5070
sg30
V18-mms.png
p5071
sg67
g11
sg68
g69
sg4109
g5071
sS'block_loop.thisTrial'
p5072
Nsg60
g61
sS'block_loop.thisTrialN'
p5073
I0
sg34
F0.50623668650587206
sg4113
V18-mms.png
p5074
sa(dp5075
S'block_loop.thisRepN'
p5076
I1
sg4096
V26-walkers_smoky_bacon.png
p5077
sg4098
V44-crunch.png
p5078
sg70
g71
sS'outcome_loop.thisRepN'
p5079
I0
sS'block_loop.thisIndex'
p5080
g4102
sS'outcome_loop.thisN'
p5081
I61
sS'outcome_loop.thisTrialN'
p5082
I61
sg62
g66
sg33
S'right'
p5083
sS'block_loop.thisN'
p5084
I1
sS'outcome_loop.thisIndex'
p5085
g63
(g96
S'=\x00\x00\x00'
tRp5086
sg30
V44-crunch.png
p5087
sg67
g11
sg68
g69
sg4109
g5087
sS'block_loop.thisTrial'
p5088
Nsg60
g61
sS'block_loop.thisTrialN'
p5089
I0
sg34
F0.59947004437708529
sg4113
V26-walkers_smoky_bacon.png
p5090
sa(dp5091
S'block_loop.thisRepN'
p5092
I1
sg4096
V36-fig_rolls.png
p5093
sg4098
V36-fig_rolls.png
p5094
sg70
g71
sS'outcome_loop.thisRepN'
p5095
I0
sS'block_loop.thisIndex'
p5096
g4102
sS'outcome_loop.thisN'
p5097
I62
sS'outcome_loop.thisTrialN'
p5098
I62
sg62
g66
sg33
S'left'
p5099
sS'block_loop.thisN'
p5100
I1
sS'outcome_loop.thisIndex'
p5101
g63
(g96
S'>\x00\x00\x00'
tRp5102
sg30
g5093
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p5103
sS'block_loop.thisTrial'
p5104
Nsg60
g61
sS'block_loop.thisTrialN'
p5105
I0
sg34
F0.74596603758436686
sg4113
V34-hula_hoops_bbq_beef.png
p5106
sa(dp5107
S'block_loop.thisRepN'
p5108
I1
sg4096
V42-mrkipling_lemon_slices.png
p5109
sg4098
V42-mrkipling_lemon_slices.png
p5110
sg70
g71
sS'outcome_loop.thisRepN'
p5111
I0
sS'block_loop.thisIndex'
p5112
g4102
sS'outcome_loop.thisN'
p5113
I63
sS'outcome_loop.thisTrialN'
p5114
I63
sg62
g66
sg33
S'left'
p5115
sS'block_loop.thisN'
p5116
I1
sS'outcome_loop.thisIndex'
p5117
g63
(g96
S'?\x00\x00\x00'
tRp5118
sg30
g5109
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p5119
sS'block_loop.thisTrial'
p5120
Nsg60
g61
sS'block_loop.thisTrialN'
p5121
I0
sg34
F0.79924319990277581
sg4113
V16-skips_prawn.png
p5122
sa(dp5123
S'block_loop.thisRepN'
p5124
I1
sg4096
V48-twix.png
p5125
sg4098
V50-polo.png
p5126
sg70
g71
sS'outcome_loop.thisRepN'
p5127
I0
sS'block_loop.thisIndex'
p5128
g4102
sS'outcome_loop.thisN'
p5129
I64
sS'outcome_loop.thisTrialN'
p5130
I64
sg62
g66
sg33
S'left'
p5131
sS'block_loop.thisN'
p5132
I1
sS'outcome_loop.thisIndex'
p5133
g63
(g96
S'@\x00\x00\x00'
tRp5134
sg30
g5125
sg67
g11
sg68
g69
sg4109
V50-polo.png
p5135
sS'block_loop.thisTrial'
p5136
Nsg60
g61
sS'block_loop.thisTrialN'
p5137
I0
sg34
F2.0778593368704605
sg4113
V48-twix.png
p5138
sa(dp5139
S'block_loop.thisRepN'
p5140
I1
sg4096
V26-walkers_smoky_bacon.png
p5141
sg4098
V26-walkers_smoky_bacon.png
p5142
sg70
g71
sS'outcome_loop.thisRepN'
p5143
I0
sS'block_loop.thisIndex'
p5144
g4102
sS'outcome_loop.thisN'
p5145
I65
sS'outcome_loop.thisTrialN'
p5146
I65
sg62
g66
sg33
S'left'
p5147
sS'block_loop.thisN'
p5148
I1
sS'outcome_loop.thisIndex'
p5149
g63
(g96
S'A\x00\x00\x00'
tRp5150
sg30
g5141
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p5151
sS'block_loop.thisTrial'
p5152
Nsg60
g61
sS'block_loop.thisTrialN'
p5153
I0
sg34
F0.51955290407022403
sg4113
V44-crunch.png
p5154
sa(dp5155
S'block_loop.thisRepN'
p5156
I1
sg4096
V31-foxs_golden_biscuits.png
p5157
sg4098
V31-foxs_golden_biscuits.png
p5158
sg70
g71
sS'outcome_loop.thisRepN'
p5159
I0
sS'block_loop.thisIndex'
p5160
g4102
sS'outcome_loop.thisN'
p5161
I66
sS'outcome_loop.thisTrialN'
p5162
I66
sg62
g66
sg33
S'left'
p5163
sS'block_loop.thisN'
p5164
I1
sS'outcome_loop.thisIndex'
p5165
g63
(g96
S'B\x00\x00\x00'
tRp5166
sg30
g5157
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p5167
sS'block_loop.thisTrial'
p5168
Nsg60
g61
sS'block_loop.thisTrialN'
p5169
I0
sg34
F0.69268803716659022
sg4113
V25-kitkat.png
p5170
sa(dp5171
S'block_loop.thisRepN'
p5172
I1
sg4096
V1-smarties_cookies.png
p5173
sg4098
V21-nakd_banana_crunch.png
p5174
sg70
g71
sS'outcome_loop.thisRepN'
p5175
I0
sS'block_loop.thisIndex'
p5176
g4102
sS'outcome_loop.thisN'
p5177
I67
sS'outcome_loop.thisTrialN'
p5178
I67
sg62
g66
sg33
S'right'
p5179
sS'block_loop.thisN'
p5180
I1
sS'outcome_loop.thisIndex'
p5181
g63
(g96
S'C\x00\x00\x00'
tRp5182
sg30
g5173
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p5183
sS'block_loop.thisTrial'
p5184
Nsg60
g61
sS'block_loop.thisTrialN'
p5185
I0
sg34
F0.7193031516562769
sg4113
V1-smarties_cookies.png
p5186
sa(dp5187
S'block_loop.thisRepN'
p5188
I1
sg4096
V48-twix.png
p5189
sg4098
V48-twix.png
p5190
sg70
g71
sS'outcome_loop.thisRepN'
p5191
I0
sS'block_loop.thisIndex'
p5192
g4102
sS'outcome_loop.thisN'
p5193
I68
sS'outcome_loop.thisTrialN'
p5194
I68
sg62
g66
sg33
S'left'
p5195
sS'block_loop.thisN'
p5196
I1
sS'outcome_loop.thisIndex'
p5197
g63
(g96
S'D\x00\x00\x00'
tRp5198
sg30
g5189
sg67
g11
sg68
g69
sg4109
V50-polo.png
p5199
sS'block_loop.thisTrial'
p5200
Nsg60
g61
sS'block_loop.thisTrialN'
p5201
I0
sg34
F1.1588556646165671
sg4113
V50-polo.png
p5202
sa(dp5203
S'block_loop.thisRepN'
p5204
I1
sg4096
V19-caramello.png
p5205
sg4098
V19-caramello.png
p5206
sg70
g71
sS'outcome_loop.thisRepN'
p5207
I0
sS'block_loop.thisIndex'
p5208
g4102
sS'outcome_loop.thisN'
p5209
I69
sS'outcome_loop.thisTrialN'
p5210
I69
sg62
g66
sg33
S'left'
p5211
sS'block_loop.thisN'
p5212
I1
sS'outcome_loop.thisIndex'
p5213
g63
(g96
S'E\x00\x00\x00'
tRp5214
sg30
V30-spaghetti_hoops.png
p5215
sg67
g11
sg68
g69
sg4109
g5215
sS'block_loop.thisTrial'
p5216
Nsg60
g61
sS'block_loop.thisTrialN'
p5217
I0
sg34
F0.83921364307389013
sg4113
V30-spaghetti_hoops.png
p5218
sa(dp5219
S'block_loop.thisRepN'
p5220
I1
sg4096
V45-chewy_nougat.png
p5221
sg4098
V41-peanuts.png
p5222
sg70
g71
sS'outcome_loop.thisRepN'
p5223
I0
sS'block_loop.thisIndex'
p5224
g4102
sS'outcome_loop.thisN'
p5225
I70
sS'outcome_loop.thisTrialN'
p5226
I70
sg62
g66
sg33
S'right'
p5227
sS'block_loop.thisN'
p5228
I1
sS'outcome_loop.thisIndex'
p5229
g63
(g96
S'F\x00\x00\x00'
tRp5230
sg30
g5221
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p5231
sS'block_loop.thisTrial'
p5232
Nsg60
g61
sS'block_loop.thisTrialN'
p5233
I0
sg34
F0.78592977598964353
sg4113
V45-chewy_nougat.png
p5234
sa(dp5235
S'block_loop.thisRepN'
p5236
I1
sg4096
V31-foxs_golden_biscuits.png
p5237
sg4098
V25-kitkat.png
p5238
sg70
g71
sS'outcome_loop.thisRepN'
p5239
I0
sS'block_loop.thisIndex'
p5240
g4102
sS'outcome_loop.thisN'
p5241
I71
sS'outcome_loop.thisTrialN'
p5242
I71
sg62
g66
sg33
S'right'
p5243
sS'block_loop.thisN'
p5244
I1
sS'outcome_loop.thisIndex'
p5245
g63
(g96
S'G\x00\x00\x00'
tRp5246
sg30
V25-kitkat.png
p5247
sg67
g11
sg68
g69
sg4109
g5247
sS'block_loop.thisTrial'
p5248
Nsg60
g61
sS'block_loop.thisTrialN'
p5249
I0
sg34
F0.70602744203461043
sg4113
V31-foxs_golden_biscuits.png
p5250
sa(dp5251
S'block_loop.thisRepN'
p5252
I1
sg4096
V46-pistachios.png
p5253
sg4098
V29-beans.png
p5254
sg70
g71
sS'outcome_loop.thisRepN'
p5255
I0
sS'block_loop.thisIndex'
p5256
g4102
sS'outcome_loop.thisN'
p5257
I72
sS'outcome_loop.thisTrialN'
p5258
I72
sg62
g66
sg33
S'right'
p5259
sS'block_loop.thisN'
p5260
I1
sS'outcome_loop.thisIndex'
p5261
g63
(g96
S'H\x00\x00\x00'
tRp5262
sg30
g5253
sg67
g11
sg68
g69
sg4109
V29-beans.png
p5263
sS'block_loop.thisTrial'
p5264
Nsg60
g61
sS'block_loop.thisTrialN'
p5265
I0
sg34
F0.61276726511459856
sg4113
V46-pistachios.png
p5266
sa(dp5267
S'block_loop.thisRepN'
p5268
I1
sg4096
V49-yorkie.png
p5269
sg4098
V35-sultanas.png
p5270
sg70
g71
sS'outcome_loop.thisRepN'
p5271
I0
sS'block_loop.thisIndex'
p5272
g4102
sS'outcome_loop.thisN'
p5273
I73
sS'outcome_loop.thisTrialN'
p5274
I73
sg62
g66
sg33
S'right'
p5275
sS'block_loop.thisN'
p5276
I1
sS'outcome_loop.thisIndex'
p5277
g63
(g96
S'I\x00\x00\x00'
tRp5278
sg30
V35-sultanas.png
p5279
sg67
g11
sg68
g69
sg4109
g5279
sS'block_loop.thisTrial'
p5280
Nsg60
g61
sS'block_loop.thisTrialN'
p5281
I0
sg34
F0.67939612436748575
sg4113
V49-yorkie.png
p5282
sa(dp5283
S'block_loop.thisRepN'
p5284
I1
sg4096
V19-caramello.png
p5285
sg4098
V30-spaghetti_hoops.png
p5286
sg70
g71
sS'outcome_loop.thisRepN'
p5287
I0
sS'block_loop.thisIndex'
p5288
g4102
sS'outcome_loop.thisN'
p5289
I74
sS'outcome_loop.thisTrialN'
p5290
I74
sg62
g66
sg33
S'right'
p5291
sS'block_loop.thisN'
p5292
I1
sS'outcome_loop.thisIndex'
p5293
g63
(g96
S'J\x00\x00\x00'
tRp5294
sg30
g5285
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p5295
sS'block_loop.thisTrial'
p5296
Nsg60
g61
sS'block_loop.thisTrialN'
p5297
I0
sg34
F0.87915614973462652
sg4113
V19-caramello.png
p5298
sa(dp5299
S'block_loop.thisRepN'
p5300
I1
sg4096
V20-fruit_pastilles.png
p5301
sg4098
V20-fruit_pastilles.png
p5302
sg70
g71
sS'outcome_loop.thisRepN'
p5303
I0
sS'block_loop.thisIndex'
p5304
g4102
sS'outcome_loop.thisN'
p5305
I75
sS'outcome_loop.thisTrialN'
p5306
I75
sg62
g66
sg33
S'left'
p5307
sS'block_loop.thisN'
p5308
I1
sS'outcome_loop.thisIndex'
p5309
g63
(g96
S'K\x00\x00\x00'
tRp5310
sg30
g5301
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p5311
sS'block_loop.thisTrial'
p5312
Nsg60
g61
sS'block_loop.thisTrialN'
p5313
I0
sg34
F0.7326587597035541
sg4113
V2-steamed_puddings.png
p5314
sa(dp5315
S'block_loop.thisRepN'
p5316
I1
sg4096
V17-jacobs_mini_cheddars.png
p5317
sg4098
V17-jacobs_mini_cheddars.png
p5318
sg70
g71
sS'outcome_loop.thisRepN'
p5319
I0
sS'block_loop.thisIndex'
p5320
g4102
sS'outcome_loop.thisN'
p5321
I76
sS'outcome_loop.thisTrialN'
p5322
I76
sg62
g66
sg33
S'left'
p5323
sS'block_loop.thisN'
p5324
I1
sS'outcome_loop.thisIndex'
p5325
g63
(g96
S'L\x00\x00\x00'
tRp5326
sg30
V8-liquorice_catherine_wheels.png
p5327
sg67
g11
sg68
g69
sg4109
g5327
sS'block_loop.thisTrial'
p5328
Nsg60
g61
sS'block_loop.thisTrialN'
p5329
I0
sg34
F0.50623193729916238
sg4113
V8-liquorice_catherine_wheels.png
p5330
sa(dp5331
S'block_loop.thisRepN'
p5332
I1
sg4096
V26-walkers_smoky_bacon.png
p5333
sg4098
V44-crunch.png
p5334
sg70
g71
sS'outcome_loop.thisRepN'
p5335
I0
sS'block_loop.thisIndex'
p5336
g4102
sS'outcome_loop.thisN'
p5337
I77
sS'outcome_loop.thisTrialN'
p5338
I77
sg62
g66
sg33
S'right'
p5339
sS'block_loop.thisN'
p5340
I1
sS'outcome_loop.thisIndex'
p5341
g63
(g96
S'M\x00\x00\x00'
tRp5342
sg30
g5333
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p5343
sS'block_loop.thisTrial'
p5344
Nsg60
g61
sS'block_loop.thisTrialN'
p5345
I0
sg34
F0.50622299761562317
sg4113
V26-walkers_smoky_bacon.png
p5346
sa(dp5347
S'block_loop.thisRepN'
p5348
I1
sg4096
V43-mrporky_pork_crackles.png
p5349
sg4098
V18-mms.png
p5350
sg70
g71
sS'outcome_loop.thisRepN'
p5351
I0
sS'block_loop.thisIndex'
p5352
g4102
sS'outcome_loop.thisN'
p5353
I78
sS'outcome_loop.thisTrialN'
p5354
I78
sg62
g66
sg33
S'right'
p5355
sS'block_loop.thisN'
p5356
I1
sS'outcome_loop.thisIndex'
p5357
g63
(g96
S'N\x00\x00\x00'
tRp5358
sg30
g5349
sg67
g11
sg68
g69
sg4109
V18-mms.png
p5359
sS'block_loop.thisTrial'
p5360
Nsg60
g61
sS'block_loop.thisTrialN'
p5361
I0
sg34
F0.59945300310573657
sg4113
V43-mrporky_pork_crackles.png
p5362
sa(dp5363
S'block_loop.thisRepN'
p5364
I1
sg4096
V46-pistachios.png
p5365
sg4098
V46-pistachios.png
p5366
sg70
g71
sS'outcome_loop.thisRepN'
p5367
I0
sS'block_loop.thisIndex'
p5368
g4102
sS'outcome_loop.thisN'
p5369
I79
sS'outcome_loop.thisTrialN'
p5370
I79
sg62
g66
sg33
S'left'
p5371
sS'block_loop.thisN'
p5372
I1
sS'outcome_loop.thisIndex'
p5373
g63
(g96
S'O\x00\x00\x00'
tRp5374
sg30
g5365
sg67
g11
sg68
g69
sg4109
V29-beans.png
p5375
sS'block_loop.thisTrial'
p5376
Nsg60
g61
sS'block_loop.thisTrialN'
p5377
I0
sg34
F0.54618645665868826
sg4113
V29-beans.png
p5378
sa(dp5379
S'block_loop.thisRepN'
p5380
I1
sg4096
V36-fig_rolls.png
p5381
sg4098
V34-hula_hoops_bbq_beef.png
p5382
sg70
g71
sS'outcome_loop.thisRepN'
p5383
I0
sS'block_loop.thisIndex'
p5384
g4102
sS'outcome_loop.thisN'
p5385
I80
sS'outcome_loop.thisTrialN'
p5386
I80
sg62
g66
sg33
S'right'
p5387
sS'block_loop.thisN'
p5388
I1
sS'outcome_loop.thisIndex'
p5389
g63
(g96
S'P\x00\x00\x00'
tRp5390
sg30
g5381
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p5391
sS'block_loop.thisTrial'
p5392
Nsg60
g61
sS'block_loop.thisTrialN'
p5393
I0
sg34
F1.3186824023723602
sg4113
V36-fig_rolls.png
p5394
sa(dp5395
S'block_loop.thisRepN'
p5396
I1
sg4096
V49-yorkie.png
p5397
sg4098
V35-sultanas.png
p5398
sg70
g71
sS'outcome_loop.thisRepN'
p5399
I0
sS'block_loop.thisIndex'
p5400
g4102
sS'outcome_loop.thisN'
p5401
I81
sS'outcome_loop.thisTrialN'
p5402
I81
sg62
g66
sg33
S'right'
p5403
sS'block_loop.thisN'
p5404
I1
sS'outcome_loop.thisIndex'
p5405
g63
(g96
S'Q\x00\x00\x00'
tRp5406
sg30
g5397
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p5407
sS'block_loop.thisTrial'
p5408
Nsg60
g61
sS'block_loop.thisTrialN'
p5409
I0
sg34
F0.58614712204871466
sg4113
V49-yorkie.png
p5410
sa(dp5411
S'block_loop.thisRepN'
p5412
I1
sg4096
V48-twix.png
p5413
sg4098
V50-polo.png
p5414
sg70
g71
sS'outcome_loop.thisRepN'
p5415
I0
sS'block_loop.thisIndex'
p5416
g4102
sS'outcome_loop.thisN'
p5417
I82
sS'outcome_loop.thisTrialN'
p5418
I82
sg62
g66
sg33
S'right'
p5419
sS'block_loop.thisN'
p5420
I1
sS'outcome_loop.thisIndex'
p5421
g63
(g96
S'R\x00\x00\x00'
tRp5422
sg30
g5413
sg67
g11
sg68
g69
sg4109
V50-polo.png
p5423
sS'block_loop.thisTrial'
p5424
Nsg60
g61
sS'block_loop.thisTrialN'
p5425
I0
sg34
F0.94576908517774427
sg4113
V48-twix.png
p5426
sa(dp5427
S'block_loop.thisRepN'
p5428
I1
sg4096
V49-yorkie.png
p5429
sg4098
V49-yorkie.png
p5430
sg70
g71
sS'outcome_loop.thisRepN'
p5431
I0
sS'block_loop.thisIndex'
p5432
g4102
sS'outcome_loop.thisN'
p5433
I83
sS'outcome_loop.thisTrialN'
p5434
I83
sg62
g66
sg33
S'left'
p5435
sS'block_loop.thisN'
p5436
I1
sS'outcome_loop.thisIndex'
p5437
g63
(g96
S'S\x00\x00\x00'
tRp5438
sg30
V35-sultanas.png
p5439
sg67
g11
sg68
g69
sg4109
g5439
sS'block_loop.thisTrial'
p5440
Nsg60
g61
sS'block_loop.thisTrialN'
p5441
I0
sg34
F0.51954452311656496
sg4113
V35-sultanas.png
p5442
sa(dp5443
S'block_loop.thisRepN'
p5444
I1
sg4096
V19-caramello.png
p5445
sg4098
V30-spaghetti_hoops.png
p5446
sg70
g71
sS'outcome_loop.thisRepN'
p5447
I0
sS'block_loop.thisIndex'
p5448
g4102
sS'outcome_loop.thisN'
p5449
I84
sS'outcome_loop.thisTrialN'
p5450
I84
sg62
g66
sg33
S'right'
p5451
sS'block_loop.thisN'
p5452
I1
sS'outcome_loop.thisIndex'
p5453
g63
(g96
S'T\x00\x00\x00'
tRp5454
sg30
g5445
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p5455
sS'block_loop.thisTrial'
p5456
Nsg60
g61
sS'block_loop.thisTrialN'
p5457
I0
sg34
F1.1455355359412351
sg4113
V19-caramello.png
p5458
sa(dp5459
S'block_loop.thisRepN'
p5460
I1
sg4096
V7-olives.png
p5461
sg4098
V22-daim.png
p5462
sg70
g71
sS'outcome_loop.thisRepN'
p5463
I0
sS'block_loop.thisIndex'
p5464
g4102
sS'outcome_loop.thisN'
p5465
I85
sS'outcome_loop.thisTrialN'
p5466
I85
sg62
g66
sg33
S'right'
p5467
sS'block_loop.thisN'
p5468
I1
sS'outcome_loop.thisIndex'
p5469
g63
(g96
S'U\x00\x00\x00'
tRp5470
sg30
g5461
sg67
g11
sg68
g69
sg4109
V22-daim.png
p5471
sS'block_loop.thisTrial'
p5472
Nsg60
g61
sS'block_loop.thisTrialN'
p5473
I0
sg34
F0.61277899844753847
sg4113
V7-olives.png
p5474
sa(dp5475
S'block_loop.thisRepN'
p5476
I1
sg4096
V48-twix.png
p5477
sg4098
V50-polo.png
p5478
sg70
g71
sS'outcome_loop.thisRepN'
p5479
I0
sS'block_loop.thisIndex'
p5480
g4102
sS'outcome_loop.thisN'
p5481
I86
sS'outcome_loop.thisTrialN'
p5482
I86
sg62
g66
sg33
S'right'
p5483
sS'block_loop.thisN'
p5484
I1
sS'outcome_loop.thisIndex'
p5485
g63
(g96
S'V\x00\x00\x00'
tRp5486
sg30
g5477
sg67
g11
sg68
g69
sg4109
V50-polo.png
p5487
sS'block_loop.thisTrial'
p5488
Nsg60
g61
sS'block_loop.thisTrialN'
p5489
I0
sg34
F1.0256770064352168
sg4113
V48-twix.png
p5490
sa(dp5491
S'block_loop.thisRepN'
p5492
I1
sg4096
V6-sour_patch_kids.png
p5493
sg4098
V38-maltesers.png
p5494
sg70
g71
sS'outcome_loop.thisRepN'
p5495
I0
sS'block_loop.thisIndex'
p5496
g4102
sS'outcome_loop.thisN'
p5497
I87
sS'outcome_loop.thisTrialN'
p5498
I87
sg62
g66
sg33
S'left'
p5499
sS'block_loop.thisN'
p5500
I1
sS'outcome_loop.thisIndex'
p5501
g63
(g96
S'W\x00\x00\x00'
tRp5502
sg30
g5493
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p5503
sS'block_loop.thisTrial'
p5504
Nsg60
g61
sS'block_loop.thisTrialN'
p5505
I0
sg34
F0.85254494635591982
sg4113
V6-sour_patch_kids.png
p5506
sa(dp5507
S'block_loop.thisRepN'
p5508
I1
sg4096
V4-corn.png
p5509
sg4098
V4-corn.png
p5510
sg70
g71
sS'outcome_loop.thisRepN'
p5511
I0
sS'block_loop.thisIndex'
p5512
g4102
sS'outcome_loop.thisN'
p5513
I88
sS'outcome_loop.thisTrialN'
p5514
I88
sg62
g66
sg33
S'left'
p5515
sS'block_loop.thisN'
p5516
I1
sS'outcome_loop.thisIndex'
p5517
g63
(g96
S'X\x00\x00\x00'
tRp5518
sg30
V10-bounty.png
p5519
sg67
g11
sg68
g69
sg4109
g5519
sS'block_loop.thisTrial'
p5520
Nsg60
g61
sS'block_loop.thisTrialN'
p5521
I0
sg34
F0.70601151822484098
sg4113
V10-bounty.png
p5522
sa(dp5523
S'block_loop.thisRepN'
p5524
I1
sg4096
V33-ambrosia_rice.png
p5525
sg4098
V23-crunchie.png
p5526
sg70
g71
sS'outcome_loop.thisRepN'
p5527
I0
sS'block_loop.thisIndex'
p5528
g4102
sS'outcome_loop.thisN'
p5529
I89
sS'outcome_loop.thisTrialN'
p5530
I89
sg62
g66
sg33
S'right'
p5531
sS'block_loop.thisN'
p5532
I1
sS'outcome_loop.thisIndex'
p5533
g63
(g96
S'Y\x00\x00\x00'
tRp5534
sg30
V23-crunchie.png
p5535
sg67
g11
sg68
g69
sg4109
g5535
sS'block_loop.thisTrial'
p5536
Nsg60
g61
sS'block_loop.thisTrialN'
p5537
I0
sg34
F0.86584887185381376
sg4113
V33-ambrosia_rice.png
p5538
sa(dp5539
S'block_loop.thisRepN'
p5540
I1
sg4096
V19-caramello.png
p5541
sg4098
V19-caramello.png
p5542
sg70
g71
sS'outcome_loop.thisRepN'
p5543
I0
sS'block_loop.thisIndex'
p5544
g4102
sS'outcome_loop.thisN'
p5545
I90
sS'outcome_loop.thisTrialN'
p5546
I90
sg62
g66
sg33
S'left'
p5547
sS'block_loop.thisN'
p5548
I1
sS'outcome_loop.thisIndex'
p5549
g63
(g96
S'Z\x00\x00\x00'
tRp5550
sg30
g5541
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p5551
sS'block_loop.thisTrial'
p5552
Nsg60
g61
sS'block_loop.thisTrialN'
p5553
I0
sg34
F0.91912268179476087
sg4113
V30-spaghetti_hoops.png
p5554
sa(dp5555
S'block_loop.thisRepN'
p5556
I1
sg4096
V51-mars.png
p5557
sg4098
V51-mars.png
p5558
sg70
g71
sS'outcome_loop.thisRepN'
p5559
I0
sS'block_loop.thisIndex'
p5560
g4102
sS'outcome_loop.thisN'
p5561
I91
sS'outcome_loop.thisTrialN'
p5562
I91
sg62
g66
sg33
S'right'
p5563
sS'block_loop.thisN'
p5564
I1
sS'outcome_loop.thisIndex'
p5565
g63
(g96
S'[\x00\x00\x00'
tRp5566
sg30
g5557
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p5567
sS'block_loop.thisTrial'
p5568
Nsg60
g61
sS'block_loop.thisTrialN'
p5569
I0
sg34
F0.83920079227937094
sg4113
V27-hartleys_raspberries_jelly.png
p5570
sa(dp5571
S'block_loop.thisRepN'
p5572
I1
sg4096
V19-caramello.png
p5573
sg4098
V30-spaghetti_hoops.png
p5574
sg70
g71
sS'outcome_loop.thisRepN'
p5575
I0
sS'block_loop.thisIndex'
p5576
g4102
sS'outcome_loop.thisN'
p5577
I92
sS'outcome_loop.thisTrialN'
p5578
I92
sg62
g66
sg33
S'right'
p5579
sS'block_loop.thisN'
p5580
I1
sS'outcome_loop.thisIndex'
p5581
g63
(g96
S'\\\x00\x00\x00'
tRp5582
sg30
g5573
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p5583
sS'block_loop.thisTrial'
p5584
Nsg60
g61
sS'block_loop.thisTrialN'
p5585
I0
sg34
F0.70601654679558123
sg4113
V19-caramello.png
p5586
sa(dp5587
S'block_loop.thisRepN'
p5588
I1
sg4096
V43-mrporky_pork_crackles.png
p5589
sg4098
V18-mms.png
p5590
sg70
g71
sS'outcome_loop.thisRepN'
p5591
I0
sS'block_loop.thisIndex'
p5592
g4102
sS'outcome_loop.thisN'
p5593
I93
sS'outcome_loop.thisTrialN'
p5594
I93
sg62
g66
sg33
S'right'
p5595
sS'block_loop.thisN'
p5596
I1
sS'outcome_loop.thisIndex'
p5597
g63
(g96
S']\x00\x00\x00'
tRp5598
sg30
g5589
sg67
g11
sg68
g69
sg4109
V18-mms.png
p5599
sS'block_loop.thisTrial'
p5600
Nsg60
g61
sS'block_loop.thisTrialN'
p5601
I0
sg34
F0.57283677115265164
sg4113
V43-mrporky_pork_crackles.png
p5602
sa(dp5603
S'block_loop.thisRepN'
p5604
I1
sg4096
V42-mrkipling_lemon_slices.png
p5605
sg4098
V16-skips_prawn.png
p5606
sg70
g71
sS'outcome_loop.thisRepN'
p5607
I0
sS'block_loop.thisIndex'
p5608
g4102
sS'outcome_loop.thisN'
p5609
I94
sS'outcome_loop.thisTrialN'
p5610
I94
sg62
g66
sg33
S'right'
p5611
sS'block_loop.thisN'
p5612
I1
sS'outcome_loop.thisIndex'
p5613
g63
(g96
S'^\x00\x00\x00'
tRp5614
sg30
g5605
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p5615
sS'block_loop.thisTrial'
p5616
Nsg60
g61
sS'block_loop.thisTrialN'
p5617
I0
sg34
F0.89248577682519681
sg4113
V42-mrkipling_lemon_slices.png
p5618
sa(dp5619
S'block_loop.thisRepN'
p5620
I1
sg4096
V43-mrporky_pork_crackles.png
p5621
sg4098
V18-mms.png
p5622
sg70
g71
sS'outcome_loop.thisRepN'
p5623
I0
sS'block_loop.thisIndex'
p5624
g4102
sS'outcome_loop.thisN'
p5625
I95
sS'outcome_loop.thisTrialN'
p5626
I95
sg62
g66
sg33
S'right'
p5627
sS'block_loop.thisN'
p5628
I1
sS'outcome_loop.thisIndex'
p5629
g63
(g96
S'_\x00\x00\x00'
tRp5630
sg30
g5621
sg67
g11
sg68
g69
sg4109
V18-mms.png
p5631
sS'block_loop.thisTrial'
p5632
Nsg60
g61
sS'block_loop.thisTrialN'
p5633
I0
sg34
F0.63837834138212202
sg4113
V43-mrporky_pork_crackles.png
p5634
sa(dp5635
S'block_loop.thisRepN'
p5636
I1
sg4096
V51-mars.png
p5637
sg4098
V51-mars.png
p5638
sg70
g71
sS'outcome_loop.thisRepN'
p5639
I0
sS'block_loop.thisIndex'
p5640
g4102
sS'outcome_loop.thisN'
p5641
I96
sS'outcome_loop.thisTrialN'
p5642
I96
sg62
g66
sg33
S'left'
p5643
sS'block_loop.thisN'
p5644
I1
sS'outcome_loop.thisIndex'
p5645
g63
(g96
S'`\x00\x00\x00'
tRp5646
sg30
g5637
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p5647
sS'block_loop.thisTrial'
p5648
Nsg60
g61
sS'block_loop.thisTrialN'
p5649
I0
sg34
F0.883352772489161
sg4113
V27-hartleys_raspberries_jelly.png
p5650
sa(dp5651
S'block_loop.thisRepN'
p5652
I1
sg4096
V46-pistachios.png
p5653
sg4098
V46-pistachios.png
p5654
sg70
g71
sS'outcome_loop.thisRepN'
p5655
I0
sS'block_loop.thisIndex'
p5656
g4102
sS'outcome_loop.thisN'
p5657
I97
sS'outcome_loop.thisTrialN'
p5658
I97
sg62
g66
sg33
S'left'
p5659
sS'block_loop.thisN'
p5660
I1
sS'outcome_loop.thisIndex'
p5661
g63
(g96
S'a\x00\x00\x00'
tRp5662
sg30
V29-beans.png
p5663
sg67
g11
sg68
g69
sg4109
g5663
sS'block_loop.thisTrial'
p5664
Nsg60
g61
sS'block_loop.thisTrialN'
p5665
I0
sg34
F0.51956156438791368
sg4113
V29-beans.png
p5666
sa(dp5667
S'block_loop.thisRepN'
p5668
I1
sg4096
V31-foxs_golden_biscuits.png
p5669
sg4098
V25-kitkat.png
p5670
sg70
g71
sS'outcome_loop.thisRepN'
p5671
I0
sS'block_loop.thisIndex'
p5672
g4102
sS'outcome_loop.thisN'
p5673
I98
sS'outcome_loop.thisTrialN'
p5674
I98
sg62
g66
sg33
S'right'
p5675
sS'block_loop.thisN'
p5676
I1
sS'outcome_loop.thisIndex'
p5677
g63
(g96
S'b\x00\x00\x00'
tRp5678
sg30
g5669
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p5679
sS'block_loop.thisTrial'
p5680
Nsg60
g61
sS'block_loop.thisTrialN'
p5681
I0
sg34
F0.61278151273472758
sg4113
V31-foxs_golden_biscuits.png
p5682
sa(dp5683
S'block_loop.thisRepN'
p5684
I1
sg4096
V49-yorkie.png
p5685
sg4098
V35-sultanas.png
p5686
sg70
g71
sS'outcome_loop.thisRepN'
p5687
I0
sS'block_loop.thisIndex'
p5688
g4102
sS'outcome_loop.thisN'
p5689
I99
sS'outcome_loop.thisTrialN'
p5690
I99
sg62
g66
sg33
S'right'
p5691
sS'block_loop.thisN'
p5692
I1
sS'outcome_loop.thisIndex'
p5693
g63
(g96
S'c\x00\x00\x00'
tRp5694
sg30
g5685
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p5695
sS'block_loop.thisTrial'
p5696
Nsg60
g61
sS'block_loop.thisTrialN'
p5697
I0
sg34
F0.69270060859707883
sg4113
V49-yorkie.png
p5698
sa(dp5699
S'block_loop.thisRepN'
p5700
I1
sg4096
V17-jacobs_mini_cheddars.png
p5701
sg4098
V8-liquorice_catherine_wheels.png
p5702
sg70
g71
sS'outcome_loop.thisRepN'
p5703
I0
sS'block_loop.thisIndex'
p5704
g4102
sS'outcome_loop.thisN'
p5705
I100
sS'outcome_loop.thisTrialN'
p5706
I100
sg62
g66
sg33
S'right'
p5707
sS'block_loop.thisN'
p5708
I1
sS'outcome_loop.thisIndex'
p5709
g63
(g96
S'd\x00\x00\x00'
tRp5710
sg30
g5701
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p5711
sS'block_loop.thisTrial'
p5712
Nsg60
g61
sS'block_loop.thisTrialN'
p5713
I0
sg34
F0.67936734976137814
sg4113
V17-jacobs_mini_cheddars.png
p5714
sa(dp5715
S'block_loop.thisRepN'
p5716
I1
sg4096
V42-mrkipling_lemon_slices.png
p5717
sg4098
V42-mrkipling_lemon_slices.png
p5718
sg70
g71
sS'outcome_loop.thisRepN'
p5719
I0
sS'block_loop.thisIndex'
p5720
g4102
sS'outcome_loop.thisN'
p5721
I101
sS'outcome_loop.thisTrialN'
p5722
I101
sg62
g66
sg33
S'left'
p5723
sS'block_loop.thisN'
p5724
I1
sS'outcome_loop.thisIndex'
p5725
g63
(g96
S'e\x00\x00\x00'
tRp5726
sg30
V16-skips_prawn.png
p5727
sg67
g11
sg68
g69
sg4109
g5727
sS'block_loop.thisTrial'
p5728
Nsg60
g61
sS'block_loop.thisTrialN'
p5729
I0
sg34
F0.62609884775883984
sg4113
V16-skips_prawn.png
p5730
sa(dp5731
S'block_loop.thisRepN'
p5732
I1
sg4096
V20-fruit_pastilles.png
p5733
sg4098
V2-steamed_puddings.png
p5734
sg70
g71
sS'outcome_loop.thisRepN'
p5735
I0
sS'block_loop.thisIndex'
p5736
g4102
sS'outcome_loop.thisN'
p5737
I102
sS'outcome_loop.thisTrialN'
p5738
I102
sg62
g66
sg33
S'right'
p5739
sS'block_loop.thisN'
p5740
I1
sS'outcome_loop.thisIndex'
p5741
g63
(g96
S'f\x00\x00\x00'
tRp5742
sg30
V2-steamed_puddings.png
p5743
sg67
g11
sg68
g69
sg4109
g5743
sS'block_loop.thisTrial'
p5744
Nsg60
g61
sS'block_loop.thisTrialN'
p5745
I0
sg34
F0.55955770914988534
sg4113
V20-fruit_pastilles.png
p5746
sa(dp5747
S'block_loop.thisRepN'
p5748
I1
sg4096
V6-sour_patch_kids.png
p5749
sg4098
V6-sour_patch_kids.png
p5750
sg70
g71
sS'outcome_loop.thisRepN'
p5751
I0
sS'block_loop.thisIndex'
p5752
g4102
sS'outcome_loop.thisN'
p5753
I103
sS'outcome_loop.thisTrialN'
p5754
I103
sg62
g66
sg33
S'right'
p5755
sS'block_loop.thisN'
p5756
I1
sS'outcome_loop.thisIndex'
p5757
g63
(g96
S'g\x00\x00\x00'
tRp5758
sg30
g5749
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p5759
sS'block_loop.thisTrial'
p5760
Nsg60
g61
sS'block_loop.thisTrialN'
p5761
I0
sg34
F0.59947116183684557
sg4113
V38-maltesers.png
p5762
sa(dp5763
S'block_loop.thisRepN'
p5764
I1
sg4096
V36-fig_rolls.png
p5765
sg4098
V36-fig_rolls.png
p5766
sg70
g71
sS'outcome_loop.thisRepN'
p5767
I0
sS'block_loop.thisIndex'
p5768
g4102
sS'outcome_loop.thisN'
p5769
I104
sS'outcome_loop.thisTrialN'
p5770
I104
sg62
g66
sg33
S'left'
p5771
sS'block_loop.thisN'
p5772
I1
sS'outcome_loop.thisIndex'
p5773
g63
(g96
S'h\x00\x00\x00'
tRp5774
sg30
g5765
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p5775
sS'block_loop.thisTrial'
p5776
Nsg60
g61
sS'block_loop.thisTrialN'
p5777
I0
sg34
F0.61279129051217751
sg4113
V34-hula_hoops_bbq_beef.png
p5778
sa(dp5779
S'block_loop.thisRepN'
p5780
I1
sg4096
V6-sour_patch_kids.png
p5781
sg4098
V38-maltesers.png
p5782
sg70
g71
sS'outcome_loop.thisRepN'
p5783
I0
sS'block_loop.thisIndex'
p5784
g4102
sS'outcome_loop.thisN'
p5785
I105
sS'outcome_loop.thisTrialN'
p5786
I105
sg62
g66
sg33
S'left'
p5787
sS'block_loop.thisN'
p5788
I1
sS'outcome_loop.thisIndex'
p5789
g63
(g96
S'i\x00\x00\x00'
tRp5790
sg30
g5781
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p5791
sS'block_loop.thisTrial'
p5792
Nsg60
g61
sS'block_loop.thisTrialN'
p5793
I0
sg34
F0.73265093747977517
sg4113
V6-sour_patch_kids.png
p5794
sa(dp5795
S'block_loop.thisRepN'
p5796
I1
sg4096
V48-twix.png
p5797
sg4098
V48-twix.png
p5798
sg70
g71
sS'outcome_loop.thisRepN'
p5799
I0
sS'block_loop.thisIndex'
p5800
g4102
sS'outcome_loop.thisN'
p5801
I106
sS'outcome_loop.thisTrialN'
p5802
I106
sg62
g66
sg33
S'left'
p5803
sS'block_loop.thisN'
p5804
I1
sS'outcome_loop.thisIndex'
p5805
g63
(g96
S'j\x00\x00\x00'
tRp5806
sg30
g5797
sg67
g11
sg68
g69
sg4109
V50-polo.png
p5807
sS'block_loop.thisTrial'
p5808
Nsg60
g61
sS'block_loop.thisTrialN'
p5809
I0
sg34
F1.3186737420546706
sg4113
V50-polo.png
p5810
sa(dp5811
S'block_loop.thisRepN'
p5812
I1
sg4096
V20-fruit_pastilles.png
p5813
sg4098
V2-steamed_puddings.png
p5814
sg70
g71
sS'outcome_loop.thisRepN'
p5815
I0
sS'block_loop.thisIndex'
p5816
g4102
sS'outcome_loop.thisN'
p5817
I107
sS'outcome_loop.thisTrialN'
p5818
I107
sg62
g66
sg33
S'right'
p5819
sS'block_loop.thisN'
p5820
I1
sS'outcome_loop.thisIndex'
p5821
g63
(g96
S'k\x00\x00\x00'
tRp5822
sg30
g5813
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p5823
sS'block_loop.thisTrial'
p5824
Nsg60
g61
sS'block_loop.thisTrialN'
p5825
I0
sg34
F1.1055857657902379
sg4113
V20-fruit_pastilles.png
p5826
sa(dp5827
S'block_loop.thisRepN'
p5828
I1
sg4096
V7-olives.png
p5829
sg4098
V7-olives.png
p5830
sg70
g71
sS'outcome_loop.thisRepN'
p5831
I0
sS'block_loop.thisIndex'
p5832
g4102
sS'outcome_loop.thisN'
p5833
I108
sS'outcome_loop.thisTrialN'
p5834
I108
sg62
g66
sg33
S'left'
p5835
sS'block_loop.thisN'
p5836
I1
sS'outcome_loop.thisIndex'
p5837
g63
(g96
S'l\x00\x00\x00'
tRp5838
sg30
V22-daim.png
p5839
sg67
g11
sg68
g69
sg4109
g5839
sS'block_loop.thisTrial'
p5840
Nsg60
g61
sS'block_loop.thisTrialN'
p5841
I0
sg34
F0.74596883123376756
sg4113
V22-daim.png
p5842
sa(dp5843
S'block_loop.thisRepN'
p5844
I1
sg4096
V51-mars.png
p5845
sg4098
V27-hartleys_raspberries_jelly.png
p5846
sg70
g71
sS'outcome_loop.thisRepN'
p5847
I0
sS'block_loop.thisIndex'
p5848
g4102
sS'outcome_loop.thisN'
p5849
I109
sS'outcome_loop.thisTrialN'
p5850
I109
sg62
g66
sg33
S'right'
p5851
sS'block_loop.thisN'
p5852
I1
sS'outcome_loop.thisIndex'
p5853
g63
(g96
S'm\x00\x00\x00'
tRp5854
sg30
g5845
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p5855
sS'block_loop.thisTrial'
p5856
Nsg60
g61
sS'block_loop.thisTrialN'
p5857
I0
sg34
F0.94576210104787606
sg4113
V51-mars.png
p5858
sa(dp5859
S'block_loop.thisRepN'
p5860
I1
sg4096
V46-pistachios.png
p5861
sg4098
V46-pistachios.png
p5862
sg70
g71
sS'outcome_loop.thisRepN'
p5863
I0
sS'block_loop.thisIndex'
p5864
g4102
sS'outcome_loop.thisN'
p5865
I110
sS'outcome_loop.thisTrialN'
p5866
I110
sg62
g66
sg33
S'left'
p5867
sS'block_loop.thisN'
p5868
I1
sS'outcome_loop.thisIndex'
p5869
g63
(g96
S'n\x00\x00\x00'
tRp5870
sg30
V29-beans.png
p5871
sg67
g11
sg68
g69
sg4109
g5871
sS'block_loop.thisTrial'
p5872
Nsg60
g61
sS'block_loop.thisTrialN'
p5873
I0
sg34
F0.55951859803462867
sg4113
V29-beans.png
p5874
sa(dp5875
S'block_loop.thisRepN'
p5876
I1
sg4096
V49-yorkie.png
p5877
sg4098
V49-yorkie.png
p5878
sg70
g71
sS'outcome_loop.thisRepN'
p5879
I0
sS'block_loop.thisIndex'
p5880
g4102
sS'outcome_loop.thisN'
p5881
I111
sS'outcome_loop.thisTrialN'
p5882
I111
sg62
g66
sg33
S'left'
p5883
sS'block_loop.thisN'
p5884
I1
sS'outcome_loop.thisIndex'
p5885
g63
(g96
S'o\x00\x00\x00'
tRp5886
sg30
g5877
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p5887
sS'block_loop.thisTrial'
p5888
Nsg60
g61
sS'block_loop.thisTrialN'
p5889
I0
sg34
F0.66607040838971443
sg4113
V35-sultanas.png
p5890
sa(dp5891
S'block_loop.thisRepN'
p5892
I1
sg4096
V17-jacobs_mini_cheddars.png
p5893
sg4098
V17-jacobs_mini_cheddars.png
p5894
sg70
g71
sS'outcome_loop.thisRepN'
p5895
I0
sS'block_loop.thisIndex'
p5896
g4102
sS'outcome_loop.thisN'
p5897
I112
sS'outcome_loop.thisTrialN'
p5898
I112
sg62
g66
sg33
S'left'
p5899
sS'block_loop.thisN'
p5900
I1
sS'outcome_loop.thisIndex'
p5901
g63
(g96
S'p\x00\x00\x00'
tRp5902
sg30
V8-liquorice_catherine_wheels.png
p5903
sg67
g11
sg68
g69
sg4109
g5903
sS'block_loop.thisTrial'
p5904
Nsg60
g61
sS'block_loop.thisTrialN'
p5905
I0
sg34
F0.53287331211140554
sg4113
V8-liquorice_catherine_wheels.png
p5906
sa(dp5907
S'block_loop.thisRepN'
p5908
I1
sg4096
V33-ambrosia_rice.png
p5909
sg4098
V33-ambrosia_rice.png
p5910
sg70
g71
sS'outcome_loop.thisRepN'
p5911
I0
sS'block_loop.thisIndex'
p5912
g4102
sS'outcome_loop.thisN'
p5913
I113
sS'outcome_loop.thisTrialN'
p5914
I113
sg62
g66
sg33
S'left'
p5915
sS'block_loop.thisN'
p5916
I1
sS'outcome_loop.thisIndex'
p5917
g63
(g96
S'q\x00\x00\x00'
tRp5918
sg30
V23-crunchie.png
p5919
sg67
g11
sg68
g69
sg4109
g5919
sS'block_loop.thisTrial'
p5920
Nsg60
g61
sS'block_loop.thisTrialN'
p5921
I0
sg34
F0.54618841221417824
sg4113
V23-crunchie.png
p5922
sa(dp5923
S'block_loop.thisRepN'
p5924
I1
sg4096
V19-caramello.png
p5925
sg4098
V30-spaghetti_hoops.png
p5926
sg70
g71
sS'outcome_loop.thisRepN'
p5927
I0
sS'block_loop.thisIndex'
p5928
g4102
sS'outcome_loop.thisN'
p5929
I114
sS'outcome_loop.thisTrialN'
p5930
I114
sg62
g66
sg33
S'right'
p5931
sS'block_loop.thisN'
p5932
I1
sS'outcome_loop.thisIndex'
p5933
g63
(g96
S'r\x00\x00\x00'
tRp5934
sg30
g5925
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p5935
sS'block_loop.thisTrial'
p5936
Nsg60
g61
sS'block_loop.thisTrialN'
p5937
I0
sg34
F0.9590523376573401
sg4113
V19-caramello.png
p5938
sa(dp5939
S'block_loop.thisRepN'
p5940
I1
sg4096
V51-mars.png
p5941
sg4098
V51-mars.png
p5942
sg70
g71
sS'outcome_loop.thisRepN'
p5943
I0
sS'block_loop.thisIndex'
p5944
g4102
sS'outcome_loop.thisN'
p5945
I115
sS'outcome_loop.thisTrialN'
p5946
I115
sg62
g66
sg33
S'left'
p5947
sS'block_loop.thisN'
p5948
I1
sS'outcome_loop.thisIndex'
p5949
g63
(g96
S's\x00\x00\x00'
tRp5950
sg30
g5941
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p5951
sS'block_loop.thisTrial'
p5952
Nsg60
g61
sS'block_loop.thisTrialN'
p5953
I0
sg34
F1.0389448938349233
sg4113
V27-hartleys_raspberries_jelly.png
p5954
sa(dp5955
S'block_loop.thisRepN'
p5956
I1
sg4096
V5-pineapple.png
p5957
sg4098
V5-pineapple.png
p5958
sg70
g71
sS'outcome_loop.thisRepN'
p5959
I0
sS'block_loop.thisIndex'
p5960
g4102
sS'outcome_loop.thisN'
p5961
I116
sS'outcome_loop.thisTrialN'
p5962
I116
sg62
g66
sg33
S'left'
p5963
sS'block_loop.thisN'
p5964
I1
sS'outcome_loop.thisIndex'
p5965
g63
(g96
S't\x00\x00\x00'
tRp5966
sg30
g5957
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p5967
sS'block_loop.thisTrial'
p5968
Nsg60
g61
sS'block_loop.thisTrialN'
p5969
I0
sg34
F0.82588485408086854
sg4113
V40-sardines.png
p5970
sa(dp5971
S'block_loop.thisRepN'
p5972
I1
sg4096
V4-corn.png
p5973
sg4098
V10-bounty.png
p5974
sg70
g71
sS'outcome_loop.thisRepN'
p5975
I0
sS'block_loop.thisIndex'
p5976
g4102
sS'outcome_loop.thisN'
p5977
I117
sS'outcome_loop.thisTrialN'
p5978
I117
sg62
g66
sg33
S'right'
p5979
sS'block_loop.thisN'
p5980
I1
sS'outcome_loop.thisIndex'
p5981
g63
(g96
S'u\x00\x00\x00'
tRp5982
sg30
g5973
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p5983
sS'block_loop.thisTrial'
p5984
Nsg60
g61
sS'block_loop.thisTrialN'
p5985
I0
sg34
F0.78592949662561296
sg4113
V4-corn.png
p5986
sa(dp5987
S'block_loop.thisRepN'
p5988
I1
sg4096
V45-chewy_nougat.png
p5989
sg4098
V41-peanuts.png
p5990
sg70
g71
sS'outcome_loop.thisRepN'
p5991
I0
sS'block_loop.thisIndex'
p5992
g4102
sS'outcome_loop.thisN'
p5993
I118
sS'outcome_loop.thisTrialN'
p5994
I118
sg62
g66
sg33
S'right'
p5995
sS'block_loop.thisN'
p5996
I1
sS'outcome_loop.thisIndex'
p5997
g63
(g96
S'v\x00\x00\x00'
tRp5998
sg30
g5989
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p5999
sS'block_loop.thisTrial'
p6000
Nsg60
g61
sS'block_loop.thisTrialN'
p6001
I0
sg34
F0.90580059756211995
sg4113
V45-chewy_nougat.png
p6002
sa(dp6003
S'block_loop.thisRepN'
p6004
I1
sg4096
V33-ambrosia_rice.png
p6005
sg4098
V33-ambrosia_rice.png
p6006
sg70
g71
sS'outcome_loop.thisRepN'
p6007
I0
sS'block_loop.thisIndex'
p6008
g4102
sS'outcome_loop.thisN'
p6009
I119
sS'outcome_loop.thisTrialN'
p6010
I119
sg62
g66
sg33
S'left'
p6011
sS'block_loop.thisN'
p6012
I1
sS'outcome_loop.thisIndex'
p6013
g63
(g96
S'w\x00\x00\x00'
tRp6014
sg30
g6005
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p6015
sS'block_loop.thisTrial'
p6016
Nsg60
g61
sS'block_loop.thisTrialN'
p6017
I0
sg34
F2.1311311912559177
sg4113
V23-crunchie.png
p6018
sa(dp6019
S'block_loop.thisRepN'
p6020
I1
sg4096
V26-walkers_smoky_bacon.png
p6021
sg4098
V44-crunch.png
p6022
sg70
g71
sS'outcome_loop.thisRepN'
p6023
I0
sS'block_loop.thisIndex'
p6024
g4102
sS'outcome_loop.thisN'
p6025
I120
sS'outcome_loop.thisTrialN'
p6026
I120
sg62
g66
sg33
S'right'
p6027
sS'block_loop.thisN'
p6028
I1
sS'outcome_loop.thisIndex'
p6029
g63
(g96
S'x\x00\x00\x00'
tRp6030
sg30
g6021
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p6031
sS'block_loop.thisTrial'
p6032
Nsg60
g61
sS'block_loop.thisTrialN'
p6033
I0
sg34
F0.59947479358379496
sg4113
V26-walkers_smoky_bacon.png
p6034
sa(dp6035
S'block_loop.thisRepN'
p6036
I1
sg4096
V48-twix.png
p6037
sg4098
V50-polo.png
p6038
sg70
g71
sS'outcome_loop.thisRepN'
p6039
I0
sS'block_loop.thisIndex'
p6040
g4102
sS'outcome_loop.thisN'
p6041
I121
sS'outcome_loop.thisTrialN'
p6042
I121
sg62
g66
sg33
S'right'
p6043
sS'block_loop.thisN'
p6044
I1
sS'outcome_loop.thisIndex'
p6045
g63
(g96
S'y\x00\x00\x00'
tRp6046
sg30
g6037
sg67
g11
sg68
g69
sg4109
V50-polo.png
p6047
sS'block_loop.thisTrial'
p6048
Nsg60
g61
sS'block_loop.thisTrialN'
p6049
I0
sg34
F1.4385562969600869
sg4113
V48-twix.png
p6050
sa(dp6051
S'block_loop.thisRepN'
p6052
I1
sg4096
V5-pineapple.png
p6053
sg4098
V40-sardines.png
p6054
sg70
g71
sS'outcome_loop.thisRepN'
p6055
I0
sS'block_loop.thisIndex'
p6056
g4102
sS'outcome_loop.thisN'
p6057
I122
sS'outcome_loop.thisTrialN'
p6058
I122
sg62
g66
sg33
S'left'
p6059
sS'block_loop.thisN'
p6060
I1
sS'outcome_loop.thisIndex'
p6061
g63
(g96
S'z\x00\x00\x00'
tRp6062
sg30
g6053
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p6063
sS'block_loop.thisTrial'
p6064
Nsg60
g61
sS'block_loop.thisTrialN'
p6065
I0
sg34
F0.51955625645132386
sg4113
V5-pineapple.png
p6066
sa(dp6067
S'block_loop.thisRepN'
p6068
I1
sg4096
V33-ambrosia_rice.png
p6069
sg4098
V23-crunchie.png
p6070
sg70
g71
sS'outcome_loop.thisRepN'
p6071
I0
sS'block_loop.thisIndex'
p6072
g4102
sS'outcome_loop.thisN'
p6073
I123
sS'outcome_loop.thisTrialN'
p6074
I123
sg62
g66
sg33
S'right'
p6075
sS'block_loop.thisN'
p6076
I1
sS'outcome_loop.thisIndex'
p6077
g63
(g96
S'{\x00\x00\x00'
tRp6078
sg30
g6069
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p6079
sS'block_loop.thisTrial'
p6080
Nsg60
g61
sS'block_loop.thisTrialN'
p6081
I0
sg34
F0.65283827972598374
sg4113
V33-ambrosia_rice.png
p6082
sa(dp6083
S'block_loop.thisRepN'
p6084
I1
sg4096
V46-pistachios.png
p6085
sg4098
V46-pistachios.png
p6086
sg70
g71
sS'outcome_loop.thisRepN'
p6087
I0
sS'block_loop.thisIndex'
p6088
g4102
sS'outcome_loop.thisN'
p6089
I124
sS'outcome_loop.thisTrialN'
p6090
I124
sg62
g66
sg33
S'left'
p6091
sS'block_loop.thisN'
p6092
I1
sS'outcome_loop.thisIndex'
p6093
g63
(g96
S'|\x00\x00\x00'
tRp6094
sg30
g6085
sg67
g11
sg68
g69
sg4109
V29-beans.png
p6095
sS'block_loop.thisTrial'
p6096
Nsg60
g61
sS'block_loop.thisTrialN'
p6097
I0
sg34
F0.66606090997629508
sg4113
V29-beans.png
p6098
sa(dp6099
S'block_loop.thisRepN'
p6100
I1
sg4096
V51-mars.png
p6101
sg4098
V27-hartleys_raspberries_jelly.png
p6102
sg70
g71
sS'outcome_loop.thisRepN'
p6103
I0
sS'block_loop.thisIndex'
p6104
g4102
sS'outcome_loop.thisN'
p6105
I125
sS'outcome_loop.thisTrialN'
p6106
I125
sg62
g66
sg33
S'right'
p6107
sS'block_loop.thisN'
p6108
I1
sS'outcome_loop.thisIndex'
p6109
g63
(g96
S'}\x00\x00\x00'
tRp6110
sg30
g6101
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p6111
sS'block_loop.thisTrial'
p6112
Nsg60
g61
sS'block_loop.thisTrialN'
p6113
I0
sg34
F0.87915028306633758
sg4113
V51-mars.png
p6114
sa(dp6115
S'block_loop.thisRepN'
p6116
I1
sg4096
V43-mrporky_pork_crackles.png
p6117
sg4098
V18-mms.png
p6118
sg70
g71
sS'outcome_loop.thisRepN'
p6119
I0
sS'block_loop.thisIndex'
p6120
g4102
sS'outcome_loop.thisN'
p6121
I126
sS'outcome_loop.thisTrialN'
p6122
I126
sg62
g66
sg33
S'right'
p6123
sS'block_loop.thisN'
p6124
I1
sS'outcome_loop.thisIndex'
p6125
g63
(g96
S'~\x00\x00\x00'
tRp6126
sg30
g6117
sg67
g11
sg68
g69
sg4109
V18-mms.png
p6127
sS'block_loop.thisTrial'
p6128
Nsg60
g61
sS'block_loop.thisTrialN'
p6129
I0
sg34
F0.63923683038046875
sg4113
V43-mrporky_pork_crackles.png
p6130
sa(dp6131
S'block_loop.thisRepN'
p6132
I1
sg4096
V7-olives.png
p6133
sg4098
V7-olives.png
p6134
sg70
g71
sS'outcome_loop.thisRepN'
p6135
I0
sS'block_loop.thisIndex'
p6136
g4102
sS'outcome_loop.thisN'
p6137
I127
sS'outcome_loop.thisTrialN'
p6138
I127
sg62
g66
sg33
S'left'
p6139
sS'block_loop.thisN'
p6140
I1
sS'outcome_loop.thisIndex'
p6141
g63
(g96
S'\x7f\x00\x00\x00'
tRp6142
sg30
g6133
sg67
g11
sg68
g69
sg4109
V22-daim.png
p6143
sS'block_loop.thisTrial'
p6144
Nsg60
g61
sS'block_loop.thisTrialN'
p6145
I0
sg34
F0.67937684817479749
sg4113
V22-daim.png
p6146
sa(dp6147
S'block_loop.thisRepN'
p6148
I1
sg4096
V4-corn.png
p6149
sg4098
V4-corn.png
p6150
sg70
g71
sS'outcome_loop.thisRepN'
p6151
I0
sS'block_loop.thisIndex'
p6152
g4102
sS'outcome_loop.thisN'
p6153
I128
sS'outcome_loop.thisTrialN'
p6154
I128
sg62
g66
sg33
S'left'
p6155
sS'block_loop.thisN'
p6156
I1
sS'outcome_loop.thisIndex'
p6157
g63
(g96
S'\x80\x00\x00\x00'
tRp6158
sg30
g6149
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p6159
sS'block_loop.thisTrial'
p6160
Nsg60
g61
sS'block_loop.thisTrialN'
p6161
I0
sg34
F1.9313666960460978
sg4113
V10-bounty.png
p6162
sa(dp6163
S'block_loop.thisRepN'
p6164
I1
sg4096
V20-fruit_pastilles.png
p6165
sg4098
V2-steamed_puddings.png
p6166
sg70
g71
sS'outcome_loop.thisRepN'
p6167
I0
sS'block_loop.thisIndex'
p6168
g4102
sS'outcome_loop.thisN'
p6169
I129
sS'outcome_loop.thisTrialN'
p6170
I129
sg62
g66
sg33
S'right'
p6171
sS'block_loop.thisN'
p6172
I1
sS'outcome_loop.thisIndex'
p6173
g63
(g96
S'\x81\x00\x00\x00'
tRp6174
sg30
g6165
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p6175
sS'block_loop.thisTrial'
p6176
Nsg60
g61
sS'block_loop.thisTrialN'
p6177
I0
sg34
F0.63955921772139845
sg4113
V20-fruit_pastilles.png
p6178
sa(dp6179
S'block_loop.thisRepN'
p6180
I1
sg4096
V4-corn.png
p6181
sg4098
V10-bounty.png
p6182
sg70
g71
sS'outcome_loop.thisRepN'
p6183
I0
sS'block_loop.thisIndex'
p6184
g4102
sS'outcome_loop.thisN'
p6185
I130
sS'outcome_loop.thisTrialN'
p6186
I130
sg62
g66
sg33
S'right'
p6187
sS'block_loop.thisN'
p6188
I1
sS'outcome_loop.thisIndex'
p6189
g63
(g96
S'\x82\x00\x00\x00'
tRp6190
sg30
g6181
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p6191
sS'block_loop.thisTrial'
p6192
Nsg60
g61
sS'block_loop.thisTrialN'
p6193
I0
sg34
F0.85252231778031273
sg4113
V4-corn.png
p6194
sa(dp6195
S'block_loop.thisRepN'
p6196
I1
sg4096
V26-walkers_smoky_bacon.png
p6197
sg4098
V44-crunch.png
p6198
sg70
g71
sS'outcome_loop.thisRepN'
p6199
I0
sS'block_loop.thisIndex'
p6200
g4102
sS'outcome_loop.thisN'
p6201
I131
sS'outcome_loop.thisTrialN'
p6202
I131
sg62
g66
sg33
S'right'
p6203
sS'block_loop.thisN'
p6204
I1
sS'outcome_loop.thisIndex'
p6205
g63
(g96
S'\x83\x00\x00\x00'
tRp6206
sg30
g6197
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p6207
sS'block_loop.thisTrial'
p6208
Nsg60
g61
sS'block_loop.thisTrialN'
p6209
I0
sg34
F0.65274580987352238
sg4113
V26-walkers_smoky_bacon.png
p6210
sa(dp6211
S'block_loop.thisRepN'
p6212
I1
sg4096
V7-olives.png
p6213
sg4098
V22-daim.png
p6214
sg70
g71
sS'outcome_loop.thisRepN'
p6215
I0
sS'block_loop.thisIndex'
p6216
g4102
sS'outcome_loop.thisN'
p6217
I132
sS'outcome_loop.thisTrialN'
p6218
I132
sg62
g66
sg33
S'right'
p6219
sS'block_loop.thisN'
p6220
I1
sS'outcome_loop.thisIndex'
p6221
g63
(g96
S'\x84\x00\x00\x00'
tRp6222
sg30
g6213
sg67
g11
sg68
g69
sg4109
V22-daim.png
p6223
sS'block_loop.thisTrial'
p6224
Nsg60
g61
sS'block_loop.thisTrialN'
p6225
I0
sg34
F0.78592362995732401
sg4113
V7-olives.png
p6226
sa(dp6227
S'block_loop.thisRepN'
p6228
I1
sg4096
V6-sour_patch_kids.png
p6229
sg4098
V6-sour_patch_kids.png
p6230
sg70
g71
sS'outcome_loop.thisRepN'
p6231
I0
sS'block_loop.thisIndex'
p6232
g4102
sS'outcome_loop.thisN'
p6233
I133
sS'outcome_loop.thisTrialN'
p6234
I133
sg62
g66
sg33
S'right'
p6235
sS'block_loop.thisN'
p6236
I1
sS'outcome_loop.thisIndex'
p6237
g63
(g96
S'\x85\x00\x00\x00'
tRp6238
sg30
g6229
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p6239
sS'block_loop.thisTrial'
p6240
Nsg60
g61
sS'block_loop.thisTrialN'
p6241
I0
sg34
F0.69269166891353962
sg4113
V38-maltesers.png
p6242
sa(dp6243
S'block_loop.thisRepN'
p6244
I1
sg4096
V36-fig_rolls.png
p6245
sg4098
V36-fig_rolls.png
p6246
sg70
g71
sS'outcome_loop.thisRepN'
p6247
I0
sS'block_loop.thisIndex'
p6248
g4102
sS'outcome_loop.thisN'
p6249
I134
sS'outcome_loop.thisTrialN'
p6250
I134
sg62
g66
sg33
S'left'
p6251
sS'block_loop.thisN'
p6252
I1
sS'outcome_loop.thisIndex'
p6253
g63
(g96
S'\x86\x00\x00\x00'
tRp6254
sg30
g6245
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p6255
sS'block_loop.thisTrial'
p6256
Nsg60
g61
sS'block_loop.thisTrialN'
p6257
I0
sg34
F0.7992613586357038
sg4113
V34-hula_hoops_bbq_beef.png
p6258
sa(dp6259
S'block_loop.thisRepN'
p6260
I1
sg4096
V49-yorkie.png
p6261
sg4098
V35-sultanas.png
p6262
sg70
g71
sS'outcome_loop.thisRepN'
p6263
I0
sS'block_loop.thisIndex'
p6264
g4102
sS'outcome_loop.thisN'
p6265
I135
sS'outcome_loop.thisTrialN'
p6266
I135
sg62
g66
sg33
S'right'
p6267
sS'block_loop.thisN'
p6268
I1
sS'outcome_loop.thisIndex'
p6269
g63
(g96
S'\x87\x00\x00\x00'
tRp6270
sg30
g6261
sg67
g11
sg68
g69
sg4109
V35-sultanas.png
p6271
sS'block_loop.thisTrial'
p6272
Nsg60
g61
sS'block_loop.thisTrialN'
p6273
I0
sg34
F0.67939807992297574
sg4113
V49-yorkie.png
p6274
sa(dp6275
S'block_loop.thisRepN'
p6276
I1
sg4096
V51-mars.png
p6277
sg4098
V27-hartleys_raspberries_jelly.png
p6278
sg70
g71
sS'outcome_loop.thisRepN'
p6279
I0
sS'block_loop.thisIndex'
p6280
g4102
sS'outcome_loop.thisN'
p6281
I136
sS'outcome_loop.thisTrialN'
p6282
I136
sg62
g66
sg33
S'right'
p6283
sS'block_loop.thisN'
p6284
I1
sS'outcome_loop.thisIndex'
p6285
g63
(g96
S'\x88\x00\x00\x00'
tRp6286
sg30
g6277
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p6287
sS'block_loop.thisTrial'
p6288
Nsg60
g61
sS'block_loop.thisTrialN'
p6289
I0
sg34
F0.74595709789900866
sg4113
V51-mars.png
p6290
sa(dp6291
S'block_loop.thisRepN'
p6292
I1
sg4096
V36-fig_rolls.png
p6293
sg4098
V36-fig_rolls.png
p6294
sg70
g71
sS'outcome_loop.thisRepN'
p6295
I0
sS'block_loop.thisIndex'
p6296
g4102
sS'outcome_loop.thisN'
p6297
I137
sS'outcome_loop.thisTrialN'
p6298
I137
sg62
g66
sg33
S'left'
p6299
sS'block_loop.thisN'
p6300
I1
sS'outcome_loop.thisIndex'
p6301
g63
(g96
S'\x89\x00\x00\x00'
tRp6302
sg30
g6293
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p6303
sS'block_loop.thisTrial'
p6304
Nsg60
g61
sS'block_loop.thisTrialN'
p6305
I0
sg34
F0.6927000498653797
sg4113
V34-hula_hoops_bbq_beef.png
p6306
sa(dp6307
S'block_loop.thisRepN'
p6308
I1
sg4096
V17-jacobs_mini_cheddars.png
p6309
sg4098
V8-liquorice_catherine_wheels.png
p6310
sg70
g71
sS'outcome_loop.thisRepN'
p6311
I0
sS'block_loop.thisIndex'
p6312
g4102
sS'outcome_loop.thisN'
p6313
I138
sS'outcome_loop.thisTrialN'
p6314
I138
sg62
g66
sg33
S'right'
p6315
sS'block_loop.thisN'
p6316
I1
sS'outcome_loop.thisIndex'
p6317
g63
(g96
S'\x8a\x00\x00\x00'
tRp6318
sg30
g6309
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p6319
sS'block_loop.thisTrial'
p6320
Nsg60
g61
sS'block_loop.thisTrialN'
p6321
I0
sg34
F0.59946669199598546
sg4113
V17-jacobs_mini_cheddars.png
p6322
sa(dp6323
S'block_loop.thisRepN'
p6324
I1
sg4096
V19-caramello.png
p6325
sg4098
V30-spaghetti_hoops.png
p6326
sg70
g71
sS'outcome_loop.thisRepN'
p6327
I0
sS'block_loop.thisIndex'
p6328
g4102
sS'outcome_loop.thisN'
p6329
I139
sS'outcome_loop.thisTrialN'
p6330
I139
sg62
g66
sg33
S'right'
p6331
sS'block_loop.thisN'
p6332
I1
sS'outcome_loop.thisIndex'
p6333
g63
(g96
S'\x8b\x00\x00\x00'
tRp6334
sg30
g6325
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p6335
sS'block_loop.thisTrial'
p6336
Nsg60
g61
sS'block_loop.thisTrialN'
p6337
I0
sg34
F0.69270479907390836
sg4113
V19-caramello.png
p6338
sa(dp6339
S'block_loop.thisRepN'
p6340
I1
sg4096
V36-fig_rolls.png
p6341
sg4098
V34-hula_hoops_bbq_beef.png
p6342
sg70
g71
sS'outcome_loop.thisRepN'
p6343
I0
sS'block_loop.thisIndex'
p6344
g4102
sS'outcome_loop.thisN'
p6345
I140
sS'outcome_loop.thisTrialN'
p6346
I140
sg62
g66
sg33
S'right'
p6347
sS'block_loop.thisN'
p6348
I1
sS'outcome_loop.thisIndex'
p6349
g63
(g96
S'\x8c\x00\x00\x00'
tRp6350
sg30
g6341
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p6351
sS'block_loop.thisTrial'
p6352
Nsg60
g61
sS'block_loop.thisTrialN'
p6353
I0
sg34
F0.79924152371313539
sg4113
V36-fig_rolls.png
p6354
sa(dp6355
S'block_loop.thisRepN'
p6356
I1
sg4096
V5-pineapple.png
p6357
sg4098
V5-pineapple.png
p6358
sg70
g71
sS'outcome_loop.thisRepN'
p6359
I0
sS'block_loop.thisIndex'
p6360
g4102
sS'outcome_loop.thisN'
p6361
I141
sS'outcome_loop.thisTrialN'
p6362
I141
sg62
g66
sg33
S'left'
p6363
sS'block_loop.thisN'
p6364
I1
sS'outcome_loop.thisIndex'
p6365
g63
(g96
S'\x8d\x00\x00\x00'
tRp6366
sg30
V40-sardines.png
p6367
sg67
g11
sg68
g69
sg4109
g6367
sS'block_loop.thisTrial'
p6368
Nsg60
g61
sS'block_loop.thisTrialN'
p6369
I0
sg34
F2.4639131509738945
sg4113
V40-sardines.png
p6370
sa(dp6371
S'block_loop.thisRepN'
p6372
I1
sg4096
V20-fruit_pastilles.png
p6373
sg4098
V20-fruit_pastilles.png
p6374
sg70
g71
sS'outcome_loop.thisRepN'
p6375
I0
sS'block_loop.thisIndex'
p6376
g4102
sS'outcome_loop.thisN'
p6377
I142
sS'outcome_loop.thisTrialN'
p6378
I142
sg62
g66
sg33
S'left'
p6379
sS'block_loop.thisN'
p6380
I1
sS'outcome_loop.thisIndex'
p6381
g63
(g96
S'\x8e\x00\x00\x00'
tRp6382
sg30
g6373
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p6383
sS'block_loop.thisTrial'
p6384
Nsg60
g61
sS'block_loop.thisTrialN'
p6385
I0
sg34
F0.99912782211140438
sg4113
V2-steamed_puddings.png
p6386
sa(dp6387
S'block_loop.thisRepN'
p6388
I1
sg4096
V1-smarties_cookies.png
p6389
sg4098
V1-smarties_cookies.png
p6390
sg70
g71
sS'outcome_loop.thisRepN'
p6391
I0
sS'block_loop.thisIndex'
p6392
g4102
sS'outcome_loop.thisN'
p6393
I143
sS'outcome_loop.thisTrialN'
p6394
I143
sg62
g66
sg33
S'left'
p6395
sS'block_loop.thisN'
p6396
I1
sS'outcome_loop.thisIndex'
p6397
g63
(g96
S'\x8f\x00\x00\x00'
tRp6398
sg30
g6389
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p6399
sS'block_loop.thisTrial'
p6400
Nsg60
g61
sS'block_loop.thisTrialN'
p6401
I0
sg34
F0.58615410617858288
sg4113
V21-nakd_banana_crunch.png
p6402
sa(dp6403
S'block_loop.thisRepN'
p6404
I1
sg4096
V33-ambrosia_rice.png
p6405
sg4098
V33-ambrosia_rice.png
p6406
sg70
g71
sS'outcome_loop.thisRepN'
p6407
I0
sS'block_loop.thisIndex'
p6408
g4102
sS'outcome_loop.thisN'
p6409
I144
sS'outcome_loop.thisTrialN'
p6410
I144
sg62
g66
sg33
S'left'
p6411
sS'block_loop.thisN'
p6412
I1
sS'outcome_loop.thisIndex'
p6413
g63
(g96
S'\x90\x00\x00\x00'
tRp6414
sg30
V23-crunchie.png
p6415
sg67
g11
sg68
g69
sg4109
g6415
sS'block_loop.thisTrial'
p6416
Nsg60
g61
sS'block_loop.thisTrialN'
p6417
I0
sg34
F0.62610722871067992
sg4113
V23-crunchie.png
p6418
sa(dp6419
S'block_loop.thisRepN'
p6420
I1
sg4096
V13-mccoys_steak_crisps.png
p6421
sg4098
V3-dole_fruit_snack.png
p6422
sg70
g71
sS'outcome_loop.thisRepN'
p6423
I0
sS'block_loop.thisIndex'
p6424
g4102
sS'outcome_loop.thisN'
p6425
I145
sS'outcome_loop.thisTrialN'
p6426
I145
sg62
g66
sg33
S'right'
p6427
sS'block_loop.thisN'
p6428
I1
sS'outcome_loop.thisIndex'
p6429
g63
(g96
S'\x91\x00\x00\x00'
tRp6430
sg30
V3-dole_fruit_snack.png
p6431
sg67
g11
sg68
g69
sg4109
g6431
sS'block_loop.thisTrial'
p6432
Nsg60
g61
sS'block_loop.thisTrialN'
p6433
I0
sg34
F1.4918418402339739
sg4113
V13-mccoys_steak_crisps.png
p6434
sa(dp6435
S'block_loop.thisRepN'
p6436
I1
sg4096
V5-pineapple.png
p6437
sg4098
V5-pineapple.png
p6438
sg70
g71
sS'outcome_loop.thisRepN'
p6439
I0
sS'block_loop.thisIndex'
p6440
g4102
sS'outcome_loop.thisN'
p6441
I146
sS'outcome_loop.thisTrialN'
p6442
I146
sg62
g66
sg33
S'left'
p6443
sS'block_loop.thisN'
p6444
I1
sS'outcome_loop.thisIndex'
p6445
g63
(g96
S'\x92\x00\x00\x00'
tRp6446
sg30
g6437
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p6447
sS'block_loop.thisTrial'
p6448
Nsg60
g61
sS'block_loop.thisTrialN'
p6449
I0
sg34
F1.8780797559466009
sg4113
V40-sardines.png
p6450
sa(dp6451
S'block_loop.thisRepN'
p6452
I1
sg4096
V7-olives.png
p6453
sg4098
V7-olives.png
p6454
sg70
g71
sS'outcome_loop.thisRepN'
p6455
I0
sS'block_loop.thisIndex'
p6456
g4102
sS'outcome_loop.thisN'
p6457
I147
sS'outcome_loop.thisTrialN'
p6458
I147
sg62
g66
sg33
S'left'
p6459
sS'block_loop.thisN'
p6460
I1
sS'outcome_loop.thisIndex'
p6461
g63
(g96
S'\x93\x00\x00\x00'
tRp6462
sg30
g6453
sg67
g11
sg68
g69
sg4109
V22-daim.png
p6463
sS'block_loop.thisTrial'
p6464
Nsg60
g61
sS'block_loop.thisTrialN'
p6465
I0
sg34
F0.94575763120701595
sg4113
V22-daim.png
p6466
sa(dp6467
S'block_loop.thisRepN'
p6468
I1
sg4096
V31-foxs_golden_biscuits.png
p6469
sg4098
V25-kitkat.png
p6470
sg70
g71
sS'outcome_loop.thisRepN'
p6471
I0
sS'block_loop.thisIndex'
p6472
g4102
sS'outcome_loop.thisN'
p6473
I148
sS'outcome_loop.thisTrialN'
p6474
I148
sg62
g66
sg33
S'right'
p6475
sS'block_loop.thisN'
p6476
I1
sS'outcome_loop.thisIndex'
p6477
g63
(g96
S'\x94\x00\x00\x00'
tRp6478
sg30
g6469
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p6479
sS'block_loop.thisTrial'
p6480
Nsg60
g61
sS'block_loop.thisTrialN'
p6481
I0
sg34
F0.73249365491938079
sg4113
V31-foxs_golden_biscuits.png
p6482
sa(dp6483
S'block_loop.thisRepN'
p6484
I1
sg4096
V42-mrkipling_lemon_slices.png
p6485
sg4098
V42-mrkipling_lemon_slices.png
p6486
sg70
g71
sS'outcome_loop.thisRepN'
p6487
I0
sS'block_loop.thisIndex'
p6488
g4102
sS'outcome_loop.thisN'
p6489
I149
sS'outcome_loop.thisTrialN'
p6490
I149
sg62
g66
sg33
S'left'
p6491
sS'block_loop.thisN'
p6492
I1
sS'outcome_loop.thisIndex'
p6493
g63
(g96
S'\x95\x00\x00\x00'
tRp6494
sg30
g6485
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p6495
sS'block_loop.thisTrial'
p6496
Nsg60
g61
sS'block_loop.thisTrialN'
p6497
I0
sg34
F1.5051636450989463
sg4113
V16-skips_prawn.png
p6498
sa(dp6499
S'block_loop.thisRepN'
p6500
I1
sg4096
V51-mars.png
p6501
sg4098
V27-hartleys_raspberries_jelly.png
p6502
sg70
g71
sS'outcome_loop.thisRepN'
p6503
I0
sS'block_loop.thisIndex'
p6504
g4102
sS'outcome_loop.thisN'
p6505
I150
sS'outcome_loop.thisTrialN'
p6506
I150
sg62
g66
sg33
S'right'
p6507
sS'block_loop.thisN'
p6508
I1
sS'outcome_loop.thisIndex'
p6509
g63
(g96
S'\x96\x00\x00\x00'
tRp6510
sg30
g6501
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p6511
sS'block_loop.thisTrial'
p6512
Nsg60
g61
sS'block_loop.thisTrialN'
p6513
I0
sg34
F0.6527365908241336
sg4113
V51-mars.png
p6514
sa(dp6515
S'block_loop.thisRepN'
p6516
I1
sg4096
V31-foxs_golden_biscuits.png
p6517
sg4098
V31-foxs_golden_biscuits.png
p6518
sg70
g71
sS'outcome_loop.thisRepN'
p6519
I0
sS'block_loop.thisIndex'
p6520
g4102
sS'outcome_loop.thisN'
p6521
I151
sS'outcome_loop.thisTrialN'
p6522
I151
sg62
g66
sg33
S'left'
p6523
sS'block_loop.thisN'
p6524
I1
sS'outcome_loop.thisIndex'
p6525
g63
(g96
S'\x97\x00\x00\x00'
tRp6526
sg30
g6517
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p6527
sS'block_loop.thisTrial'
p6528
Nsg60
g61
sS'block_loop.thisTrialN'
p6529
I0
sg34
F0.5994672507258656
sg4113
V25-kitkat.png
p6530
sa(dp6531
S'block_loop.thisRepN'
p6532
I1
sg4096
V1-smarties_cookies.png
p6533
sg4098
V21-nakd_banana_crunch.png
p6534
sg70
g71
sS'outcome_loop.thisRepN'
p6535
I0
sS'block_loop.thisIndex'
p6536
g4102
sS'outcome_loop.thisN'
p6537
I152
sS'outcome_loop.thisTrialN'
p6538
I152
sg62
g66
sg33
S'right'
p6539
sS'block_loop.thisN'
p6540
I1
sS'outcome_loop.thisIndex'
p6541
g63
(g96
S'\x98\x00\x00\x00'
tRp6542
sg30
g6533
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p6543
sS'block_loop.thisTrial'
p6544
Nsg60
g61
sS'block_loop.thisTrialN'
p6545
I0
sg34
F0.77261355842711055
sg4113
V1-smarties_cookies.png
p6546
sa(dp6547
S'block_loop.thisRepN'
p6548
I1
sg4096
V45-chewy_nougat.png
p6549
sg4098
V45-chewy_nougat.png
p6550
sg70
g71
sS'outcome_loop.thisRepN'
p6551
I0
sS'block_loop.thisIndex'
p6552
g4102
sS'outcome_loop.thisN'
p6553
I153
sS'outcome_loop.thisTrialN'
p6554
I153
sg62
g66
sg33
S'left'
p6555
sS'block_loop.thisN'
p6556
I1
sS'outcome_loop.thisIndex'
p6557
g63
(g96
S'\x99\x00\x00\x00'
tRp6558
sg30
V41-peanuts.png
p6559
sg67
g11
sg68
g69
sg4109
g6559
sS'block_loop.thisTrial'
p6560
Nsg60
g61
sS'block_loop.thisTrialN'
p6561
I0
sg34
F0.61283291591644229
sg4113
V41-peanuts.png
p6562
sa(dp6563
S'block_loop.thisRepN'
p6564
I1
sg4096
V20-fruit_pastilles.png
p6565
sg4098
V2-steamed_puddings.png
p6566
sg70
g71
sS'outcome_loop.thisRepN'
p6567
I0
sS'block_loop.thisIndex'
p6568
g4102
sS'outcome_loop.thisN'
p6569
I154
sS'outcome_loop.thisTrialN'
p6570
I154
sg62
g66
sg33
S'right'
p6571
sS'block_loop.thisN'
p6572
I1
sS'outcome_loop.thisIndex'
p6573
g63
(g96
S'\x9a\x00\x00\x00'
tRp6574
sg30
g6565
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p6575
sS'block_loop.thisTrial'
p6576
Nsg60
g61
sS'block_loop.thisTrialN'
p6577
I0
sg34
F0.67938439103272685
sg4113
V20-fruit_pastilles.png
p6578
sa(dp6579
S'block_loop.thisRepN'
p6580
I1
sg4096
V7-olives.png
p6581
sg4098
V22-daim.png
p6582
sg70
g71
sS'outcome_loop.thisRepN'
p6583
I0
sS'block_loop.thisIndex'
p6584
g4102
sS'outcome_loop.thisN'
p6585
I155
sS'outcome_loop.thisTrialN'
p6586
I155
sg62
g66
sg33
S'right'
p6587
sS'block_loop.thisN'
p6588
I1
sS'outcome_loop.thisIndex'
p6589
g63
(g96
S'\x9b\x00\x00\x00'
tRp6590
sg30
g6581
sg67
g11
sg68
g69
sg4109
V22-daim.png
p6591
sS'block_loop.thisTrial'
p6592
Nsg60
g61
sS'block_loop.thisTrialN'
p6593
I0
sg34
F0.69268608161110024
sg4113
V7-olives.png
p6594
sa(dp6595
S'block_loop.thisRepN'
p6596
I1
sg4096
V31-foxs_golden_biscuits.png
p6597
sg4098
V31-foxs_golden_biscuits.png
p6598
sg70
g71
sS'outcome_loop.thisRepN'
p6599
I0
sS'block_loop.thisIndex'
p6600
g4102
sS'outcome_loop.thisN'
p6601
I156
sS'outcome_loop.thisTrialN'
p6602
I156
sg62
g66
sg33
S'left'
p6603
sS'block_loop.thisN'
p6604
I1
sS'outcome_loop.thisIndex'
p6605
g63
(g96
S'\x9c\x00\x00\x00'
tRp6606
sg30
V25-kitkat.png
p6607
sg67
g11
sg68
g69
sg4109
g6607
sS'block_loop.thisTrial'
p6608
Nsg60
g61
sS'block_loop.thisTrialN'
p6609
I0
sg34
F0.85233877490099985
sg4113
V25-kitkat.png
p6610
sa(dp6611
S'block_loop.thisRepN'
p6612
I1
sg4096
V42-mrkipling_lemon_slices.png
p6613
sg4098
V42-mrkipling_lemon_slices.png
p6614
sg70
g71
sS'outcome_loop.thisRepN'
p6615
I0
sS'block_loop.thisIndex'
p6616
g4102
sS'outcome_loop.thisN'
p6617
I157
sS'outcome_loop.thisTrialN'
p6618
I157
sg62
g66
sg33
S'left'
p6619
sS'block_loop.thisN'
p6620
I1
sS'outcome_loop.thisIndex'
p6621
g63
(g96
S'\x9d\x00\x00\x00'
tRp6622
sg30
g6613
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p6623
sS'block_loop.thisTrial'
p6624
Nsg60
g61
sS'block_loop.thisTrialN'
p6625
I0
sg34
F0.62609326045640046
sg4113
V16-skips_prawn.png
p6626
sa(dp6627
S'block_loop.thisRepN'
p6628
I1
sg4096
V6-sour_patch_kids.png
p6629
sg4098
V38-maltesers.png
p6630
sg70
g71
sS'outcome_loop.thisRepN'
p6631
I0
sS'block_loop.thisIndex'
p6632
g4102
sS'outcome_loop.thisN'
p6633
I158
sS'outcome_loop.thisTrialN'
p6634
I158
sg62
g66
sg33
S'left'
p6635
sS'block_loop.thisN'
p6636
I1
sS'outcome_loop.thisIndex'
p6637
g63
(g96
S'\x9e\x00\x00\x00'
tRp6638
sg30
V38-maltesers.png
p6639
sg67
g11
sg68
g69
sg4109
g6639
sS'block_loop.thisTrial'
p6640
Nsg60
g61
sS'block_loop.thisTrialN'
p6641
I0
sg34
F0.77260908858443145
sg4113
V6-sour_patch_kids.png
p6642
sa(dp6643
S'block_loop.thisRepN'
p6644
I1
sg4096
V4-corn.png
p6645
sg4098
V4-corn.png
p6646
sg70
g71
sS'outcome_loop.thisRepN'
p6647
I0
sS'block_loop.thisIndex'
p6648
g4102
sS'outcome_loop.thisN'
p6649
I159
sS'outcome_loop.thisTrialN'
p6650
I159
sg62
g66
sg33
S'left'
p6651
sS'block_loop.thisN'
p6652
I1
sS'outcome_loop.thisIndex'
p6653
g63
(g96
S'\x9f\x00\x00\x00'
tRp6654
sg30
g6645
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p6655
sS'block_loop.thisTrial'
p6656
Nsg60
g61
sS'block_loop.thisTrialN'
p6657
I0
sg34
F1.0523130733090511
sg4113
V10-bounty.png
p6658
sa(dp6659
S'block_loop.thisRepN'
p6660
I1
sg4096
V45-chewy_nougat.png
p6661
sg4098
V45-chewy_nougat.png
p6662
sg70
g71
sS'outcome_loop.thisRepN'
p6663
I0
sS'block_loop.thisIndex'
p6664
g4102
sS'outcome_loop.thisN'
p6665
I160
sS'outcome_loop.thisTrialN'
p6666
I160
sg62
g66
sg33
S'left'
p6667
sS'block_loop.thisN'
p6668
I1
sS'outcome_loop.thisIndex'
p6669
g63
(g96
S'\xa0\x00\x00\x00'
tRp6670
sg30
V41-peanuts.png
p6671
sg67
g11
sg68
g69
sg4109
g6671
sS'block_loop.thisTrial'
p6672
Nsg60
g61
sS'block_loop.thisTrialN'
p6673
I0
sg34
F0.8258652985223307
sg4113
V41-peanuts.png
p6674
sa(dp6675
S'block_loop.thisRepN'
p6676
I1
sg4096
V20-fruit_pastilles.png
p6677
sg4098
V20-fruit_pastilles.png
p6678
sg70
g71
sS'outcome_loop.thisRepN'
p6679
I0
sS'block_loop.thisIndex'
p6680
g4102
sS'outcome_loop.thisN'
p6681
I161
sS'outcome_loop.thisTrialN'
p6682
I161
sg62
g66
sg33
S'left'
p6683
sS'block_loop.thisN'
p6684
I1
sS'outcome_loop.thisIndex'
p6685
g63
(g96
S'\xa1\x00\x00\x00'
tRp6686
sg30
g6677
sg67
g11
sg68
g69
sg4109
V2-steamed_puddings.png
p6687
sS'block_loop.thisTrial'
p6688
Nsg60
g61
sS'block_loop.thisTrialN'
p6689
I0
sg34
F0.66605141156105674
sg4113
V2-steamed_puddings.png
p6690
sa(dp6691
S'block_loop.thisRepN'
p6692
I1
sg4096
V45-chewy_nougat.png
p6693
sg4098
V41-peanuts.png
p6694
sg70
g71
sS'outcome_loop.thisRepN'
p6695
I0
sS'block_loop.thisIndex'
p6696
g4102
sS'outcome_loop.thisN'
p6697
I162
sS'outcome_loop.thisTrialN'
p6698
I162
sg62
g66
sg33
S'right'
p6699
sS'block_loop.thisN'
p6700
I1
sS'outcome_loop.thisIndex'
p6701
g63
(g96
S'\xa2\x00\x00\x00'
tRp6702
sg30
g6693
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p6703
sS'block_loop.thisTrial'
p6704
Nsg60
g61
sS'block_loop.thisTrialN'
p6705
I0
sg34
F0.89245225301056053
sg4113
V45-chewy_nougat.png
p6706
sa(dp6707
S'block_loop.thisRepN'
p6708
I1
sg4096
V5-pineapple.png
p6709
sg4098
V40-sardines.png
p6710
sg70
g71
sS'outcome_loop.thisRepN'
p6711
I0
sS'block_loop.thisIndex'
p6712
g4102
sS'outcome_loop.thisN'
p6713
I163
sS'outcome_loop.thisTrialN'
p6714
I163
sg62
g66
sg33
S'right'
p6715
sS'block_loop.thisN'
p6716
I1
sS'outcome_loop.thisIndex'
p6717
g63
(g96
S'\xa3\x00\x00\x00'
tRp6718
sg30
g6709
sg67
g11
sg68
g69
sg4109
V40-sardines.png
p6719
sS'block_loop.thisTrial'
p6720
Nsg60
g61
sS'block_loop.thisTrialN'
p6721
I0
sg34
F0.91911485956916295
sg4113
V5-pineapple.png
p6722
sa(dp6723
S'block_loop.thisRepN'
p6724
I1
sg4096
V13-mccoys_steak_crisps.png
p6725
sg4098
V13-mccoys_steak_crisps.png
p6726
sg70
g71
sS'outcome_loop.thisRepN'
p6727
I0
sS'block_loop.thisIndex'
p6728
g4102
sS'outcome_loop.thisN'
p6729
I164
sS'outcome_loop.thisTrialN'
p6730
I164
sg62
g66
sg33
S'left'
p6731
sS'block_loop.thisN'
p6732
I1
sS'outcome_loop.thisIndex'
p6733
g63
(g96
S'\xa4\x00\x00\x00'
tRp6734
sg30
g6725
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p6735
sS'block_loop.thisTrial'
p6736
Nsg60
g61
sS'block_loop.thisTrialN'
p6737
I0
sg34
F0.58615606173407286
sg4113
V3-dole_fruit_snack.png
p6738
sa(dp6739
S'block_loop.thisRepN'
p6740
I1
sg4096
V36-fig_rolls.png
p6741
sg4098
V36-fig_rolls.png
p6742
sg70
g71
sS'outcome_loop.thisRepN'
p6743
I0
sS'block_loop.thisIndex'
p6744
g4102
sS'outcome_loop.thisN'
p6745
I165
sS'outcome_loop.thisTrialN'
p6746
I165
sg62
g66
sg33
S'left'
p6747
sS'block_loop.thisN'
p6748
I1
sS'outcome_loop.thisIndex'
p6749
g63
(g96
S'\xa5\x00\x00\x00'
tRp6750
sg30
g6741
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p6751
sS'block_loop.thisTrial'
p6752
Nsg60
g61
sS'block_loop.thisTrialN'
p6753
I0
sg34
F0.61277983654326817
sg4113
V34-hula_hoops_bbq_beef.png
p6754
sa(dp6755
S'block_loop.thisRepN'
p6756
I1
sg4096
V19-caramello.png
p6757
sg4098
V19-caramello.png
p6758
sg70
g71
sS'outcome_loop.thisRepN'
p6759
I0
sS'block_loop.thisIndex'
p6760
g4102
sS'outcome_loop.thisN'
p6761
I166
sS'outcome_loop.thisTrialN'
p6762
I166
sg62
g66
sg33
S'left'
p6763
sS'block_loop.thisN'
p6764
I1
sS'outcome_loop.thisIndex'
p6765
g63
(g96
S'\xa6\x00\x00\x00'
tRp6766
sg30
g6757
sg67
g11
sg68
g69
sg4109
V30-spaghetti_hoops.png
p6767
sS'block_loop.thisTrial'
p6768
Nsg60
g61
sS'block_loop.thisTrialN'
p6769
I0
sg34
F0.86586004645869252
sg4113
V30-spaghetti_hoops.png
p6770
sa(dp6771
S'block_loop.thisRepN'
p6772
I1
sg4096
V13-mccoys_steak_crisps.png
p6773
sg4098
V13-mccoys_steak_crisps.png
p6774
sg70
g71
sS'outcome_loop.thisRepN'
p6775
I0
sS'block_loop.thisIndex'
p6776
g4102
sS'outcome_loop.thisN'
p6777
I167
sS'outcome_loop.thisTrialN'
p6778
I167
sg62
g66
sg33
S'left'
p6779
sS'block_loop.thisN'
p6780
I1
sS'outcome_loop.thisIndex'
p6781
g63
(g96
S'\xa7\x00\x00\x00'
tRp6782
sg30
g6773
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p6783
sS'block_loop.thisTrial'
p6784
Nsg60
g61
sS'block_loop.thisTrialN'
p6785
I0
sg34
F0.4529452765636961
sg4113
V3-dole_fruit_snack.png
p6786
sa(dp6787
S'block_loop.thisRepN'
p6788
I1
sg4096
V43-mrporky_pork_crackles.png
p6789
sg4098
V43-mrporky_pork_crackles.png
p6790
sg70
g71
sS'outcome_loop.thisRepN'
p6791
I0
sS'block_loop.thisIndex'
p6792
g4102
sS'outcome_loop.thisN'
p6793
I168
sS'outcome_loop.thisTrialN'
p6794
I168
sg62
g66
sg33
S'left'
p6795
sS'block_loop.thisN'
p6796
I1
sS'outcome_loop.thisIndex'
p6797
g63
(g96
S'\xa8\x00\x00\x00'
tRp6798
sg30
g6789
sg67
g11
sg68
g69
sg4109
V18-mms.png
p6799
sS'block_loop.thisTrial'
p6800
Nsg60
g61
sS'block_loop.thisTrialN'
p6801
I0
sg34
F0.59945859040817595
sg4113
V18-mms.png
p6802
sa(dp6803
S'block_loop.thisRepN'
p6804
I1
sg4096
V13-mccoys_steak_crisps.png
p6805
sg4098
V3-dole_fruit_snack.png
p6806
sg70
g71
sS'outcome_loop.thisRepN'
p6807
I0
sS'block_loop.thisIndex'
p6808
g4102
sS'outcome_loop.thisN'
p6809
I169
sS'outcome_loop.thisTrialN'
p6810
I169
sg62
g66
sg33
S'right'
p6811
sS'block_loop.thisN'
p6812
I1
sS'outcome_loop.thisIndex'
p6813
g63
(g96
S'\xa9\x00\x00\x00'
tRp6814
sg30
g6805
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p6815
sS'block_loop.thisTrial'
p6816
Nsg60
g61
sS'block_loop.thisTrialN'
p6817
I0
sg34
F0.53283783274127927
sg4113
V13-mccoys_steak_crisps.png
p6818
sa(dp6819
S'block_loop.thisRepN'
p6820
I1
sg4096
V17-jacobs_mini_cheddars.png
p6821
sg4098
V8-liquorice_catherine_wheels.png
p6822
sg70
g71
sS'outcome_loop.thisRepN'
p6823
I0
sS'block_loop.thisIndex'
p6824
g4102
sS'outcome_loop.thisN'
p6825
I170
sS'outcome_loop.thisTrialN'
p6826
I170
sg62
g66
sg33
S'right'
p6827
sS'block_loop.thisN'
p6828
I1
sS'outcome_loop.thisIndex'
p6829
g63
(g96
S'\xaa\x00\x00\x00'
tRp6830
sg30
g6821
sg67
g11
sg68
g69
sg4109
V8-liquorice_catherine_wheels.png
p6831
sS'block_loop.thisTrial'
p6832
Nsg60
g61
sS'block_loop.thisTrialN'
p6833
I0
sg34
F0.63940891929087229
sg4113
V17-jacobs_mini_cheddars.png
p6834
sa(dp6835
S'block_loop.thisRepN'
p6836
I1
sg4096
V42-mrkipling_lemon_slices.png
p6837
sg4098
V42-mrkipling_lemon_slices.png
p6838
sg70
g71
sS'outcome_loop.thisRepN'
p6839
I0
sS'block_loop.thisIndex'
p6840
g4102
sS'outcome_loop.thisN'
p6841
I171
sS'outcome_loop.thisTrialN'
p6842
I171
sg62
g66
sg33
S'left'
p6843
sS'block_loop.thisN'
p6844
I1
sS'outcome_loop.thisIndex'
p6845
g63
(g96
S'\xab\x00\x00\x00'
tRp6846
sg30
g6837
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p6847
sS'block_loop.thisTrial'
p6848
Nsg60
g61
sS'block_loop.thisTrialN'
p6849
I0
sg34
F0.73265289303526515
sg4113
V16-skips_prawn.png
p6850
sa(dp6851
S'block_loop.thisRepN'
p6852
I1
sg4096
V36-fig_rolls.png
p6853
sg4098
V34-hula_hoops_bbq_beef.png
p6854
sg70
g71
sS'outcome_loop.thisRepN'
p6855
I0
sS'block_loop.thisIndex'
p6856
g4102
sS'outcome_loop.thisN'
p6857
I172
sS'outcome_loop.thisTrialN'
p6858
I172
sg62
g66
sg33
S'right'
p6859
sS'block_loop.thisN'
p6860
I1
sS'outcome_loop.thisIndex'
p6861
g63
(g96
S'\xac\x00\x00\x00'
tRp6862
sg30
g6853
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p6863
sS'block_loop.thisTrial'
p6864
Nsg60
g61
sS'block_loop.thisTrialN'
p6865
I0
sg34
F0.8924841006337374
sg4113
V36-fig_rolls.png
p6866
sa(dp6867
S'block_loop.thisRepN'
p6868
I1
sg4096
V13-mccoys_steak_crisps.png
p6869
sg4098
V13-mccoys_steak_crisps.png
p6870
sg70
g71
sS'outcome_loop.thisRepN'
p6871
I0
sS'block_loop.thisIndex'
p6872
g4102
sS'outcome_loop.thisN'
p6873
I173
sS'outcome_loop.thisTrialN'
p6874
I173
sg62
g66
sg33
S'left'
p6875
sS'block_loop.thisN'
p6876
I1
sS'outcome_loop.thisIndex'
p6877
g63
(g96
S'\xad\x00\x00\x00'
tRp6878
sg30
g6869
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p6879
sS'block_loop.thisTrial'
p6880
Nsg60
g61
sS'block_loop.thisTrialN'
p6881
I0
sg34
F0.50623556904611178
sg4113
V3-dole_fruit_snack.png
p6882
sa(dp6883
S'block_loop.thisRepN'
p6884
I1
sg4096
V45-chewy_nougat.png
p6885
sg4098
V41-peanuts.png
p6886
sg70
g71
sS'outcome_loop.thisRepN'
p6887
I0
sS'block_loop.thisIndex'
p6888
g4102
sS'outcome_loop.thisN'
p6889
I174
sS'outcome_loop.thisTrialN'
p6890
I174
sg62
g66
sg33
S'right'
p6891
sS'block_loop.thisN'
p6892
I1
sS'outcome_loop.thisIndex'
p6893
g63
(g96
S'\xae\x00\x00\x00'
tRp6894
sg30
g6885
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p6895
sS'block_loop.thisTrial'
p6896
Nsg60
g61
sS'block_loop.thisTrialN'
p6897
I0
sg34
F0.61265859208469919
sg4113
V45-chewy_nougat.png
p6898
sa(dp6899
S'block_loop.thisRepN'
p6900
I1
sg4096
V33-ambrosia_rice.png
p6901
sg4098
V33-ambrosia_rice.png
p6902
sg70
g71
sS'outcome_loop.thisRepN'
p6903
I0
sS'block_loop.thisIndex'
p6904
g4102
sS'outcome_loop.thisN'
p6905
I175
sS'outcome_loop.thisTrialN'
p6906
I175
sg62
g66
sg33
S'left'
p6907
sS'block_loop.thisN'
p6908
I1
sS'outcome_loop.thisIndex'
p6909
g63
(g96
S'\xaf\x00\x00\x00'
tRp6910
sg30
g6901
sg67
g11
sg68
g69
sg4109
V23-crunchie.png
p6911
sS'block_loop.thisTrial'
p6912
Nsg60
g61
sS'block_loop.thisTrialN'
p6913
I0
sg34
F0.71933220563005307
sg4113
V23-crunchie.png
p6914
sa(dp6915
S'block_loop.thisRepN'
p6916
I1
sg4096
V48-twix.png
p6917
sg4098
V50-polo.png
p6918
sg70
g71
sS'outcome_loop.thisRepN'
p6919
I0
sS'block_loop.thisIndex'
p6920
g4102
sS'outcome_loop.thisN'
p6921
I176
sS'outcome_loop.thisTrialN'
p6922
I176
sg62
g66
sg33
S'right'
p6923
sS'block_loop.thisN'
p6924
I1
sS'outcome_loop.thisIndex'
p6925
g63
(g96
S'\xb0\x00\x00\x00'
tRp6926
sg30
g6917
sg67
g11
sg68
g69
sg4109
V50-polo.png
p6927
sS'block_loop.thisTrial'
p6928
Nsg60
g61
sS'block_loop.thisTrialN'
p6929
I0
sg34
F1.5184628213919495
sg4113
V48-twix.png
p6930
sa(dp6931
S'block_loop.thisRepN'
p6932
I1
sg4096
V43-mrporky_pork_crackles.png
p6933
sg4098
V18-mms.png
p6934
sg70
g71
sS'outcome_loop.thisRepN'
p6935
I0
sS'block_loop.thisIndex'
p6936
g4102
sS'outcome_loop.thisN'
p6937
I177
sS'outcome_loop.thisTrialN'
p6938
I177
sg62
g66
sg33
S'right'
p6939
sS'block_loop.thisN'
p6940
I1
sS'outcome_loop.thisIndex'
p6941
g63
(g96
S'\xb1\x00\x00\x00'
tRp6942
sg30
V18-mms.png
p6943
sg67
g11
sg68
g69
sg4109
g6943
sS'block_loop.thisTrial'
p6944
Nsg60
g61
sS'block_loop.thisTrialN'
p6945
I0
sg34
F0.61278095400484744
sg4113
V43-mrporky_pork_crackles.png
p6946
sa(dp6947
S'block_loop.thisRepN'
p6948
I1
sg4096
V4-corn.png
p6949
sg4098
V10-bounty.png
p6950
sg70
g71
sS'outcome_loop.thisRepN'
p6951
I0
sS'block_loop.thisIndex'
p6952
g4102
sS'outcome_loop.thisN'
p6953
I178
sS'outcome_loop.thisTrialN'
p6954
I178
sg62
g66
sg33
S'right'
p6955
sS'block_loop.thisN'
p6956
I1
sS'outcome_loop.thisIndex'
p6957
g63
(g96
S'\xb2\x00\x00\x00'
tRp6958
sg30
g6949
sg67
g11
sg68
g69
sg4109
V10-bounty.png
p6959
sS'block_loop.thisTrial'
p6960
Nsg60
g61
sS'block_loop.thisTrialN'
p6961
I0
sg34
F0.79922839355276665
sg4113
V4-corn.png
p6962
sa(dp6963
S'block_loop.thisRepN'
p6964
I1
sg4096
V7-olives.png
p6965
sg4098
V7-olives.png
p6966
sg70
g71
sS'outcome_loop.thisRepN'
p6967
I0
sS'block_loop.thisIndex'
p6968
g4102
sS'outcome_loop.thisN'
p6969
I179
sS'outcome_loop.thisTrialN'
p6970
I179
sg62
g66
sg33
S'left'
p6971
sS'block_loop.thisN'
p6972
I1
sS'outcome_loop.thisIndex'
p6973
g63
(g96
S'\xb3\x00\x00\x00'
tRp6974
sg30
g6965
sg67
g11
sg68
g69
sg4109
V22-daim.png
p6975
sS'block_loop.thisTrial'
p6976
Nsg60
g61
sS'block_loop.thisTrialN'
p6977
I0
sg34
F0.9723909044314496
sg4113
V22-daim.png
p6978
sa(dp6979
S'block_loop.thisRepN'
p6980
I1
sg4096
V51-mars.png
p6981
sg4098
V51-mars.png
p6982
sg70
g71
sS'outcome_loop.thisRepN'
p6983
I0
sS'block_loop.thisIndex'
p6984
g4102
sS'outcome_loop.thisN'
p6985
I180
sS'outcome_loop.thisTrialN'
p6986
I180
sg62
g66
sg33
S'left'
p6987
sS'block_loop.thisN'
p6988
I1
sS'outcome_loop.thisIndex'
p6989
g63
(g96
S'\xb4\x00\x00\x00'
tRp6990
sg30
g6981
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p6991
sS'block_loop.thisTrial'
p6992
Nsg60
g61
sS'block_loop.thisTrialN'
p6993
I0
sg34
F0.98571103310678154
sg4113
V27-hartleys_raspberries_jelly.png
p6994
sa(dp6995
S'block_loop.thisRepN'
p6996
I1
sg4096
V26-walkers_smoky_bacon.png
p6997
sg4098
V26-walkers_smoky_bacon.png
p6998
sg70
g71
sS'outcome_loop.thisRepN'
p6999
I0
sS'block_loop.thisIndex'
p7000
g4102
sS'outcome_loop.thisN'
p7001
I181
sS'outcome_loop.thisTrialN'
p7002
I181
sg62
g66
sg33
S'left'
p7003
sS'block_loop.thisN'
p7004
I1
sS'outcome_loop.thisIndex'
p7005
g63
(g96
S'\xb5\x00\x00\x00'
tRp7006
sg30
g6997
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p7007
sS'block_loop.thisTrial'
p7008
Nsg60
g61
sS'block_loop.thisTrialN'
p7009
I0
sg34
F0.69270368161414808
sg4113
V44-crunch.png
p7010
sa(dp7011
S'block_loop.thisRepN'
p7012
I1
sg4096
V45-chewy_nougat.png
p7013
sg4098
V45-chewy_nougat.png
p7014
sg70
g71
sS'outcome_loop.thisRepN'
p7015
I0
sS'block_loop.thisIndex'
p7016
g4102
sS'outcome_loop.thisN'
p7017
I182
sS'outcome_loop.thisTrialN'
p7018
I182
sg62
g66
sg33
S'left'
p7019
sS'block_loop.thisN'
p7020
I1
sS'outcome_loop.thisIndex'
p7021
g63
(g96
S'\xb6\x00\x00\x00'
tRp7022
sg30
V41-peanuts.png
p7023
sg67
g11
sg68
g69
sg4109
g7023
sS'block_loop.thisTrial'
p7024
Nsg60
g61
sS'block_loop.thisTrialN'
p7025
I0
sg34
F0.63941506532319181
sg4113
V41-peanuts.png
p7026
sa(dp7027
S'block_loop.thisRepN'
p7028
I1
sg4096
V7-olives.png
p7029
sg4098
V22-daim.png
p7030
sg70
g71
sS'outcome_loop.thisRepN'
p7031
I0
sS'block_loop.thisIndex'
p7032
g4102
sS'outcome_loop.thisN'
p7033
I183
sS'outcome_loop.thisTrialN'
p7034
I183
sg62
g66
sg33
S'right'
p7035
sS'block_loop.thisN'
p7036
I1
sS'outcome_loop.thisIndex'
p7037
g63
(g96
S'\xb7\x00\x00\x00'
tRp7038
sg30
g7029
sg67
g11
sg68
g69
sg4109
V22-daim.png
p7039
sS'block_loop.thisTrial'
p7040
Nsg60
g61
sS'block_loop.thisTrialN'
p7041
I0
sg34
F0.58595855059866153
sg4113
V7-olives.png
p7042
sa(dp7043
S'block_loop.thisRepN'
p7044
I1
sg4096
V45-chewy_nougat.png
p7045
sg4098
V45-chewy_nougat.png
p7046
sg70
g71
sS'outcome_loop.thisRepN'
p7047
I0
sS'block_loop.thisIndex'
p7048
g4102
sS'outcome_loop.thisN'
p7049
I184
sS'outcome_loop.thisTrialN'
p7050
I184
sg62
g66
sg33
S'left'
p7051
sS'block_loop.thisN'
p7052
I1
sS'outcome_loop.thisIndex'
p7053
g63
(g96
S'\xb8\x00\x00\x00'
tRp7054
sg30
g7045
sg67
g11
sg68
g69
sg4109
V41-peanuts.png
p7055
sS'block_loop.thisTrial'
p7056
Nsg60
g61
sS'block_loop.thisTrialN'
p7057
I0
sg34
F0.51954312629095512
sg4113
V41-peanuts.png
p7058
sa(dp7059
S'block_loop.thisRepN'
p7060
I1
sg4096
V51-mars.png
p7061
sg4098
V27-hartleys_raspberries_jelly.png
p7062
sg70
g71
sS'outcome_loop.thisRepN'
p7063
I0
sS'block_loop.thisIndex'
p7064
g4102
sS'outcome_loop.thisN'
p7065
I185
sS'outcome_loop.thisTrialN'
p7066
I185
sg62
g66
sg33
S'right'
p7067
sS'block_loop.thisN'
p7068
I1
sS'outcome_loop.thisIndex'
p7069
g63
(g96
S'\xb9\x00\x00\x00'
tRp7070
sg30
g7061
sg67
g11
sg68
g69
sg4109
V27-hartleys_raspberries_jelly.png
p7071
sS'block_loop.thisTrial'
p7072
Nsg60
g61
sS'block_loop.thisTrialN'
p7073
I0
sg34
F0.61286532226768031
sg4113
V51-mars.png
p7074
sa(dp7075
S'block_loop.thisRepN'
p7076
I1
sg4096
V36-fig_rolls.png
p7077
sg4098
V34-hula_hoops_bbq_beef.png
p7078
sg70
g71
sS'outcome_loop.thisRepN'
p7079
I0
sS'block_loop.thisIndex'
p7080
g4102
sS'outcome_loop.thisN'
p7081
I186
sS'outcome_loop.thisTrialN'
p7082
I186
sg62
g66
sg33
S'right'
p7083
sS'block_loop.thisN'
p7084
I1
sS'outcome_loop.thisIndex'
p7085
g63
(g96
S'\xba\x00\x00\x00'
tRp7086
sg30
g7077
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p7087
sS'block_loop.thisTrial'
p7088
Nsg60
g61
sS'block_loop.thisTrialN'
p7089
I0
sg34
F0.74597805028315634
sg4113
V36-fig_rolls.png
p7090
sa(dp7091
S'block_loop.thisRepN'
p7092
I1
sg4096
V48-twix.png
p7093
sg4098
V48-twix.png
p7094
sg70
g71
sS'outcome_loop.thisRepN'
p7095
I0
sS'block_loop.thisIndex'
p7096
g4102
sS'outcome_loop.thisN'
p7097
I187
sS'outcome_loop.thisTrialN'
p7098
I187
sg62
g66
sg33
S'left'
p7099
sS'block_loop.thisN'
p7100
I1
sS'outcome_loop.thisIndex'
p7101
g63
(g96
S'\xbb\x00\x00\x00'
tRp7102
sg30
g7093
sg67
g11
sg68
g69
sg4109
V50-polo.png
p7103
sS'block_loop.thisTrial'
p7104
Nsg60
g61
sS'block_loop.thisTrialN'
p7105
I0
sg34
F0.69269893240561942
sg4113
V50-polo.png
p7106
sa(dp7107
S'block_loop.thisRepN'
p7108
I1
sg4096
V46-pistachios.png
p7109
sg4098
V29-beans.png
p7110
sg70
g71
sS'outcome_loop.thisRepN'
p7111
I0
sS'block_loop.thisIndex'
p7112
g4102
sS'outcome_loop.thisN'
p7113
I188
sS'outcome_loop.thisTrialN'
p7114
I188
sg62
g66
sg33
S'right'
p7115
sS'block_loop.thisN'
p7116
I1
sS'outcome_loop.thisIndex'
p7117
g63
(g96
S'\xbc\x00\x00\x00'
tRp7118
sg30
V29-beans.png
p7119
sg67
g11
sg68
g69
sg4109
g7119
sS'block_loop.thisTrial'
p7120
Nsg60
g61
sS'block_loop.thisTrialN'
p7121
I0
sg34
F0.62609298109055089
sg4113
V46-pistachios.png
p7122
sa(dp7123
S'block_loop.thisRepN'
p7124
I1
sg4096
V1-smarties_cookies.png
p7125
sg4098
V1-smarties_cookies.png
p7126
sg70
g71
sS'outcome_loop.thisRepN'
p7127
I0
sS'block_loop.thisIndex'
p7128
g4102
sS'outcome_loop.thisN'
p7129
I189
sS'outcome_loop.thisTrialN'
p7130
I189
sg62
g66
sg33
S'left'
p7131
sS'block_loop.thisN'
p7132
I1
sS'outcome_loop.thisIndex'
p7133
g63
(g96
S'\xbd\x00\x00\x00'
tRp7134
sg30
g7125
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p7135
sS'block_loop.thisTrial'
p7136
Nsg60
g61
sS'block_loop.thisTrialN'
p7137
I0
sg34
F0.61278430638594727
sg4113
V21-nakd_banana_crunch.png
p7138
sa(dp7139
S'block_loop.thisRepN'
p7140
I1
sg4096
V26-walkers_smoky_bacon.png
p7141
sg4098
V44-crunch.png
p7142
sg70
g71
sS'outcome_loop.thisRepN'
p7143
I0
sS'block_loop.thisIndex'
p7144
g4102
sS'outcome_loop.thisN'
p7145
I190
sS'outcome_loop.thisTrialN'
p7146
I190
sg62
g66
sg33
S'right'
p7147
sS'block_loop.thisN'
p7148
I1
sS'outcome_loop.thisIndex'
p7149
g63
(g96
S'\xbe\x00\x00\x00'
tRp7150
sg30
g7141
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p7151
sS'block_loop.thisTrial'
p7152
Nsg60
g61
sS'block_loop.thisTrialN'
p7153
I0
sg34
F0.51955402152998431
sg4113
V26-walkers_smoky_bacon.png
p7154
sa(dp7155
S'block_loop.thisRepN'
p7156
I1
sg4096
V42-mrkipling_lemon_slices.png
p7157
sg4098
V16-skips_prawn.png
p7158
sg70
g71
sS'outcome_loop.thisRepN'
p7159
I0
sS'block_loop.thisIndex'
p7160
g4102
sS'outcome_loop.thisN'
p7161
I191
sS'outcome_loop.thisTrialN'
p7162
I191
sg62
g66
sg33
S'right'
p7163
sS'block_loop.thisN'
p7164
I1
sS'outcome_loop.thisIndex'
p7165
g63
(g96
S'\xbf\x00\x00\x00'
tRp7166
sg30
g7157
sg67
g11
sg68
g69
sg4109
V16-skips_prawn.png
p7167
sS'block_loop.thisTrial'
p7168
Nsg60
g61
sS'block_loop.thisTrialN'
p7169
I0
sg34
F1.1189075706552103
sg4113
V42-mrkipling_lemon_slices.png
p7170
sa(dp7171
S'block_loop.thisRepN'
p7172
I1
sg4096
V1-smarties_cookies.png
p7173
sg4098
V21-nakd_banana_crunch.png
p7174
sg70
g71
sS'outcome_loop.thisRepN'
p7175
I0
sS'block_loop.thisIndex'
p7176
g4102
sS'outcome_loop.thisN'
p7177
I192
sS'outcome_loop.thisTrialN'
p7178
I192
sg62
g66
sg33
S'right'
p7179
sS'block_loop.thisN'
p7180
I1
sS'outcome_loop.thisIndex'
p7181
g63
(g96
S'\xc0\x00\x00\x00'
tRp7182
sg30
g7173
sg67
g11
sg68
g69
sg4109
V21-nakd_banana_crunch.png
p7183
sS'block_loop.thisTrial'
p7184
Nsg60
g61
sS'block_loop.thisTrialN'
p7185
I0
sg34
F0.78593424583232263
sg4113
V1-smarties_cookies.png
p7186
sa(dp7187
S'block_loop.thisRepN'
p7188
I1
sg4096
V6-sour_patch_kids.png
p7189
sg4098
V6-sour_patch_kids.png
p7190
sg70
g71
sS'outcome_loop.thisRepN'
p7191
I0
sS'block_loop.thisIndex'
p7192
g4102
sS'outcome_loop.thisN'
p7193
I193
sS'outcome_loop.thisTrialN'
p7194
I193
sg62
g66
sg33
S'right'
p7195
sS'block_loop.thisN'
p7196
I1
sS'outcome_loop.thisIndex'
p7197
g63
(g96
S'\xc1\x00\x00\x00'
tRp7198
sg30
g7189
sg67
g11
sg68
g69
sg4109
V38-maltesers.png
p7199
sS'block_loop.thisTrial'
p7200
Nsg60
g61
sS'block_loop.thisTrialN'
p7201
I0
sg34
F0.59946501580452605
sg4113
V38-maltesers.png
p7202
sa(dp7203
S'block_loop.thisRepN'
p7204
I1
sg4096
V31-foxs_golden_biscuits.png
p7205
sg4098
V31-foxs_golden_biscuits.png
p7206
sg70
g71
sS'outcome_loop.thisRepN'
p7207
I0
sS'block_loop.thisIndex'
p7208
g4102
sS'outcome_loop.thisN'
p7209
I194
sS'outcome_loop.thisTrialN'
p7210
I194
sg62
g66
sg33
S'left'
p7211
sS'block_loop.thisN'
p7212
I1
sS'outcome_loop.thisIndex'
p7213
g63
(g96
S'\xc2\x00\x00\x00'
tRp7214
sg30
g7205
sg67
g11
sg68
g69
sg4109
V25-kitkat.png
p7215
sS'block_loop.thisTrial'
p7216
Nsg60
g61
sS'block_loop.thisTrialN'
p7217
I0
sg34
F1.1988146538169531
sg4113
V25-kitkat.png
p7218
sa(dp7219
S'block_loop.thisRepN'
p7220
I1
sg4096
V13-mccoys_steak_crisps.png
p7221
sg4098
V13-mccoys_steak_crisps.png
p7222
sg70
g71
sS'outcome_loop.thisRepN'
p7223
I0
sS'block_loop.thisIndex'
p7224
g4102
sS'outcome_loop.thisN'
p7225
I195
sS'outcome_loop.thisTrialN'
p7226
I195
sg62
g66
sg33
S'left'
p7227
sS'block_loop.thisN'
p7228
I1
sS'outcome_loop.thisIndex'
p7229
g63
(g96
S'\xc3\x00\x00\x00'
tRp7230
sg30
g7221
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p7231
sS'block_loop.thisTrial'
p7232
Nsg60
g61
sS'block_loop.thisTrialN'
p7233
I0
sg34
F0.53287694385835493
sg4113
V3-dole_fruit_snack.png
p7234
sa(dp7235
S'block_loop.thisRepN'
p7236
I1
sg4096
V48-twix.png
p7237
sg4098
V48-twix.png
p7238
sg70
g71
sS'outcome_loop.thisRepN'
p7239
I0
sS'block_loop.thisIndex'
p7240
g4102
sS'outcome_loop.thisN'
p7241
I196
sS'outcome_loop.thisTrialN'
p7242
I196
sg62
g66
sg33
S'left'
p7243
sS'block_loop.thisN'
p7244
I1
sS'outcome_loop.thisIndex'
p7245
g63
(g96
S'\xc4\x00\x00\x00'
tRp7246
sg30
g7237
sg67
g11
sg68
g69
sg4109
V50-polo.png
p7247
sS'block_loop.thisTrial'
p7248
Nsg60
g61
sS'block_loop.thisTrialN'
p7249
I0
sg34
F2.1311306325242185
sg4113
V50-polo.png
p7250
sa(dp7251
S'block_loop.thisRepN'
p7252
I1
sg4096
V26-walkers_smoky_bacon.png
p7253
sg4098
V26-walkers_smoky_bacon.png
p7254
sg70
g71
sS'outcome_loop.thisRepN'
p7255
I0
sS'block_loop.thisIndex'
p7256
g4102
sS'outcome_loop.thisN'
p7257
I197
sS'outcome_loop.thisTrialN'
p7258
I197
sg62
g66
sg33
S'left'
p7259
sS'block_loop.thisN'
p7260
I1
sS'outcome_loop.thisIndex'
p7261
g63
(g96
S'\xc5\x00\x00\x00'
tRp7262
sg30
g7253
sg67
g11
sg68
g69
sg4109
V44-crunch.png
p7263
sS'block_loop.thisTrial'
p7264
Nsg60
g61
sS'block_loop.thisTrialN'
p7265
I0
sg34
F0.57282196480264247
sg4113
V44-crunch.png
p7266
sa(dp7267
S'block_loop.thisRepN'
p7268
I1
sg4096
V36-fig_rolls.png
p7269
sg4098
V34-hula_hoops_bbq_beef.png
p7270
sg70
g71
sS'outcome_loop.thisRepN'
p7271
I0
sS'block_loop.thisIndex'
p7272
g4102
sS'outcome_loop.thisN'
p7273
I198
sS'outcome_loop.thisTrialN'
p7274
I198
sg62
g66
sg33
S'right'
p7275
sS'block_loop.thisN'
p7276
I1
sS'outcome_loop.thisIndex'
p7277
g63
(g96
S'\xc6\x00\x00\x00'
tRp7278
sg30
g7269
sg67
g11
sg68
g69
sg4109
V34-hula_hoops_bbq_beef.png
p7279
sS'block_loop.thisTrial'
p7280
Nsg60
g61
sS'block_loop.thisTrialN'
p7281
I0
sg34
F0.70601570869985153
sg4113
V36-fig_rolls.png
p7282
sa(dp7283
S'block_loop.thisRepN'
p7284
I1
sg4096
V13-mccoys_steak_crisps.png
p7285
sg4098
V3-dole_fruit_snack.png
p7286
sg70
g71
sS'outcome_loop.thisRepN'
p7287
I0
sS'block_loop.thisIndex'
p7288
g4102
sS'outcome_loop.thisN'
p7289
I199
sS'outcome_loop.thisTrialN'
p7290
I199
sg62
g66
sg33
S'right'
p7291
sS'block_loop.thisN'
p7292
I1
sS'outcome_loop.thisIndex'
p7293
g63
(g96
S'\xc7\x00\x00\x00'
tRp7294
sg30
g7285
sg67
g11
sg68
g69
sg4109
V3-dole_fruit_snack.png
p7295
sS'block_loop.thisTrial'
p7296
Nsg60
g61
sS'block_loop.thisTrialN'
p7297
I0
sg34
F0.57282811083496199
sg4113
V13-mccoys_steak_crisps.png
p7298
sa(dp7299
S'block_loop.thisRepN'
p7300
I1
sg67
g11
sg36
F0.50651856590593525
sg70
g71
sS'block_loop.thisIndex'
p7301
g4102
sg62
g66
sS'block_loop.thisN'
p7302
I1
sg35
S'space'
p7303
sg68
g69
sS'block_loop.thisTrial'
p7304
Nsg60
g61
sS'block_loop.thisTrialN'
p7305
I0
sa(dp7306
S'block_loop.thisRepN'
p7307
I2
sS'img_correct'
p7308
V5-pineapple.png
p7309
sS'img_left'
p7310
V5-pineapple.png
p7311
sg70
g71
sS'outcome_loop.thisRepN'
p7312
I0
sS'block_loop.thisIndex'
p7313
g63
(g96
S'\x00\x00\x00\x00'
tRp7314
sS'outcome_loop.thisN'
p7315
I0
sS'outcome_loop.thisTrialN'
p7316
I0
sg62
g66
sg33
S'left'
p7317
sS'block_loop.thisN'
p7318
I2
sS'outcome_loop.thisIndex'
p7319
g63
(g96
S'\x00\x00\x00\x00'
tRp7320
sg30
g7309
sg67
g11
sg68
g69
sS'img_wrong'
p7321
V40-sardines.png
p7322
sS'block_loop.thisTrial'
p7323
Nsg60
g61
sS'block_loop.thisTrialN'
p7324
I0
sg34
F0.81256891588236613
sS'img_right'
p7325
V40-sardines.png
p7326
sa(dp7327
S'block_loop.thisRepN'
p7328
I2
sg7308
V42-mrkipling_lemon_slices.png
p7329
sg7310
V16-skips_prawn.png
p7330
sg70
g71
sS'outcome_loop.thisRepN'
p7331
I0
sS'block_loop.thisIndex'
p7332
g7314
sS'outcome_loop.thisN'
p7333
I1
sS'outcome_loop.thisTrialN'
p7334
I1
sg62
g66
sg33
S'right'
p7335
sS'block_loop.thisN'
p7336
I2
sS'outcome_loop.thisIndex'
p7337
g63
(g96
S'\x01\x00\x00\x00'
tRp7338
sg30
V16-skips_prawn.png
p7339
sg67
g11
sg68
g69
sg7321
g7339
sS'block_loop.thisTrial'
p7340
Nsg60
g61
sS'block_loop.thisTrialN'
p7341
I0
sg34
F0.78599933790428622
sg7325
V42-mrkipling_lemon_slices.png
p7342
sa(dp7343
S'block_loop.thisRepN'
p7344
I2
sg7308
V33-ambrosia_rice.png
p7345
sg7310
V23-crunchie.png
p7346
sg70
g71
sS'outcome_loop.thisRepN'
p7347
I0
sS'block_loop.thisIndex'
p7348
g7314
sS'outcome_loop.thisN'
p7349
I2
sS'outcome_loop.thisTrialN'
p7350
I2
sg62
g66
sg33
S'right'
p7351
sS'block_loop.thisN'
p7352
I2
sS'outcome_loop.thisIndex'
p7353
g63
(g96
S'\x02\x00\x00\x00'
tRp7354
sg30
V23-crunchie.png
p7355
sg67
g11
sg68
g69
sg7321
g7355
sS'block_loop.thisTrial'
p7356
Nsg60
g61
sS'block_loop.thisTrialN'
p7357
I0
sg34
F0.71931711991419434
sg7325
V33-ambrosia_rice.png
p7358
sa(dp7359
S'block_loop.thisRepN'
p7360
I2
sg7308
V13-mccoys_steak_crisps.png
p7361
sg7310
V3-dole_fruit_snack.png
p7362
sg70
g71
sS'outcome_loop.thisRepN'
p7363
I0
sS'block_loop.thisIndex'
p7364
g7314
sS'outcome_loop.thisN'
p7365
I3
sS'outcome_loop.thisTrialN'
p7366
I3
sg62
g66
sg33
S'right'
p7367
sS'block_loop.thisN'
p7368
I2
sS'outcome_loop.thisIndex'
p7369
g63
(g96
S'\x03\x00\x00\x00'
tRp7370
sg30
g7361
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p7371
sS'block_loop.thisTrial'
p7372
Nsg60
g61
sS'block_loop.thisTrialN'
p7373
I0
sg34
F0.58612924268345523
sg7325
V13-mccoys_steak_crisps.png
p7374
sa(dp7375
S'block_loop.thisRepN'
p7376
I2
sg7308
V17-jacobs_mini_cheddars.png
p7377
sg7310
V8-liquorice_catherine_wheels.png
p7378
sg70
g71
sS'outcome_loop.thisRepN'
p7379
I0
sS'block_loop.thisIndex'
p7380
g7314
sS'outcome_loop.thisN'
p7381
I4
sS'outcome_loop.thisTrialN'
p7382
I4
sg62
g66
sg33
S'right'
p7383
sS'block_loop.thisN'
p7384
I2
sS'outcome_loop.thisIndex'
p7385
g63
(g96
S'\x04\x00\x00\x00'
tRp7386
sg30
g7377
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p7387
sS'block_loop.thisTrial'
p7388
Nsg60
g61
sS'block_loop.thisTrialN'
p7389
I0
sg34
F0.98570349024703319
sg7325
V17-jacobs_mini_cheddars.png
p7390
sa(dp7391
S'block_loop.thisRepN'
p7392
I2
sg7308
V43-mrporky_pork_crackles.png
p7393
sg7310
V18-mms.png
p7394
sg70
g71
sS'outcome_loop.thisRepN'
p7395
I0
sS'block_loop.thisIndex'
p7396
g7314
sS'outcome_loop.thisN'
p7397
I5
sS'outcome_loop.thisTrialN'
p7398
I5
sg62
g66
sg33
S'right'
p7399
sS'block_loop.thisN'
p7400
I2
sS'outcome_loop.thisIndex'
p7401
g63
(g96
S'\x05\x00\x00\x00'
tRp7402
sg30
V18-mms.png
p7403
sg67
g11
sg68
g69
sg7321
g7403
sS'block_loop.thisTrial'
p7404
Nsg60
g61
sS'block_loop.thisTrialN'
p7405
I0
sg34
F0.58614432839931396
sg7325
V43-mrporky_pork_crackles.png
p7406
sa(dp7407
S'block_loop.thisRepN'
p7408
I2
sg7308
V4-corn.png
p7409
sg7310
V4-corn.png
p7410
sg70
g71
sS'outcome_loop.thisRepN'
p7411
I0
sS'block_loop.thisIndex'
p7412
g7314
sS'outcome_loop.thisN'
p7413
I6
sS'outcome_loop.thisTrialN'
p7414
I6
sg62
g66
sg33
S'left'
p7415
sS'block_loop.thisN'
p7416
I2
sS'outcome_loop.thisIndex'
p7417
g63
(g96
S'\x06\x00\x00\x00'
tRp7418
sg30
g7409
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p7419
sS'block_loop.thisTrial'
p7420
Nsg60
g61
sS'block_loop.thisTrialN'
p7421
I0
sg34
F0.93244281047009281
sg7325
V10-bounty.png
p7422
sa(dp7423
S'block_loop.thisRepN'
p7424
I2
sg7308
V33-ambrosia_rice.png
p7425
sg7310
V33-ambrosia_rice.png
p7426
sg70
g71
sS'outcome_loop.thisRepN'
p7427
I0
sS'block_loop.thisIndex'
p7428
g7314
sS'outcome_loop.thisN'
p7429
I7
sS'outcome_loop.thisTrialN'
p7430
I7
sg62
g66
sg33
S'left'
p7431
sS'block_loop.thisN'
p7432
I2
sS'outcome_loop.thisIndex'
p7433
g63
(g96
S'\x07\x00\x00\x00'
tRp7434
sg30
g7425
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p7435
sS'block_loop.thisTrial'
p7436
Nsg60
g61
sS'block_loop.thisTrialN'
p7437
I0
sg34
F0.65277234955829044
sg7325
V23-crunchie.png
p7438
sa(dp7439
S'block_loop.thisRepN'
p7440
I2
sg7308
V26-walkers_smoky_bacon.png
p7441
sg7310
V44-crunch.png
p7442
sg70
g71
sS'outcome_loop.thisRepN'
p7443
I0
sS'block_loop.thisIndex'
p7444
g7314
sS'outcome_loop.thisN'
p7445
I8
sS'outcome_loop.thisTrialN'
p7446
I8
sg62
g66
sg33
S'right'
p7447
sS'block_loop.thisN'
p7448
I2
sS'outcome_loop.thisIndex'
p7449
g63
(g96
S'\x08\x00\x00\x00'
tRp7450
sg30
V44-crunch.png
p7451
sg67
g11
sg68
g69
sg7321
g7451
sS'block_loop.thisTrial'
p7452
Nsg60
g61
sS'block_loop.thisTrialN'
p7453
I0
sg34
F0.58613538871577475
sg7325
V26-walkers_smoky_bacon.png
p7454
sa(dp7455
S'block_loop.thisRepN'
p7456
I2
sg7308
V6-sour_patch_kids.png
p7457
sg7310
V6-sour_patch_kids.png
p7458
sg70
g71
sS'outcome_loop.thisRepN'
p7459
I0
sS'block_loop.thisIndex'
p7460
g7314
sS'outcome_loop.thisN'
p7461
I9
sS'outcome_loop.thisTrialN'
p7462
I9
sg62
g66
sg33
S'right'
p7463
sS'block_loop.thisN'
p7464
I2
sS'outcome_loop.thisIndex'
p7465
g63
(g96
S'\t\x00\x00\x00'
tRp7466
sg30
g7457
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p7467
sS'block_loop.thisTrial'
p7468
Nsg60
g61
sS'block_loop.thisTrialN'
p7469
I0
sg34
F0.61279631908473675
sg7325
V38-maltesers.png
p7470
sa(dp7471
S'block_loop.thisRepN'
p7472
I2
sg7308
V26-walkers_smoky_bacon.png
p7473
sg7310
V26-walkers_smoky_bacon.png
p7474
sg70
g71
sS'outcome_loop.thisRepN'
p7475
I0
sS'block_loop.thisIndex'
p7476
g7314
sS'outcome_loop.thisN'
p7477
I10
sS'outcome_loop.thisTrialN'
p7478
I10
sg62
g66
sg33
S'left'
p7479
sS'block_loop.thisN'
p7480
I2
sS'outcome_loop.thisIndex'
p7481
g63
(g96
S'\n\x00\x00\x00'
tRp7482
sg30
g7473
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p7483
sS'block_loop.thisTrial'
p7484
Nsg60
g61
sS'block_loop.thisTrialN'
p7485
I0
sg34
F0.62610331759969995
sg7325
V44-crunch.png
p7486
sa(dp7487
S'block_loop.thisRepN'
p7488
I2
sg7308
V49-yorkie.png
p7489
sg7310
V35-sultanas.png
p7490
sg70
g71
sS'outcome_loop.thisRepN'
p7491
I0
sS'block_loop.thisIndex'
p7492
g7314
sS'outcome_loop.thisN'
p7493
I11
sS'outcome_loop.thisTrialN'
p7494
I11
sg62
g66
sg33
S'right'
p7495
sS'block_loop.thisN'
p7496
I2
sS'outcome_loop.thisIndex'
p7497
g63
(g96
S'\x0b\x00\x00\x00'
tRp7498
sg30
g7489
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p7499
sS'block_loop.thisTrial'
p7500
Nsg60
g61
sS'block_loop.thisTrialN'
p7501
I0
sg34
F0.74596911059961712
sg7325
V49-yorkie.png
p7502
sa(dp7503
S'block_loop.thisRepN'
p7504
I2
sg7308
V19-caramello.png
p7505
sg7310
V19-caramello.png
p7506
sg70
g71
sS'outcome_loop.thisRepN'
p7507
I0
sS'block_loop.thisIndex'
p7508
g7314
sS'outcome_loop.thisN'
p7509
I12
sS'outcome_loop.thisTrialN'
p7510
I12
sg62
g66
sg33
S'left'
p7511
sS'block_loop.thisN'
p7512
I2
sS'outcome_loop.thisIndex'
p7513
g63
(g96
S'\x0c\x00\x00\x00'
tRp7514
sg30
g7505
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p7515
sS'block_loop.thisTrial'
p7516
Nsg60
g61
sS'block_loop.thisTrialN'
p7517
I0
sg34
F0.95907552496100834
sg7325
V30-spaghetti_hoops.png
p7518
sa(dp7519
S'block_loop.thisRepN'
p7520
I2
sg7308
V6-sour_patch_kids.png
p7521
sg7310
V38-maltesers.png
p7522
sg70
g71
sS'outcome_loop.thisRepN'
p7523
I0
sS'block_loop.thisIndex'
p7524
g7314
sS'outcome_loop.thisN'
p7525
I13
sS'outcome_loop.thisTrialN'
p7526
I13
sg62
g66
sg33
S'left'
p7527
sS'block_loop.thisN'
p7528
I2
sS'outcome_loop.thisIndex'
p7529
g63
(g96
S'\r\x00\x00\x00'
tRp7530
sg30
g7521
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p7531
sS'block_loop.thisTrial'
p7532
Nsg60
g61
sS'block_loop.thisTrialN'
p7533
I0
sg34
F1.2787276036469848
sg7325
V6-sour_patch_kids.png
p7534
sa(dp7535
S'block_loop.thisRepN'
p7536
I2
sg7308
V45-chewy_nougat.png
p7537
sg7310
V45-chewy_nougat.png
p7538
sg70
g71
sS'outcome_loop.thisRepN'
p7539
I0
sS'block_loop.thisIndex'
p7540
g7314
sS'outcome_loop.thisN'
p7541
I14
sS'outcome_loop.thisTrialN'
p7542
I14
sg62
g66
sg33
S'left'
p7543
sS'block_loop.thisN'
p7544
I2
sS'outcome_loop.thisIndex'
p7545
g63
(g96
S'\x0e\x00\x00\x00'
tRp7546
sg30
g7537
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p7547
sS'block_loop.thisTrial'
p7548
Nsg60
g61
sS'block_loop.thisTrialN'
p7549
I0
sg34
F0.5994753523136751
sg7325
V41-peanuts.png
p7550
sa(dp7551
S'block_loop.thisRepN'
p7552
I2
sg7308
V6-sour_patch_kids.png
p7553
sg7310
V38-maltesers.png
p7554
sg70
g71
sS'outcome_loop.thisRepN'
p7555
I0
sS'block_loop.thisIndex'
p7556
g7314
sS'outcome_loop.thisN'
p7557
I15
sS'outcome_loop.thisTrialN'
p7558
I15
sg62
g66
sg33
S'left'
p7559
sS'block_loop.thisN'
p7560
I2
sS'outcome_loop.thisIndex'
p7561
g63
(g96
S'\x0f\x00\x00\x00'
tRp7562
sg30
V38-maltesers.png
p7563
sg67
g11
sg68
g69
sg7321
g7563
sS'block_loop.thisTrial'
p7564
Nsg60
g61
sS'block_loop.thisTrialN'
p7565
I0
sg34
F0.54618198681600916
sg7325
V6-sour_patch_kids.png
p7566
sa(dp7567
S'block_loop.thisRepN'
p7568
I2
sg7308
V7-olives.png
p7569
sg7310
V7-olives.png
p7570
sg70
g71
sS'outcome_loop.thisRepN'
p7571
I0
sS'block_loop.thisIndex'
p7572
g7314
sS'outcome_loop.thisN'
p7573
I16
sS'outcome_loop.thisTrialN'
p7574
I16
sg62
g66
sg33
S'left'
p7575
sS'block_loop.thisN'
p7576
I2
sS'outcome_loop.thisIndex'
p7577
g63
(g96
S'\x10\x00\x00\x00'
tRp7578
sg30
g7569
sg67
g11
sg68
g69
sg7321
V22-daim.png
p7579
sS'block_loop.thisTrial'
p7580
Nsg60
g61
sS'block_loop.thisTrialN'
p7581
I0
sg34
F0.59948205707587476
sg7325
V22-daim.png
p7582
sa(dp7583
S'block_loop.thisRepN'
p7584
I2
sg7308
V5-pineapple.png
p7585
sg7310
V5-pineapple.png
p7586
sg70
g71
sS'outcome_loop.thisRepN'
p7587
I0
sS'block_loop.thisIndex'
p7588
g7314
sS'outcome_loop.thisN'
p7589
I17
sS'outcome_loop.thisTrialN'
p7590
I17
sg62
g66
sg33
S'left'
p7591
sS'block_loop.thisN'
p7592
I2
sS'outcome_loop.thisIndex'
p7593
g63
(g96
S'\x11\x00\x00\x00'
tRp7594
sg30
g7585
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p7595
sS'block_loop.thisTrial'
p7596
Nsg60
g61
sS'block_loop.thisTrialN'
p7597
I0
sg34
F0.55946495993157441
sg7325
V40-sardines.png
p7598
sa(dp7599
S'block_loop.thisRepN'
p7600
I2
sg7308
V33-ambrosia_rice.png
p7601
sg7310
V33-ambrosia_rice.png
p7602
sg70
g71
sS'outcome_loop.thisRepN'
p7603
I0
sS'block_loop.thisIndex'
p7604
g7314
sS'outcome_loop.thisN'
p7605
I18
sS'outcome_loop.thisTrialN'
p7606
I18
sg62
g66
sg33
S'left'
p7607
sS'block_loop.thisN'
p7608
I2
sS'outcome_loop.thisIndex'
p7609
g63
(g96
S'\x12\x00\x00\x00'
tRp7610
sg30
g7601
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p7611
sS'block_loop.thisTrial'
p7612
Nsg60
g61
sS'block_loop.thisTrialN'
p7613
I0
sg34
F0.58615354744870274
sg7325
V23-crunchie.png
p7614
sa(dp7615
S'block_loop.thisRepN'
p7616
I2
sg7308
V5-pineapple.png
p7617
sg7310
V5-pineapple.png
p7618
sg70
g71
sS'outcome_loop.thisRepN'
p7619
I0
sS'block_loop.thisIndex'
p7620
g7314
sS'outcome_loop.thisN'
p7621
I19
sS'outcome_loop.thisTrialN'
p7622
I19
sg62
g66
sg33
S'left'
p7623
sS'block_loop.thisN'
p7624
I2
sS'outcome_loop.thisIndex'
p7625
g63
(g96
S'\x13\x00\x00\x00'
tRp7626
sg30
g7617
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p7627
sS'block_loop.thisTrial'
p7628
Nsg60
g61
sS'block_loop.thisTrialN'
p7629
I0
sg34
F0.46627518302011595
sg7325
V40-sardines.png
p7630
sa(dp7631
S'block_loop.thisRepN'
p7632
I2
sg7308
V42-mrkipling_lemon_slices.png
p7633
sg7310
V16-skips_prawn.png
p7634
sg70
g71
sS'outcome_loop.thisRepN'
p7635
I0
sS'block_loop.thisIndex'
p7636
g7314
sS'outcome_loop.thisN'
p7637
I20
sS'outcome_loop.thisTrialN'
p7638
I20
sg62
g66
sg33
S'right'
p7639
sS'block_loop.thisN'
p7640
I2
sS'outcome_loop.thisIndex'
p7641
g63
(g96
S'\x14\x00\x00\x00'
tRp7642
sg30
g7633
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p7643
sS'block_loop.thisTrial'
p7644
Nsg60
g61
sS'block_loop.thisTrialN'
p7645
I0
sg34
F0.75929007736885978
sg7325
V42-mrkipling_lemon_slices.png
p7646
sa(dp7647
S'block_loop.thisRepN'
p7648
I2
sg7308
V51-mars.png
p7649
sg7310
V27-hartleys_raspberries_jelly.png
p7650
sg70
g71
sS'outcome_loop.thisRepN'
p7651
I0
sS'block_loop.thisIndex'
p7652
g7314
sS'outcome_loop.thisN'
p7653
I21
sS'outcome_loop.thisTrialN'
p7654
I21
sg62
g66
sg33
S'right'
p7655
sS'block_loop.thisN'
p7656
I2
sS'outcome_loop.thisIndex'
p7657
g63
(g96
S'\x15\x00\x00\x00'
tRp7658
sg30
g7649
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p7659
sS'block_loop.thisTrial'
p7660
Nsg60
g61
sS'block_loop.thisTrialN'
p7661
I0
sg34
F0.87916760370535485
sg7325
V51-mars.png
p7662
sa(dp7663
S'block_loop.thisRepN'
p7664
I2
sg7308
V42-mrkipling_lemon_slices.png
p7665
sg7310
V16-skips_prawn.png
p7666
sg70
g71
sS'outcome_loop.thisRepN'
p7667
I0
sS'block_loop.thisIndex'
p7668
g7314
sS'outcome_loop.thisN'
p7669
I22
sS'outcome_loop.thisTrialN'
p7670
I22
sg62
g66
sg33
S'right'
p7671
sS'block_loop.thisN'
p7672
I2
sS'outcome_loop.thisIndex'
p7673
g63
(g96
S'\x16\x00\x00\x00'
tRp7674
sg30
g7665
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p7675
sS'block_loop.thisTrial'
p7676
Nsg60
g61
sS'block_loop.thisTrialN'
p7677
I0
sg34
F0.79924822847715404
sg7325
V42-mrkipling_lemon_slices.png
p7678
sa(dp7679
S'block_loop.thisRepN'
p7680
I2
sg7308
V48-twix.png
p7681
sg7310
V48-twix.png
p7682
sg70
g71
sS'outcome_loop.thisRepN'
p7683
I0
sS'block_loop.thisIndex'
p7684
g7314
sS'outcome_loop.thisN'
p7685
I23
sS'outcome_loop.thisTrialN'
p7686
I23
sg62
g66
sg33
S'left'
p7687
sS'block_loop.thisN'
p7688
I2
sS'outcome_loop.thisIndex'
p7689
g63
(g96
S'\x17\x00\x00\x00'
tRp7690
sg30
g7681
sg67
g11
sg68
g69
sg7321
V50-polo.png
p7691
sS'block_loop.thisTrial'
p7692
Nsg60
g61
sS'block_loop.thisTrialN'
p7693
I0
sg34
F0.95906462972197914
sg7325
V50-polo.png
p7694
sa(dp7695
S'block_loop.thisRepN'
p7696
I2
sg7308
V51-mars.png
p7697
sg7310
V27-hartleys_raspberries_jelly.png
p7698
sg70
g71
sS'outcome_loop.thisRepN'
p7699
I0
sS'block_loop.thisIndex'
p7700
g7314
sS'outcome_loop.thisN'
p7701
I24
sS'outcome_loop.thisTrialN'
p7702
I24
sg62
g66
sg33
S'right'
p7703
sS'block_loop.thisN'
p7704
I2
sS'outcome_loop.thisIndex'
p7705
g63
(g96
S'\x18\x00\x00\x00'
tRp7706
sg30
V27-hartleys_raspberries_jelly.png
p7707
sg67
g11
sg68
g69
sg7321
g7707
sS'block_loop.thisTrial'
p7708
Nsg60
g61
sS'block_loop.thisTrialN'
p7709
I0
sg34
F1.1322279786963918
sg7325
V51-mars.png
p7710
sa(dp7711
S'block_loop.thisRepN'
p7712
I2
sg7308
V43-mrporky_pork_crackles.png
p7713
sg7310
V43-mrporky_pork_crackles.png
p7714
sg70
g71
sS'outcome_loop.thisRepN'
p7715
I0
sS'block_loop.thisIndex'
p7716
g7314
sS'outcome_loop.thisN'
p7717
I25
sS'outcome_loop.thisTrialN'
p7718
I25
sg62
g66
sg33
S'left'
p7719
sS'block_loop.thisN'
p7720
I2
sS'outcome_loop.thisIndex'
p7721
g63
(g96
S'\x19\x00\x00\x00'
tRp7722
sg30
V18-mms.png
p7723
sg67
g11
sg68
g69
sg7321
g7723
sS'block_loop.thisTrial'
p7724
Nsg60
g61
sS'block_loop.thisTrialN'
p7725
I0
sg34
F0.58614544585907424
sg7325
V18-mms.png
p7726
sa(dp7727
S'block_loop.thisRepN'
p7728
I2
sg7308
V51-mars.png
p7729
sg7310
V27-hartleys_raspberries_jelly.png
p7730
sg70
g71
sS'outcome_loop.thisRepN'
p7731
I0
sS'block_loop.thisIndex'
p7732
g7314
sS'outcome_loop.thisN'
p7733
I26
sS'outcome_loop.thisTrialN'
p7734
I26
sg62
g66
sg33
S'right'
p7735
sS'block_loop.thisN'
p7736
I2
sS'outcome_loop.thisIndex'
p7737
g63
(g96
S'\x1a\x00\x00\x00'
tRp7738
sg30
g7729
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p7739
sS'block_loop.thisTrial'
p7740
Nsg60
g61
sS'block_loop.thisTrialN'
p7741
I0
sg34
F0.6127759254322882
sg7325
V51-mars.png
p7742
sa(dp7743
S'block_loop.thisRepN'
p7744
I2
sg7308
V43-mrporky_pork_crackles.png
p7745
sg7310
V43-mrporky_pork_crackles.png
p7746
sg70
g71
sS'outcome_loop.thisRepN'
p7747
I0
sS'block_loop.thisIndex'
p7748
g7314
sS'outcome_loop.thisN'
p7749
I27
sS'outcome_loop.thisTrialN'
p7750
I27
sg62
g66
sg33
S'left'
p7751
sS'block_loop.thisN'
p7752
I2
sS'outcome_loop.thisIndex'
p7753
g63
(g96
S'\x1b\x00\x00\x00'
tRp7754
sg30
g7745
sg67
g11
sg68
g69
sg7321
V18-mms.png
p7755
sS'block_loop.thisTrial'
p7756
Nsg60
g61
sS'block_loop.thisTrialN'
p7757
I0
sg34
F0.54618058999039931
sg7325
V18-mms.png
p7758
sa(dp7759
S'block_loop.thisRepN'
p7760
I2
sg7308
V7-olives.png
p7761
sg7310
V22-daim.png
p7762
sg70
g71
sS'outcome_loop.thisRepN'
p7763
I0
sS'block_loop.thisIndex'
p7764
g7314
sS'outcome_loop.thisN'
p7765
I28
sS'outcome_loop.thisTrialN'
p7766
I28
sg62
g66
sg33
S'right'
p7767
sS'block_loop.thisN'
p7768
I2
sS'outcome_loop.thisIndex'
p7769
g63
(g96
S'\x1c\x00\x00\x00'
tRp7770
sg30
g7761
sg67
g11
sg68
g69
sg7321
V22-daim.png
p7771
sS'block_loop.thisTrial'
p7772
Nsg60
g61
sS'block_loop.thisTrialN'
p7773
I0
sg34
F0.57283202194776095
sg7325
V7-olives.png
p7774
sa(dp7775
S'block_loop.thisRepN'
p7776
I2
sg7308
V20-fruit_pastilles.png
p7777
sg7310
V20-fruit_pastilles.png
p7778
sg70
g71
sS'outcome_loop.thisRepN'
p7779
I0
sS'block_loop.thisIndex'
p7780
g7314
sS'outcome_loop.thisN'
p7781
I29
sS'outcome_loop.thisTrialN'
p7782
I29
sg62
g66
sg33
S'left'
p7783
sS'block_loop.thisN'
p7784
I2
sS'outcome_loop.thisIndex'
p7785
g63
(g96
S'\x1d\x00\x00\x00'
tRp7786
sg30
V2-steamed_puddings.png
p7787
sg67
g11
sg68
g69
sg7321
g7787
sS'block_loop.thisTrial'
p7788
Nsg60
g61
sS'block_loop.thisTrialN'
p7789
I0
sg34
F1.1856001251544512
sg7325
V2-steamed_puddings.png
p7790
sa(dp7791
S'block_loop.thisRepN'
p7792
I2
sg7308
V19-caramello.png
p7793
sg7310
V19-caramello.png
p7794
sg70
g71
sS'outcome_loop.thisRepN'
p7795
I0
sS'block_loop.thisIndex'
p7796
g7314
sS'outcome_loop.thisN'
p7797
I30
sS'outcome_loop.thisTrialN'
p7798
I30
sg62
g66
sg33
S'left'
p7799
sS'block_loop.thisN'
p7800
I2
sS'outcome_loop.thisIndex'
p7801
g63
(g96
S'\x1e\x00\x00\x00'
tRp7802
sg30
g7793
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p7803
sS'block_loop.thisTrial'
p7804
Nsg60
g61
sS'block_loop.thisTrialN'
p7805
I0
sg34
F0.83921168751840014
sg7325
V30-spaghetti_hoops.png
p7806
sa(dp7807
S'block_loop.thisRepN'
p7808
I2
sg7308
V48-twix.png
p7809
sg7310
V48-twix.png
p7810
sg70
g71
sS'outcome_loop.thisRepN'
p7811
I0
sS'block_loop.thisIndex'
p7812
g7314
sS'outcome_loop.thisN'
p7813
I31
sS'outcome_loop.thisTrialN'
p7814
I31
sg62
g66
sg33
S'left'
p7815
sS'block_loop.thisN'
p7816
I2
sS'outcome_loop.thisIndex'
p7817
g63
(g96
S'\x1f\x00\x00\x00'
tRp7818
sg30
V50-polo.png
p7819
sg67
g11
sg68
g69
sg7321
g7819
sS'block_loop.thisTrial'
p7820
Nsg60
g61
sS'block_loop.thisTrialN'
p7821
I0
sg34
F0.57280659972275316
sg7325
V50-polo.png
p7822
sa(dp7823
S'block_loop.thisRepN'
p7824
I2
sg7308
V46-pistachios.png
p7825
sg7310
V29-beans.png
p7826
sg70
g71
sS'outcome_loop.thisRepN'
p7827
I0
sS'block_loop.thisIndex'
p7828
g7314
sS'outcome_loop.thisN'
p7829
I32
sS'outcome_loop.thisTrialN'
p7830
I32
sg62
g66
sg33
S'right'
p7831
sS'block_loop.thisN'
p7832
I2
sS'outcome_loop.thisIndex'
p7833
g63
(g96
S' \x00\x00\x00'
tRp7834
sg30
g7825
sg67
g11
sg68
g69
sg7321
V29-beans.png
p7835
sS'block_loop.thisTrial'
p7836
Nsg60
g61
sS'block_loop.thisTrialN'
p7837
I0
sg34
F0.55950909961939033
sg7325
V46-pistachios.png
p7838
sa(dp7839
S'block_loop.thisRepN'
p7840
I2
sg7308
V43-mrporky_pork_crackles.png
p7841
sg7310
V43-mrporky_pork_crackles.png
p7842
sg70
g71
sS'outcome_loop.thisRepN'
p7843
I0
sS'block_loop.thisIndex'
p7844
g7314
sS'outcome_loop.thisN'
p7845
I33
sS'outcome_loop.thisTrialN'
p7846
I33
sg62
g66
sg33
S'left'
p7847
sS'block_loop.thisN'
p7848
I2
sS'outcome_loop.thisIndex'
p7849
g63
(g96
S'!\x00\x00\x00'
tRp7850
sg30
g7841
sg67
g11
sg68
g69
sg7321
V18-mms.png
p7851
sS'block_loop.thisTrial'
p7852
Nsg60
g61
sS'block_loop.thisTrialN'
p7853
I0
sg34
F0.54619176459527807
sg7325
V18-mms.png
p7854
sa(dp7855
S'block_loop.thisRepN'
p7856
I2
sg7308
V7-olives.png
p7857
sg7310
V22-daim.png
p7858
sg70
g71
sS'outcome_loop.thisRepN'
p7859
I0
sS'block_loop.thisIndex'
p7860
g7314
sS'outcome_loop.thisN'
p7861
I34
sS'outcome_loop.thisTrialN'
p7862
I34
sg62
g66
sg33
S'right'
p7863
sS'block_loop.thisN'
p7864
I2
sS'outcome_loop.thisIndex'
p7865
g63
(g96
S'"\x00\x00\x00'
tRp7866
sg30
g7857
sg67
g11
sg68
g69
sg7321
V22-daim.png
p7867
sS'block_loop.thisTrial'
p7868
Nsg60
g61
sS'block_loop.thisTrialN'
p7869
I0
sg34
F0.5994745142179454
sg7325
V7-olives.png
p7870
sa(dp7871
S'block_loop.thisRepN'
p7872
I2
sg7308
V6-sour_patch_kids.png
p7873
sg7310
V38-maltesers.png
p7874
sg70
g71
sS'outcome_loop.thisRepN'
p7875
I0
sS'block_loop.thisIndex'
p7876
g7314
sS'outcome_loop.thisN'
p7877
I35
sS'outcome_loop.thisTrialN'
p7878
I35
sg62
g66
sg33
S'left'
p7879
sS'block_loop.thisN'
p7880
I2
sS'outcome_loop.thisIndex'
p7881
g63
(g96
S'#\x00\x00\x00'
tRp7882
sg30
g7873
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p7883
sS'block_loop.thisTrial'
p7884
Nsg60
g61
sS'block_loop.thisTrialN'
p7885
I0
sg34
F0.47959559105947847
sg7325
V6-sour_patch_kids.png
p7886
sa(dp7887
S'block_loop.thisRepN'
p7888
I2
sg7308
V20-fruit_pastilles.png
p7889
sg7310
V20-fruit_pastilles.png
p7890
sg70
g71
sS'outcome_loop.thisRepN'
p7891
I0
sS'block_loop.thisIndex'
p7892
g7314
sS'outcome_loop.thisN'
p7893
I36
sS'outcome_loop.thisTrialN'
p7894
I36
sg62
g66
sg33
S'left'
p7895
sS'block_loop.thisN'
p7896
I2
sS'outcome_loop.thisIndex'
p7897
g63
(g96
S'$\x00\x00\x00'
tRp7898
sg30
g7889
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p7899
sS'block_loop.thisTrial'
p7900
Nsg60
g61
sS'block_loop.thisTrialN'
p7901
I0
sg34
F0.75928840117921936
sg7325
V2-steamed_puddings.png
p7902
sa(dp7903
S'block_loop.thisRepN'
p7904
I2
sg7308
V4-corn.png
p7905
sg7310
V10-bounty.png
p7906
sg70
g71
sS'outcome_loop.thisRepN'
p7907
I0
sS'block_loop.thisIndex'
p7908
g7314
sS'outcome_loop.thisN'
p7909
I37
sS'outcome_loop.thisTrialN'
p7910
I37
sg62
g66
sg33
S'right'
p7911
sS'block_loop.thisN'
p7912
I2
sS'outcome_loop.thisIndex'
p7913
g63
(g96
S'%\x00\x00\x00'
tRp7914
sg30
V10-bounty.png
p7915
sg67
g11
sg68
g69
sg7321
g7915
sS'block_loop.thisTrial'
p7916
Nsg60
g61
sS'block_loop.thisTrialN'
p7917
I0
sg34
F0.94575651374725567
sg7325
V4-corn.png
p7918
sa(dp7919
S'block_loop.thisRepN'
p7920
I2
sg7308
V46-pistachios.png
p7921
sg7310
V29-beans.png
p7922
sg70
g71
sS'outcome_loop.thisRepN'
p7923
I0
sS'block_loop.thisIndex'
p7924
g7314
sS'outcome_loop.thisN'
p7925
I38
sS'outcome_loop.thisTrialN'
p7926
I38
sg62
g66
sg33
S'right'
p7927
sS'block_loop.thisN'
p7928
I2
sS'outcome_loop.thisIndex'
p7929
g63
(g96
S'&\x00\x00\x00'
tRp7930
sg30
g7921
sg67
g11
sg68
g69
sg7321
V29-beans.png
p7931
sS'block_loop.thisTrial'
p7932
Nsg60
g61
sS'block_loop.thisTrialN'
p7933
I0
sg34
F0.59947311739233555
sg7325
V46-pistachios.png
p7934
sa(dp7935
S'block_loop.thisRepN'
p7936
I2
sg7308
V51-mars.png
p7937
sg7310
V51-mars.png
p7938
sg70
g71
sS'outcome_loop.thisRepN'
p7939
I0
sS'block_loop.thisIndex'
p7940
g7314
sS'outcome_loop.thisN'
p7941
I39
sS'outcome_loop.thisTrialN'
p7942
I39
sg62
g66
sg33
S'left'
p7943
sS'block_loop.thisN'
p7944
I2
sS'outcome_loop.thisIndex'
p7945
g63
(g96
S"'\x00\x00\x00"
tRp7946
sg30
g7937
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p7947
sS'block_loop.thisTrial'
p7948
Nsg60
g61
sS'block_loop.thisTrialN'
p7949
I0
sg34
F0.74606130108804791
sg7325
V27-hartleys_raspberries_jelly.png
p7950
sa(dp7951
S'block_loop.thisRepN'
p7952
I2
sg7308
V36-fig_rolls.png
p7953
sg7310
V36-fig_rolls.png
p7954
sg70
g71
sS'outcome_loop.thisRepN'
p7955
I0
sS'block_loop.thisIndex'
p7956
g7314
sS'outcome_loop.thisN'
p7957
I40
sS'outcome_loop.thisTrialN'
p7958
I40
sg62
g66
sg33
S'left'
p7959
sS'block_loop.thisN'
p7960
I2
sS'outcome_loop.thisIndex'
p7961
g63
(g96
S'(\x00\x00\x00'
tRp7962
sg30
V34-hula_hoops_bbq_beef.png
p7963
sg67
g11
sg68
g69
sg7321
g7963
sS'block_loop.thisTrial'
p7964
Nsg60
g61
sS'block_loop.thisTrialN'
p7965
I0
sg34
F1.1988135363571928
sg7325
V34-hula_hoops_bbq_beef.png
p7966
sa(dp7967
S'block_loop.thisRepN'
p7968
I2
sg7308
V42-mrkipling_lemon_slices.png
p7969
sg7310
V42-mrkipling_lemon_slices.png
p7970
sg70
g71
sS'outcome_loop.thisRepN'
p7971
I0
sS'block_loop.thisIndex'
p7972
g7314
sS'outcome_loop.thisN'
p7973
I41
sS'outcome_loop.thisTrialN'
p7974
I41
sg62
g66
sg33
S'left'
p7975
sS'block_loop.thisN'
p7976
I2
sS'outcome_loop.thisIndex'
p7977
g63
(g96
S')\x00\x00\x00'
tRp7978
sg30
g7969
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p7979
sS'block_loop.thisTrial'
p7980
Nsg60
g61
sS'block_loop.thisTrialN'
p7981
I0
sg34
F0.53286241687055735
sg7325
V16-skips_prawn.png
p7982
sa(dp7983
S'block_loop.thisRepN'
p7984
I2
sg7308
V13-mccoys_steak_crisps.png
p7985
sg7310
V13-mccoys_steak_crisps.png
p7986
sg70
g71
sS'outcome_loop.thisRepN'
p7987
I0
sS'block_loop.thisIndex'
p7988
g7314
sS'outcome_loop.thisN'
p7989
I42
sS'outcome_loop.thisTrialN'
p7990
I42
sg62
g66
sg33
S'left'
p7991
sS'block_loop.thisN'
p7992
I2
sS'outcome_loop.thisIndex'
p7993
g63
(g96
S'*\x00\x00\x00'
tRp7994
sg30
g7985
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p7995
sS'block_loop.thisTrial'
p7996
Nsg60
g61
sS'block_loop.thisTrialN'
p7997
I0
sg34
F0.49291907211591024
sg7325
V3-dole_fruit_snack.png
p7998
sa(dp7999
S'block_loop.thisRepN'
p8000
I2
sg7308
V46-pistachios.png
p8001
sg7310
V46-pistachios.png
p8002
sg70
g71
sS'outcome_loop.thisRepN'
p8003
I0
sS'block_loop.thisIndex'
p8004
g7314
sS'outcome_loop.thisN'
p8005
I43
sS'outcome_loop.thisTrialN'
p8006
I43
sg62
g66
sg33
S'left'
p8007
sS'block_loop.thisN'
p8008
I2
sS'outcome_loop.thisIndex'
p8009
g63
(g96
S'+\x00\x00\x00'
tRp8010
sg30
g8001
sg67
g11
sg68
g69
sg7321
V29-beans.png
p8011
sS'block_loop.thisTrial'
p8012
Nsg60
g61
sS'block_loop.thisTrialN'
p8013
I0
sg34
F0.54618897094405838
sg7325
V29-beans.png
p8014
sa(dp8015
S'block_loop.thisRepN'
p8016
I2
sg7308
V20-fruit_pastilles.png
p8017
sg7310
V20-fruit_pastilles.png
p8018
sg70
g71
sS'outcome_loop.thisRepN'
p8019
I0
sS'block_loop.thisIndex'
p8020
g7314
sS'outcome_loop.thisN'
p8021
I44
sS'outcome_loop.thisTrialN'
p8022
I44
sg62
g66
sg33
S'left'
p8023
sS'block_loop.thisN'
p8024
I2
sS'outcome_loop.thisIndex'
p8025
g63
(g96
S',\x00\x00\x00'
tRp8026
sg30
g8017
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p8027
sS'block_loop.thisTrial'
p8028
Nsg60
g61
sS'block_loop.thisTrialN'
p8029
I0
sg34
F0.73261294382427877
sg7325
V2-steamed_puddings.png
p8030
sa(dp8031
S'block_loop.thisRepN'
p8032
I2
sg7308
V46-pistachios.png
p8033
sg7310
V46-pistachios.png
p8034
sg70
g71
sS'outcome_loop.thisRepN'
p8035
I0
sS'block_loop.thisIndex'
p8036
g7314
sS'outcome_loop.thisN'
p8037
I45
sS'outcome_loop.thisTrialN'
p8038
I45
sg62
g66
sg33
S'left'
p8039
sS'block_loop.thisN'
p8040
I2
sS'outcome_loop.thisIndex'
p8041
g63
(g96
S'-\x00\x00\x00'
tRp8042
sg30
g8033
sg67
g11
sg68
g69
sg7321
V29-beans.png
p8043
sS'block_loop.thisTrial'
p8044
Nsg60
g61
sS'block_loop.thisTrialN'
p8045
I0
sg34
F0.47960145772776741
sg7325
V29-beans.png
p8046
sa(dp8047
S'block_loop.thisRepN'
p8048
I2
sg7308
V48-twix.png
p8049
sg7310
V50-polo.png
p8050
sg70
g71
sS'outcome_loop.thisRepN'
p8051
I0
sS'block_loop.thisIndex'
p8052
g7314
sS'outcome_loop.thisN'
p8053
I46
sS'outcome_loop.thisTrialN'
p8054
I46
sg62
g66
sg33
S'left'
p8055
sS'block_loop.thisN'
p8056
I2
sS'outcome_loop.thisIndex'
p8057
g63
(g96
S'.\x00\x00\x00'
tRp8058
sg30
g8049
sg67
g11
sg68
g69
sg7321
V50-polo.png
p8059
sS'block_loop.thisTrial'
p8060
Nsg60
g61
sS'block_loop.thisTrialN'
p8061
I0
sg34
F0.62603906362346606
sg7325
V48-twix.png
p8062
sa(dp8063
S'block_loop.thisRepN'
p8064
I2
sg7308
V45-chewy_nougat.png
p8065
sg7310
V41-peanuts.png
p8066
sg70
g71
sS'outcome_loop.thisRepN'
p8067
I0
sS'block_loop.thisIndex'
p8068
g7314
sS'outcome_loop.thisN'
p8069
I47
sS'outcome_loop.thisTrialN'
p8070
I47
sg62
g66
sg33
S'left'
p8071
sS'block_loop.thisN'
p8072
I2
sS'outcome_loop.thisIndex'
p8073
g63
(g96
S'/\x00\x00\x00'
tRp8074
sg30
g8065
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p8075
sS'block_loop.thisTrial'
p8076
Nsg60
g61
sS'block_loop.thisTrialN'
p8077
I0
sg34
F0.50623081983758311
sg7325
V45-chewy_nougat.png
p8078
sa(dp8079
S'block_loop.thisRepN'
p8080
I2
sg7308
V36-fig_rolls.png
p8081
sg7310
V36-fig_rolls.png
p8082
sg70
g71
sS'outcome_loop.thisRepN'
p8083
I0
sS'block_loop.thisIndex'
p8084
g7314
sS'outcome_loop.thisN'
p8085
I48
sS'outcome_loop.thisTrialN'
p8086
I48
sg62
g66
sg33
S'left'
p8087
sS'block_loop.thisN'
p8088
I2
sS'outcome_loop.thisIndex'
p8089
g63
(g96
S'0\x00\x00\x00'
tRp8090
sg30
g8081
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p8091
sS'block_loop.thisTrial'
p8092
Nsg60
g61
sS'block_loop.thisTrialN'
p8093
I0
sg34
F0.69268971335623064
sg7325
V34-hula_hoops_bbq_beef.png
p8094
sa(dp8095
S'block_loop.thisRepN'
p8096
I2
sg7308
V31-foxs_golden_biscuits.png
p8097
sg7310
V25-kitkat.png
p8098
sg70
g71
sS'outcome_loop.thisRepN'
p8099
I0
sS'block_loop.thisIndex'
p8100
g7314
sS'outcome_loop.thisN'
p8101
I49
sS'outcome_loop.thisTrialN'
p8102
I49
sg62
g66
sg33
S'right'
p8103
sS'block_loop.thisN'
p8104
I2
sS'outcome_loop.thisIndex'
p8105
g63
(g96
S'1\x00\x00\x00'
tRp8106
sg30
g8097
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8107
sS'block_loop.thisTrial'
p8108
Nsg60
g61
sS'block_loop.thisTrialN'
p8109
I0
sg34
F0.65274273685645312
sg7325
V31-foxs_golden_biscuits.png
p8110
sa(dp8111
S'block_loop.thisRepN'
p8112
I2
sg7308
V5-pineapple.png
p8113
sg7310
V5-pineapple.png
p8114
sg70
g71
sS'outcome_loop.thisRepN'
p8115
I0
sS'block_loop.thisIndex'
p8116
g7314
sS'outcome_loop.thisN'
p8117
I50
sS'outcome_loop.thisTrialN'
p8118
I50
sg62
g66
sg33
S'left'
p8119
sS'block_loop.thisN'
p8120
I2
sS'outcome_loop.thisIndex'
p8121
g63
(g96
S'2\x00\x00\x00'
tRp8122
sg30
g8113
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p8123
sS'block_loop.thisTrial'
p8124
Nsg60
g61
sS'block_loop.thisTrialN'
p8125
I0
sg34
F0.79924487609605421
sg7325
V40-sardines.png
p8126
sa(dp8127
S'block_loop.thisRepN'
p8128
I2
sg7308
V42-mrkipling_lemon_slices.png
p8129
sg7310
V42-mrkipling_lemon_slices.png
p8130
sg70
g71
sS'outcome_loop.thisRepN'
p8131
I0
sS'block_loop.thisIndex'
p8132
g7314
sS'outcome_loop.thisN'
p8133
I51
sS'outcome_loop.thisTrialN'
p8134
I51
sg62
g66
sg33
S'left'
p8135
sS'block_loop.thisN'
p8136
I2
sS'outcome_loop.thisIndex'
p8137
g63
(g96
S'3\x00\x00\x00'
tRp8138
sg30
g8129
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p8139
sS'block_loop.thisTrial'
p8140
Nsg60
g61
sS'block_loop.thisTrialN'
p8141
I0
sg34
F0.65274357495218283
sg7325
V16-skips_prawn.png
p8142
sa(dp8143
S'block_loop.thisRepN'
p8144
I2
sg7308
V51-mars.png
p8145
sg7310
V51-mars.png
p8146
sg70
g71
sS'outcome_loop.thisRepN'
p8147
I0
sS'block_loop.thisIndex'
p8148
g7314
sS'outcome_loop.thisN'
p8149
I52
sS'outcome_loop.thisTrialN'
p8150
I52
sg62
g66
sg33
S'left'
p8151
sS'block_loop.thisN'
p8152
I2
sS'outcome_loop.thisIndex'
p8153
g63
(g96
S'4\x00\x00\x00'
tRp8154
sg30
V27-hartleys_raspberries_jelly.png
p8155
sg67
g11
sg68
g69
sg7321
g8155
sS'block_loop.thisTrial'
p8156
Nsg60
g61
sS'block_loop.thisTrialN'
p8157
I0
sg34
F0.8525306987339718
sg7325
V27-hartleys_raspberries_jelly.png
p8158
sa(dp8159
S'block_loop.thisRepN'
p8160
I2
sg7308
V26-walkers_smoky_bacon.png
p8161
sg7310
V44-crunch.png
p8162
sg70
g71
sS'outcome_loop.thisRepN'
p8163
I0
sS'block_loop.thisIndex'
p8164
g7314
sS'outcome_loop.thisN'
p8165
I53
sS'outcome_loop.thisTrialN'
p8166
I53
sg62
g66
sg33
S'right'
p8167
sS'block_loop.thisN'
p8168
I2
sS'outcome_loop.thisIndex'
p8169
g63
(g96
S'5\x00\x00\x00'
tRp8170
sg30
g8161
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p8171
sS'block_loop.thisTrial'
p8172
Nsg60
g61
sS'block_loop.thisTrialN'
p8173
I0
sg34
F0.57282559654959186
sg7325
V26-walkers_smoky_bacon.png
p8174
sa(dp8175
S'block_loop.thisRepN'
p8176
I2
sg7308
V1-smarties_cookies.png
p8177
sg7310
V21-nakd_banana_crunch.png
p8178
sg70
g71
sS'outcome_loop.thisRepN'
p8179
I0
sS'block_loop.thisIndex'
p8180
g7314
sS'outcome_loop.thisN'
p8181
I54
sS'outcome_loop.thisTrialN'
p8182
I54
sg62
g66
sg33
S'right'
p8183
sS'block_loop.thisN'
p8184
I2
sS'outcome_loop.thisIndex'
p8185
g63
(g96
S'6\x00\x00\x00'
tRp8186
sg30
g8177
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p8187
sS'block_loop.thisTrial'
p8188
Nsg60
g61
sS'block_loop.thisTrialN'
p8189
I0
sg34
F0.83920582085011119
sg7325
V1-smarties_cookies.png
p8190
sa(dp8191
S'block_loop.thisRepN'
p8192
I2
sg7308
V51-mars.png
p8193
sg7310
V27-hartleys_raspberries_jelly.png
p8194
sg70
g71
sS'outcome_loop.thisRepN'
p8195
I0
sS'block_loop.thisIndex'
p8196
g7314
sS'outcome_loop.thisN'
p8197
I55
sS'outcome_loop.thisTrialN'
p8198
I55
sg62
g66
sg33
S'right'
p8199
sS'block_loop.thisN'
p8200
I2
sS'outcome_loop.thisIndex'
p8201
g63
(g96
S'7\x00\x00\x00'
tRp8202
sg30
g8193
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p8203
sS'block_loop.thisTrial'
p8204
Nsg60
g61
sS'block_loop.thisTrialN'
p8205
I0
sg34
F0.70601822298522166
sg7325
V51-mars.png
p8206
sa(dp8207
S'block_loop.thisRepN'
p8208
I2
sg7308
V13-mccoys_steak_crisps.png
p8209
sg7310
V13-mccoys_steak_crisps.png
p8210
sg70
g71
sS'outcome_loop.thisRepN'
p8211
I0
sS'block_loop.thisIndex'
p8212
g7314
sS'outcome_loop.thisN'
p8213
I56
sS'outcome_loop.thisTrialN'
p8214
I56
sg62
g66
sg33
S'left'
p8215
sS'block_loop.thisN'
p8216
I2
sS'outcome_loop.thisIndex'
p8217
g63
(g96
S'8\x00\x00\x00'
tRp8218
sg30
g8209
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p8219
sS'block_loop.thisTrial'
p8220
Nsg60
g61
sS'block_loop.thisTrialN'
p8221
I0
sg34
F0.53287135655591555
sg7325
V3-dole_fruit_snack.png
p8222
sa(dp8223
S'block_loop.thisRepN'
p8224
I2
sg7308
V49-yorkie.png
p8225
sg7310
V49-yorkie.png
p8226
sg70
g71
sS'outcome_loop.thisRepN'
p8227
I0
sS'block_loop.thisIndex'
p8228
g7314
sS'outcome_loop.thisN'
p8229
I57
sS'outcome_loop.thisTrialN'
p8230
I57
sg62
g66
sg33
S'left'
p8231
sS'block_loop.thisN'
p8232
I2
sS'outcome_loop.thisIndex'
p8233
g63
(g96
S'9\x00\x00\x00'
tRp8234
sg30
g8225
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p8235
sS'block_loop.thisTrial'
p8236
Nsg60
g61
sS'block_loop.thisTrialN'
p8237
I0
sg34
F0.74596911059779814
sg7325
V35-sultanas.png
p8238
sa(dp8239
S'block_loop.thisRepN'
p8240
I2
sg7308
V36-fig_rolls.png
p8241
sg7310
V34-hula_hoops_bbq_beef.png
p8242
sg70
g71
sS'outcome_loop.thisRepN'
p8243
I0
sS'block_loop.thisIndex'
p8244
g7314
sS'outcome_loop.thisN'
p8245
I58
sS'outcome_loop.thisTrialN'
p8246
I58
sg62
g66
sg33
S'right'
p8247
sS'block_loop.thisN'
p8248
I2
sS'outcome_loop.thisIndex'
p8249
g63
(g96
S':\x00\x00\x00'
tRp8250
sg30
g8241
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p8251
sS'block_loop.thisTrial'
p8252
Nsg60
g61
sS'block_loop.thisTrialN'
p8253
I0
sg34
F0.71932242784896516
sg7325
V36-fig_rolls.png
p8254
sa(dp8255
S'block_loop.thisRepN'
p8256
I2
sg7308
V1-smarties_cookies.png
p8257
sg7310
V1-smarties_cookies.png
p8258
sg70
g71
sS'outcome_loop.thisRepN'
p8259
I0
sS'block_loop.thisIndex'
p8260
g7314
sS'outcome_loop.thisN'
p8261
I59
sS'outcome_loop.thisTrialN'
p8262
I59
sg62
g66
sg33
S'left'
p8263
sS'block_loop.thisN'
p8264
I2
sS'outcome_loop.thisIndex'
p8265
g63
(g96
S';\x00\x00\x00'
tRp8266
sg30
g8257
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p8267
sS'block_loop.thisTrial'
p8268
Nsg60
g61
sS'block_loop.thisTrialN'
p8269
I0
sg34
F0.66585920836405421
sg7325
V21-nakd_banana_crunch.png
p8270
sa(dp8271
S'block_loop.thisRepN'
p8272
I2
sg7308
V46-pistachios.png
p8273
sg7310
V46-pistachios.png
p8274
sg70
g71
sS'outcome_loop.thisRepN'
p8275
I0
sS'block_loop.thisIndex'
p8276
g7314
sS'outcome_loop.thisN'
p8277
I60
sS'outcome_loop.thisTrialN'
p8278
I60
sg62
g66
sg33
S'left'
p8279
sS'block_loop.thisN'
p8280
I2
sS'outcome_loop.thisIndex'
p8281
g63
(g96
S'<\x00\x00\x00'
tRp8282
sg30
g8273
sg67
g11
sg68
g69
sg7321
V29-beans.png
p8283
sS'block_loop.thisTrial'
p8284
Nsg60
g61
sS'block_loop.thisTrialN'
p8285
I0
sg34
F0.65269133367655741
sg7325
V29-beans.png
p8286
sa(dp8287
S'block_loop.thisRepN'
p8288
I2
sg7308
V45-chewy_nougat.png
p8289
sg7310
V41-peanuts.png
p8290
sg70
g71
sS'outcome_loop.thisRepN'
p8291
I0
sS'block_loop.thisIndex'
p8292
g7314
sS'outcome_loop.thisN'
p8293
I61
sS'outcome_loop.thisTrialN'
p8294
I61
sg62
g66
sg33
S'right'
p8295
sS'block_loop.thisN'
p8296
I2
sS'outcome_loop.thisIndex'
p8297
g63
(g96
S'=\x00\x00\x00'
tRp8298
sg30
g8289
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p8299
sS'block_loop.thisTrial'
p8300
Nsg60
g61
sS'block_loop.thisTrialN'
p8301
I0
sg34
F0.77260797112467117
sg7325
V45-chewy_nougat.png
p8302
sa(dp8303
S'block_loop.thisRepN'
p8304
I2
sg7308
V13-mccoys_steak_crisps.png
p8305
sg7310
V3-dole_fruit_snack.png
p8306
sg70
g71
sS'outcome_loop.thisRepN'
p8307
I0
sS'block_loop.thisIndex'
p8308
g7314
sS'outcome_loop.thisN'
p8309
I62
sS'outcome_loop.thisTrialN'
p8310
I62
sg62
g66
sg33
S'right'
p8311
sS'block_loop.thisN'
p8312
I2
sS'outcome_loop.thisIndex'
p8313
g63
(g96
S'>\x00\x00\x00'
tRp8314
sg30
V3-dole_fruit_snack.png
p8315
sg67
g11
sg68
g69
sg7321
g8315
sS'block_loop.thisTrial'
p8316
Nsg60
g61
sS'block_loop.thisTrialN'
p8317
I0
sg34
F0.55950686469986977
sg7325
V13-mccoys_steak_crisps.png
p8318
sa(dp8319
S'block_loop.thisRepN'
p8320
I2
sg7308
V42-mrkipling_lemon_slices.png
p8321
sg7310
V42-mrkipling_lemon_slices.png
p8322
sg70
g71
sS'outcome_loop.thisRepN'
p8323
I0
sS'block_loop.thisIndex'
p8324
g7314
sS'outcome_loop.thisN'
p8325
I63
sS'outcome_loop.thisTrialN'
p8326
I63
sg62
g66
sg33
S'left'
p8327
sS'block_loop.thisN'
p8328
I2
sS'outcome_loop.thisIndex'
p8329
g63
(g96
S'?\x00\x00\x00'
tRp8330
sg30
g8321
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p8331
sS'block_loop.thisTrial'
p8332
Nsg60
g61
sS'block_loop.thisTrialN'
p8333
I0
sg34
F0.58614935697005421
sg7325
V16-skips_prawn.png
p8334
sa(dp8335
S'block_loop.thisRepN'
p8336
I2
sg7308
V19-caramello.png
p8337
sg7310
V30-spaghetti_hoops.png
p8338
sg70
g71
sS'outcome_loop.thisRepN'
p8339
I0
sS'block_loop.thisIndex'
p8340
g7314
sS'outcome_loop.thisN'
p8341
I64
sS'outcome_loop.thisTrialN'
p8342
I64
sg62
g66
sg33
S'right'
p8343
sS'block_loop.thisN'
p8344
I2
sS'outcome_loop.thisIndex'
p8345
g63
(g96
S'@\x00\x00\x00'
tRp8346
sg30
g8337
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p8347
sS'block_loop.thisTrial'
p8348
Nsg60
g61
sS'block_loop.thisTrialN'
p8349
I0
sg34
F0.77260573620333162
sg7325
V19-caramello.png
p8350
sa(dp8351
S'block_loop.thisRepN'
p8352
I2
sg7308
V36-fig_rolls.png
p8353
sg7310
V34-hula_hoops_bbq_beef.png
p8354
sg70
g71
sS'outcome_loop.thisRepN'
p8355
I0
sS'block_loop.thisIndex'
p8356
g7314
sS'outcome_loop.thisN'
p8357
I65
sS'outcome_loop.thisTrialN'
p8358
I65
sg62
g66
sg33
S'right'
p8359
sS'block_loop.thisN'
p8360
I2
sS'outcome_loop.thisIndex'
p8361
g63
(g96
S'A\x00\x00\x00'
tRp8362
sg30
g8353
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p8363
sS'block_loop.thisTrial'
p8364
Nsg60
g61
sS'block_loop.thisTrialN'
p8365
I0
sg34
F1.4119171570691833
sg7325
V36-fig_rolls.png
p8366
sa(dp8367
S'block_loop.thisRepN'
p8368
I2
sg7308
V45-chewy_nougat.png
p8369
sg7310
V41-peanuts.png
p8370
sg70
g71
sS'outcome_loop.thisRepN'
p8371
I0
sS'block_loop.thisIndex'
p8372
g7314
sS'outcome_loop.thisN'
p8373
I66
sS'outcome_loop.thisTrialN'
p8374
I66
sg62
g66
sg33
S'right'
p8375
sS'block_loop.thisN'
p8376
I2
sS'outcome_loop.thisIndex'
p8377
g63
(g96
S'B\x00\x00\x00'
tRp8378
sg30
V41-peanuts.png
p8379
sg67
g11
sg68
g69
sg7321
g8379
sS'block_loop.thisTrial'
p8380
Nsg60
g61
sS'block_loop.thisTrialN'
p8381
I0
sg34
F0.75929901705421798
sg7325
V45-chewy_nougat.png
p8382
sa(dp8383
S'block_loop.thisRepN'
p8384
I2
sg7308
V49-yorkie.png
p8385
sg7310
V49-yorkie.png
p8386
sg70
g71
sS'outcome_loop.thisRepN'
p8387
I0
sS'block_loop.thisIndex'
p8388
g7314
sS'outcome_loop.thisN'
p8389
I67
sS'outcome_loop.thisTrialN'
p8390
I67
sg62
g66
sg33
S'left'
p8391
sS'block_loop.thisN'
p8392
I2
sS'outcome_loop.thisIndex'
p8393
g63
(g96
S'C\x00\x00\x00'
tRp8394
sg30
g8385
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p8395
sS'block_loop.thisTrial'
p8396
Nsg60
g61
sS'block_loop.thisTrialN'
p8397
I0
sg34
F0.62611449220457871
sg7325
V35-sultanas.png
p8398
sa(dp8399
S'block_loop.thisRepN'
p8400
I2
sg7308
V17-jacobs_mini_cheddars.png
p8401
sg7310
V8-liquorice_catherine_wheels.png
p8402
sg70
g71
sS'outcome_loop.thisRepN'
p8403
I0
sS'block_loop.thisIndex'
p8404
g7314
sS'outcome_loop.thisN'
p8405
I68
sS'outcome_loop.thisTrialN'
p8406
I68
sg62
g66
sg33
S'right'
p8407
sS'block_loop.thisN'
p8408
I2
sS'outcome_loop.thisIndex'
p8409
g63
(g96
S'D\x00\x00\x00'
tRp8410
sg30
g8401
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p8411
sS'block_loop.thisTrial'
p8412
Nsg60
g61
sS'block_loop.thisTrialN'
p8413
I0
sg34
F0.62610862553628976
sg7325
V17-jacobs_mini_cheddars.png
p8414
sa(dp8415
S'block_loop.thisRepN'
p8416
I2
sg7308
V33-ambrosia_rice.png
p8417
sg7310
V23-crunchie.png
p8418
sg70
g71
sS'outcome_loop.thisRepN'
p8419
I0
sS'block_loop.thisIndex'
p8420
g7314
sS'outcome_loop.thisN'
p8421
I69
sS'outcome_loop.thisTrialN'
p8422
I69
sg62
g66
sg33
S'right'
p8423
sS'block_loop.thisN'
p8424
I2
sS'outcome_loop.thisIndex'
p8425
g63
(g96
S'E\x00\x00\x00'
tRp8426
sg30
g8417
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p8427
sS'block_loop.thisTrial'
p8428
Nsg60
g61
sS'block_loop.thisTrialN'
p8429
I0
sg34
F1.0389817700288404
sg7325
V33-ambrosia_rice.png
p8430
sa(dp8431
S'block_loop.thisRepN'
p8432
I2
sg7308
V4-corn.png
p8433
sg7310
V4-corn.png
p8434
sg70
g71
sS'outcome_loop.thisRepN'
p8435
I0
sS'block_loop.thisIndex'
p8436
g7314
sS'outcome_loop.thisN'
p8437
I70
sS'outcome_loop.thisTrialN'
p8438
I70
sg62
g66
sg33
S'left'
p8439
sS'block_loop.thisN'
p8440
I2
sS'outcome_loop.thisIndex'
p8441
g63
(g96
S'F\x00\x00\x00'
tRp8442
sg30
g8433
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p8443
sS'block_loop.thisTrial'
p8444
Nsg60
g61
sS'block_loop.thisTrialN'
p8445
I0
sg34
F0.78591133789268497
sg7325
V10-bounty.png
p8446
sa(dp8447
S'block_loop.thisRepN'
p8448
I2
sg7308
V1-smarties_cookies.png
p8449
sg7310
V1-smarties_cookies.png
p8450
sg70
g71
sS'outcome_loop.thisRepN'
p8451
I0
sS'block_loop.thisIndex'
p8452
g7314
sS'outcome_loop.thisN'
p8453
I71
sS'outcome_loop.thisTrialN'
p8454
I71
sg62
g66
sg33
S'left'
p8455
sS'block_loop.thisN'
p8456
I2
sS'outcome_loop.thisIndex'
p8457
g63
(g96
S'G\x00\x00\x00'
tRp8458
sg30
g8449
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p8459
sS'block_loop.thisTrial'
p8460
Nsg60
g61
sS'block_loop.thisTrialN'
p8461
I0
sg34
F0.62627987635278259
sg7325
V21-nakd_banana_crunch.png
p8462
sa(dp8463
S'block_loop.thisRepN'
p8464
I2
sg7308
V26-walkers_smoky_bacon.png
p8465
sg7310
V44-crunch.png
p8466
sg70
g71
sS'outcome_loop.thisRepN'
p8467
I0
sS'block_loop.thisIndex'
p8468
g7314
sS'outcome_loop.thisN'
p8469
I72
sS'outcome_loop.thisTrialN'
p8470
I72
sg62
g66
sg33
S'right'
p8471
sS'block_loop.thisN'
p8472
I2
sS'outcome_loop.thisIndex'
p8473
g63
(g96
S'H\x00\x00\x00'
tRp8474
sg30
g8465
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p8475
sS'block_loop.thisTrial'
p8476
Nsg60
g61
sS'block_loop.thisTrialN'
p8477
I0
sg34
F0.53288336925470503
sg7325
V26-walkers_smoky_bacon.png
p8478
sa(dp8479
S'block_loop.thisRepN'
p8480
I2
sg7308
V31-foxs_golden_biscuits.png
p8481
sg7310
V25-kitkat.png
p8482
sg70
g71
sS'outcome_loop.thisRepN'
p8483
I0
sS'block_loop.thisIndex'
p8484
g7314
sS'outcome_loop.thisN'
p8485
I73
sS'outcome_loop.thisTrialN'
p8486
I73
sg62
g66
sg33
S'right'
p8487
sS'block_loop.thisN'
p8488
I2
sS'outcome_loop.thisIndex'
p8489
g63
(g96
S'I\x00\x00\x00'
tRp8490
sg30
g8481
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8491
sS'block_loop.thisTrial'
p8492
Nsg60
g61
sS'block_loop.thisTrialN'
p8493
I0
sg34
F0.69269390383487917
sg7325
V31-foxs_golden_biscuits.png
p8494
sa(dp8495
S'block_loop.thisRepN'
p8496
I2
sg7308
V51-mars.png
p8497
sg7310
V51-mars.png
p8498
sg70
g71
sS'outcome_loop.thisRepN'
p8499
I0
sS'block_loop.thisIndex'
p8500
g7314
sS'outcome_loop.thisN'
p8501
I74
sS'outcome_loop.thisTrialN'
p8502
I74
sg62
g66
sg33
S'left'
p8503
sS'block_loop.thisN'
p8504
I2
sS'outcome_loop.thisIndex'
p8505
g63
(g96
S'J\x00\x00\x00'
tRp8506
sg30
g8497
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p8507
sS'block_loop.thisTrial'
p8508
Nsg60
g61
sS'block_loop.thisTrialN'
p8509
I0
sg34
F0.69269138954769005
sg7325
V27-hartleys_raspberries_jelly.png
p8510
sa(dp8511
S'block_loop.thisRepN'
p8512
I2
sg7308
V13-mccoys_steak_crisps.png
p8513
sg7310
V13-mccoys_steak_crisps.png
p8514
sg70
g71
sS'outcome_loop.thisRepN'
p8515
I0
sS'block_loop.thisIndex'
p8516
g7314
sS'outcome_loop.thisN'
p8517
I75
sS'outcome_loop.thisTrialN'
p8518
I75
sg62
g66
sg33
S'left'
p8519
sS'block_loop.thisN'
p8520
I2
sS'outcome_loop.thisIndex'
p8521
g63
(g96
S'K\x00\x00\x00'
tRp8522
sg30
g8513
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p8523
sS'block_loop.thisTrial'
p8524
Nsg60
g61
sS'block_loop.thisTrialN'
p8525
I0
sg34
F0.51954256756107497
sg7325
V3-dole_fruit_snack.png
p8526
sa(dp8527
S'block_loop.thisRepN'
p8528
I2
sg7308
V7-olives.png
p8529
sg7310
V7-olives.png
p8530
sg70
g71
sS'outcome_loop.thisRepN'
p8531
I0
sS'block_loop.thisIndex'
p8532
g7314
sS'outcome_loop.thisN'
p8533
I76
sS'outcome_loop.thisTrialN'
p8534
I76
sg62
g66
sg33
S'left'
p8535
sS'block_loop.thisN'
p8536
I2
sS'outcome_loop.thisIndex'
p8537
g63
(g96
S'L\x00\x00\x00'
tRp8538
sg30
g8529
sg67
g11
sg68
g69
sg7321
V22-daim.png
p8539
sS'block_loop.thisTrial'
p8540
Nsg60
g61
sS'block_loop.thisTrialN'
p8541
I0
sg34
F0.62608655569238181
sg7325
V22-daim.png
p8542
sa(dp8543
S'block_loop.thisRepN'
p8544
I2
sg7308
V1-smarties_cookies.png
p8545
sg7310
V1-smarties_cookies.png
p8546
sg70
g71
sS'outcome_loop.thisRepN'
p8547
I0
sS'block_loop.thisIndex'
p8548
g7314
sS'outcome_loop.thisN'
p8549
I77
sS'outcome_loop.thisTrialN'
p8550
I77
sg62
g66
sg33
S'left'
p8551
sS'block_loop.thisN'
p8552
I2
sS'outcome_loop.thisIndex'
p8553
g63
(g96
S'M\x00\x00\x00'
tRp8554
sg30
g8545
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p8555
sS'block_loop.thisTrial'
p8556
Nsg60
g61
sS'block_loop.thisTrialN'
p8557
I0
sg34
F0.5861485188761435
sg7325
V21-nakd_banana_crunch.png
p8558
sa(dp8559
S'block_loop.thisRepN'
p8560
I2
sg7308
V33-ambrosia_rice.png
p8561
sg7310
V33-ambrosia_rice.png
p8562
sg70
g71
sS'outcome_loop.thisRepN'
p8563
I0
sS'block_loop.thisIndex'
p8564
g7314
sS'outcome_loop.thisN'
p8565
I78
sS'outcome_loop.thisTrialN'
p8566
I78
sg62
g66
sg33
S'left'
p8567
sS'block_loop.thisN'
p8568
I2
sS'outcome_loop.thisIndex'
p8569
g63
(g96
S'N\x00\x00\x00'
tRp8570
sg30
g8561
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p8571
sS'block_loop.thisTrial'
p8572
Nsg60
g61
sS'block_loop.thisTrialN'
p8573
I0
sg34
F0.81257673810432607
sg7325
V23-crunchie.png
p8574
sa(dp8575
S'block_loop.thisRepN'
p8576
I2
sg7308
V7-olives.png
p8577
sg7310
V22-daim.png
p8578
sg70
g71
sS'outcome_loop.thisRepN'
p8579
I0
sS'block_loop.thisIndex'
p8580
g7314
sS'outcome_loop.thisN'
p8581
I79
sS'outcome_loop.thisTrialN'
p8582
I79
sg62
g66
sg33
S'right'
p8583
sS'block_loop.thisN'
p8584
I2
sS'outcome_loop.thisIndex'
p8585
g63
(g96
S'O\x00\x00\x00'
tRp8586
sg30
g8577
sg67
g11
sg68
g69
sg7321
V22-daim.png
p8587
sS'block_loop.thisTrial'
p8588
Nsg60
g61
sS'block_loop.thisTrialN'
p8589
I0
sg34
F0.78593201091098308
sg7325
V7-olives.png
p8590
sa(dp8591
S'block_loop.thisRepN'
p8592
I2
sg7308
V42-mrkipling_lemon_slices.png
p8593
sg7310
V42-mrkipling_lemon_slices.png
p8594
sg70
g71
sS'outcome_loop.thisRepN'
p8595
I0
sS'block_loop.thisIndex'
p8596
g7314
sS'outcome_loop.thisN'
p8597
I80
sS'outcome_loop.thisTrialN'
p8598
I80
sg62
g66
sg33
S'left'
p8599
sS'block_loop.thisN'
p8600
I2
sS'outcome_loop.thisIndex'
p8601
g63
(g96
S'P\x00\x00\x00'
tRp8602
sg30
g8593
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p8603
sS'block_loop.thisTrial'
p8604
Nsg60
g61
sS'block_loop.thisTrialN'
p8605
I0
sg34
F0.61277005876399926
sg7325
V16-skips_prawn.png
p8606
sa(dp8607
S'block_loop.thisRepN'
p8608
I2
sg7308
V26-walkers_smoky_bacon.png
p8609
sg7310
V44-crunch.png
p8610
sg70
g71
sS'outcome_loop.thisRepN'
p8611
I0
sS'block_loop.thisIndex'
p8612
g7314
sS'outcome_loop.thisN'
p8613
I81
sS'outcome_loop.thisTrialN'
p8614
I81
sg62
g66
sg33
S'right'
p8615
sS'block_loop.thisN'
p8616
I2
sS'outcome_loop.thisIndex'
p8617
g63
(g96
S'Q\x00\x00\x00'
tRp8618
sg30
g8609
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p8619
sS'block_loop.thisTrial'
p8620
Nsg60
g61
sS'block_loop.thisTrialN'
p8621
I0
sg34
F0.50623361349062179
sg7325
V26-walkers_smoky_bacon.png
p8622
sa(dp8623
S'block_loop.thisRepN'
p8624
I2
sg7308
V31-foxs_golden_biscuits.png
p8625
sg7310
V31-foxs_golden_biscuits.png
p8626
sg70
g71
sS'outcome_loop.thisRepN'
p8627
I0
sS'block_loop.thisIndex'
p8628
g7314
sS'outcome_loop.thisN'
p8629
I82
sS'outcome_loop.thisTrialN'
p8630
I82
sg62
g66
sg33
S'left'
p8631
sS'block_loop.thisN'
p8632
I2
sS'outcome_loop.thisIndex'
p8633
g63
(g96
S'R\x00\x00\x00'
tRp8634
sg30
g8625
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8635
sS'block_loop.thisTrial'
p8636
Nsg60
g61
sS'block_loop.thisTrialN'
p8637
I0
sg34
F0.49291236735371058
sg7325
V25-kitkat.png
p8638
sa(dp8639
S'block_loop.thisRepN'
p8640
I2
sg7308
V36-fig_rolls.png
p8641
sg7310
V36-fig_rolls.png
p8642
sg70
g71
sS'outcome_loop.thisRepN'
p8643
I0
sS'block_loop.thisIndex'
p8644
g7314
sS'outcome_loop.thisN'
p8645
I83
sS'outcome_loop.thisTrialN'
p8646
I83
sg62
g66
sg33
S'left'
p8647
sS'block_loop.thisN'
p8648
I2
sS'outcome_loop.thisIndex'
p8649
g63
(g96
S'S\x00\x00\x00'
tRp8650
sg30
V34-hula_hoops_bbq_beef.png
p8651
sg67
g11
sg68
g69
sg7321
g8651
sS'block_loop.thisTrial'
p8652
Nsg60
g61
sS'block_loop.thisTrialN'
p8653
I0
sg34
F0.6660553226738557
sg7325
V34-hula_hoops_bbq_beef.png
p8654
sa(dp8655
S'block_loop.thisRepN'
p8656
I2
sg7308
V45-chewy_nougat.png
p8657
sg7310
V45-chewy_nougat.png
p8658
sg70
g71
sS'outcome_loop.thisRepN'
p8659
I0
sS'block_loop.thisIndex'
p8660
g7314
sS'outcome_loop.thisN'
p8661
I84
sS'outcome_loop.thisTrialN'
p8662
I84
sg62
g66
sg33
S'left'
p8663
sS'block_loop.thisN'
p8664
I2
sS'outcome_loop.thisIndex'
p8665
g63
(g96
S'T\x00\x00\x00'
tRp8666
sg30
g8657
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p8667
sS'block_loop.thisTrial'
p8668
Nsg60
g61
sS'block_loop.thisTrialN'
p8669
I0
sg34
F0.54619818999344716
sg7325
V41-peanuts.png
p8670
sa(dp8671
S'block_loop.thisRepN'
p8672
I2
sg7308
V19-caramello.png
p8673
sg7310
V19-caramello.png
p8674
sg70
g71
sS'outcome_loop.thisRepN'
p8675
I0
sS'block_loop.thisIndex'
p8676
g7314
sS'outcome_loop.thisN'
p8677
I85
sS'outcome_loop.thisTrialN'
p8678
I85
sg62
g66
sg33
S'left'
p8679
sS'block_loop.thisN'
p8680
I2
sS'outcome_loop.thisIndex'
p8681
g63
(g96
S'U\x00\x00\x00'
tRp8682
sg30
V30-spaghetti_hoops.png
p8683
sg67
g11
sg68
g69
sg7321
g8683
sS'block_loop.thisTrial'
p8684
Nsg60
g61
sS'block_loop.thisTrialN'
p8685
I0
sg34
F0.75928728371945908
sg7325
V30-spaghetti_hoops.png
p8686
sa(dp8687
S'block_loop.thisRepN'
p8688
I2
sg7308
V49-yorkie.png
p8689
sg7310
V35-sultanas.png
p8690
sg70
g71
sS'outcome_loop.thisRepN'
p8691
I0
sS'block_loop.thisIndex'
p8692
g7314
sS'outcome_loop.thisN'
p8693
I86
sS'outcome_loop.thisTrialN'
p8694
I86
sg62
g66
sg33
S'right'
p8695
sS'block_loop.thisN'
p8696
I2
sS'outcome_loop.thisIndex'
p8697
g63
(g96
S'V\x00\x00\x00'
tRp8698
sg30
g8689
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p8699
sS'block_loop.thisTrial'
p8700
Nsg60
g61
sS'block_loop.thisTrialN'
p8701
I0
sg34
F0.70599168330045359
sg7325
V49-yorkie.png
p8702
sa(dp8703
S'block_loop.thisRepN'
p8704
I2
sg7308
V46-pistachios.png
p8705
sg7310
V29-beans.png
p8706
sg70
g71
sS'outcome_loop.thisRepN'
p8707
I0
sS'block_loop.thisIndex'
p8708
g7314
sS'outcome_loop.thisN'
p8709
I87
sS'outcome_loop.thisTrialN'
p8710
I87
sg62
g66
sg33
S'right'
p8711
sS'block_loop.thisN'
p8712
I2
sS'outcome_loop.thisIndex'
p8713
g63
(g96
S'W\x00\x00\x00'
tRp8714
sg30
g8705
sg67
g11
sg68
g69
sg7321
V29-beans.png
p8715
sS'block_loop.thisTrial'
p8716
Nsg60
g61
sS'block_loop.thisTrialN'
p8717
I0
sg34
F0.63941925580002135
sg7325
V46-pistachios.png
p8718
sa(dp8719
S'block_loop.thisRepN'
p8720
I2
sg7308
V6-sour_patch_kids.png
p8721
sg7310
V6-sour_patch_kids.png
p8722
sg70
g71
sS'outcome_loop.thisRepN'
p8723
I0
sS'block_loop.thisIndex'
p8724
g7314
sS'outcome_loop.thisN'
p8725
I88
sS'outcome_loop.thisTrialN'
p8726
I88
sg62
g66
sg33
S'right'
p8727
sS'block_loop.thisN'
p8728
I2
sS'outcome_loop.thisIndex'
p8729
g63
(g96
S'X\x00\x00\x00'
tRp8730
sg30
g8721
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p8731
sS'block_loop.thisTrial'
p8732
Nsg60
g61
sS'block_loop.thisTrialN'
p8733
I0
sg34
F0.66606370362751477
sg7325
V38-maltesers.png
p8734
sa(dp8735
S'block_loop.thisRepN'
p8736
I2
sg7308
V5-pineapple.png
p8737
sg7310
V40-sardines.png
p8738
sg70
g71
sS'outcome_loop.thisRepN'
p8739
I0
sS'block_loop.thisIndex'
p8740
g7314
sS'outcome_loop.thisN'
p8741
I89
sS'outcome_loop.thisTrialN'
p8742
I89
sg62
g66
sg33
S'right'
p8743
sS'block_loop.thisN'
p8744
I2
sS'outcome_loop.thisIndex'
p8745
g63
(g96
S'Y\x00\x00\x00'
tRp8746
sg30
V40-sardines.png
p8747
sg67
g11
sg68
g69
sg7321
g8747
sS'block_loop.thisTrial'
p8748
Nsg60
g61
sS'block_loop.thisTrialN'
p8749
I0
sg34
F1.0522890479096532
sg7325
V5-pineapple.png
p8750
sa(dp8751
S'block_loop.thisRepN'
p8752
I2
sg7308
V17-jacobs_mini_cheddars.png
p8753
sg7310
V17-jacobs_mini_cheddars.png
p8754
sg70
g71
sS'outcome_loop.thisRepN'
p8755
I0
sS'block_loop.thisIndex'
p8756
g7314
sS'outcome_loop.thisN'
p8757
I90
sS'outcome_loop.thisTrialN'
p8758
I90
sg62
g66
sg33
S'left'
p8759
sS'block_loop.thisN'
p8760
I2
sS'outcome_loop.thisIndex'
p8761
g63
(g96
S'Z\x00\x00\x00'
tRp8762
sg30
g8753
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p8763
sS'block_loop.thisTrial'
p8764
Nsg60
g61
sS'block_loop.thisTrialN'
p8765
I0
sg34
F0.69270228478853824
sg7325
V8-liquorice_catherine_wheels.png
p8766
sa(dp8767
S'block_loop.thisRepN'
p8768
I2
sg7308
V4-corn.png
p8769
sg7310
V10-bounty.png
p8770
sg70
g71
sS'outcome_loop.thisRepN'
p8771
I0
sS'block_loop.thisIndex'
p8772
g7314
sS'outcome_loop.thisN'
p8773
I91
sS'outcome_loop.thisTrialN'
p8774
I91
sg62
g66
sg33
S'right'
p8775
sS'block_loop.thisN'
p8776
I2
sS'outcome_loop.thisIndex'
p8777
g63
(g96
S'[\x00\x00\x00'
tRp8778
sg30
g8769
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p8779
sS'block_loop.thisTrial'
p8780
Nsg60
g61
sS'block_loop.thisTrialN'
p8781
I0
sg34
F0.65274329558633326
sg7325
V4-corn.png
p8782
sa(dp8783
S'block_loop.thisRepN'
p8784
I2
sg7308
V48-twix.png
p8785
sg7310
V50-polo.png
p8786
sg70
g71
sS'outcome_loop.thisRepN'
p8787
I0
sS'block_loop.thisIndex'
p8788
g7314
sS'outcome_loop.thisN'
p8789
I92
sS'outcome_loop.thisTrialN'
p8790
I92
sg62
g66
sg33
S'right'
p8791
sS'block_loop.thisN'
p8792
I2
sS'outcome_loop.thisIndex'
p8793
g63
(g96
S'\\\x00\x00\x00'
tRp8794
sg30
g8785
sg67
g11
sg68
g69
sg7321
V50-polo.png
p8795
sS'block_loop.thisTrial'
p8796
Nsg60
g61
sS'block_loop.thisTrialN'
p8797
I0
sg34
F1.1988261077876814
sg7325
V48-twix.png
p8798
sa(dp8799
S'block_loop.thisRepN'
p8800
I2
sg7308
V36-fig_rolls.png
p8801
sg7310
V36-fig_rolls.png
p8802
sg70
g71
sS'outcome_loop.thisRepN'
p8803
I0
sS'block_loop.thisIndex'
p8804
g7314
sS'outcome_loop.thisN'
p8805
I93
sS'outcome_loop.thisTrialN'
p8806
I93
sg62
g66
sg33
S'left'
p8807
sS'block_loop.thisN'
p8808
I2
sS'outcome_loop.thisIndex'
p8809
g63
(g96
S']\x00\x00\x00'
tRp8810
sg30
g8801
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p8811
sS'block_loop.thisTrial'
p8812
Nsg60
g61
sS'block_loop.thisTrialN'
p8813
I0
sg34
F0.67936986404674826
sg7325
V34-hula_hoops_bbq_beef.png
p8814
sa(dp8815
S'block_loop.thisRepN'
p8816
I2
sg7308
V4-corn.png
p8817
sg7310
V4-corn.png
p8818
sg70
g71
sS'outcome_loop.thisRepN'
p8819
I0
sS'block_loop.thisIndex'
p8820
g7314
sS'outcome_loop.thisN'
p8821
I94
sS'outcome_loop.thisTrialN'
p8822
I94
sg62
g66
sg33
S'left'
p8823
sS'block_loop.thisN'
p8824
I2
sS'outcome_loop.thisIndex'
p8825
g63
(g96
S'^\x00\x00\x00'
tRp8826
sg30
g8817
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p8827
sS'block_loop.thisTrial'
p8828
Nsg60
g61
sS'block_loop.thisTrialN'
p8829
I0
sg34
F0.78593284900671279
sg7325
V10-bounty.png
p8830
sa(dp8831
S'block_loop.thisRepN'
p8832
I2
sg7308
V31-foxs_golden_biscuits.png
p8833
sg7310
V31-foxs_golden_biscuits.png
p8834
sg70
g71
sS'outcome_loop.thisRepN'
p8835
I0
sS'block_loop.thisIndex'
p8836
g7314
sS'outcome_loop.thisN'
p8837
I95
sS'outcome_loop.thisTrialN'
p8838
I95
sg62
g66
sg33
S'left'
p8839
sS'block_loop.thisN'
p8840
I2
sS'outcome_loop.thisIndex'
p8841
g63
(g96
S'_\x00\x00\x00'
tRp8842
sg30
g8833
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8843
sS'block_loop.thisTrial'
p8844
Nsg60
g61
sS'block_loop.thisTrialN'
p8845
I0
sg34
F0.67937880373028747
sg7325
V25-kitkat.png
p8846
sa(dp8847
S'block_loop.thisRepN'
p8848
I2
sg7308
V5-pineapple.png
p8849
sg7310
V40-sardines.png
p8850
sg70
g71
sS'outcome_loop.thisRepN'
p8851
I0
sS'block_loop.thisIndex'
p8852
g7314
sS'outcome_loop.thisN'
p8853
I96
sS'outcome_loop.thisTrialN'
p8854
I96
sg62
g66
sg33
S'right'
p8855
sS'block_loop.thisN'
p8856
I2
sS'outcome_loop.thisIndex'
p8857
g63
(g96
S'`\x00\x00\x00'
tRp8858
sg30
g8849
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p8859
sS'block_loop.thisTrial'
p8860
Nsg60
g61
sS'block_loop.thisTrialN'
p8861
I0
sg34
F0.70601459124009125
sg7325
V5-pineapple.png
p8862
sa(dp8863
S'block_loop.thisRepN'
p8864
I2
sg7308
V13-mccoys_steak_crisps.png
p8865
sg7310
V3-dole_fruit_snack.png
p8866
sg70
g71
sS'outcome_loop.thisRepN'
p8867
I0
sS'block_loop.thisIndex'
p8868
g7314
sS'outcome_loop.thisN'
p8869
I97
sS'outcome_loop.thisTrialN'
p8870
I97
sg62
g66
sg33
S'right'
p8871
sS'block_loop.thisN'
p8872
I2
sS'outcome_loop.thisIndex'
p8873
g63
(g96
S'a\x00\x00\x00'
tRp8874
sg30
g8865
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p8875
sS'block_loop.thisTrial'
p8876
Nsg60
g61
sS'block_loop.thisTrialN'
p8877
I0
sg34
F0.63942204944942205
sg7325
V13-mccoys_steak_crisps.png
p8878
sa(dp8879
S'block_loop.thisRepN'
p8880
I2
sg7308
V31-foxs_golden_biscuits.png
p8881
sg7310
V25-kitkat.png
p8882
sg70
g71
sS'outcome_loop.thisRepN'
p8883
I0
sS'block_loop.thisIndex'
p8884
g7314
sS'outcome_loop.thisN'
p8885
I98
sS'outcome_loop.thisTrialN'
p8886
I98
sg62
g66
sg33
S'right'
p8887
sS'block_loop.thisN'
p8888
I2
sS'outcome_loop.thisIndex'
p8889
g63
(g96
S'b\x00\x00\x00'
tRp8890
sg30
g8881
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8891
sS'block_loop.thisTrial'
p8892
Nsg60
g61
sS'block_loop.thisTrialN'
p8893
I0
sg34
F0.54618505983307841
sg7325
V31-foxs_golden_biscuits.png
p8894
sa(dp8895
S'block_loop.thisRepN'
p8896
I2
sg7308
V20-fruit_pastilles.png
p8897
sg7310
V20-fruit_pastilles.png
p8898
sg70
g71
sS'outcome_loop.thisRepN'
p8899
I0
sS'block_loop.thisIndex'
p8900
g7314
sS'outcome_loop.thisN'
p8901
I99
sS'outcome_loop.thisTrialN'
p8902
I99
sg62
g66
sg33
S'left'
p8903
sS'block_loop.thisN'
p8904
I2
sS'outcome_loop.thisIndex'
p8905
g63
(g96
S'c\x00\x00\x00'
tRp8906
sg30
g8897
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p8907
sS'block_loop.thisTrial'
p8908
Nsg60
g61
sS'block_loop.thisTrialN'
p8909
I0
sg34
F0.82589183820709877
sg7325
V2-steamed_puddings.png
p8910
sa(dp8911
S'block_loop.thisRepN'
p8912
I2
sg7308
V26-walkers_smoky_bacon.png
p8913
sg7310
V26-walkers_smoky_bacon.png
p8914
sg70
g71
sS'outcome_loop.thisRepN'
p8915
I0
sS'block_loop.thisIndex'
p8916
g7314
sS'outcome_loop.thisN'
p8917
I100
sS'outcome_loop.thisTrialN'
p8918
I100
sg62
g66
sg33
S'left'
p8919
sS'block_loop.thisN'
p8920
I2
sS'outcome_loop.thisIndex'
p8921
g63
(g96
S'd\x00\x00\x00'
tRp8922
sg30
g8913
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p8923
sS'block_loop.thisTrial'
p8924
Nsg60
g61
sS'block_loop.thisTrialN'
p8925
I0
sg34
F0.54619288205685734
sg7325
V44-crunch.png
p8926
sa(dp8927
S'block_loop.thisRepN'
p8928
I2
sg7308
V31-foxs_golden_biscuits.png
p8929
sg7310
V25-kitkat.png
p8930
sg70
g71
sS'outcome_loop.thisRepN'
p8931
I0
sS'block_loop.thisIndex'
p8932
g7314
sS'outcome_loop.thisN'
p8933
I101
sS'outcome_loop.thisTrialN'
p8934
I101
sg62
g66
sg33
S'right'
p8935
sS'block_loop.thisN'
p8936
I2
sS'outcome_loop.thisIndex'
p8937
g63
(g96
S'e\x00\x00\x00'
tRp8938
sg30
g8929
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p8939
sS'block_loop.thisTrial'
p8940
Nsg60
g61
sS'block_loop.thisTrialN'
p8941
I0
sg34
F0.59946920628135558
sg7325
V31-foxs_golden_biscuits.png
p8942
sa(dp8943
S'block_loop.thisRepN'
p8944
I2
sg7308
V48-twix.png
p8945
sg7310
V48-twix.png
p8946
sg70
g71
sS'outcome_loop.thisRepN'
p8947
I0
sS'block_loop.thisIndex'
p8948
g7314
sS'outcome_loop.thisN'
p8949
I102
sS'outcome_loop.thisTrialN'
p8950
I102
sg62
g66
sg33
S'left'
p8951
sS'block_loop.thisN'
p8952
I2
sS'outcome_loop.thisIndex'
p8953
g63
(g96
S'f\x00\x00\x00'
tRp8954
sg30
V50-polo.png
p8955
sg67
g11
sg68
g69
sg7321
g8955
sS'block_loop.thisTrial'
p8956
Nsg60
g61
sS'block_loop.thisTrialN'
p8957
I0
sg34
F0.57282364099228289
sg7325
V50-polo.png
p8958
sa(dp8959
S'block_loop.thisRepN'
p8960
I2
sg7308
V49-yorkie.png
p8961
sg7310
V35-sultanas.png
p8962
sg70
g71
sS'outcome_loop.thisRepN'
p8963
I0
sS'block_loop.thisIndex'
p8964
g7314
sS'outcome_loop.thisN'
p8965
I103
sS'outcome_loop.thisTrialN'
p8966
I103
sg62
g66
sg33
S'right'
p8967
sS'block_loop.thisN'
p8968
I2
sS'outcome_loop.thisIndex'
p8969
g63
(g96
S'g\x00\x00\x00'
tRp8970
sg30
V35-sultanas.png
p8971
sg67
g11
sg68
g69
sg7321
g8971
sS'block_loop.thisTrial'
p8972
Nsg60
g61
sS'block_loop.thisTrialN'
p8973
I0
sg34
F0.86583909407454485
sg7325
V49-yorkie.png
p8974
sa(dp8975
S'block_loop.thisRepN'
p8976
I2
sg7308
V17-jacobs_mini_cheddars.png
p8977
sg7310
V8-liquorice_catherine_wheels.png
p8978
sg70
g71
sS'outcome_loop.thisRepN'
p8979
I0
sS'block_loop.thisIndex'
p8980
g7314
sS'outcome_loop.thisN'
p8981
I104
sS'outcome_loop.thisTrialN'
p8982
I104
sg62
g66
sg33
S'right'
p8983
sS'block_loop.thisN'
p8984
I2
sS'outcome_loop.thisIndex'
p8985
g63
(g96
S'h\x00\x00\x00'
tRp8986
sg30
g8977
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p8987
sS'block_loop.thisTrial'
p8988
Nsg60
g61
sS'block_loop.thisTrialN'
p8989
I0
sg34
F0.95908278845490713
sg7325
V17-jacobs_mini_cheddars.png
p8990
sa(dp8991
S'block_loop.thisRepN'
p8992
I2
sg7308
V1-smarties_cookies.png
p8993
sg7310
V1-smarties_cookies.png
p8994
sg70
g71
sS'outcome_loop.thisRepN'
p8995
I0
sS'block_loop.thisIndex'
p8996
g7314
sS'outcome_loop.thisN'
p8997
I105
sS'outcome_loop.thisTrialN'
p8998
I105
sg62
g66
sg33
S'left'
p8999
sS'block_loop.thisN'
p9000
I2
sS'outcome_loop.thisIndex'
p9001
g63
(g96
S'i\x00\x00\x00'
tRp9002
sg30
g8993
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p9003
sS'block_loop.thisTrial'
p9004
Nsg60
g61
sS'block_loop.thisTrialN'
p9005
I0
sg34
F0.47959223867837864
sg7325
V21-nakd_banana_crunch.png
p9006
sa(dp9007
S'block_loop.thisRepN'
p9008
I2
sg7308
V36-fig_rolls.png
p9009
sg7310
V36-fig_rolls.png
p9010
sg70
g71
sS'outcome_loop.thisRepN'
p9011
I0
sS'block_loop.thisIndex'
p9012
g7314
sS'outcome_loop.thisN'
p9013
I106
sS'outcome_loop.thisTrialN'
p9014
I106
sg62
g66
sg33
S'left'
p9015
sS'block_loop.thisN'
p9016
I2
sS'outcome_loop.thisIndex'
p9017
g63
(g96
S'j\x00\x00\x00'
tRp9018
sg30
g9009
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p9019
sS'block_loop.thisTrial'
p9020
Nsg60
g61
sS'block_loop.thisTrialN'
p9021
I0
sg34
F0.57282028861118306
sg7325
V34-hula_hoops_bbq_beef.png
p9022
sa(dp9023
S'block_loop.thisRepN'
p9024
I2
sg7308
V6-sour_patch_kids.png
p9025
sg7310
V38-maltesers.png
p9026
sg70
g71
sS'outcome_loop.thisRepN'
p9027
I0
sS'block_loop.thisIndex'
p9028
g7314
sS'outcome_loop.thisN'
p9029
I107
sS'outcome_loop.thisTrialN'
p9030
I107
sg62
g66
sg33
S'left'
p9031
sS'block_loop.thisN'
p9032
I2
sS'outcome_loop.thisIndex'
p9033
g63
(g96
S'k\x00\x00\x00'
tRp9034
sg30
V38-maltesers.png
p9035
sg67
g11
sg68
g69
sg7321
g9035
sS'block_loop.thisTrial'
p9036
Nsg60
g61
sS'block_loop.thisTrialN'
p9037
I0
sg34
F0.81257254762749653
sg7325
V6-sour_patch_kids.png
p9038
sa(dp9039
S'block_loop.thisRepN'
p9040
I2
sg7308
V43-mrporky_pork_crackles.png
p9041
sg7310
V43-mrporky_pork_crackles.png
p9042
sg70
g71
sS'outcome_loop.thisRepN'
p9043
I0
sS'block_loop.thisIndex'
p9044
g7314
sS'outcome_loop.thisN'
p9045
I108
sS'outcome_loop.thisTrialN'
p9046
I108
sg62
g66
sg33
S'left'
p9047
sS'block_loop.thisN'
p9048
I2
sS'outcome_loop.thisIndex'
p9049
g63
(g96
S'l\x00\x00\x00'
tRp9050
sg30
V18-mms.png
p9051
sg67
g11
sg68
g69
sg7321
g9051
sS'block_loop.thisTrial'
p9052
Nsg60
g61
sS'block_loop.thisTrialN'
p9053
I0
sg34
F0.62609828902714071
sg7325
V18-mms.png
p9054
sa(dp9055
S'block_loop.thisRepN'
p9056
I2
sg7308
V42-mrkipling_lemon_slices.png
p9057
sg7310
V16-skips_prawn.png
p9058
sg70
g71
sS'outcome_loop.thisRepN'
p9059
I0
sS'block_loop.thisIndex'
p9060
g7314
sS'outcome_loop.thisN'
p9061
I109
sS'outcome_loop.thisTrialN'
p9062
I109
sg62
g66
sg33
S'left'
p9063
sS'block_loop.thisN'
p9064
I2
sS'outcome_loop.thisIndex'
p9065
g63
(g96
S'm\x00\x00\x00'
tRp9066
sg30
g9057
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p9067
sS'block_loop.thisTrial'
p9068
Nsg60
g61
sS'block_loop.thisTrialN'
p9069
I0
sg34
F0.5195495516891242
sg7325
V42-mrkipling_lemon_slices.png
p9070
sa(dp9071
S'block_loop.thisRepN'
p9072
I2
sg7308
V49-yorkie.png
p9073
sg7310
V49-yorkie.png
p9074
sg70
g71
sS'outcome_loop.thisRepN'
p9075
I0
sS'block_loop.thisIndex'
p9076
g7314
sS'outcome_loop.thisN'
p9077
I110
sS'outcome_loop.thisTrialN'
p9078
I110
sg62
g66
sg33
S'left'
p9079
sS'block_loop.thisN'
p9080
I2
sS'outcome_loop.thisIndex'
p9081
g63
(g96
S'n\x00\x00\x00'
tRp9082
sg30
g9073
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p9083
sS'block_loop.thisTrial'
p9084
Nsg60
g61
sS'block_loop.thisTrialN'
p9085
I0
sg34
F0.61278011590729875
sg7325
V35-sultanas.png
p9086
sa(dp9087
S'block_loop.thisRepN'
p9088
I2
sg7308
V13-mccoys_steak_crisps.png
p9089
sg7310
V13-mccoys_steak_crisps.png
p9090
sg70
g71
sS'outcome_loop.thisRepN'
p9091
I0
sS'block_loop.thisIndex'
p9092
g7314
sS'outcome_loop.thisN'
p9093
I111
sS'outcome_loop.thisTrialN'
p9094
I111
sg62
g66
sg33
S'left'
p9095
sS'block_loop.thisN'
p9096
I2
sS'outcome_loop.thisIndex'
p9097
g63
(g96
S'o\x00\x00\x00'
tRp9098
sg30
g9089
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p9099
sS'block_loop.thisTrial'
p9100
Nsg60
g61
sS'block_loop.thisTrialN'
p9101
I0
sg34
F0.63942568119819043
sg7325
V3-dole_fruit_snack.png
p9102
sa(dp9103
S'block_loop.thisRepN'
p9104
I2
sg7308
V17-jacobs_mini_cheddars.png
p9105
sg7310
V17-jacobs_mini_cheddars.png
p9106
sg70
g71
sS'outcome_loop.thisRepN'
p9107
I0
sS'block_loop.thisIndex'
p9108
g7314
sS'outcome_loop.thisN'
p9109
I112
sS'outcome_loop.thisTrialN'
p9110
I112
sg62
g66
sg33
S'left'
p9111
sS'block_loop.thisN'
p9112
I2
sS'outcome_loop.thisIndex'
p9113
g63
(g96
S'p\x00\x00\x00'
tRp9114
sg30
V8-liquorice_catherine_wheels.png
p9115
sg67
g11
sg68
g69
sg7321
g9115
sS'block_loop.thisTrial'
p9116
Nsg60
g61
sS'block_loop.thisTrialN'
p9117
I0
sg34
F0.89258802445692709
sg7325
V8-liquorice_catherine_wheels.png
p9118
sa(dp9119
S'block_loop.thisRepN'
p9120
I2
sg7308
V46-pistachios.png
p9121
sg7310
V29-beans.png
p9122
sg70
g71
sS'outcome_loop.thisRepN'
p9123
I0
sS'block_loop.thisIndex'
p9124
g7314
sS'outcome_loop.thisN'
p9125
I113
sS'outcome_loop.thisTrialN'
p9126
I113
sg62
g66
sg33
S'right'
p9127
sS'block_loop.thisN'
p9128
I2
sS'outcome_loop.thisIndex'
p9129
g63
(g96
S'q\x00\x00\x00'
tRp9130
sg30
g9121
sg67
g11
sg68
g69
sg7321
V29-beans.png
p9131
sS'block_loop.thisTrial'
p9132
Nsg60
g61
sS'block_loop.thisTrialN'
p9133
I0
sg34
F0.77261299969723041
sg7325
V46-pistachios.png
p9134
sa(dp9135
S'block_loop.thisRepN'
p9136
I2
sg7308
V20-fruit_pastilles.png
p9137
sg7310
V20-fruit_pastilles.png
p9138
sg70
g71
sS'outcome_loop.thisRepN'
p9139
I0
sS'block_loop.thisIndex'
p9140
g7314
sS'outcome_loop.thisN'
p9141
I114
sS'outcome_loop.thisTrialN'
p9142
I114
sg62
g66
sg33
S'left'
p9143
sS'block_loop.thisN'
p9144
I2
sS'outcome_loop.thisIndex'
p9145
g63
(g96
S'r\x00\x00\x00'
tRp9146
sg30
g9137
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p9147
sS'block_loop.thisTrial'
p9148
Nsg60
g61
sS'block_loop.thisTrialN'
p9149
I0
sg34
F0.79924096498325525
sg7325
V2-steamed_puddings.png
p9150
sa(dp9151
S'block_loop.thisRepN'
p9152
I2
sg7308
V45-chewy_nougat.png
p9153
sg7310
V45-chewy_nougat.png
p9154
sg70
g71
sS'outcome_loop.thisRepN'
p9155
I0
sS'block_loop.thisIndex'
p9156
g7314
sS'outcome_loop.thisN'
p9157
I115
sS'outcome_loop.thisTrialN'
p9158
I115
sg62
g66
sg33
S'left'
p9159
sS'block_loop.thisN'
p9160
I2
sS'outcome_loop.thisIndex'
p9161
g63
(g96
S's\x00\x00\x00'
tRp9162
sg30
V41-peanuts.png
p9163
sg67
g11
sg68
g69
sg7321
g9163
sS'block_loop.thisTrial'
p9164
Nsg60
g61
sS'block_loop.thisTrialN'
p9165
I0
sg34
F0.86587513217455125
sg7325
V41-peanuts.png
p9166
sa(dp9167
S'block_loop.thisRepN'
p9168
I2
sg7308
V33-ambrosia_rice.png
p9169
sg7310
V33-ambrosia_rice.png
p9170
sg70
g71
sS'outcome_loop.thisRepN'
p9171
I0
sS'block_loop.thisIndex'
p9172
g7314
sS'outcome_loop.thisN'
p9173
I116
sS'outcome_loop.thisTrialN'
p9174
I116
sg62
g66
sg33
S'left'
p9175
sS'block_loop.thisN'
p9176
I2
sS'outcome_loop.thisIndex'
p9177
g63
(g96
S't\x00\x00\x00'
tRp9178
sg30
g9169
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p9179
sS'block_loop.thisTrial'
p9180
Nsg60
g61
sS'block_loop.thisTrialN'
p9181
I0
sg34
F0.94575930739847536
sg7325
V23-crunchie.png
p9182
sa(dp9183
S'block_loop.thisRepN'
p9184
I2
sg7308
V42-mrkipling_lemon_slices.png
p9185
sg7310
V16-skips_prawn.png
p9186
sg70
g71
sS'outcome_loop.thisRepN'
p9187
I0
sS'block_loop.thisIndex'
p9188
g7314
sS'outcome_loop.thisN'
p9189
I117
sS'outcome_loop.thisTrialN'
p9190
I117
sg62
g66
sg33
S'right'
p9191
sS'block_loop.thisN'
p9192
I2
sS'outcome_loop.thisIndex'
p9193
g63
(g96
S'u\x00\x00\x00'
tRp9194
sg30
g9185
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p9195
sS'block_loop.thisTrial'
p9196
Nsg60
g61
sS'block_loop.thisTrialN'
p9197
I0
sg34
F0.81257394445492537
sg7325
V42-mrkipling_lemon_slices.png
p9198
sa(dp9199
S'block_loop.thisRepN'
p9200
I2
sg7308
V45-chewy_nougat.png
p9201
sg7310
V45-chewy_nougat.png
p9202
sg70
g71
sS'outcome_loop.thisRepN'
p9203
I0
sS'block_loop.thisIndex'
p9204
g7314
sS'outcome_loop.thisN'
p9205
I118
sS'outcome_loop.thisTrialN'
p9206
I118
sg62
g66
sg33
S'left'
p9207
sS'block_loop.thisN'
p9208
I2
sS'outcome_loop.thisIndex'
p9209
g63
(g96
S'v\x00\x00\x00'
tRp9210
sg30
g9201
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p9211
sS'block_loop.thisTrial'
p9212
Nsg60
g61
sS'block_loop.thisTrialN'
p9213
I0
sg34
F0.61278542384570756
sg7325
V41-peanuts.png
p9214
sa(dp9215
S'block_loop.thisRepN'
p9216
I2
sg7308
V7-olives.png
p9217
sg7310
V7-olives.png
p9218
sg70
g71
sS'outcome_loop.thisRepN'
p9219
I0
sS'block_loop.thisIndex'
p9220
g7314
sS'outcome_loop.thisN'
p9221
I119
sS'outcome_loop.thisTrialN'
p9222
I119
sg62
g66
sg33
S'left'
p9223
sS'block_loop.thisN'
p9224
I2
sS'outcome_loop.thisIndex'
p9225
g63
(g96
S'w\x00\x00\x00'
tRp9226
sg30
g9217
sg67
g11
sg68
g69
sg7321
V22-daim.png
p9227
sS'block_loop.thisTrial'
p9228
Nsg60
g61
sS'block_loop.thisTrialN'
p9229
I0
sg34
F0.66603967822629784
sg7325
V22-daim.png
p9230
sa(dp9231
S'block_loop.thisRepN'
p9232
I2
sg7308
V20-fruit_pastilles.png
p9233
sg7310
V2-steamed_puddings.png
p9234
sg70
g71
sS'outcome_loop.thisRepN'
p9235
I0
sS'block_loop.thisIndex'
p9236
g7314
sS'outcome_loop.thisN'
p9237
I120
sS'outcome_loop.thisTrialN'
p9238
I120
sg62
g66
sg33
S'right'
p9239
sS'block_loop.thisN'
p9240
I2
sS'outcome_loop.thisIndex'
p9241
g63
(g96
S'x\x00\x00\x00'
tRp9242
sg30
g9233
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p9243
sS'block_loop.thisTrial'
p9244
Nsg60
g61
sS'block_loop.thisTrialN'
p9245
I0
sg34
F0.59946110469354608
sg7325
V20-fruit_pastilles.png
p9246
sa(dp9247
S'block_loop.thisRepN'
p9248
I2
sg7308
V51-mars.png
p9249
sg7310
V51-mars.png
p9250
sg70
g71
sS'outcome_loop.thisRepN'
p9251
I0
sS'block_loop.thisIndex'
p9252
g7314
sS'outcome_loop.thisN'
p9253
I121
sS'outcome_loop.thisTrialN'
p9254
I121
sg62
g66
sg33
S'left'
p9255
sS'block_loop.thisN'
p9256
I2
sS'outcome_loop.thisIndex'
p9257
g63
(g96
S'y\x00\x00\x00'
tRp9258
sg30
g9249
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p9259
sS'block_loop.thisTrial'
p9260
Nsg60
g61
sS'block_loop.thisTrialN'
p9261
I0
sg34
F0.93245063269205275
sg7325
V27-hartleys_raspberries_jelly.png
p9262
sa(dp9263
S'block_loop.thisRepN'
p9264
I2
sg7308
V17-jacobs_mini_cheddars.png
p9265
sg7310
V17-jacobs_mini_cheddars.png
p9266
sg70
g71
sS'outcome_loop.thisRepN'
p9267
I0
sS'block_loop.thisIndex'
p9268
g7314
sS'outcome_loop.thisN'
p9269
I122
sS'outcome_loop.thisTrialN'
p9270
I122
sg62
g66
sg33
S'left'
p9271
sS'block_loop.thisN'
p9272
I2
sS'outcome_loop.thisIndex'
p9273
g63
(g96
S'z\x00\x00\x00'
tRp9274
sg30
g9265
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p9275
sS'block_loop.thisTrial'
p9276
Nsg60
g61
sS'block_loop.thisTrialN'
p9277
I0
sg34
F0.66606510045312461
sg7325
V8-liquorice_catherine_wheels.png
p9278
sa(dp9279
S'block_loop.thisRepN'
p9280
I2
sg7308
V26-walkers_smoky_bacon.png
p9281
sg7310
V44-crunch.png
p9282
sg70
g71
sS'outcome_loop.thisRepN'
p9283
I0
sS'block_loop.thisIndex'
p9284
g7314
sS'outcome_loop.thisN'
p9285
I123
sS'outcome_loop.thisTrialN'
p9286
I123
sg62
g66
sg33
S'right'
p9287
sS'block_loop.thisN'
p9288
I2
sS'outcome_loop.thisIndex'
p9289
g63
(g96
S'{\x00\x00\x00'
tRp9290
sg30
g9281
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p9291
sS'block_loop.thisTrial'
p9292
Nsg60
g61
sS'block_loop.thisTrialN'
p9293
I0
sg34
F0.54633284398005344
sg7325
V26-walkers_smoky_bacon.png
p9294
sa(dp9295
S'block_loop.thisRepN'
p9296
I2
sg7308
V4-corn.png
p9297
sg7310
V10-bounty.png
p9298
sg70
g71
sS'outcome_loop.thisRepN'
p9299
I0
sS'block_loop.thisIndex'
p9300
g7314
sS'outcome_loop.thisN'
p9301
I124
sS'outcome_loop.thisTrialN'
p9302
I124
sg62
g66
sg33
S'right'
p9303
sS'block_loop.thisN'
p9304
I2
sS'outcome_loop.thisIndex'
p9305
g63
(g96
S'|\x00\x00\x00'
tRp9306
sg30
g9297
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p9307
sS'block_loop.thisTrial'
p9308
Nsg60
g61
sS'block_loop.thisTrialN'
p9309
I0
sg34
F0.77269317748505273
sg7325
V4-corn.png
p9310
sa(dp9311
S'block_loop.thisRepN'
p9312
I2
sg7308
V49-yorkie.png
p9313
sg7310
V49-yorkie.png
p9314
sg70
g71
sS'outcome_loop.thisRepN'
p9315
I0
sS'block_loop.thisIndex'
p9316
g7314
sS'outcome_loop.thisN'
p9317
I125
sS'outcome_loop.thisTrialN'
p9318
I125
sg62
g66
sg33
S'left'
p9319
sS'block_loop.thisN'
p9320
I2
sS'outcome_loop.thisIndex'
p9321
g63
(g96
S'}\x00\x00\x00'
tRp9322
sg30
g9313
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p9323
sS'block_loop.thisTrial'
p9324
Nsg60
g61
sS'block_loop.thisTrialN'
p9325
I0
sg34
F0.66604498616470664
sg7325
V35-sultanas.png
p9326
sa(dp9327
S'block_loop.thisRepN'
p9328
I2
sg7308
V17-jacobs_mini_cheddars.png
p9329
sg7310
V8-liquorice_catherine_wheels.png
p9330
sg70
g71
sS'outcome_loop.thisRepN'
p9331
I0
sS'block_loop.thisIndex'
p9332
g7314
sS'outcome_loop.thisN'
p9333
I126
sS'outcome_loop.thisTrialN'
p9334
I126
sg62
g66
sg33
S'right'
p9335
sS'block_loop.thisN'
p9336
I2
sS'outcome_loop.thisIndex'
p9337
g63
(g96
S'~\x00\x00\x00'
tRp9338
sg30
g9329
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p9339
sS'block_loop.thisTrial'
p9340
Nsg60
g61
sS'block_loop.thisTrialN'
p9341
I0
sg34
F0.54620908523247635
sg7325
V17-jacobs_mini_cheddars.png
p9342
sa(dp9343
S'block_loop.thisRepN'
p9344
I2
sg7308
V5-pineapple.png
p9345
sg7310
V5-pineapple.png
p9346
sg70
g71
sS'outcome_loop.thisRepN'
p9347
I0
sS'block_loop.thisIndex'
p9348
g7314
sS'outcome_loop.thisN'
p9349
I127
sS'outcome_loop.thisTrialN'
p9350
I127
sg62
g66
sg33
S'left'
p9351
sS'block_loop.thisN'
p9352
I2
sS'outcome_loop.thisIndex'
p9353
g63
(g96
S'\x7f\x00\x00\x00'
tRp9354
sg30
g9345
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p9355
sS'block_loop.thisTrial'
p9356
Nsg60
g61
sS'block_loop.thisTrialN'
p9357
I0
sg34
F0.78592474741890328
sg7325
V40-sardines.png
p9358
sa(dp9359
S'block_loop.thisRepN'
p9360
I2
sg7308
V13-mccoys_steak_crisps.png
p9361
sg7310
V3-dole_fruit_snack.png
p9362
sg70
g71
sS'outcome_loop.thisRepN'
p9363
I0
sS'block_loop.thisIndex'
p9364
g7314
sS'outcome_loop.thisN'
p9365
I128
sS'outcome_loop.thisTrialN'
p9366
I128
sg62
g66
sg33
S'right'
p9367
sS'block_loop.thisN'
p9368
I2
sS'outcome_loop.thisIndex'
p9369
g63
(g96
S'\x80\x00\x00\x00'
tRp9370
sg30
g9361
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p9371
sS'block_loop.thisTrial'
p9372
Nsg60
g61
sS'block_loop.thisTrialN'
p9373
I0
sg34
F0.57283341877337079
sg7325
V13-mccoys_steak_crisps.png
p9374
sa(dp9375
S'block_loop.thisRepN'
p9376
I2
sg7308
V1-smarties_cookies.png
p9377
sg7310
V21-nakd_banana_crunch.png
p9378
sg70
g71
sS'outcome_loop.thisRepN'
p9379
I0
sS'block_loop.thisIndex'
p9380
g7314
sS'outcome_loop.thisN'
p9381
I129
sS'outcome_loop.thisTrialN'
p9382
I129
sg62
g66
sg33
S'right'
p9383
sS'block_loop.thisN'
p9384
I2
sS'outcome_loop.thisIndex'
p9385
g63
(g96
S'\x81\x00\x00\x00'
tRp9386
sg30
g9377
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p9387
sS'block_loop.thisTrial'
p9388
Nsg60
g61
sS'block_loop.thisTrialN'
p9389
I0
sg34
F0.82589016201745835
sg7325
V1-smarties_cookies.png
p9390
sa(dp9391
S'block_loop.thisRepN'
p9392
I2
sg7308
V17-jacobs_mini_cheddars.png
p9393
sg7310
V17-jacobs_mini_cheddars.png
p9394
sg70
g71
sS'outcome_loop.thisRepN'
p9395
I0
sS'block_loop.thisIndex'
p9396
g7314
sS'outcome_loop.thisN'
p9397
I130
sS'outcome_loop.thisTrialN'
p9398
I130
sg62
g66
sg33
S'left'
p9399
sS'block_loop.thisN'
p9400
I2
sS'outcome_loop.thisIndex'
p9401
g63
(g96
S'\x82\x00\x00\x00'
tRp9402
sg30
g9393
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p9403
sS'block_loop.thisTrial'
p9404
Nsg60
g61
sS'block_loop.thisTrialN'
p9405
I0
sg34
F0.50623417222050193
sg7325
V8-liquorice_catherine_wheels.png
p9406
sa(dp9407
S'block_loop.thisRepN'
p9408
I2
sg7308
V48-twix.png
p9409
sg7310
V48-twix.png
p9410
sg70
g71
sS'outcome_loop.thisRepN'
p9411
I0
sS'block_loop.thisIndex'
p9412
g7314
sS'outcome_loop.thisN'
p9413
I131
sS'outcome_loop.thisTrialN'
p9414
I131
sg62
g66
sg33
S'left'
p9415
sS'block_loop.thisN'
p9416
I2
sS'outcome_loop.thisIndex'
p9417
g63
(g96
S'\x83\x00\x00\x00'
tRp9418
sg30
g9409
sg67
g11
sg68
g69
sg7321
V50-polo.png
p9419
sS'block_loop.thisTrial'
p9420
Nsg60
g61
sS'block_loop.thisTrialN'
p9421
I0
sg34
F1.0922614466362575
sg7325
V50-polo.png
p9422
sa(dp9423
S'block_loop.thisRepN'
p9424
I2
sg7308
V6-sour_patch_kids.png
p9425
sg7310
V38-maltesers.png
p9426
sg70
g71
sS'outcome_loop.thisRepN'
p9427
I0
sS'block_loop.thisIndex'
p9428
g7314
sS'outcome_loop.thisN'
p9429
I132
sS'outcome_loop.thisTrialN'
p9430
I132
sg62
g66
sg33
S'left'
p9431
sS'block_loop.thisN'
p9432
I2
sS'outcome_loop.thisIndex'
p9433
g63
(g96
S'\x84\x00\x00\x00'
tRp9434
sg30
g9425
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p9435
sS'block_loop.thisTrial'
p9436
Nsg60
g61
sS'block_loop.thisTrialN'
p9437
I0
sg34
F0.87918604180231341
sg7325
V6-sour_patch_kids.png
p9438
sa(dp9439
S'block_loop.thisRepN'
p9440
I2
sg7308
V48-twix.png
p9441
sg7310
V50-polo.png
p9442
sg70
g71
sS'outcome_loop.thisRepN'
p9443
I0
sS'block_loop.thisIndex'
p9444
g7314
sS'outcome_loop.thisN'
p9445
I133
sS'outcome_loop.thisTrialN'
p9446
I133
sg62
g66
sg33
S'right'
p9447
sS'block_loop.thisN'
p9448
I2
sS'outcome_loop.thisIndex'
p9449
g63
(g96
S'\x85\x00\x00\x00'
tRp9450
sg30
g9441
sg67
g11
sg68
g69
sg7321
V50-polo.png
p9451
sS'block_loop.thisTrial'
p9452
Nsg60
g61
sS'block_loop.thisTrialN'
p9453
I0
sg34
F0.91912519608013099
sg7325
V48-twix.png
p9454
sa(dp9455
S'block_loop.thisRepN'
p9456
I2
sg7308
V1-smarties_cookies.png
p9457
sg7310
V1-smarties_cookies.png
p9458
sg70
g71
sS'outcome_loop.thisRepN'
p9459
I0
sS'block_loop.thisIndex'
p9460
g7314
sS'outcome_loop.thisN'
p9461
I134
sS'outcome_loop.thisTrialN'
p9462
I134
sg62
g66
sg33
S'left'
p9463
sS'block_loop.thisN'
p9464
I2
sS'outcome_loop.thisIndex'
p9465
g63
(g96
S'\x86\x00\x00\x00'
tRp9466
sg30
g9457
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p9467
sS'block_loop.thisTrial'
p9468
Nsg60
g61
sS'block_loop.thisTrialN'
p9469
I0
sg34
F0.49305791657934606
sg7325
V21-nakd_banana_crunch.png
p9470
sa(dp9471
S'block_loop.thisRepN'
p9472
I2
sg7308
V13-mccoys_steak_crisps.png
p9473
sg7310
V13-mccoys_steak_crisps.png
p9474
sg70
g71
sS'outcome_loop.thisRepN'
p9475
I0
sS'block_loop.thisIndex'
p9476
g7314
sS'outcome_loop.thisN'
p9477
I135
sS'outcome_loop.thisTrialN'
p9478
I135
sg62
g66
sg33
S'left'
p9479
sS'block_loop.thisN'
p9480
I2
sS'outcome_loop.thisIndex'
p9481
g63
(g96
S'\x87\x00\x00\x00'
tRp9482
sg30
g9473
sg67
g11
sg68
g69
sg7321
V3-dole_fruit_snack.png
p9483
sS'block_loop.thisTrial'
p9484
Nsg60
g61
sS'block_loop.thisTrialN'
p9485
I0
sg34
F0.4929185133860301
sg7325
V3-dole_fruit_snack.png
p9486
sa(dp9487
S'block_loop.thisRepN'
p9488
I2
sg7308
V46-pistachios.png
p9489
sg7310
V46-pistachios.png
p9490
sg70
g71
sS'outcome_loop.thisRepN'
p9491
I0
sS'block_loop.thisIndex'
p9492
g7314
sS'outcome_loop.thisN'
p9493
I136
sS'outcome_loop.thisTrialN'
p9494
I136
sg62
g66
sg33
S'left'
p9495
sS'block_loop.thisN'
p9496
I2
sS'outcome_loop.thisIndex'
p9497
g63
(g96
S'\x88\x00\x00\x00'
tRp9498
sg30
g9489
sg67
g11
sg68
g69
sg7321
V29-beans.png
p9499
sS'block_loop.thisTrial'
p9500
Nsg60
g61
sS'block_loop.thisTrialN'
p9501
I0
sg34
F0.51958251677206135
sg7325
V29-beans.png
p9502
sa(dp9503
S'block_loop.thisRepN'
p9504
I2
sg7308
V17-jacobs_mini_cheddars.png
p9505
sg7310
V17-jacobs_mini_cheddars.png
p9506
sg70
g71
sS'outcome_loop.thisRepN'
p9507
I0
sS'block_loop.thisIndex'
p9508
g7314
sS'outcome_loop.thisN'
p9509
I137
sS'outcome_loop.thisTrialN'
p9510
I137
sg62
g66
sg33
S'left'
p9511
sS'block_loop.thisN'
p9512
I2
sS'outcome_loop.thisIndex'
p9513
g63
(g96
S'\x89\x00\x00\x00'
tRp9514
sg30
g9505
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p9515
sS'block_loop.thisTrial'
p9516
Nsg60
g61
sS'block_loop.thisTrialN'
p9517
I0
sg34
F0.506242553174161
sg7325
V8-liquorice_catherine_wheels.png
p9518
sa(dp9519
S'block_loop.thisRepN'
p9520
I2
sg7308
V45-chewy_nougat.png
p9521
sg7310
V41-peanuts.png
p9522
sg70
g71
sS'outcome_loop.thisRepN'
p9523
I0
sS'block_loop.thisIndex'
p9524
g7314
sS'outcome_loop.thisN'
p9525
I138
sS'outcome_loop.thisTrialN'
p9526
I138
sg62
g66
sg33
S'right'
p9527
sS'block_loop.thisN'
p9528
I2
sS'outcome_loop.thisIndex'
p9529
g63
(g96
S'\x8a\x00\x00\x00'
tRp9530
sg30
g9521
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p9531
sS'block_loop.thisTrial'
p9532
Nsg60
g61
sS'block_loop.thisTrialN'
p9533
I0
sg34
F0.62610443506127922
sg7325
V45-chewy_nougat.png
p9534
sa(dp9535
S'block_loop.thisRepN'
p9536
I2
sg7308
V1-smarties_cookies.png
p9537
sg7310
V21-nakd_banana_crunch.png
p9538
sg70
g71
sS'outcome_loop.thisRepN'
p9539
I0
sS'block_loop.thisIndex'
p9540
g7314
sS'outcome_loop.thisN'
p9541
I139
sS'outcome_loop.thisTrialN'
p9542
I139
sg62
g66
sg33
S'right'
p9543
sS'block_loop.thisN'
p9544
I2
sS'outcome_loop.thisIndex'
p9545
g63
(g96
S'\x8b\x00\x00\x00'
tRp9546
sg30
V21-nakd_banana_crunch.png
p9547
sg67
g11
sg68
g69
sg7321
g9547
sS'block_loop.thisTrial'
p9548
Nsg60
g61
sS'block_loop.thisTrialN'
p9549
I0
sg34
F0.6394223288170906
sg7325
V1-smarties_cookies.png
p9550
sa(dp9551
S'block_loop.thisRepN'
p9552
I2
sg7308
V4-corn.png
p9553
sg7310
V4-corn.png
p9554
sg70
g71
sS'outcome_loop.thisRepN'
p9555
I0
sS'block_loop.thisIndex'
p9556
g7314
sS'outcome_loop.thisN'
p9557
I140
sS'outcome_loop.thisTrialN'
p9558
I140
sg62
g66
sg33
S'left'
p9559
sS'block_loop.thisN'
p9560
I2
sS'outcome_loop.thisIndex'
p9561
g63
(g96
S'\x8c\x00\x00\x00'
tRp9562
sg30
g9553
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p9563
sS'block_loop.thisTrial'
p9564
Nsg60
g61
sS'block_loop.thisTrialN'
p9565
I0
sg34
F0.59951949200149102
sg7325
V10-bounty.png
p9566
sa(dp9567
S'block_loop.thisRepN'
p9568
I2
sg7308
V31-foxs_golden_biscuits.png
p9569
sg7310
V31-foxs_golden_biscuits.png
p9570
sg70
g71
sS'outcome_loop.thisRepN'
p9571
I0
sS'block_loop.thisIndex'
p9572
g7314
sS'outcome_loop.thisN'
p9573
I141
sS'outcome_loop.thisTrialN'
p9574
I141
sg62
g66
sg33
S'left'
p9575
sS'block_loop.thisN'
p9576
I2
sS'outcome_loop.thisIndex'
p9577
g63
(g96
S'\x8d\x00\x00\x00'
tRp9578
sg30
g9569
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p9579
sS'block_loop.thisTrial'
p9580
Nsg60
g61
sS'block_loop.thisTrialN'
p9581
I0
sg34
F0.58615773792553227
sg7325
V25-kitkat.png
p9582
sa(dp9583
S'block_loop.thisRepN'
p9584
I2
sg7308
V33-ambrosia_rice.png
p9585
sg7310
V33-ambrosia_rice.png
p9586
sg70
g71
sS'outcome_loop.thisRepN'
p9587
I0
sS'block_loop.thisIndex'
p9588
g7314
sS'outcome_loop.thisN'
p9589
I142
sS'outcome_loop.thisTrialN'
p9590
I142
sg62
g66
sg33
S'left'
p9591
sS'block_loop.thisN'
p9592
I2
sS'outcome_loop.thisIndex'
p9593
g63
(g96
S'\x8e\x00\x00\x00'
tRp9594
sg30
g9585
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p9595
sS'block_loop.thisTrial'
p9596
Nsg60
g61
sS'block_loop.thisTrialN'
p9597
I0
sg34
F0.54619735189771745
sg7325
V23-crunchie.png
p9598
sa(dp9599
S'block_loop.thisRepN'
p9600
I2
sg7308
V20-fruit_pastilles.png
p9601
sg7310
V2-steamed_puddings.png
p9602
sg70
g71
sS'outcome_loop.thisRepN'
p9603
I0
sS'block_loop.thisIndex'
p9604
g7314
sS'outcome_loop.thisN'
p9605
I143
sS'outcome_loop.thisTrialN'
p9606
I143
sg62
g66
sg33
S'right'
p9607
sS'block_loop.thisN'
p9608
I2
sS'outcome_loop.thisIndex'
p9609
g63
(g96
S'\x8f\x00\x00\x00'
tRp9610
sg30
g9601
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p9611
sS'block_loop.thisTrial'
p9612
Nsg60
g61
sS'block_loop.thisTrialN'
p9613
I0
sg34
F0.59947172056672571
sg7325
V20-fruit_pastilles.png
p9614
sa(dp9615
S'block_loop.thisRepN'
p9616
I2
sg7308
V6-sour_patch_kids.png
p9617
sg7310
V6-sour_patch_kids.png
p9618
sg70
g71
sS'outcome_loop.thisRepN'
p9619
I0
sS'block_loop.thisIndex'
p9620
g7314
sS'outcome_loop.thisN'
p9621
I144
sS'outcome_loop.thisTrialN'
p9622
I144
sg62
g66
sg33
S'right'
p9623
sS'block_loop.thisN'
p9624
I2
sS'outcome_loop.thisIndex'
p9625
g63
(g96
S'\x90\x00\x00\x00'
tRp9626
sg30
V38-maltesers.png
p9627
sg67
g11
sg68
g69
sg7321
g9627
sS'block_loop.thisTrial'
p9628
Nsg60
g61
sS'block_loop.thisTrialN'
p9629
I0
sg34
F0.77269876478749211
sg7325
V38-maltesers.png
p9630
sa(dp9631
S'block_loop.thisRepN'
p9632
I2
sg7308
V31-foxs_golden_biscuits.png
p9633
sg7310
V31-foxs_golden_biscuits.png
p9634
sg70
g71
sS'outcome_loop.thisRepN'
p9635
I0
sS'block_loop.thisIndex'
p9636
g7314
sS'outcome_loop.thisN'
p9637
I145
sS'outcome_loop.thisTrialN'
p9638
I145
sg62
g66
sg33
S'left'
p9639
sS'block_loop.thisN'
p9640
I2
sS'outcome_loop.thisIndex'
p9641
g63
(g96
S'\x91\x00\x00\x00'
tRp9642
sg30
g9633
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p9643
sS'block_loop.thisTrial'
p9644
Nsg60
g61
sS'block_loop.thisTrialN'
p9645
I0
sg34
F0.51955206597449433
sg7325
V25-kitkat.png
p9646
sa(dp9647
S'block_loop.thisRepN'
p9648
I2
sg7308
V49-yorkie.png
p9649
sg7310
V49-yorkie.png
p9650
sg70
g71
sS'outcome_loop.thisRepN'
p9651
I0
sS'block_loop.thisIndex'
p9652
g7314
sS'outcome_loop.thisN'
p9653
I146
sS'outcome_loop.thisTrialN'
p9654
I146
sg62
g66
sg33
S'left'
p9655
sS'block_loop.thisN'
p9656
I2
sS'outcome_loop.thisIndex'
p9657
g63
(g96
S'\x92\x00\x00\x00'
tRp9658
sg30
g9649
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p9659
sS'block_loop.thisTrial'
p9660
Nsg60
g61
sS'block_loop.thisTrialN'
p9661
I0
sg34
F0.61258288413773698
sg7325
V35-sultanas.png
p9662
sa(dp9663
S'block_loop.thisRepN'
p9664
I2
sg7308
V36-fig_rolls.png
p9665
sg7310
V34-hula_hoops_bbq_beef.png
p9666
sg70
g71
sS'outcome_loop.thisRepN'
p9667
I0
sS'block_loop.thisIndex'
p9668
g7314
sS'outcome_loop.thisN'
p9669
I147
sS'outcome_loop.thisTrialN'
p9670
I147
sg62
g66
sg33
S'right'
p9671
sS'block_loop.thisN'
p9672
I2
sS'outcome_loop.thisIndex'
p9673
g63
(g96
S'\x93\x00\x00\x00'
tRp9674
sg30
g9665
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p9675
sS'block_loop.thisTrial'
p9676
Nsg60
g61
sS'block_loop.thisTrialN'
p9677
I0
sg34
F0.67939780055712617
sg7325
V36-fig_rolls.png
p9678
sa(dp9679
S'block_loop.thisRepN'
p9680
I2
sg7308
V7-olives.png
p9681
sg7310
V22-daim.png
p9682
sg70
g71
sS'outcome_loop.thisRepN'
p9683
I0
sS'block_loop.thisIndex'
p9684
g7314
sS'outcome_loop.thisN'
p9685
I148
sS'outcome_loop.thisTrialN'
p9686
I148
sg62
g66
sg33
S'right'
p9687
sS'block_loop.thisN'
p9688
I2
sS'outcome_loop.thisIndex'
p9689
g63
(g96
S'\x94\x00\x00\x00'
tRp9690
sg30
g9681
sg67
g11
sg68
g69
sg7321
V22-daim.png
p9691
sS'block_loop.thisTrial'
p9692
Nsg60
g61
sS'block_loop.thisTrialN'
p9693
I0
sg34
F0.77260657429906132
sg7325
V7-olives.png
p9694
sa(dp9695
S'block_loop.thisRepN'
p9696
I2
sg7308
V26-walkers_smoky_bacon.png
p9697
sg7310
V26-walkers_smoky_bacon.png
p9698
sg70
g71
sS'outcome_loop.thisRepN'
p9699
I0
sS'block_loop.thisIndex'
p9700
g7314
sS'outcome_loop.thisN'
p9701
I149
sS'outcome_loop.thisTrialN'
p9702
I149
sg62
g66
sg33
S'left'
p9703
sS'block_loop.thisN'
p9704
I2
sS'outcome_loop.thisIndex'
p9705
g63
(g96
S'\x95\x00\x00\x00'
tRp9706
sg30
g9697
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p9707
sS'block_loop.thisTrial'
p9708
Nsg60
g61
sS'block_loop.thisTrialN'
p9709
I0
sg34
F0.57283090448618168
sg7325
V44-crunch.png
p9710
sa(dp9711
S'block_loop.thisRepN'
p9712
I2
sg7308
V46-pistachios.png
p9713
sg7310
V29-beans.png
p9714
sg70
g71
sS'outcome_loop.thisRepN'
p9715
I0
sS'block_loop.thisIndex'
p9716
g7314
sS'outcome_loop.thisN'
p9717
I150
sS'outcome_loop.thisTrialN'
p9718
I150
sg62
g66
sg33
S'right'
p9719
sS'block_loop.thisN'
p9720
I2
sS'outcome_loop.thisIndex'
p9721
g63
(g96
S'\x96\x00\x00\x00'
tRp9722
sg30
g9713
sg67
g11
sg68
g69
sg7321
V29-beans.png
p9723
sS'block_loop.thisTrial'
p9724
Nsg60
g61
sS'block_loop.thisTrialN'
p9725
I0
sg34
F0.58615187125724333
sg7325
V46-pistachios.png
p9726
sa(dp9727
S'block_loop.thisRepN'
p9728
I2
sg7308
V48-twix.png
p9729
sg7310
V48-twix.png
p9730
sg70
g71
sS'outcome_loop.thisRepN'
p9731
I0
sS'block_loop.thisIndex'
p9732
g7314
sS'outcome_loop.thisN'
p9733
I151
sS'outcome_loop.thisTrialN'
p9734
I151
sg62
g66
sg33
S'left'
p9735
sS'block_loop.thisN'
p9736
I2
sS'outcome_loop.thisIndex'
p9737
g63
(g96
S'\x97\x00\x00\x00'
tRp9738
sg30
g9729
sg67
g11
sg68
g69
sg7321
V50-polo.png
p9739
sS'block_loop.thisTrial'
p9740
Nsg60
g61
sS'block_loop.thisTrialN'
p9741
I0
sg34
F0.81256807778663642
sg7325
V50-polo.png
p9742
sa(dp9743
S'block_loop.thisRepN'
p9744
I2
sg7308
V19-caramello.png
p9745
sg7310
V19-caramello.png
p9746
sg70
g71
sS'outcome_loop.thisRepN'
p9747
I0
sS'block_loop.thisIndex'
p9748
g7314
sS'outcome_loop.thisN'
p9749
I152
sS'outcome_loop.thisTrialN'
p9750
I152
sg62
g66
sg33
S'left'
p9751
sS'block_loop.thisN'
p9752
I2
sS'outcome_loop.thisIndex'
p9753
g63
(g96
S'\x98\x00\x00\x00'
tRp9754
sg30
V30-spaghetti_hoops.png
p9755
sg67
g11
sg68
g69
sg7321
g9755
sS'block_loop.thisTrial'
p9756
Nsg60
g61
sS'block_loop.thisTrialN'
p9757
I0
sg34
F0.86585026867942361
sg7325
V30-spaghetti_hoops.png
p9758
sa(dp9759
S'block_loop.thisRepN'
p9760
I2
sg7308
V36-fig_rolls.png
p9761
sg7310
V34-hula_hoops_bbq_beef.png
p9762
sg70
g71
sS'outcome_loop.thisRepN'
p9763
I0
sS'block_loop.thisIndex'
p9764
g7314
sS'outcome_loop.thisN'
p9765
I153
sS'outcome_loop.thisTrialN'
p9766
I153
sg62
g66
sg33
S'right'
p9767
sS'block_loop.thisN'
p9768
I2
sS'outcome_loop.thisIndex'
p9769
g63
(g96
S'\x99\x00\x00\x00'
tRp9770
sg30
g9761
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p9771
sS'block_loop.thisTrial'
p9772
Nsg60
g61
sS'block_loop.thisTrialN'
p9773
I0
sg34
F0.66586256074515404
sg7325
V36-fig_rolls.png
p9774
sa(dp9775
S'block_loop.thisRepN'
p9776
I2
sg7308
V17-jacobs_mini_cheddars.png
p9777
sg7310
V8-liquorice_catherine_wheels.png
p9778
sg70
g71
sS'outcome_loop.thisRepN'
p9779
I0
sS'block_loop.thisIndex'
p9780
g7314
sS'outcome_loop.thisN'
p9781
I154
sS'outcome_loop.thisTrialN'
p9782
I154
sg62
g66
sg33
S'right'
p9783
sS'block_loop.thisN'
p9784
I2
sS'outcome_loop.thisIndex'
p9785
g63
(g96
S'\x9a\x00\x00\x00'
tRp9786
sg30
g9777
sg67
g11
sg68
g69
sg7321
V8-liquorice_catherine_wheels.png
p9787
sS'block_loop.thisTrial'
p9788
Nsg60
g61
sS'block_loop.thisTrialN'
p9789
I0
sg34
F0.63942177008539147
sg7325
V17-jacobs_mini_cheddars.png
p9790
sa(dp9791
S'block_loop.thisRepN'
p9792
I2
sg7308
V49-yorkie.png
p9793
sg7310
V35-sultanas.png
p9794
sg70
g71
sS'outcome_loop.thisRepN'
p9795
I0
sS'block_loop.thisIndex'
p9796
g7314
sS'outcome_loop.thisN'
p9797
I155
sS'outcome_loop.thisTrialN'
p9798
I155
sg62
g66
sg33
S'right'
p9799
sS'block_loop.thisN'
p9800
I2
sS'outcome_loop.thisIndex'
p9801
g63
(g96
S'\x9b\x00\x00\x00'
tRp9802
sg30
g9793
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p9803
sS'block_loop.thisTrial'
p9804
Nsg60
g61
sS'block_loop.thisTrialN'
p9805
I0
sg34
F0.69269390383306018
sg7325
V49-yorkie.png
p9806
sa(dp9807
S'block_loop.thisRepN'
p9808
I2
sg7308
V33-ambrosia_rice.png
p9809
sg7310
V23-crunchie.png
p9810
sg70
g71
sS'outcome_loop.thisRepN'
p9811
I0
sS'block_loop.thisIndex'
p9812
g7314
sS'outcome_loop.thisN'
p9813
I156
sS'outcome_loop.thisTrialN'
p9814
I156
sg62
g66
sg33
S'right'
p9815
sS'block_loop.thisN'
p9816
I2
sS'outcome_loop.thisIndex'
p9817
g63
(g96
S'\x9c\x00\x00\x00'
tRp9818
sg30
g9809
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p9819
sS'block_loop.thisTrial'
p9820
Nsg60
g61
sS'block_loop.thisTrialN'
p9821
I0
sg34
F0.86584524010868336
sg7325
V33-ambrosia_rice.png
p9822
sa(dp9823
S'block_loop.thisRepN'
p9824
I2
sg7308
V46-pistachios.png
p9825
sg7310
V46-pistachios.png
p9826
sg70
g71
sS'outcome_loop.thisRepN'
p9827
I0
sS'block_loop.thisIndex'
p9828
g7314
sS'outcome_loop.thisN'
p9829
I157
sS'outcome_loop.thisTrialN'
p9830
I157
sg62
g66
sg33
S'left'
p9831
sS'block_loop.thisN'
p9832
I2
sS'outcome_loop.thisIndex'
p9833
g63
(g96
S'\x9d\x00\x00\x00'
tRp9834
sg30
V29-beans.png
p9835
sg67
g11
sg68
g69
sg7321
g9835
sS'block_loop.thisTrial'
p9836
Nsg60
g61
sS'block_loop.thisTrialN'
p9837
I0
sg34
F0.54610879315805505
sg7325
V29-beans.png
p9838
sa(dp9839
S'block_loop.thisRepN'
p9840
I2
sg7308
V20-fruit_pastilles.png
p9841
sg7310
V2-steamed_puddings.png
p9842
sg70
g71
sS'outcome_loop.thisRepN'
p9843
I0
sS'block_loop.thisIndex'
p9844
g7314
sS'outcome_loop.thisN'
p9845
I158
sS'outcome_loop.thisTrialN'
p9846
I158
sg62
g66
sg33
S'right'
p9847
sS'block_loop.thisN'
p9848
I2
sS'outcome_loop.thisIndex'
p9849
g63
(g96
S'\x9e\x00\x00\x00'
tRp9850
sg30
g9841
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p9851
sS'block_loop.thisTrial'
p9852
Nsg60
g61
sS'block_loop.thisTrialN'
p9853
I0
sg34
F0.59946389834476577
sg7325
V20-fruit_pastilles.png
p9854
sa(dp9855
S'block_loop.thisRepN'
p9856
I2
sg7308
V43-mrporky_pork_crackles.png
p9857
sg7310
V43-mrporky_pork_crackles.png
p9858
sg70
g71
sS'outcome_loop.thisRepN'
p9859
I0
sS'block_loop.thisIndex'
p9860
g7314
sS'outcome_loop.thisN'
p9861
I159
sS'outcome_loop.thisTrialN'
p9862
I159
sg62
g66
sg33
S'left'
p9863
sS'block_loop.thisN'
p9864
I2
sS'outcome_loop.thisIndex'
p9865
g63
(g96
S'\x9f\x00\x00\x00'
tRp9866
sg30
V18-mms.png
p9867
sg67
g11
sg68
g69
sg7321
g9867
sS'block_loop.thisTrial'
p9868
Nsg60
g61
sS'block_loop.thisTrialN'
p9869
I0
sg34
F0.54619372015258705
sg7325
V18-mms.png
p9870
sa(dp9871
S'block_loop.thisRepN'
p9872
I2
sg7308
V19-caramello.png
p9873
sg7310
V30-spaghetti_hoops.png
p9874
sg70
g71
sS'outcome_loop.thisRepN'
p9875
I0
sS'block_loop.thisIndex'
p9876
g7314
sS'outcome_loop.thisN'
p9877
I160
sS'outcome_loop.thisTrialN'
p9878
I160
sg62
g66
sg33
S'right'
p9879
sS'block_loop.thisN'
p9880
I2
sS'outcome_loop.thisIndex'
p9881
g63
(g96
S'\xa0\x00\x00\x00'
tRp9882
sg30
g9873
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p9883
sS'block_loop.thisTrial'
p9884
Nsg60
g61
sS'block_loop.thisTrialN'
p9885
I0
sg34
F0.79946780945647333
sg7325
V19-caramello.png
p9886
sa(dp9887
S'block_loop.thisRepN'
p9888
I2
sg7308
V6-sour_patch_kids.png
p9889
sg7310
V6-sour_patch_kids.png
p9890
sg70
g71
sS'outcome_loop.thisRepN'
p9891
I0
sS'block_loop.thisIndex'
p9892
g7314
sS'outcome_loop.thisN'
p9893
I161
sS'outcome_loop.thisTrialN'
p9894
I161
sg62
g66
sg33
S'right'
p9895
sS'block_loop.thisN'
p9896
I2
sS'outcome_loop.thisIndex'
p9897
g63
(g96
S'\xa1\x00\x00\x00'
tRp9898
sg30
g9889
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p9899
sS'block_loop.thisTrial'
p9900
Nsg60
g61
sS'block_loop.thisTrialN'
p9901
I0
sg34
F0.66605671949946554
sg7325
V38-maltesers.png
p9902
sa(dp9903
S'block_loop.thisRepN'
p9904
I2
sg7308
V45-chewy_nougat.png
p9905
sg7310
V41-peanuts.png
p9906
sg70
g71
sS'outcome_loop.thisRepN'
p9907
I0
sS'block_loop.thisIndex'
p9908
g7314
sS'outcome_loop.thisN'
p9909
I162
sS'outcome_loop.thisTrialN'
p9910
I162
sg62
g66
sg33
S'right'
p9911
sS'block_loop.thisN'
p9912
I2
sS'outcome_loop.thisIndex'
p9913
g63
(g96
S'\xa2\x00\x00\x00'
tRp9914
sg30
g9905
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p9915
sS'block_loop.thisTrial'
p9916
Nsg60
g61
sS'block_loop.thisTrialN'
p9917
I0
sg34
F0.78593173154695251
sg7325
V45-chewy_nougat.png
p9918
sa(dp9919
S'block_loop.thisRepN'
p9920
I2
sg7308
V4-corn.png
p9921
sg7310
V4-corn.png
p9922
sg70
g71
sS'outcome_loop.thisRepN'
p9923
I0
sS'block_loop.thisIndex'
p9924
g7314
sS'outcome_loop.thisN'
p9925
I163
sS'outcome_loop.thisTrialN'
p9926
I163
sg62
g66
sg33
S'left'
p9927
sS'block_loop.thisN'
p9928
I2
sS'outcome_loop.thisIndex'
p9929
g63
(g96
S'\xa3\x00\x00\x00'
tRp9930
sg30
V10-bounty.png
p9931
sg67
g11
sg68
g69
sg7321
g9931
sS'block_loop.thisTrial'
p9932
Nsg60
g61
sS'block_loop.thisTrialN'
p9933
I0
sg34
F0.75929482657738845
sg7325
V10-bounty.png
p9934
sa(dp9935
S'block_loop.thisRepN'
p9936
I2
sg7308
V43-mrporky_pork_crackles.png
p9937
sg7310
V18-mms.png
p9938
sg70
g71
sS'outcome_loop.thisRepN'
p9939
I0
sS'block_loop.thisIndex'
p9940
g7314
sS'outcome_loop.thisN'
p9941
I164
sS'outcome_loop.thisTrialN'
p9942
I164
sg62
g66
sg33
S'right'
p9943
sS'block_loop.thisN'
p9944
I2
sS'outcome_loop.thisIndex'
p9945
g63
(g96
S'\xa4\x00\x00\x00'
tRp9946
sg30
g9937
sg67
g11
sg68
g69
sg7321
V18-mms.png
p9947
sS'block_loop.thisTrial'
p9948
Nsg60
g61
sS'block_loop.thisTrialN'
p9949
I0
sg34
F0.49289923719334183
sg7325
V43-mrporky_pork_crackles.png
p9950
sa(dp9951
S'block_loop.thisRepN'
p9952
I2
sg7308
V19-caramello.png
p9953
sg7310
V30-spaghetti_hoops.png
p9954
sg70
g71
sS'outcome_loop.thisRepN'
p9955
I0
sS'block_loop.thisIndex'
p9956
g7314
sS'outcome_loop.thisN'
p9957
I165
sS'outcome_loop.thisTrialN'
p9958
I165
sg62
g66
sg33
S'right'
p9959
sS'block_loop.thisN'
p9960
I2
sS'outcome_loop.thisIndex'
p9961
g63
(g96
S'\xa5\x00\x00\x00'
tRp9962
sg30
g9953
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p9963
sS'block_loop.thisTrial'
p9964
Nsg60
g61
sS'block_loop.thisTrialN'
p9965
I0
sg34
F0.66605811632507539
sg7325
V19-caramello.png
p9966
sa(dp9967
S'block_loop.thisRepN'
p9968
I2
sg7308
V31-foxs_golden_biscuits.png
p9969
sg7310
V31-foxs_golden_biscuits.png
p9970
sg70
g71
sS'outcome_loop.thisRepN'
p9971
I0
sS'block_loop.thisIndex'
p9972
g7314
sS'outcome_loop.thisN'
p9973
I166
sS'outcome_loop.thisTrialN'
p9974
I166
sg62
g66
sg33
S'left'
p9975
sS'block_loop.thisN'
p9976
I2
sS'outcome_loop.thisIndex'
p9977
g63
(g96
S'\xa6\x00\x00\x00'
tRp9978
sg30
g9969
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p9979
sS'block_loop.thisTrial'
p9980
Nsg60
g61
sS'block_loop.thisTrialN'
p9981
I0
sg34
F0.69275815781111305
sg7325
V25-kitkat.png
p9982
sa(dp9983
S'block_loop.thisRepN'
p9984
I2
sg7308
V51-mars.png
p9985
sg7310
V27-hartleys_raspberries_jelly.png
p9986
sg70
g71
sS'outcome_loop.thisRepN'
p9987
I0
sS'block_loop.thisIndex'
p9988
g7314
sS'outcome_loop.thisN'
p9989
I167
sS'outcome_loop.thisTrialN'
p9990
I167
sg62
g66
sg33
S'right'
p9991
sS'block_loop.thisN'
p9992
I2
sS'outcome_loop.thisIndex'
p9993
g63
(g96
S'\xa7\x00\x00\x00'
tRp9994
sg30
g9985
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p9995
sS'block_loop.thisTrial'
p9996
Nsg60
g61
sS'block_loop.thisTrialN'
p9997
I0
sg34
F1.2252593555895146
sg7325
V51-mars.png
p9998
sa(dp9999
S'block_loop.thisRepN'
p10000
I2
sg7308
V5-pineapple.png
p10001
sg7310
V40-sardines.png
p10002
sg70
g71
sS'outcome_loop.thisRepN'
p10003
I0
sS'block_loop.thisIndex'
p10004
g7314
sS'outcome_loop.thisN'
p10005
I168
sS'outcome_loop.thisTrialN'
p10006
I168
sg62
g66
sg33
S'right'
p10007
sS'block_loop.thisN'
p10008
I2
sS'outcome_loop.thisIndex'
p10009
g63
(g96
S'\xa8\x00\x00\x00'
tRp10010
sg30
g10001
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p10011
sS'block_loop.thisTrial'
p10012
Nsg60
g61
sS'block_loop.thisTrialN'
p10013
I0
sg34
F1.0389901509843185
sg7325
V5-pineapple.png
p10014
sa(dp10015
S'block_loop.thisRepN'
p10016
I2
sg7308
V33-ambrosia_rice.png
p10017
sg7310
V23-crunchie.png
p10018
sg70
g71
sS'outcome_loop.thisRepN'
p10019
I0
sS'block_loop.thisIndex'
p10020
g7314
sS'outcome_loop.thisN'
p10021
I169
sS'outcome_loop.thisTrialN'
p10022
I169
sg62
g66
sg33
S'right'
p10023
sS'block_loop.thisN'
p10024
I2
sS'outcome_loop.thisIndex'
p10025
g63
(g96
S'\xa9\x00\x00\x00'
tRp10026
sg30
V23-crunchie.png
p10027
sg67
g11
sg68
g69
sg7321
g10027
sS'block_loop.thisTrial'
p10028
Nsg60
g61
sS'block_loop.thisTrialN'
p10029
I0
sg34
F0.73264590890721593
sg7325
V33-ambrosia_rice.png
p10030
sa(dp10031
S'block_loop.thisRepN'
p10032
I2
sg7308
V5-pineapple.png
p10033
sg7310
V40-sardines.png
p10034
sg70
g71
sS'outcome_loop.thisRepN'
p10035
I0
sS'block_loop.thisIndex'
p10036
g7314
sS'outcome_loop.thisN'
p10037
I170
sS'outcome_loop.thisTrialN'
p10038
I170
sg62
g66
sg33
S'right'
p10039
sS'block_loop.thisN'
p10040
I2
sS'outcome_loop.thisIndex'
p10041
g63
(g96
S'\xaa\x00\x00\x00'
tRp10042
sg30
g10033
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p10043
sS'block_loop.thisTrial'
p10044
Nsg60
g61
sS'block_loop.thisTrialN'
p10045
I0
sg34
F0.69273078002879629
sg7325
V5-pineapple.png
p10046
sa(dp10047
S'block_loop.thisRepN'
p10048
I2
sg7308
V51-mars.png
p10049
sg7310
V51-mars.png
p10050
sg70
g71
sS'outcome_loop.thisRepN'
p10051
I0
sS'block_loop.thisIndex'
p10052
g7314
sS'outcome_loop.thisN'
p10053
I171
sS'outcome_loop.thisTrialN'
p10054
I171
sg62
g66
sg33
S'left'
p10055
sS'block_loop.thisN'
p10056
I2
sS'outcome_loop.thisIndex'
p10057
g63
(g96
S'\xab\x00\x00\x00'
tRp10058
sg30
g10049
sg67
g11
sg68
g69
sg7321
V27-hartleys_raspberries_jelly.png
p10059
sS'block_loop.thisTrial'
p10060
Nsg60
g61
sS'block_loop.thisTrialN'
p10061
I0
sg34
F1.0789415973249561
sg7325
V27-hartleys_raspberries_jelly.png
p10062
sa(dp10063
S'block_loop.thisRepN'
p10064
I2
sg7308
V26-walkers_smoky_bacon.png
p10065
sg7310
V26-walkers_smoky_bacon.png
p10066
sg70
g71
sS'outcome_loop.thisRepN'
p10067
I0
sS'block_loop.thisIndex'
p10068
g7314
sS'outcome_loop.thisN'
p10069
I172
sS'outcome_loop.thisTrialN'
p10070
I172
sg62
g66
sg33
S'left'
p10071
sS'block_loop.thisN'
p10072
I2
sS'outcome_loop.thisIndex'
p10073
g63
(g96
S'\xac\x00\x00\x00'
tRp10074
sg30
V44-crunch.png
p10075
sg67
g11
sg68
g69
sg7321
g10075
sS'block_loop.thisTrial'
p10076
Nsg60
g61
sS'block_loop.thisTrialN'
p10077
I0
sg34
F0.70602157536814047
sg7325
V44-crunch.png
p10078
sa(dp10079
S'block_loop.thisRepN'
p10080
I2
sg7308
V13-mccoys_steak_crisps.png
p10081
sg7310
V3-dole_fruit_snack.png
p10082
sg70
g71
sS'outcome_loop.thisRepN'
p10083
I0
sS'block_loop.thisIndex'
p10084
g7314
sS'outcome_loop.thisN'
p10085
I173
sS'outcome_loop.thisTrialN'
p10086
I173
sg62
g66
sg33
S'right'
p10087
sS'block_loop.thisN'
p10088
I2
sS'outcome_loop.thisIndex'
p10089
g63
(g96
S'\xad\x00\x00\x00'
tRp10090
sg30
V3-dole_fruit_snack.png
p10091
sg67
g11
sg68
g69
sg7321
g10091
sS'block_loop.thisTrial'
p10092
Nsg60
g61
sS'block_loop.thisTrialN'
p10093
I0
sg34
F0.492895884812242
sg7325
V13-mccoys_steak_crisps.png
p10094
sa(dp10095
S'block_loop.thisRepN'
p10096
I2
sg7308
V48-twix.png
p10097
sg7310
V50-polo.png
p10098
sg70
g71
sS'outcome_loop.thisRepN'
p10099
I0
sS'block_loop.thisIndex'
p10100
g7314
sS'outcome_loop.thisN'
p10101
I174
sS'outcome_loop.thisTrialN'
p10102
I174
sg62
g66
sg33
S'right'
p10103
sS'block_loop.thisN'
p10104
I2
sS'outcome_loop.thisIndex'
p10105
g63
(g96
S'\xae\x00\x00\x00'
tRp10106
sg30
g10097
sg67
g11
sg68
g69
sg7321
V50-polo.png
p10107
sS'block_loop.thisTrial'
p10108
Nsg60
g61
sS'block_loop.thisTrialN'
p10109
I0
sg34
F0.70597520075898501
sg7325
V48-twix.png
p10110
sa(dp10111
S'block_loop.thisRepN'
p10112
I2
sg7308
V5-pineapple.png
p10113
sg7310
V40-sardines.png
p10114
sg70
g71
sS'outcome_loop.thisRepN'
p10115
I0
sS'block_loop.thisIndex'
p10116
g7314
sS'outcome_loop.thisN'
p10117
I175
sS'outcome_loop.thisTrialN'
p10118
I175
sg62
g66
sg33
S'right'
p10119
sS'block_loop.thisN'
p10120
I2
sS'outcome_loop.thisIndex'
p10121
g63
(g96
S'\xaf\x00\x00\x00'
tRp10122
sg30
g10113
sg67
g11
sg68
g69
sg7321
V40-sardines.png
p10123
sS'block_loop.thisTrial'
p10124
Nsg60
g61
sS'block_loop.thisTrialN'
p10125
I0
sg34
F0.62610890490213933
sg7325
V5-pineapple.png
p10126
sa(dp10127
S'block_loop.thisRepN'
p10128
I2
sg7308
V19-caramello.png
p10129
sg7310
V19-caramello.png
p10130
sg70
g71
sS'outcome_loop.thisRepN'
p10131
I0
sS'block_loop.thisIndex'
p10132
g7314
sS'outcome_loop.thisN'
p10133
I176
sS'outcome_loop.thisTrialN'
p10134
I176
sg62
g66
sg33
S'left'
p10135
sS'block_loop.thisN'
p10136
I2
sS'outcome_loop.thisIndex'
p10137
g63
(g96
S'\xb0\x00\x00\x00'
tRp10138
sg30
g10129
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p10139
sS'block_loop.thisTrial'
p10140
Nsg60
g61
sS'block_loop.thisTrialN'
p10141
I0
sg34
F0.73265037874807604
sg7325
V30-spaghetti_hoops.png
p10142
sa(dp10143
S'block_loop.thisRepN'
p10144
I2
sg7308
V7-olives.png
p10145
sg7310
V22-daim.png
p10146
sg70
g71
sS'outcome_loop.thisRepN'
p10147
I0
sS'block_loop.thisIndex'
p10148
g7314
sS'outcome_loop.thisN'
p10149
I177
sS'outcome_loop.thisTrialN'
p10150
I177
sg62
g66
sg33
S'right'
p10151
sS'block_loop.thisN'
p10152
I2
sS'outcome_loop.thisIndex'
p10153
g63
(g96
S'\xb1\x00\x00\x00'
tRp10154
sg30
g10145
sg67
g11
sg68
g69
sg7321
V22-daim.png
p10155
sS'block_loop.thisTrial'
p10156
Nsg60
g61
sS'block_loop.thisTrialN'
p10157
I0
sg34
F0.59945914913805609
sg7325
V7-olives.png
p10158
sa(dp10159
S'block_loop.thisRepN'
p10160
I2
sg7308
V43-mrporky_pork_crackles.png
p10161
sg7310
V18-mms.png
p10162
sg70
g71
sS'outcome_loop.thisRepN'
p10163
I0
sS'block_loop.thisIndex'
p10164
g7314
sS'outcome_loop.thisN'
p10165
I178
sS'outcome_loop.thisTrialN'
p10166
I178
sg62
g66
sg33
S'right'
p10167
sS'block_loop.thisN'
p10168
I2
sS'outcome_loop.thisIndex'
p10169
g63
(g96
S'\xb2\x00\x00\x00'
tRp10170
sg30
g10161
sg67
g11
sg68
g69
sg7321
V18-mms.png
p10171
sS'block_loop.thisTrial'
p10172
Nsg60
g61
sS'block_loop.thisTrialN'
p10173
I0
sg34
F0.62609884775702085
sg7325
V43-mrporky_pork_crackles.png
p10174
sa(dp10175
S'block_loop.thisRepN'
p10176
I2
sg7308
V20-fruit_pastilles.png
p10177
sg7310
V2-steamed_puddings.png
p10178
sg70
g71
sS'outcome_loop.thisRepN'
p10179
I0
sS'block_loop.thisIndex'
p10180
g7314
sS'outcome_loop.thisN'
p10181
I179
sS'outcome_loop.thisTrialN'
p10182
I179
sg62
g66
sg33
S'right'
p10183
sS'block_loop.thisN'
p10184
I2
sS'outcome_loop.thisIndex'
p10185
g63
(g96
S'\xb3\x00\x00\x00'
tRp10186
sg30
g10177
sg67
g11
sg68
g69
sg7321
V2-steamed_puddings.png
p10187
sS'block_loop.thisTrial'
p10188
Nsg60
g61
sS'block_loop.thisTrialN'
p10189
I0
sg34
F0.77260797112467117
sg7325
V20-fruit_pastilles.png
p10190
sa(dp10191
S'block_loop.thisRepN'
p10192
I2
sg7308
V26-walkers_smoky_bacon.png
p10193
sg7310
V26-walkers_smoky_bacon.png
p10194
sg70
g71
sS'outcome_loop.thisRepN'
p10195
I0
sS'block_loop.thisIndex'
p10196
g7314
sS'outcome_loop.thisN'
p10197
I180
sS'outcome_loop.thisTrialN'
p10198
I180
sg62
g66
sg33
S'left'
p10199
sS'block_loop.thisN'
p10200
I2
sS'outcome_loop.thisIndex'
p10201
g63
(g96
S'\xb4\x00\x00\x00'
tRp10202
sg30
g10193
sg67
g11
sg68
g69
sg7321
V44-crunch.png
p10203
sS'block_loop.thisTrial'
p10204
Nsg60
g61
sS'block_loop.thisTrialN'
p10205
I0
sg34
F0.53286604861750675
sg7325
V44-crunch.png
p10206
sa(dp10207
S'block_loop.thisRepN'
p10208
I2
sg7308
V7-olives.png
p10209
sg7310
V7-olives.png
p10210
sg70
g71
sS'outcome_loop.thisRepN'
p10211
I0
sS'block_loop.thisIndex'
p10212
g7314
sS'outcome_loop.thisN'
p10213
I181
sS'outcome_loop.thisTrialN'
p10214
I181
sg62
g66
sg33
S'left'
p10215
sS'block_loop.thisN'
p10216
I2
sS'outcome_loop.thisIndex'
p10217
g63
(g96
S'\xb5\x00\x00\x00'
tRp10218
sg30
g10209
sg67
g11
sg68
g69
sg7321
V22-daim.png
p10219
sS'block_loop.thisTrial'
p10220
Nsg60
g61
sS'block_loop.thisTrialN'
p10221
I0
sg34
F0.59941919992706971
sg7325
V22-daim.png
p10222
sa(dp10223
S'block_loop.thisRepN'
p10224
I2
sg7308
V45-chewy_nougat.png
p10225
sg7310
V45-chewy_nougat.png
p10226
sg70
g71
sS'outcome_loop.thisRepN'
p10227
I0
sS'block_loop.thisIndex'
p10228
g7314
sS'outcome_loop.thisN'
p10229
I182
sS'outcome_loop.thisTrialN'
p10230
I182
sg62
g66
sg33
S'left'
p10231
sS'block_loop.thisN'
p10232
I2
sS'outcome_loop.thisIndex'
p10233
g63
(g96
S'\xb6\x00\x00\x00'
tRp10234
sg30
g10225
sg67
g11
sg68
g69
sg7321
V41-peanuts.png
p10235
sS'block_loop.thisTrial'
p10236
Nsg60
g61
sS'block_loop.thisTrialN'
p10237
I0
sg34
F0.61278654130546784
sg7325
V41-peanuts.png
p10238
sa(dp10239
S'block_loop.thisRepN'
p10240
I2
sg7308
V43-mrporky_pork_crackles.png
p10241
sg7310
V18-mms.png
p10242
sg70
g71
sS'outcome_loop.thisRepN'
p10243
I0
sS'block_loop.thisIndex'
p10244
g7314
sS'outcome_loop.thisN'
p10245
I183
sS'outcome_loop.thisTrialN'
p10246
I183
sg62
g66
sg33
S'right'
p10247
sS'block_loop.thisN'
p10248
I2
sS'outcome_loop.thisIndex'
p10249
g63
(g96
S'\xb7\x00\x00\x00'
tRp10250
sg30
g10241
sg67
g11
sg68
g69
sg7321
V18-mms.png
p10251
sS'block_loop.thisTrial'
p10252
Nsg60
g61
sS'block_loop.thisTrialN'
p10253
I0
sg34
F0.61279408416521619
sg7325
V43-mrporky_pork_crackles.png
p10254
sa(dp10255
S'block_loop.thisRepN'
p10256
I2
sg7308
V4-corn.png
p10257
sg7310
V10-bounty.png
p10258
sg70
g71
sS'outcome_loop.thisRepN'
p10259
I0
sS'block_loop.thisIndex'
p10260
g7314
sS'outcome_loop.thisN'
p10261
I184
sS'outcome_loop.thisTrialN'
p10262
I184
sg62
g66
sg33
S'right'
p10263
sS'block_loop.thisN'
p10264
I2
sS'outcome_loop.thisIndex'
p10265
g63
(g96
S'\xb8\x00\x00\x00'
tRp10266
sg30
g10257
sg67
g11
sg68
g69
sg7321
V10-bounty.png
p10267
sS'block_loop.thisTrial'
p10268
Nsg60
g61
sS'block_loop.thisTrialN'
p10269
I0
sg34
F0.95907580432685791
sg7325
V4-corn.png
p10270
sa(dp10271
S'block_loop.thisRepN'
p10272
I2
sg7308
V19-caramello.png
p10273
sg7310
V30-spaghetti_hoops.png
p10274
sg70
g71
sS'outcome_loop.thisRepN'
p10275
I0
sS'block_loop.thisIndex'
p10276
g7314
sS'outcome_loop.thisN'
p10277
I185
sS'outcome_loop.thisTrialN'
p10278
I185
sg62
g66
sg33
S'right'
p10279
sS'block_loop.thisN'
p10280
I2
sS'outcome_loop.thisIndex'
p10281
g63
(g96
S'\xb9\x00\x00\x00'
tRp10282
sg30
g10273
sg67
g11
sg68
g69
sg7321
V30-spaghetti_hoops.png
p10283
sS'block_loop.thisTrial'
p10284
Nsg60
g61
sS'block_loop.thisTrialN'
p10285
I0
sg34
F0.86584300518734381
sg7325
V19-caramello.png
p10286
sa(dp10287
S'block_loop.thisRepN'
p10288
I2
sg7308
V42-mrkipling_lemon_slices.png
p10289
sg7310
V42-mrkipling_lemon_slices.png
p10290
sg70
g71
sS'outcome_loop.thisRepN'
p10291
I0
sS'block_loop.thisIndex'
p10292
g7314
sS'outcome_loop.thisN'
p10293
I186
sS'outcome_loop.thisTrialN'
p10294
I186
sg62
g66
sg33
S'left'
p10295
sS'block_loop.thisN'
p10296
I2
sS'outcome_loop.thisIndex'
p10297
g63
(g96
S'\xba\x00\x00\x00'
tRp10298
sg30
g10289
sg67
g11
sg68
g69
sg7321
V16-skips_prawn.png
p10299
sS'block_loop.thisTrial'
p10300
Nsg60
g61
sS'block_loop.thisTrialN'
p10301
I0
sg34
F0.66606593854885432
sg7325
V16-skips_prawn.png
p10302
sa(dp10303
S'block_loop.thisRepN'
p10304
I2
sg7308
V33-ambrosia_rice.png
p10305
sg7310
V23-crunchie.png
p10306
sg70
g71
sS'outcome_loop.thisRepN'
p10307
I0
sS'block_loop.thisIndex'
p10308
g7314
sS'outcome_loop.thisN'
p10309
I187
sS'outcome_loop.thisTrialN'
p10310
I187
sg62
g66
sg33
S'right'
p10311
sS'block_loop.thisN'
p10312
I2
sS'outcome_loop.thisIndex'
p10313
g63
(g96
S'\xbb\x00\x00\x00'
tRp10314
sg30
g10305
sg67
g11
sg68
g69
sg7321
V23-crunchie.png
p10315
sS'block_loop.thisTrial'
p10316
Nsg60
g61
sS'block_loop.thisTrialN'
p10317
I0
sg34
F0.65273882574365416
sg7325
V33-ambrosia_rice.png
p10318
sa(dp10319
S'block_loop.thisRepN'
p10320
I2
sg7308
V49-yorkie.png
p10321
sg7310
V35-sultanas.png
p10322
sg70
g71
sS'outcome_loop.thisRepN'
p10323
I0
sS'block_loop.thisIndex'
p10324
g7314
sS'outcome_loop.thisN'
p10325
I188
sS'outcome_loop.thisTrialN'
p10326
I188
sg62
g66
sg33
S'right'
p10327
sS'block_loop.thisN'
p10328
I2
sS'outcome_loop.thisIndex'
p10329
g63
(g96
S'\xbc\x00\x00\x00'
tRp10330
sg30
g10321
sg67
g11
sg68
g69
sg7321
V35-sultanas.png
p10331
sS'block_loop.thisTrial'
p10332
Nsg60
g61
sS'block_loop.thisTrialN'
p10333
I0
sg34
F0.9058056261328602
sg7325
V49-yorkie.png
p10334
sa(dp10335
S'block_loop.thisRepN'
p10336
I2
sg7308
V31-foxs_golden_biscuits.png
p10337
sg7310
V25-kitkat.png
p10338
sg70
g71
sS'outcome_loop.thisRepN'
p10339
I0
sS'block_loop.thisIndex'
p10340
g7314
sS'outcome_loop.thisN'
p10341
I189
sS'outcome_loop.thisTrialN'
p10342
I189
sg62
g66
sg33
S'right'
p10343
sS'block_loop.thisN'
p10344
I2
sS'outcome_loop.thisIndex'
p10345
g63
(g96
S'\xbd\x00\x00\x00'
tRp10346
sg30
g10337
sg67
g11
sg68
g69
sg7321
V25-kitkat.png
p10347
sS'block_loop.thisTrial'
p10348
Nsg60
g61
sS'block_loop.thisTrialN'
p10349
I0
sg34
F0.67937181960405724
sg7325
V31-foxs_golden_biscuits.png
p10350
sa(dp10351
S'block_loop.thisRepN'
p10352
I2
sg7308
V1-smarties_cookies.png
p10353
sg7310
V21-nakd_banana_crunch.png
p10354
sg70
g71
sS'outcome_loop.thisRepN'
p10355
I0
sS'block_loop.thisIndex'
p10356
g7314
sS'outcome_loop.thisN'
p10357
I190
sS'outcome_loop.thisTrialN'
p10358
I190
sg62
g66
sg33
S'right'
p10359
sS'block_loop.thisN'
p10360
I2
sS'outcome_loop.thisIndex'
p10361
g63
(g96
S'\xbe\x00\x00\x00'
tRp10362
sg30
g10353
sg67
g11
sg68
g69
sg7321
V21-nakd_banana_crunch.png
p10363
sS'block_loop.thisTrial'
p10364
Nsg60
g61
sS'block_loop.thisTrialN'
p10365
I0
sg34
F0.62611058109359874
sg7325
V1-smarties_cookies.png
p10366
sa(dp10367
S'block_loop.thisRepN'
p10368
I2
sg7308
V6-sour_patch_kids.png
p10369
sg7310
V6-sour_patch_kids.png
p10370
sg70
g71
sS'outcome_loop.thisRepN'
p10371
I0
sS'block_loop.thisIndex'
p10372
g7314
sS'outcome_loop.thisN'
p10373
I191
sS'outcome_loop.thisTrialN'
p10374
I191
sg62
g66
sg33
S'right'
p10375
sS'block_loop.thisN'
p10376
I2
sS'outcome_loop.thisIndex'
p10377
g63
(g96
S'\xbf\x00\x00\x00'
tRp10378
sg30
g10369
sg67
g11
sg68
g69
sg7321
V38-maltesers.png
p10379
sS'block_loop.thisTrial'
p10380
Nsg60
g61
sS'block_loop.thisTrialN'
p10381
I0
sg34
F0.54619763126356702
sg7325
V38-maltesers.png
p10382
sa(dp10383
S'block_loop.thisRepN'
p10384
I2
sg7308
V1-smarties_cookies.png
p10385
sg7310
V21-nakd_banana_crunch.png
p10386
sg70
g71
sS'outcome_loop.thisRepN'
p10387
I0
sS'block_loop.thisIndex'
p10388
g7314
sS'outcome_loop.thisN'
p10389
I192
sS'outcome_loop.thisTrialN'
p10390
I192
sg62
g66
sg33
S'right'
p10391
sS'block_loop.thisN'
p10392
I2
sS'outcome_loop.thisIndex'
p10393
g63
(g96
S'\xc0\x00\x00\x00'
tRp10394
sg30
V21-nakd_banana_crunch.png
p10395
sg67
g11
sg68
g69
sg7321
g10395
sS'block_loop.thisTrial'
p10396
Nsg60
g61
sS'block_loop.thisTrialN'
p10397
I0
sg34
F0.53286716607908602
sg7325
V1-smarties_cookies.png
p10398
sa(dp10399
S'block_loop.thisRepN'
p10400
I2
sg7308
V19-caramello.png
p10401
sg7310
V30-spaghetti_hoops.png
p10402
sg70
g71
sS'outcome_loop.thisRepN'
p10403
I0
sS'block_loop.thisIndex'
p10404
g7314
sS'outcome_loop.thisN'
p10405
I193
sS'outcome_loop.thisTrialN'
p10406
I193
sg62
g66
sg33
S'right'
p10407
sS'block_loop.thisN'
p10408
I2
sS'outcome_loop.thisIndex'
p10409
g63
(g96
S'\xc1\x00\x00\x00'
tRp10410
sg30
V30-spaghetti_hoops.png
p10411
sg67
g11
sg68
g69
sg7321
g10411
sS'block_loop.thisTrial'
p10412
Nsg60
g61
sS'block_loop.thisTrialN'
p10413
I0
sg34
F0.57283034575630154
sg7325
V19-caramello.png
p10414
sa(dp10415
S'block_loop.thisRepN'
p10416
I2
sg7308
V48-twix.png
p10417
sg7310
V50-polo.png
p10418
sg70
g71
sS'outcome_loop.thisRepN'
p10419
I0
sS'block_loop.thisIndex'
p10420
g7314
sS'outcome_loop.thisN'
p10421
I194
sS'outcome_loop.thisTrialN'
p10422
I194
sg62
g66
sg33
S'right'
p10423
sS'block_loop.thisN'
p10424
I2
sS'outcome_loop.thisIndex'
p10425
g63
(g96
S'\xc2\x00\x00\x00'
tRp10426
sg30
V50-polo.png
p10427
sg67
g11
sg68
g69
sg7321
g10427
sS'block_loop.thisTrial'
p10428
Nsg60
g61
sS'block_loop.thisTrialN'
p10429
I0
sg34
F0.73266825811697345
sg7325
V48-twix.png
p10430
sa(dp10431
S'block_loop.thisRepN'
p10432
I2
sg7308
V43-mrporky_pork_crackles.png
p10433
sg7310
V18-mms.png
p10434
sg70
g71
sS'outcome_loop.thisRepN'
p10435
I0
sS'block_loop.thisIndex'
p10436
g7314
sS'outcome_loop.thisN'
p10437
I195
sS'outcome_loop.thisTrialN'
p10438
I195
sg62
g66
sg33
S'right'
p10439
sS'block_loop.thisN'
p10440
I2
sS'outcome_loop.thisIndex'
p10441
g63
(g96
S'\xc3\x00\x00\x00'
tRp10442
sg30
g10433
sg67
g11
sg68
g69
sg7321
V18-mms.png
p10443
sS'block_loop.thisTrial'
p10444
Nsg60
g61
sS'block_loop.thisTrialN'
p10445
I0
sg34
F0.47960145772776741
sg7325
V43-mrporky_pork_crackles.png
p10446
sa(dp10447
S'block_loop.thisRepN'
p10448
I2
sg7308
V4-corn.png
p10449
sg7310
V10-bounty.png
p10450
sg70
g71
sS'outcome_loop.thisRepN'
p10451
I0
sS'block_loop.thisIndex'
p10452
g7314
sS'outcome_loop.thisN'
p10453
I196
sS'outcome_loop.thisTrialN'
p10454
I196
sg62
g66
sg33
S'right'
p10455
sS'block_loop.thisN'
p10456
I2
sS'outcome_loop.thisIndex'
p10457
g63
(g96
S'\xc4\x00\x00\x00'
tRp10458
sg30
V10-bounty.png
p10459
sg67
g11
sg68
g69
sg7321
g10459
sS'block_loop.thisTrial'
p10460
Nsg60
g61
sS'block_loop.thisTrialN'
p10461
I0
sg34
F0.69268747843671008
sg7325
V4-corn.png
p10462
sa(dp10463
S'block_loop.thisRepN'
p10464
I2
sg7308
V36-fig_rolls.png
p10465
sg7310
V34-hula_hoops_bbq_beef.png
p10466
sg70
g71
sS'outcome_loop.thisRepN'
p10467
I0
sS'block_loop.thisIndex'
p10468
g7314
sS'outcome_loop.thisN'
p10469
I197
sS'outcome_loop.thisTrialN'
p10470
I197
sg62
g66
sg33
S'right'
p10471
sS'block_loop.thisN'
p10472
I2
sS'outcome_loop.thisIndex'
p10473
g63
(g96
S'\xc5\x00\x00\x00'
tRp10474
sg30
g10465
sg67
g11
sg68
g69
sg7321
V34-hula_hoops_bbq_beef.png
p10475
sS'block_loop.thisTrial'
p10476
Nsg60
g61
sS'block_loop.thisTrialN'
p10477
I0
sg34
F0.62609884775883984
sg7325
V36-fig_rolls.png
p10478
sa(dp10479
S'block_loop.thisRepN'
p10480
I2
sg7308
V7-olives.png
p10481
sg7310
V7-olives.png
p10482
sg70
g71
sS'outcome_loop.thisRepN'
p10483
I0
sS'block_loop.thisIndex'
p10484
g7314
sS'outcome_loop.thisN'
p10485
I198
sS'outcome_loop.thisTrialN'
p10486
I198
sg62
g66
sg33
S'left'
p10487
sS'block_loop.thisN'
p10488
I2
sS'outcome_loop.thisIndex'
p10489
g63
(g96
S'\xc6\x00\x00\x00'
tRp10490
sg30
V22-daim.png
p10491
sg67
g11
sg68
g69
sg7321
g10491
sS'block_loop.thisTrial'
p10492
Nsg60
g61
sS'block_loop.thisTrialN'
p10493
I0
sg34
F0.61277341114509909
sg7325
V22-daim.png
p10494
sa(dp10495
S'block_loop.thisRepN'
p10496
I2
sg7308
V20-fruit_pastilles.png
p10497
sg7310
V2-steamed_puddings.png
p10498
sg70
g71
sS'outcome_loop.thisRepN'
p10499
I0
sS'block_loop.thisIndex'
p10500
g7314
sS'outcome_loop.thisN'
p10501
I199
sS'outcome_loop.thisTrialN'
p10502
I199
sg62
g66
sg33
S'right'
p10503
sS'block_loop.thisN'
p10504
I2
sS'outcome_loop.thisIndex'
p10505
g63
(g96
S'\xc7\x00\x00\x00'
tRp10506
sg30
V2-steamed_puddings.png
p10507
sg67
g11
sg68
g69
sg7321
g10507
sS'block_loop.thisTrial'
p10508
Nsg60
g61
sS'block_loop.thisTrialN'
p10509
I0
sg34
F0.66607767188179423
sg7325
V20-fruit_pastilles.png
p10510
sa(dp10511
S'block_loop.thisRepN'
p10512
I2
sg70
g71
sS'block_loop.thisIndex'
p10513
g7314
sg62
g66
sS'block_loop.thisN'
p10514
I2
sg67
g11
sg68
g69
sS'block_loop.thisTrial'
p10515
Nsg60
g61
sS'block_loop.thisTrialN'
p10516
I0
sa(dp10517
g68
g69
sg38
I72
sg67
g11
sg60
g61
sg37
I528
sg70
g71
sg62
g66
sa(dp10518
g68
g69
sg67
g11
sg39
S'space'
p10519
sg70
g71
sg60
g61
sg40
F3.2900502717529889
sg62
g66
sa(dp10520
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10521
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10522
I0
sS'bdm_loop2.thisIndex'
p10523
g63
(g96
S'\x07\x00\x00\x00'
tRp10524
sS'bdm_loop2.thisN'
p10525
I0
sg42
F2.0939999999999999
sg60
g61
sVbdm_img
p10526
V8-liquorice_catherine_wheels.png
p10527
sa(dp10528
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10529
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10530
I1
sS'bdm_loop2.thisIndex'
p10531
g63
(g96
S'\x02\x00\x00\x00'
tRp10532
sS'bdm_loop2.thisN'
p10533
I1
sg42
F1.534
sg60
g61
sg10526
V3-dole_fruit_snack.png
p10534
sa(dp10535
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10536
I0
sg70
g71
sg62
g66
sg41
F0.31999999999999895
sS'bdm_loop2.thisTrialN'
p10537
I2
sS'bdm_loop2.thisIndex'
p10538
g63
(g96
S'\x05\x00\x00\x00'
tRp10539
sS'bdm_loop2.thisN'
p10540
I2
sg42
F3.2120000000000002
sg60
g61
sg10526
V6-sour_patch_kids.png
p10541
sa(dp10542
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10543
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10544
I3
sS'bdm_loop2.thisIndex'
p10545
g63
(g96
S'\x12\x00\x00\x00'
tRp10546
sS'bdm_loop2.thisN'
p10547
I3
sg42
F1.681
sg60
g61
sg10526
V25-kitkat.png
p10548
sa(dp10549
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10550
I0
sg70
g71
sg62
g66
sg41
F0.13999999999999896
sS'bdm_loop2.thisTrialN'
p10551
I4
sS'bdm_loop2.thisIndex'
p10552
g63
(g96
S'$\x00\x00\x00'
tRp10553
sS'bdm_loop2.thisN'
p10554
I4
sg42
F1.841
sg60
g61
sg10526
V48-twix.png
p10555
sa(dp10556
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10557
I0
sg70
g71
sg62
g66
sg41
F0.49999999999999911
sS'bdm_loop2.thisTrialN'
p10558
I5
sS'bdm_loop2.thisIndex'
p10559
g63
(g96
S'\x13\x00\x00\x00'
tRp10560
sS'bdm_loop2.thisN'
p10561
I5
sg42
F1.494
sg60
g61
sg10526
V26-walkers_smoky_bacon.png
p10562
sa(dp10563
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10564
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10565
I6
sS'bdm_loop2.thisIndex'
p10566
g63
(g96
S'\r\x00\x00\x00'
tRp10567
sS'bdm_loop2.thisN'
p10568
I6
sg42
F1.494
sg60
g61
sg10526
V19-caramello.png
p10569
sa(dp10570
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10571
I0
sg70
g71
sg62
g66
sg41
F0.47999999999999909
sS'bdm_loop2.thisTrialN'
p10572
I7
sS'bdm_loop2.thisIndex'
p10573
g63
(g96
S'\x01\x00\x00\x00'
tRp10574
sS'bdm_loop2.thisN'
p10575
I7
sg42
F1.1479999999999999
sg60
g61
sg10526
V2-steamed_puddings.png
p10576
sa(dp10577
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10578
I0
sg70
g71
sg62
g66
sg41
F0.31999999999999895
sS'bdm_loop2.thisTrialN'
p10579
I8
sS'bdm_loop2.thisIndex'
p10580
g63
(g96
S'"\x00\x00\x00'
tRp10581
sS'bdm_loop2.thisN'
p10582
I8
sg42
F1.401
sg60
g61
sg10526
V45-chewy_nougat.png
p10583
sa(dp10584
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10585
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10586
I9
sS'bdm_loop2.thisIndex'
p10587
g63
(g96
S'\x1f\x00\x00\x00'
tRp10588
sS'bdm_loop2.thisN'
p10589
I9
sg42
F3.7189999999999999
sg60
g61
sg10526
V42-mrkipling_lemon_slices.png
p10590
sa(dp10591
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10592
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10593
I10
sS'bdm_loop2.thisIndex'
p10594
g63
(g96
S'#\x00\x00\x00'
tRp10595
sS'bdm_loop2.thisN'
p10596
I10
sg42
F1.454
sg60
g61
sg10526
V46-pistachios.png
p10597
sa(dp10598
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10599
I0
sg70
g71
sg62
g66
sg41
F0.47999999999999909
sS'bdm_loop2.thisTrialN'
p10600
I11
sS'bdm_loop2.thisIndex'
p10601
g63
(g96
S'\x1c\x00\x00\x00'
tRp10602
sS'bdm_loop2.thisN'
p10603
I11
sg42
F1.2010000000000001
sg60
g61
sg10526
V38-maltesers.png
p10604
sa(dp10605
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10606
I0
sg70
g71
sg62
g66
sg41
F0.63999999999999924
sS'bdm_loop2.thisTrialN'
p10607
I12
sS'bdm_loop2.thisIndex'
p10608
g63
(g96
S' \x00\x00\x00'
tRp10609
sS'bdm_loop2.thisN'
p10610
I12
sg42
F1.228
sg60
g61
sg10526
V43-mrporky_pork_crackles.png
p10611
sa(dp10612
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10613
I0
sg70
g71
sg62
g66
sg41
F0.019999999999998939
sS'bdm_loop2.thisTrialN'
p10614
I13
sS'bdm_loop2.thisIndex'
p10615
g63
(g96
S'\x15\x00\x00\x00'
tRp10616
sS'bdm_loop2.thisN'
p10617
I13
sg42
F1.4810000000000001
sg60
g61
sg10526
V29-beans.png
p10618
sa(dp10619
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10620
I0
sg70
g71
sg62
g66
sg41
F0.039999999999998939
sS'bdm_loop2.thisTrialN'
p10621
I14
sS'bdm_loop2.thisIndex'
p10622
g63
(g96
S'\x0c\x00\x00\x00'
tRp10623
sS'bdm_loop2.thisN'
p10624
I14
sg42
F1.361
sg60
g61
sg10526
V18-mms.png
p10625
sa(dp10626
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10627
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10628
I15
sS'bdm_loop2.thisIndex'
p10629
g63
(g96
S'\x14\x00\x00\x00'
tRp10630
sS'bdm_loop2.thisN'
p10631
I15
sg42
F1.575
sg60
g61
sg10526
V27-hartleys_raspberries_jelly.png
p10632
sa(dp10633
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10634
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10635
I16
sS'bdm_loop2.thisIndex'
p10636
g63
(g96
S'!\x00\x00\x00'
tRp10637
sS'bdm_loop2.thisN'
p10638
I16
sg42
F1.3879999999999999
sg60
g61
sg10526
V44-crunch.png
p10639
sa(dp10640
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10641
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10642
I17
sS'bdm_loop2.thisIndex'
p10643
g63
(g96
S'\x1a\x00\x00\x00'
tRp10644
sS'bdm_loop2.thisN'
p10645
I17
sg42
F1.454
sg60
g61
sg10526
V35-sultanas.png
p10646
sa(dp10647
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10648
I0
sg70
g71
sg62
g66
sg41
F0.019999999999998939
sS'bdm_loop2.thisTrialN'
p10649
I18
sS'bdm_loop2.thisIndex'
p10650
g63
(g96
S'\x1e\x00\x00\x00'
tRp10651
sS'bdm_loop2.thisN'
p10652
I18
sg42
F1.3879999999999999
sg60
g61
sg10526
V41-peanuts.png
p10653
sa(dp10654
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10655
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10656
I19
sS'bdm_loop2.thisIndex'
p10657
g63
(g96
S'\x10\x00\x00\x00'
tRp10658
sS'bdm_loop2.thisN'
p10659
I19
sg42
F1.4410000000000001
sg60
g61
sg10526
V22-daim.png
p10660
sa(dp10661
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10662
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10663
I20
sS'bdm_loop2.thisIndex'
p10664
g63
(g96
S'&\x00\x00\x00'
tRp10665
sS'bdm_loop2.thisN'
p10666
I20
sg42
F1.4139999999999999
sg60
g61
sg10526
V50-polo.png
p10667
sa(dp10668
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10669
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10670
I21
sS'bdm_loop2.thisIndex'
p10671
g63
(g96
S'\x0e\x00\x00\x00'
tRp10672
sS'bdm_loop2.thisN'
p10673
I21
sg42
F1.375
sg60
g61
sg10526
V20-fruit_pastilles.png
p10674
sa(dp10675
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10676
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10677
I22
sS'bdm_loop2.thisIndex'
p10678
g63
(g96
S"'\x00\x00\x00"
tRp10679
sS'bdm_loop2.thisN'
p10680
I22
sg42
F1.361
sg60
g61
sg10526
V51-mars.png
p10681
sa(dp10682
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10683
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10684
I23
sS'bdm_loop2.thisIndex'
p10685
g63
(g96
S'\x06\x00\x00\x00'
tRp10686
sS'bdm_loop2.thisN'
p10687
I23
sg42
F1.1479999999999999
sg60
g61
sg10526
V7-olives.png
p10688
sa(dp10689
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10690
I0
sg70
g71
sg62
g66
sg41
F0.079999999999998947
sS'bdm_loop2.thisTrialN'
p10691
I24
sS'bdm_loop2.thisIndex'
p10692
g63
(g96
S'\n\x00\x00\x00'
tRp10693
sS'bdm_loop2.thisN'
p10694
I24
sg42
F2.0139999999999998
sg60
g61
sg10526
V16-skips_prawn.png
p10695
sa(dp10696
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10697
I0
sg70
g71
sg62
g66
sg41
F0.47999999999999909
sS'bdm_loop2.thisTrialN'
p10698
I25
sS'bdm_loop2.thisIndex'
p10699
g63
(g96
S'\x19\x00\x00\x00'
tRp10700
sS'bdm_loop2.thisN'
p10701
I25
sg42
F1.1080000000000001
sg60
g61
sg10526
V34-hula_hoops_bbq_beef.png
p10702
sa(dp10703
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10704
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10705
I26
sS'bdm_loop2.thisIndex'
p10706
g63
(g96
S'\x11\x00\x00\x00'
tRp10707
sS'bdm_loop2.thisN'
p10708
I26
sg42
F1.375
sg60
g61
sg10526
V23-crunchie.png
p10709
sa(dp10710
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10711
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10712
I27
sS'bdm_loop2.thisIndex'
p10713
g63
(g96
S'\x04\x00\x00\x00'
tRp10714
sS'bdm_loop2.thisN'
p10715
I27
sg42
F1.3480000000000001
sg60
g61
sg10526
V5-pineapple.png
p10716
sa(dp10717
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10718
I0
sg70
g71
sg62
g66
sg41
F0.65999999999999925
sS'bdm_loop2.thisTrialN'
p10719
I28
sS'bdm_loop2.thisIndex'
p10720
g63
(g96
S'\t\x00\x00\x00'
tRp10721
sS'bdm_loop2.thisN'
p10722
I28
sg42
F1.3480000000000001
sg60
g61
sg10526
V13-mccoys_steak_crisps.png
p10723
sa(dp10724
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10725
I0
sg70
g71
sg62
g66
sg41
F0.61999999999999922
sS'bdm_loop2.thisTrialN'
p10726
I29
sS'bdm_loop2.thisIndex'
p10727
g63
(g96
S'\x00\x00\x00\x00'
tRp10728
sS'bdm_loop2.thisN'
p10729
I29
sg42
F1.2150000000000001
sg60
g61
sg10526
V1-smarties_cookies.png
p10730
sa(dp10731
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10732
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10733
I30
sS'bdm_loop2.thisIndex'
p10734
g63
(g96
S'\x0f\x00\x00\x00'
tRp10735
sS'bdm_loop2.thisN'
p10736
I30
sg42
F1.3740000000000001
sg60
g61
sg10526
V21-nakd_banana_crunch.png
p10737
sa(dp10738
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10739
I0
sg70
g71
sg62
g66
sg41
F0.47999999999999909
sS'bdm_loop2.thisTrialN'
p10740
I31
sS'bdm_loop2.thisIndex'
p10741
g63
(g96
S'\x17\x00\x00\x00'
tRp10742
sS'bdm_loop2.thisN'
p10743
I31
sg42
F1.6140000000000001
sg60
g61
sg10526
V31-foxs_golden_biscuits.png
p10744
sa(dp10745
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10746
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10747
I32
sS'bdm_loop2.thisIndex'
p10748
g63
(g96
S'%\x00\x00\x00'
tRp10749
sS'bdm_loop2.thisN'
p10750
I32
sg42
F1.601
sg60
g61
sg10526
V49-yorkie.png
p10751
sa(dp10752
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10753
I0
sg70
g71
sg62
g66
sg41
F0.5999999999999992
sS'bdm_loop2.thisTrialN'
p10754
I33
sS'bdm_loop2.thisIndex'
p10755
g63
(g96
S'\x0b\x00\x00\x00'
tRp10756
sS'bdm_loop2.thisN'
p10757
I33
sg42
F1.1479999999999999
sg60
g61
sg10526
V17-jacobs_mini_cheddars.png
p10758
sa(dp10759
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10760
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10761
I34
sS'bdm_loop2.thisIndex'
p10762
g63
(g96
S'\x1d\x00\x00\x00'
tRp10763
sS'bdm_loop2.thisN'
p10764
I34
sg42
F1.494
sg60
g61
sg10526
V40-sardines.png
p10765
sa(dp10766
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10767
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10768
I35
sS'bdm_loop2.thisIndex'
p10769
g63
(g96
S'\x08\x00\x00\x00'
tRp10770
sS'bdm_loop2.thisN'
p10771
I35
sg42
F1.1619999999999999
sg60
g61
sg10526
V10-bounty.png
p10772
sa(dp10773
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10774
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10775
I36
sS'bdm_loop2.thisIndex'
p10776
g63
(g96
S'\x16\x00\x00\x00'
tRp10777
sS'bdm_loop2.thisN'
p10778
I36
sg42
F1.1220000000000001
sg60
g61
sg10526
V30-spaghetti_hoops.png
p10779
sa(dp10780
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10781
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10782
I37
sS'bdm_loop2.thisIndex'
p10783
g63
(g96
S'\x18\x00\x00\x00'
tRp10784
sS'bdm_loop2.thisN'
p10785
I37
sg42
F1.028
sg60
g61
sg10526
V33-ambrosia_rice.png
p10786
sa(dp10787
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10788
I0
sg70
g71
sg62
g66
sg41
F0
sS'bdm_loop2.thisTrialN'
p10789
I38
sS'bdm_loop2.thisIndex'
p10790
g63
(g96
S'\x03\x00\x00\x00'
tRp10791
sS'bdm_loop2.thisN'
p10792
I38
sg42
F1.0549999999999999
sg60
g61
sg10526
V4-corn.png
p10793
sa(dp10794
g68
g69
sg67
g11
sS'bdm_loop2.thisRepN'
p10795
I0
sg70
g71
sg62
g66
sg41
F0.53999999999999915
sS'bdm_loop2.thisTrialN'
p10796
I39
sS'bdm_loop2.thisIndex'
p10797
g63
(g96
S'\x1b\x00\x00\x00'
tRp10798
sS'bdm_loop2.thisN'
p10799
I39
sg42
F1.0149999999999999
sg60
g61
sg10526
V36-fig_rolls.png
p10800
sa(dp10801
g68
g69
sg60
g61
sg67
g11
sg44
F1.9714757043147983
sg43
S'space'
p10802
sg70
g71
sg62
g66
sa(dp10803
g68
g69
sS'choice_left'
p10804
V26-walkers_smoky_bacon.png
p10805
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10806
sS'choice_right'
p10807
V44-crunch.png
p10808
sg46
F3.2632407191413222
sg60
g61
sg67
g11
sS'binary2.thisN'
p10809
I0
sS'binary2.thisIndex'
p10810
g63
(g96
S'\x00\x00\x00\x00'
tRp10811
sg70
g71
sS'binary2.thisTrialN'
p10812
I0
sS'binary2.thisRepN'
p10813
I0
sg48
F0.90800000000000003
sa(dp10814
g68
g69
sg10804
V48-twix.png
p10815
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10816
sg10807
V50-polo.png
p10817
sg46
F6.6195949485190795
sg60
g61
sg67
g11
sS'binary2.thisN'
p10818
I1
sS'binary2.thisIndex'
p10819
g63
(g96
S'\x01\x00\x00\x00'
tRp10820
sg70
g71
sS'binary2.thisTrialN'
p10821
I1
sS'binary2.thisRepN'
p10822
I0
sg48
F1.748
sa(dp10823
g68
g69
sg10804
V42-mrkipling_lemon_slices.png
p10824
sg47
F4.8000000000000007
sg62
g66
sg45
S'right'
p10825
sg10807
V16-skips_prawn.png
p10826
sg46
F2.4907394654910604
sg60
g61
sg67
g11
sS'binary2.thisN'
p10827
I2
sS'binary2.thisIndex'
p10828
g63
(g96
S'\x02\x00\x00\x00'
tRp10829
sg70
g71
sS'binary2.thisTrialN'
p10830
I2
sS'binary2.thisRepN'
p10831
I0
sg48
F1.401
sa(dp10832
g68
g69
sg10804
V43-mrporky_pork_crackles.png
p10833
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10834
sg10807
V18-mms.png
p10835
sg46
F0.5461805899922183
sg60
g61
sg67
g11
sS'binary2.thisN'
p10836
I3
sS'binary2.thisIndex'
p10837
g63
(g96
S'\x03\x00\x00\x00'
tRp10838
sg70
g71
sS'binary2.thisTrialN'
p10839
I3
sS'binary2.thisRepN'
p10840
I0
sg48
F0.496
sa(dp10841
g68
g69
sg10804
V13-mccoys_steak_crisps.png
p10842
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10843
sg10807
V3-dole_fruit_snack.png
p10844
sg46
F0.45295896545576397
sg60
g61
sg67
g11
sS'binary2.thisN'
p10845
I4
sS'binary2.thisIndex'
p10846
g63
(g96
S'\x04\x00\x00\x00'
tRp10847
sg70
g71
sS'binary2.thisTrialN'
p10848
I4
sS'binary2.thisRepN'
p10849
I0
sg48
F1.361
sa(dp10850
g68
g69
sg10804
V8-liquorice_catherine_wheels.png
p10851
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10852
sg10807
V17-jacobs_mini_cheddars.png
p10853
sg46
F0.55950435041449964
sg60
g61
sg67
g11
sS'binary2.thisN'
p10854
I5
sS'binary2.thisIndex'
p10855
g63
(g96
S'\x05\x00\x00\x00'
tRp10856
sg70
g71
sS'binary2.thisTrialN'
p10857
I5
sS'binary2.thisRepN'
p10858
I0
sg48
F0.52200000000000002
sa(dp10859
g68
g69
sg10804
V21-nakd_banana_crunch.png
p10860
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10861
sg10807
V1-smarties_cookies.png
p10862
sg46
F0.98570349024703319
sg60
g61
sg67
g11
sS'binary2.thisN'
p10863
I6
sS'binary2.thisIndex'
p10864
g63
(g96
S'\x06\x00\x00\x00'
tRp10865
sg70
g71
sS'binary2.thisTrialN'
p10866
I6
sS'binary2.thisRepN'
p10867
I0
sg48
F0.69499999999999995
sa(dp10868
g68
g69
sg10804
V51-mars.png
p10869
sg47
F5.1000000000000005
sg62
g66
sg45
S'left'
p10870
sg10807
V27-hartleys_raspberries_jelly.png
p10871
sg46
F0.5861557823682233
sg60
g61
sg67
g11
sS'binary2.thisN'
p10872
I7
sS'binary2.thisIndex'
p10873
g63
(g96
S'\x07\x00\x00\x00'
tRp10874
sg70
g71
sS'binary2.thisTrialN'
p10875
I7
sS'binary2.thisRepN'
p10876
I0
sg48
F0.58899999999999997
sa(dp10877
g68
g69
sg10804
V29-beans.png
p10878
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10879
sg10807
V46-pistachios.png
p10880
sg46
F0.59946697136183502
sg60
g61
sg67
g11
sS'binary2.thisN'
p10881
I8
sS'binary2.thisIndex'
p10882
g63
(g96
S'\x08\x00\x00\x00'
tRp10883
sg70
g71
sS'binary2.thisTrialN'
p10884
I8
sS'binary2.thisRepN'
p10885
I0
sg48
F0.496
sa(dp10886
g68
g69
sg10804
V41-peanuts.png
p10887
sg47
F5.3999999999999995
sg62
g66
sg45
S'right'
p10888
sg10807
V45-chewy_nougat.png
p10889
sg46
F0.87916201640109648
sg60
g61
sg67
g11
sS'binary2.thisN'
p10890
I9
sS'binary2.thisIndex'
p10891
g63
(g96
S'\t\x00\x00\x00'
tRp10892
sg70
g71
sS'binary2.thisTrialN'
p10893
I9
sS'binary2.thisRepN'
p10894
I0
sg48
F0.45600000000000002
sa(dp10895
g68
g69
sg10804
V34-hula_hoops_bbq_beef.png
p10896
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10897
sg10807
V36-fig_rolls.png
p10898
sg46
F1.3053698165549577
sg60
g61
sg67
g11
sS'binary2.thisN'
p10899
I10
sS'binary2.thisIndex'
p10900
g63
(g96
S'\n\x00\x00\x00'
tRp10901
sg70
g71
sS'binary2.thisTrialN'
p10902
I10
sS'binary2.thisRepN'
p10903
I0
sg48
F0.42899999999999999
sa(dp10904
g68
g69
sg10804
V30-spaghetti_hoops.png
p10905
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10906
sg10807
V19-caramello.png
p10907
sg46
F1.7583360455028014
sg60
g61
sg67
g11
sS'binary2.thisN'
p10908
I11
sS'binary2.thisIndex'
p10909
g63
(g96
S'\x0b\x00\x00\x00'
tRp10910
sg70
g71
sS'binary2.thisTrialN'
p10911
I11
sS'binary2.thisRepN'
p10912
I0
sg48
F0.442
sa(dp10913
g68
g69
sg10804
V40-sardines.png
p10914
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10915
sg10807
V5-pineapple.png
p10916
sg46
F0.66606118934214464
sg60
g61
sg67
g11
sS'binary2.thisN'
p10917
I12
sS'binary2.thisIndex'
p10918
g63
(g96
S'\x0c\x00\x00\x00'
tRp10919
sg70
g71
sS'binary2.thisTrialN'
p10920
I12
sS'binary2.thisRepN'
p10921
I0
sg48
F0.89500000000000002
sa(dp10922
g68
g69
sg10804
V16-skips_prawn.png
p10923
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10924
sg10807
V42-mrkipling_lemon_slices.png
p10925
sg46
F0.81257869366163504
sg60
g61
sg67
g11
sS'binary2.thisN'
p10926
I13
sS'binary2.thisIndex'
p10927
g63
(g96
S'\r\x00\x00\x00'
tRp10928
sg70
g71
sS'binary2.thisTrialN'
p10929
I13
sS'binary2.thisRepN'
p10930
I0
sg48
F0.46899999999999997
sa(dp10931
g68
g69
sg10804
V35-sultanas.png
p10932
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10933
sg10807
V49-yorkie.png
p10934
sg46
F1.0123663761733042
sg60
g61
sg67
g11
sS'binary2.thisN'
p10935
I14
sS'binary2.thisIndex'
p10936
g63
(g96
S'\x0e\x00\x00\x00'
tRp10937
sg70
g71
sS'binary2.thisTrialN'
p10938
I14
sS'binary2.thisRepN'
p10939
I0
sg48
F0.46899999999999997
sa(dp10940
g68
g69
sg10804
V36-fig_rolls.png
p10941
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10942
sg10807
V34-hula_hoops_bbq_beef.png
p10943
sg46
F0.75929007737067877
sg60
g61
sg67
g11
sS'binary2.thisN'
p10944
I15
sS'binary2.thisIndex'
p10945
g63
(g96
S'\x0f\x00\x00\x00'
tRp10946
sg70
g71
sS'binary2.thisTrialN'
p10947
I15
sS'binary2.thisRepN'
p10948
I0
sg48
F0.48199999999999998
sa(dp10949
g68
g69
sg10804
V6-sour_patch_kids.png
p10950
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10951
sg10807
V38-maltesers.png
p10952
sg46
F0.57282056797703262
sg60
g61
sg67
g11
sS'binary2.thisN'
p10953
I16
sS'binary2.thisIndex'
p10954
g63
(g96
S'\x10\x00\x00\x00'
tRp10955
sg70
g71
sS'binary2.thisTrialN'
p10956
I16
sS'binary2.thisRepN'
p10957
I0
sg48
F0.442
sa(dp10958
g68
g69
sg10804
V27-hartleys_raspberries_jelly.png
p10959
sg47
F3.5
sg62
g66
sg45
S'left'
p10960
sg10807
V51-mars.png
p10961
sg46
F1.1055765467390302
sg60
g61
sg67
g11
sS'binary2.thisN'
p10962
I17
sS'binary2.thisIndex'
p10963
g63
(g96
S'\x11\x00\x00\x00'
tRp10964
sg70
g71
sS'binary2.thisTrialN'
p10965
I17
sS'binary2.thisRepN'
p10966
I0
sg48
F0.52200000000000002
sa(dp10967
g68
g69
sg10804
V10-bounty.png
p10968
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10969
sg10807
V4-corn.png
p10970
sg46
F0.99903479352724389
sg60
g61
sg67
g11
sS'binary2.thisN'
p10971
I18
sS'binary2.thisIndex'
p10972
g63
(g96
S'\x12\x00\x00\x00'
tRp10973
sg70
g71
sS'binary2.thisTrialN'
p10974
I18
sS'binary2.thisRepN'
p10975
I0
sg48
F0.42899999999999999
sa(dp10976
g68
g69
sg10804
V20-fruit_pastilles.png
p10977
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10978
sg10807
V2-steamed_puddings.png
p10979
sg46
F0.71932801515322353
sg60
g61
sg67
g11
sS'binary2.thisN'
p10980
I19
sS'binary2.thisIndex'
p10981
g63
(g96
S'\x13\x00\x00\x00'
tRp10982
sg70
g71
sS'binary2.thisTrialN'
p10983
I19
sS'binary2.thisRepN'
p10984
I0
sg48
F0.45600000000000002
sa(dp10985
g68
g69
sg10804
V46-pistachios.png
p10986
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p10987
sg10807
V29-beans.png
p10988
sg46
F0.6527321209814545
sg60
g61
sg67
g11
sS'binary2.thisN'
p10989
I20
sS'binary2.thisIndex'
p10990
g63
(g96
S'\x14\x00\x00\x00'
tRp10991
sg70
g71
sS'binary2.thisTrialN'
p10992
I20
sS'binary2.thisRepN'
p10993
I0
sg48
F0.45600000000000002
sa(dp10994
g68
g69
sg10804
V18-mms.png
p10995
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p10996
sg10807
V43-mrporky_pork_crackles.png
p10997
sg46
F0.54619036776966823
sg60
g61
sg67
g11
sS'binary2.thisN'
p10998
I21
sS'binary2.thisIndex'
p10999
g63
(g96
S'\x15\x00\x00\x00'
tRp11000
sg70
g71
sS'binary2.thisTrialN'
p11001
I21
sS'binary2.thisRepN'
p11002
I0
sg48
F0.442
sa(dp11003
g68
g69
sg10804
V49-yorkie.png
p11004
sg47
F5.2999999999999998
sg62
g66
sg45
S'left'
p11005
sg10807
V35-sultanas.png
p11006
sg46
F0.74597218361486739
sg60
g61
sg67
g11
sS'binary2.thisN'
p11007
I22
sS'binary2.thisIndex'
p11008
g63
(g96
S'\x16\x00\x00\x00'
tRp11009
sg70
g71
sS'binary2.thisTrialN'
p11010
I22
sS'binary2.thisRepN'
p11011
I0
sg48
F0.50900000000000001
sa(dp11012
g68
g69
sg10804
V45-chewy_nougat.png
p11013
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11014
sg10807
V41-peanuts.png
p11015
sg46
F0.63940137643294293
sg60
g61
sg67
g11
sS'binary2.thisN'
p11016
I23
sS'binary2.thisIndex'
p11017
g63
(g96
S'\x17\x00\x00\x00'
tRp11018
sg70
g71
sS'binary2.thisTrialN'
p11019
I23
sS'binary2.thisRepN'
p11020
I0
sg48
F0.42899999999999999
sa(dp11021
g68
g69
sg10804
V3-dole_fruit_snack.png
p11022
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11023
sg10807
V13-mccoys_steak_crisps.png
p11024
sg46
F0.5328727533815254
sg60
g61
sg67
g11
sS'binary2.thisN'
p11025
I24
sS'binary2.thisIndex'
p11026
g63
(g96
S'\x18\x00\x00\x00'
tRp11027
sg70
g71
sS'binary2.thisTrialN'
p11028
I24
sS'binary2.thisRepN'
p11029
I0
sg48
F0.96199999999999997
sa(dp11030
g68
g69
sg10804
V44-crunch.png
p11031
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11032
sg10807
V26-walkers_smoky_bacon.png
p11033
sg46
F0.45294779085088521
sg60
g61
sg67
g11
sS'binary2.thisN'
p11034
I25
sS'binary2.thisIndex'
p11035
g63
(g96
S'\x19\x00\x00\x00'
tRp11036
sg70
g71
sS'binary2.thisTrialN'
p11037
I25
sS'binary2.thisRepN'
p11038
I0
sg48
F0.496
sa(dp11039
g68
g69
sg10804
V5-pineapple.png
p11040
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11041
sg10807
V40-sardines.png
p11042
sg46
F0.932437502531684
sg60
g61
sg67
g11
sS'binary2.thisN'
p11043
I26
sS'binary2.thisIndex'
p11044
g63
(g96
S'\x1a\x00\x00\x00'
tRp11045
sg70
g71
sS'binary2.thisTrialN'
p11046
I26
sS'binary2.thisRepN'
p11047
I0
sg48
F0.442
sa(dp11048
g68
g69
sg10804
V33-ambrosia_rice.png
p11049
sg47
F5.4999999999999991
sg62
g66
sg45
S'left'
p11050
sg10807
V23-crunchie.png
p11051
sg46
F0.51955569772144372
sg60
g61
sg67
g11
sS'binary2.thisN'
p11052
I27
sS'binary2.thisIndex'
p11053
g63
(g96
S'\x1b\x00\x00\x00'
tRp11054
sg70
g71
sS'binary2.thisTrialN'
p11055
I27
sS'binary2.thisRepN'
p11056
I0
sg48
F0.89500000000000002
sa(dp11057
g68
g69
sg10804
V17-jacobs_mini_cheddars.png
p11058
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11059
sg10807
V8-liquorice_catherine_wheels.png
p11060
sg46
F0.63942456373661116
sg60
g61
sg67
g11
sS'binary2.thisN'
p11061
I28
sS'binary2.thisIndex'
p11062
g63
(g96
S'\x1c\x00\x00\x00'
tRp11063
sg70
g71
sS'binary2.thisTrialN'
p11064
I28
sS'binary2.thisRepN'
p11065
I0
sg48
F0.52200000000000002
sa(dp11066
g68
g69
sg10804
V7-olives.png
p11067
sg47
F1
sg62
g66
sg45
S'left'
p11068
sg10807
V22-daim.png
p11069
sg46
F0.75929510594141902
sg60
g61
sg67
g11
sS'binary2.thisN'
p11070
I29
sS'binary2.thisIndex'
p11071
g63
(g96
S'\x1d\x00\x00\x00'
tRp11072
sg70
g71
sS'binary2.thisTrialN'
p11073
I29
sS'binary2.thisRepN'
p11074
I0
sg48
F1.0680000000000001
sa(dp11075
g68
g69
sg10804
V4-corn.png
p11076
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11077
sg10807
V10-bounty.png
p11078
sg46
F0.71938360880994878
sg60
g61
sg67
g11
sS'binary2.thisN'
p11079
I30
sS'binary2.thisIndex'
p11080
g63
(g96
S'\x1e\x00\x00\x00'
tRp11081
sg70
g71
sS'binary2.thisTrialN'
p11082
I30
sS'binary2.thisRepN'
p11083
I0
sg48
F0.45600000000000002
sa(dp11084
g68
g69
sg10804
V22-daim.png
p11085
sg47
F1
sg62
g66
sg45
S'right'
p11086
sg10807
V7-olives.png
p11087
sg46
F0.59945384120146628
sg60
g61
sg67
g11
sS'binary2.thisN'
p11088
I31
sS'binary2.thisIndex'
p11089
g63
(g96
S'\x1f\x00\x00\x00'
tRp11090
sg70
g71
sS'binary2.thisTrialN'
p11091
I31
sS'binary2.thisRepN'
p11092
I0
sg48
F0.50900000000000001
sa(dp11093
g68
g69
sg10804
V19-caramello.png
p11094
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11095
sg10807
V30-spaghetti_hoops.png
p11096
sg46
F1.1055810165817093
sg60
g61
sg67
g11
sS'binary2.thisN'
p11097
I32
sS'binary2.thisIndex'
p11098
g63
(g96
S' \x00\x00\x00'
tRp11099
sg70
g71
sS'binary2.thisTrialN'
p11100
I32
sS'binary2.thisRepN'
p11101
I0
sg48
F0.41599999999999998
sa(dp11102
g68
g69
sg10804
V2-steamed_puddings.png
p11103
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11104
sg10807
V20-fruit_pastilles.png
p11105
sg46
F0.69268524351537053
sg60
g61
sg67
g11
sS'binary2.thisN'
p11106
I33
sS'binary2.thisIndex'
p11107
g63
(g96
S'!\x00\x00\x00'
tRp11108
sg70
g71
sS'binary2.thisTrialN'
p11109
I33
sS'binary2.thisRepN'
p11110
I0
sg48
F0.41599999999999998
sa(dp11111
g68
g69
sg10804
V38-maltesers.png
p11112
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11113
sg10807
V6-sour_patch_kids.png
p11114
sg46
F0.55951077581084974
sg60
g61
sg67
g11
sS'binary2.thisN'
p11115
I34
sS'binary2.thisIndex'
p11116
g63
(g96
S'"\x00\x00\x00'
tRp11117
sg70
g71
sS'binary2.thisTrialN'
p11118
I34
sS'binary2.thisRepN'
p11119
I0
sg48
F0.442
sa(dp11120
g68
g69
sg10804
V50-polo.png
p11121
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11122
sg10807
V48-twix.png
p11123
sg46
F0.71929616753004666
sg60
g61
sg67
g11
sS'binary2.thisN'
p11124
I35
sS'binary2.thisIndex'
p11125
g63
(g96
S'#\x00\x00\x00'
tRp11126
sg70
g71
sS'binary2.thisTrialN'
p11127
I35
sS'binary2.thisRepN'
p11128
I0
sg48
F0.45600000000000002
sa(dp11129
g68
g69
sg10804
V31-foxs_golden_biscuits.png
p11130
sg47
F5.5999999999999988
sg62
g66
sg45
S'left'
p11131
sg10807
V25-kitkat.png
p11132
sg46
F0.58614432839931396
sg60
g61
sg67
g11
sS'binary2.thisN'
p11133
I36
sS'binary2.thisIndex'
p11134
g63
(g96
S'$\x00\x00\x00'
tRp11135
sg70
g71
sS'binary2.thisTrialN'
p11136
I36
sS'binary2.thisRepN'
p11137
I0
sg48
F0.496
sa(dp11138
g68
g69
sg10804
V1-smarties_cookies.png
p11139
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11140
sg10807
V21-nakd_banana_crunch.png
p11141
sg46
F0.59946892691550602
sg60
g61
sg67
g11
sS'binary2.thisN'
p11142
I37
sS'binary2.thisIndex'
p11143
g63
(g96
S'%\x00\x00\x00'
tRp11144
sg70
g71
sS'binary2.thisTrialN'
p11145
I37
sS'binary2.thisRepN'
p11146
I0
sg48
F0.46899999999999997
sa(dp11147
g68
g69
sg10804
V23-crunchie.png
p11148
sg47
F5.9999999999999973
sg62
g66
sg45
S'left'
p11149
sg10807
V33-ambrosia_rice.png
p11150
sg46
F1.1455416819735547
sg60
g61
sg67
g11
sS'binary2.thisN'
p11151
I38
sS'binary2.thisIndex'
p11152
g63
(g96
S'&\x00\x00\x00'
tRp11153
sg70
g71
sS'binary2.thisTrialN'
p11154
I38
sS'binary2.thisRepN'
p11155
I0
sg48
F0.50900000000000001
sa(dp11156
g68
g69
sg10804
V25-kitkat.png
p11157
sg47
F5.9999999999999973
sg62
g66
sg45
S'right'
p11158
sg10807
V31-foxs_golden_biscuits.png
p11159
sg46
F0.65274692733328266
sg60
g61
sg67
g11
sS'binary2.thisN'
p11160
I39
sS'binary2.thisIndex'
p11161
g63
(g96
S"'\x00\x00\x00"
tRp11162
sg70
g71
sS'binary2.thisTrialN'
p11163
I39
sS'binary2.thisRepN'
p11164
I0
sg48
F0.41599999999999998
sa(dp11165
g68
g69
sg38
I72
sg67
g11
sg70
g71
sg50
F1.9199999999999999
sg37
I528
sg54
F0.01
sg62
g66
sg49
I00
sg53
I25
sg52
g722
sg56
F30.280000000000001
sg51
F0.51999999999999913
sg60
g61
sg55
I0
sa(dp11166
g60
g61
sg70
g71
sg67
g11
sg62
g66
sg68
g69
sasS'loops'
p11167
(lp11168
g1
(cpsychopy.data
TrialHandler
p11169
g3
NtRp11170
(dp11171
S'origin'
p11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11173
sS'thisTrial'
p11174
(lp11175
sS'_exp'
p11176
I89576816
sg10
S'bdm_loop1'
p11177
sg6
S'C:\\Program Files\\PsychoPy2\\lib\\site-packages\\psychopy-1.80.03-py2.7.egg\\psychopy\\data.py'
p11178
sS'thisRepN'
p11179
I1
sg57
I01
sg58
g59
sS'data'
p11180
g1
(cpsychopy.data
DataHandler
p11181
c__builtin__
dict
p11182
(dp11183
S'ran'
p11184
cnumpy.ma.core
_mareconstruct
p11185
(cnumpy.ma.core
MaskedArray
p11186
cnumpy
ndarray
p11187
(I0
tp11188
S'b'
tRp11189
(I1
(I40
I1
tg64
(S'f4'
I0
I1
tRp11190
(I3
S'<'
NNNI-1
I-1
I0
tbI00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg18
g11185
(g11186
g11187
g11188
S'b'
tRp11191
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x00\x00\xc3\xf5(?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xb8\x1e\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xb8\x1e\x05?q=\n?\xb8\x1e\x05?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\\\x8fB?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xa4p=?\x00\x00\x00\x00\n\xd7#?\x00\x00\x00\x00\xb8\x1e\x05?\x1f\x85\xeb>\xb8\x1e\x05?\x00\x00\x00\x00\x00\x00\x80?\x14\xaeG?\x00\x00\x00\x00\x00\x00\x00\x00)\\\x0f>\x00\x00\x00\x00\xaeGa>\x1f\x85\xeb>\x00\x00\x00\x00'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg19
g11185
(g11186
g11187
g11188
S'b'
tRp11192
(I1
(I40
I1
tg11190
I00
S'T\xe3\x0fA\x9c\xc4$A\\\x8f\x02@-\xb2\r@d;\xbf?\x04V\xba@`\xe5\x00@\xa0\x1a\xe7@\xe3\xa5\xeb?\xc5 \x90@\x00\x00\xb0?\xc1\xca\xd1@\x98n\x1a@^\xba\x01@\x1f\x85+@\x91\xed\\@\xdd$\xc6?d;\xbf?%\x06\xc1?\xac\x1c"@Zd\x01Ah\x91\xbd?\x8f\xc2\x89@D\x8b\x00A/\xdd4@Zd\x97@X9\x84@\xe5\xd0\x9a@{\x14\x82@J\x0c\x89A\xe3\xa5\x13@\x1b/\x1bA\x83\xc0\x1aA\x10X\xd1@\xcf\xf7s@\xac\x1c"@^\xbaQ@\x17\xd9\x06@j\xbc\xf4@\n\xd7#@'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbsS'order'
p11193
g11185
(g11186
g11187
g11188
S'b'
tRp11194
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x00A\x00\x00\x90A\x00\x00\xa0@\x00\x00`A\x00\x00\x18B\x00\x00@@\x00\x00\x1cB\x00\x00\x00\x00\x00\x00\xa8A\x00\x00\xf8A\x00\x00\x10B\x00\x00\xe0A\x00\x00\x0cB\x00\x00\xc0A\x00\x00pA\x00\x00\xf0A\x00\x00\x04B\x00\x00\xc8A\x00\x00\x14B\x00\x00\x08B\x00\x00\x00@\x00\x00\xb8A\x00\x00\x88A\x00\x00\x80A\x00\x00\xb0A\x00\x00\x10A\x00\x00PA\x00\x00\x00B\x00\x00\xa0A\x00\x00\x80?\x00\x000A\x00\x00\x80@\x00\x00\x98A\x00\x00\xe8A\x00\x00\xd0A\x00\x00\xc0@\x00\x00\xd8A\x00\x00@A\x00\x00\xe0@\x00\x00 A'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbstRp11195
(dp11196
S'isNumeric'
p11197
(dp11198
g11184
I01
sg18
I01
sg19
I01
sg11193
I01
ssS'trials'
p11199
g11170
sS'dataTypes'
p11200
(lp11201
g11184
ag11193
ag18
ag19
asS'dataShape'
p11202
(lp11203
I40
aI1
asbsS'method'
p11204
Vrandom
p11205
sS'sequenceIndices'
p11206
cnumpy.core.multiarray
_reconstruct
p11207
(g11187
(I0
tS'b'
tRp11208
(I1
(I40
I1
tg96
I01
S'\x07\x00\x00\x00\x1d\x00\x00\x00\x14\x00\x00\x00\x05\x00\x00\x00\x1f\x00\x00\x00\x02\x00\x00\x00#\x00\x00\x00&\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x00\'\x00\x00\x00\x1e\x00\x00\x00%\x00\x00\x00\x1a\x00\x00\x00\x03\x00\x00\x00\x0e\x00\x00\x00\x17\x00\x00\x00\x16\x00\x00\x00\x01\x00\x00\x00 \x00\x00\x00\x1c\x00\x00\x00\x08\x00\x00\x00\x18\x00\x00\x00\x15\x00\x00\x00\r\x00\x00\x00\x11\x00\x00\x00"\x00\x00\x00$\x00\x00\x00\x0b\x00\x00\x00!\x00\x00\x00\x0f\x00\x00\x00\t\x00\x00\x00\x1b\x00\x00\x00\x10\x00\x00\x00\x13\x00\x00\x00\x0c\x00\x00\x00\n\x00\x00\x00\x12\x00\x00\x00\x04\x00\x00\x00\x06\x00\x00\x00'
tbsS'finished'
p11209
I01
sS'nReps'
p11210
I1
sS'nRemaining'
p11211
I-1
sS'trialList'
p11212
(lp11213
g1
(cpsychopy.data
TrialType
p11214
g11182
(dp11215
g80
g156
stRp11216
ag1
(g11214
g11182
(dp11217
g80
g226
stRp11218
ag1
(g11214
g11182
(dp11219
g80
g135
stRp11220
ag1
(g11214
g11182
(dp11221
g80
g198
stRp11222
ag1
(g11214
g11182
(dp11223
g80
g366
stRp11224
ag1
(g11214
g11182
(dp11225
g80
g121
stRp11226
ag1
(g11214
g11182
(dp11227
g80
g373
stRp11228
ag1
(g11214
g11182
(dp11229
g80
g100
stRp11230
ag1
(g11214
g11182
(dp11231
g80
g247
stRp11232
ag1
(g11214
g11182
(dp11233
g80
g317
stRp11234
ag1
(g11214
g11182
(dp11235
g80
g352
stRp11236
ag1
(g11214
g11182
(dp11237
g80
g296
stRp11238
ag1
(g11214
g11182
(dp11239
g80
g345
stRp11240
ag1
(g11214
g11182
(dp11241
g80
g268
stRp11242
ag1
(g11214
g11182
(dp11243
g80
g205
stRp11244
ag1
(g11214
g11182
(dp11245
g80
g310
stRp11246
ag1
(g11214
g11182
(dp11247
g80
g331
stRp11248
ag1
(g11214
g11182
(dp11249
g80
g275
stRp11250
ag1
(g11214
g11182
(dp11251
g80
g359
stRp11252
ag1
(g11214
g11182
(dp11253
g80
g338
stRp11254
ag1
(g11214
g11182
(dp11255
g80
g114
stRp11256
ag1
(g11214
g11182
(dp11257
g80
g261
stRp11258
ag1
(g11214
g11182
(dp11259
g80
g219
stRp11260
ag1
(g11214
g11182
(dp11261
g80
g212
stRp11262
ag1
(g11214
g11182
(dp11263
g80
g254
stRp11264
ag1
(g11214
g11182
(dp11265
g80
g163
stRp11266
ag1
(g11214
g11182
(dp11267
g80
g191
stRp11268
ag1
(g11214
g11182
(dp11269
g80
g324
stRp11270
ag1
(g11214
g11182
(dp11271
g80
g240
stRp11272
ag1
(g11214
g11182
(dp11273
g80
g107
stRp11274
ag1
(g11214
g11182
(dp11275
g80
g177
stRp11276
ag1
(g11214
g11182
(dp11277
g80
g128
stRp11278
ag1
(g11214
g11182
(dp11279
g80
g233
stRp11280
ag1
(g11214
g11182
(dp11281
g80
g303
stRp11282
ag1
(g11214
g11182
(dp11283
g80
g282
stRp11284
ag1
(g11214
g11182
(dp11285
g80
g142
stRp11286
ag1
(g11214
g11182
(dp11287
g80
g289
stRp11288
ag1
(g11214
g11182
(dp11289
g80
g184
stRp11290
ag1
(g11214
g11182
(dp11291
g80
g149
stRp11292
ag1
(g11214
g11182
(dp11293
g80
g170
stRp11294
asS'seed'
p11295
NsS'thisIndex'
p11296
g370
sS'thisN'
p11297
I40
sS'thisTrialN'
p11298
I0
sS'nTotal'
p11299
I40
sS'_warnUseOfNext'
p11300
I01
sbag1
(g11169
g3
NtRp11301
(dp11302
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11303
sg11174
(lp11304
sg11176
I89576816
sg10
S'binary1'
p11305
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp11306
g22
g11207
(g11187
(I0
tS'b'
tRp11307
(I1
(I40
I1
tg64
(S'O4'
I0
I1
tRp11308
(I3
S'|'
NNNI-1
I-1
I63
tbI00
(lp11309
g377
ag386
ag395
ag404
ag413
ag422
ag431
ag440
ag449
ag458
ag467
ag476
ag485
ag494
ag503
ag512
ag521
ag530
ag539
ag548
ag557
ag566
ag575
ag584
ag593
ag602
ag611
ag620
ag629
ag638
ag647
ag656
ag665
ag674
ag683
ag692
ag701
ag710
ag719
ag728
atbsg24
g11185
(g11186
g11187
g11188
S'b'
tRp11310
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\xc0@\x00\x00\xc0@\x00\x00`@\x00\x00\xc0@\x00\x00\xc0@33s@\x9a\x99\x89@\x9a\x99\x99@\x00\x00\xc0@\x00\x00\xc0@\x00\x00`@33s@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\x80@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\xcd\xcc\x9c@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\xcd\xcc\x9c@33\xa3@\x00\x00\x80@\x00\x00\xc0@\x9a\x999@\xcd\xcc\x9c@\x00\x00\xc0@\x00\x00\x90@\x00\x00\xc0@\x00\x00\xa0@\x00\x00\xc0@\xcd\xcc\xac@'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11184
g11185
(g11186
g11187
g11188
S'b'
tRp11311
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg23
g11185
(g11186
g11187
g11188
S'b'
tRp11312
(I1
(I40
I1
tg11190
I00
S"\x8a\xc3E@\x19/\xc9?j\xea[@m=\x89@\xfeE\x9d@\xfcJk?'[\x8e@\xc9:\xda?\x19\x05\xb3?,\xf3\n@l\xa6\xa6@\x95\xd4\x9f@#1\x92@pa\xa5?.\xc4E?\x16\x7f\xaa?\x87\xc9E?e|\x03A+\x04P?\x9fw\xc7@\xd8\x11a?1W|?\x81\x06~@.\xc9E?\xed\xc4\x11@(\xb2\x86?K\x01\xd0?[8\x8f?\xb0c<@\xdb\x07\x16@\x17\xb5\xd1?5\x04P?\x7f\xf2>@\xc7J\xb1?\xcf\xde\x1c?\xae>\t@_&\x9b?\xc6\xb8\xe5@\x90?Z?JD\xa0?"
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp11313
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg25
g11185
(g11186
g11187
g11188
S'b'
tRp11314
(I1
(I40
I1
tg11190
I00
S'9\xb4~A\x89A\xcc@\x8f\xc2\xa5?w\xbe??\xdfOM?w\xbe??\xe7\xfb9@\xdd$\xc6?J\x0c\xd2?\x85\xeb\x81?ffF?\x8f\xc2\xa5?d;\xbf?\xd7\xa3P?D\x8b\x0c?\xcb\xa1\x05?\xc5 \xf0>ff\x96?ffF?\x8d\x97.?\x96C+?\xc5 \xf0>%\x06!?\xc3\xf5\x08?!\xb0r?^\xba\x99?\xe3\xa5\xdb>\xa4p\xfd>\xcf\xf7S?\x8bl\xa7?\xb0r\xb8?\xc5 \xf0>\x98n\xf2?\xcb\xa1\x05?\x1dZ$?\xcf\xf7\xa3?\xb6\xf3\xfd>\xa6\x9b\x94?\xb4\xc8\xf6>\xc1\xcaa?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbstRp11315
(dp11316
g11197
(dp11317
g22
I00
sg24
I01
sg11184
I01
sg23
I01
sg11193
I01
sg25
I01
ssg11199
g11301
sg11200
(lp11318
g11184
ag11193
ag22
ag23
ag24
ag25
asg11202
(lp11319
I40
aI1
asbsg11204
Vsequential
p11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp11321
(I1
(I40
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp11322
g1
(g11214
g11182
(dp11323
g81
g383
sg82
g380
stRp11324
ag1
(g11214
g11182
(dp11325
g81
g392
sg82
g389
stRp11326
ag1
(g11214
g11182
(dp11327
g81
g401
sg82
g398
stRp11328
ag1
(g11214
g11182
(dp11329
g81
g410
sg82
g407
stRp11330
ag1
(g11214
g11182
(dp11331
g81
g419
sg82
g416
stRp11332
ag1
(g11214
g11182
(dp11333
g81
g428
sg82
g425
stRp11334
ag1
(g11214
g11182
(dp11335
g81
g437
sg82
g434
stRp11336
ag1
(g11214
g11182
(dp11337
g81
g446
sg82
g443
stRp11338
ag1
(g11214
g11182
(dp11339
g81
g455
sg82
g452
stRp11340
ag1
(g11214
g11182
(dp11341
g81
g464
sg82
g461
stRp11342
ag1
(g11214
g11182
(dp11343
g81
g473
sg82
g470
stRp11344
ag1
(g11214
g11182
(dp11345
g81
g482
sg82
g479
stRp11346
ag1
(g11214
g11182
(dp11347
g81
g491
sg82
g488
stRp11348
ag1
(g11214
g11182
(dp11349
g81
g500
sg82
g497
stRp11350
ag1
(g11214
g11182
(dp11351
g81
g509
sg82
g506
stRp11352
ag1
(g11214
g11182
(dp11353
g81
g518
sg82
g515
stRp11354
ag1
(g11214
g11182
(dp11355
g81
g527
sg82
g524
stRp11356
ag1
(g11214
g11182
(dp11357
g81
g536
sg82
g533
stRp11358
ag1
(g11214
g11182
(dp11359
g81
g545
sg82
g542
stRp11360
ag1
(g11214
g11182
(dp11361
g81
g554
sg82
g551
stRp11362
ag1
(g11214
g11182
(dp11363
g81
g563
sg82
g560
stRp11364
ag1
(g11214
g11182
(dp11365
g81
g572
sg82
g569
stRp11366
ag1
(g11214
g11182
(dp11367
g81
g581
sg82
g578
stRp11368
ag1
(g11214
g11182
(dp11369
g81
g590
sg82
g587
stRp11370
ag1
(g11214
g11182
(dp11371
g81
g599
sg82
g596
stRp11372
ag1
(g11214
g11182
(dp11373
g81
g608
sg82
g605
stRp11374
ag1
(g11214
g11182
(dp11375
g81
g617
sg82
g614
stRp11376
ag1
(g11214
g11182
(dp11377
g81
g626
sg82
g623
stRp11378
ag1
(g11214
g11182
(dp11379
g81
g635
sg82
g632
stRp11380
ag1
(g11214
g11182
(dp11381
g81
g644
sg82
g641
stRp11382
ag1
(g11214
g11182
(dp11383
g81
g653
sg82
g650
stRp11384
ag1
(g11214
g11182
(dp11385
g81
g662
sg82
g659
stRp11386
ag1
(g11214
g11182
(dp11387
g81
g671
sg82
g668
stRp11388
ag1
(g11214
g11182
(dp11389
g81
g680
sg82
g677
stRp11390
ag1
(g11214
g11182
(dp11391
g81
g689
sg82
g686
stRp11392
ag1
(g11214
g11182
(dp11393
g81
g698
sg82
g695
stRp11394
ag1
(g11214
g11182
(dp11395
g81
g707
sg82
g704
stRp11396
ag1
(g11214
g11182
(dp11397
g81
g716
sg82
g713
stRp11398
ag1
(g11214
g11182
(dp11399
g81
g725
sg82
g722
stRp11400
ag1
(g11214
g11182
(dp11401
g81
g734
sg82
g731
stRp11402
asg11295
Nsg11296
g733
sg11297
I40
sg11298
I0
sg11299
I40
sg11300
I01
sbag1
(g11169
g3
NtRp11403
(dp11404
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11405
sg11174
(lp11406
sg11176
I89576816
sg10
S'practice_loop'
p11407
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp11408
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp11409
(I1
(I14
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp11410
(I1
(I14
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg30
g11207
(g11187
(I0
tS'b'
tRp11411
(I1
(I14
I1
tg11308
I00
(lp11412
g746
ag751
ag766
ag771
ag781
ag796
ag801
ag811
ag821
ag831
ag841
ag851
ag866
ag876
atbstRp11413
(dp11414
g11197
(dp11415
g11184
I01
sg11193
I01
sg30
I00
ssg11199
g11403
sg11200
(lp11416
g11184
ag11193
ag30
asg11202
(lp11417
I14
aI1
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp11418
(I1
(I14
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp11419
g1
(g11214
g11182
(dp11420
g83
g741
sg84
g742
sg85
g746
sg86
g749
stRp11421
ag1
(g11214
g11182
(dp11422
g83
g751
sg84
g752
sg85
g756
sg86
g759
stRp11423
ag1
(g11214
g11182
(dp11424
g83
g761
sg84
g762
sg85
g766
sg86
g769
stRp11425
ag1
(g11214
g11182
(dp11426
g83
g771
sg84
g772
sg85
g776
sg86
g779
stRp11427
ag1
(g11214
g11182
(dp11428
g83
g781
sg84
g782
sg85
g786
sg86
g789
stRp11429
ag1
(g11214
g11182
(dp11430
g83
g791
sg84
g792
sg85
g796
sg86
g799
stRp11431
ag1
(g11214
g11182
(dp11432
g83
g801
sg84
g802
sg85
g806
sg86
g809
stRp11433
ag1
(g11214
g11182
(dp11434
g83
g811
sg84
g812
sg85
g816
sg86
g819
stRp11435
ag1
(g11214
g11182
(dp11436
g83
g821
sg84
g822
sg85
g826
sg86
g829
stRp11437
ag1
(g11214
g11182
(dp11438
g83
g831
sg84
g832
sg85
g836
sg86
g839
stRp11439
ag1
(g11214
g11182
(dp11440
g83
g841
sg84
g842
sg85
g846
sg86
g849
stRp11441
ag1
(g11214
g11182
(dp11442
g83
g851
sg84
g852
sg85
g856
sg86
g859
stRp11443
ag1
(g11214
g11182
(dp11444
g83
g861
sg84
g862
sg85
g866
sg86
g869
stRp11445
ag1
(g11214
g11182
(dp11446
g83
g871
sg84
g872
sg85
g876
sg86
g879
stRp11447
asg11295
Nsg11296
g878
sg11297
I14
sg11298
I0
sg11299
I14
sg11300
I01
sbag1
(g11169
g3
NtRp11448
(dp11449
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11450
sg11174
(lp11451
sg11176
I89576816
sg10
S'block_loop'
p11452
sg6
g11178
sg11179
I3
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp11453
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp11454
(I1
(I1
I3
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00'
Ntbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp11455
(I1
(I1
I3
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@'
S'\x00\x00\x00'
NtbstRp11456
(dp11457
g11197
(dp11458
g11184
I01
sg11193
I01
ssg11199
g11448
sg11200
(lp11459
g11184
ag11193
asg11202
(lp11460
I1
aI3
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp11461
(I1
(I1
I3
tg96
I00
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
tbsg11209
I01
sg11210
I3
sg11211
I-1
sg11212
(lp11462
Nasg11295
Nsg11296
g7314
sg11297
I3
sg11298
I0
sg11299
I3
sg11300
I01
sbag1
(g11169
g3
NtRp11463
(dp11464
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11465
sg11174
(lp11466
sg11176
I89576816
sg10
S'outcome_loop'
p11467
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp11468
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp11469
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg33
g11207
(g11187
(I0
tS'b'
tRp11470
(I1
(I200
I1
tg11308
I00
(lp11471
g893
ag911
ag927
ag943
ag959
ag975
ag991
ag1007
ag1023
ag1039
ag1055
ag1071
ag1087
ag1103
ag1119
ag1135
ag1151
ag1167
ag1183
ag1199
ag1215
ag1231
ag1247
ag1263
ag1279
ag1295
ag1311
ag1327
ag1343
ag1359
ag1375
ag1391
ag1407
ag1423
ag1439
ag1455
ag1471
ag1487
ag1503
ag1519
ag1535
ag1551
ag1567
ag1583
ag1599
ag1615
ag1631
ag1647
ag1663
ag1679
ag1695
ag1711
ag1727
ag1743
ag1759
ag1775
ag1791
ag1807
ag1823
ag1839
ag1855
ag1871
ag1887
ag1903
ag1919
ag1935
ag1951
ag1967
ag1983
ag1999
ag2015
ag2031
ag2047
ag2063
ag2079
ag2095
ag2111
ag2127
ag2143
ag2159
ag2175
ag2191
ag2207
ag2223
ag2239
ag2255
ag2271
ag2287
ag2303
ag2319
ag2335
ag2351
ag2367
ag2383
ag2399
ag2415
ag2431
ag2447
ag2463
ag2479
ag2495
ag2511
ag2527
ag2543
ag2559
ag2575
ag2591
ag2607
ag2623
ag2639
ag2655
ag2671
ag2687
ag2703
ag2719
ag2735
ag2751
ag2767
ag2783
ag2799
ag2815
ag2831
ag2847
ag2863
ag2879
ag2895
ag2911
ag2927
ag2943
ag2959
ag2975
ag2991
ag3007
ag3023
ag3039
ag3055
ag3071
ag3087
ag3103
ag3119
ag3135
ag3151
ag3167
ag3183
ag3199
ag3215
ag3231
ag3247
ag3263
ag3279
ag3295
ag3311
ag3327
ag3343
ag3359
ag3375
ag3391
ag3407
ag3423
ag3439
ag3455
ag3471
ag3487
ag3503
ag3519
ag3535
ag3551
ag3567
ag3583
ag3599
ag3615
ag3631
ag3647
ag3663
ag3679
ag3695
ag3711
ag3727
ag3743
ag3759
ag3775
ag3791
ag3807
ag3823
ag3839
ag3855
ag3871
ag3887
ag3903
ag3919
ag3935
ag3951
ag3967
ag3983
ag3999
ag4015
ag4031
ag4047
ag4063
ag4079
atbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp11472
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB\x00\x00 B\x00\x00$B\x00\x00(B\x00\x00,B\x00\x000B\x00\x004B\x00\x008B\x00\x00<B\x00\x00@B\x00\x00DB\x00\x00HB\x00\x00LB\x00\x00PB\x00\x00TB\x00\x00XB\x00\x00\\B\x00\x00`B\x00\x00dB\x00\x00hB\x00\x00lB\x00\x00pB\x00\x00tB\x00\x00xB\x00\x00|B\x00\x00\x80B\x00\x00\x82B\x00\x00\x84B\x00\x00\x86B\x00\x00\x88B\x00\x00\x8aB\x00\x00\x8cB\x00\x00\x8eB\x00\x00\x90B\x00\x00\x92B\x00\x00\x94B\x00\x00\x96B\x00\x00\x98B\x00\x00\x9aB\x00\x00\x9cB\x00\x00\x9eB\x00\x00\xa0B\x00\x00\xa2B\x00\x00\xa4B\x00\x00\xa6B\x00\x00\xa8B\x00\x00\xaaB\x00\x00\xacB\x00\x00\xaeB\x00\x00\xb0B\x00\x00\xb2B\x00\x00\xb4B\x00\x00\xb6B\x00\x00\xb8B\x00\x00\xbaB\x00\x00\xbcB\x00\x00\xbeB\x00\x00\xc0B\x00\x00\xc2B\x00\x00\xc4B\x00\x00\xc6B\x00\x00\xc8B\x00\x00\xcaB\x00\x00\xccB\x00\x00\xceB\x00\x00\xd0B\x00\x00\xd2B\x00\x00\xd4B\x00\x00\xd6B\x00\x00\xd8B\x00\x00\xdaB\x00\x00\xdcB\x00\x00\xdeB\x00\x00\xe0B\x00\x00\xe2B\x00\x00\xe4B\x00\x00\xe6B\x00\x00\xe8B\x00\x00\xeaB\x00\x00\xecB\x00\x00\xeeB\x00\x00\xf0B\x00\x00\xf2B\x00\x00\xf4B\x00\x00\xf6B\x00\x00\xf8B\x00\x00\xfaB\x00\x00\xfcB\x00\x00\xfeB\x00\x00\x00C\x00\x00\x01C\x00\x00\x02C\x00\x00\x03C\x00\x00\x04C\x00\x00\x05C\x00\x00\x06C\x00\x00\x07C\x00\x00\x08C\x00\x00\tC\x00\x00\nC\x00\x00\x0bC\x00\x00\x0cC\x00\x00\rC\x00\x00\x0eC\x00\x00\x0fC\x00\x00\x10C\x00\x00\x11C\x00\x00\x12C\x00\x00\x13C\x00\x00\x14C\x00\x00\x15C\x00\x00\x16C\x00\x00\x17C\x00\x00\x18C\x00\x00\x19C\x00\x00\x1aC\x00\x00\x1bC\x00\x00\x1cC\x00\x00\x1dC\x00\x00\x1eC\x00\x00\x1fC\x00\x00 C\x00\x00!C\x00\x00"C\x00\x00#C\x00\x00$C\x00\x00%C\x00\x00&C\x00\x00\'C\x00\x00(C\x00\x00)C\x00\x00*C\x00\x00+C\x00\x00,C\x00\x00-C\x00\x00.C\x00\x00/C\x00\x000C\x00\x001C\x00\x002C\x00\x003C\x00\x004C\x00\x005C\x00\x006C\x00\x007C\x00\x008C\x00\x009C\x00\x00:C\x00\x00;C\x00\x00<C\x00\x00=C\x00\x00>C\x00\x00?C\x00\x00@C\x00\x00AC\x00\x00BC\x00\x00CC\x00\x00DC\x00\x00EC\x00\x00FC\x00\x00GC'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg34
g11185
(g11186
g11187
g11188
S'b'
tRp11473
(I1
(I200
I1
tg11190
I00
S"<\xb6\xd1?\xc0\xe2g?\x17\xca\xa8?\xe9\x9aL?\x1c}*@\x06b\xa5?\x08\x1b\x8a?Y\xa9\xc0?Z\x04P?\xa9\xbe\x97?\xd0\x1dr?A!\x04@\x91.\xc9?\x13*\xe6?m\xeb\xf8?\xa3\xcd\xf3?~\xc1\xe2?\xcdyd?XX|?Y\xbc\x17@\xca\xd2\xd6?\xec\xd5\x05@C\xe5\x93@\xe8S\xfc?\xd0\x86\xd8?\xc2\xa7]?a|\xaa@%\xa8]?\xc41,@\xa3\xc9E?pI\x83?\xfe\xd5V?5\xc1\xe2?88\x8f?\xe3\xc3E@\x18\xbe\x97?_mS?\xd9\xf4\xbe?\xaa\x04P?kB @\x9b\xb4\xd1?\x178\x8f?>\x12\xc4?\xe0\xb3n?\xe6\x1cr?\x02\x84\x8d?\xa8\xfd\x84?I5C@\xb1\xa8]?\x91\x89;@'\xc4E@@\xd7\xb9?I\x9f\xfa?\x15\xa3)@e\xc0\xe2?\x8d\xe3\xca?\x97\x94\x81?\xbaX\xdf?\x97\xe3\xca?D\x8fL?W\x8f;?H\xc4E@\x1b\xbebAn\xb3\x83@=\x9bL?\xd11I?\xd6H\x83?6\xc3\x97?\x03\xb5n?\xfb\\\xc2?\xe1%8?\x07v\x19?G\xe2\x16@\xda\x10a?\xf47\x8f?4\xc1\x7f?\x07\xf7!@0L\xce?a\x05P?=\xc1\x7f?\x07\xa1\x92?\x0c\x07\x96@\x07\xb4\x1d@\xde\xbf\x7f?A\xca\x0b@\x89 \x8a?\xf7\xc0\x7f?\xda_%@\xa5\x80\xaa?\xf9m\xb6?uaB?\xe1]\xc2?\x89%\x1b@(]\xc2?\x08\xed-?\xa2\xc0\x7f?\xeeS\x14@\xb3\x85u?\x10)2@\x87\x19'?\xa6`<@\x93\xbe\xe2@%\xd9\x1c@6\x10a?,\xb0\x06@j\xe1J@M\xf7>?>\xb3Q@*M\x83?U\x16\xa7?\xae\x80\xd8?\xc5r\x99?\x8e\xba4?Z\xcf\x8b?\xb9.\xc9?\xac\x99c@N\n\x96?\xdd;Z?\xf2`B?\xdc\xe2g?*]\xc2?=R\xb1?g\xd2V?|f\x88?h\xe1-?\xe2P\xb1?\xac\xf5>?\x85>Z?3\xb1#?f\xa4\xdd?\x143I?\xe61\x8f?8\xee\xbe??\xb3\xb4?\xc7mS?(\x9f\xfa?\xe5E\x03@7yd?\xb0v\x19?\x05aB?\xd2yd?b_\x8b@\xd3\xdb\x9c?\xf3\x0c\x96?JnS?)8\x8f?AaB?\xa5\r\x16?\x92\xcf\x8b?\xaf\xbd4?-\x9aL?\x97>Z?8\xb1#?!\xb2\x86?\x1d\xf0x?V\xbf\x7f?;U1?UKk?\x1fn\xb6?w`S?9\x1a'?\xbb\x82*?yH ?w\xa7]?pf\x85@X\xed-?\xb5\x92\x01@\xdfP\xb1?\xd6\x10a?\xcft0@\x98r\x99?\x0c\xd6V?~\xd9\x1c@RZ1?,T\xfc?c\x16\xa7?t\xb94?\x90\x8f;?9\x04P?\xda&8?=lS?\xef\xbc4?\xdf\xb0#?\x14\x04P?\xa1\xeex?\xbd\xf7>?\x1f_\xfc>\xd0\xec-?\x1d\xcaE?=\xeb-?\x9cG ?Y\x90;?\x19\xb4n?\xd6\xc9E?4T1?)\xbe4?\x81\xdf\x1c?W\x16\xa7?\xd6\xa3\x12?i\xc54?"
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg30
g11207
(g11187
(I0
tS'b'
tRp11474
(I1
(I200
I1
tg11308
I00
(lp11475
g885
ag905
ag931
ag937
ag963
ag969
ag995
ag1011
ag1017
ag1033
ag1059
ag1065
ag1081
ag1097
ag1113
ag1129
ag1145
ag1171
ag1177
ag1203
ag1209
ag1225
ag1241
ag1257
ag1273
ag1289
ag1305
ag1331
ag1337
ag1353
ag1369
ag1395
ag1401
ag1427
ag1433
ag1449
ag1465
ag1481
ag1497
ag1513
ag1529
ag1545
ag1561
ag1587
ag1593
ag1609
ag1625
ag1651
ag1667
ag1673
ag1689
ag1705
ag1721
ag1747
ag1753
ag1779
ag1785
ag1801
ag1817
ag1843
ag1849
ag1865
ag1881
ag1897
ag1913
ag1929
ag1945
ag1971
ag1977
ag1993
ag2009
ag2025
ag2041
ag2057
ag2073
ag2089
ag2105
ag2121
ag2137
ag2153
ag2169
ag2185
ag2211
ag2217
ag2233
ag2249
ag2265
ag2281
ag2297
ag2313
ag2329
ag2345
ag2361
ag2377
ag2393
ag2409
ag2425
ag2441
ag2457
ag2473
ag2489
ag2505
ag2521
ag2537
ag2563
ag2579
ag2585
ag2611
ag2617
ag2633
ag2649
ag2665
ag2681
ag2707
ag2713
ag2739
ag2755
ag2761
ag2777
ag2793
ag2809
ag2825
ag2841
ag2857
ag2873
ag2889
ag2905
ag2921
ag2937
ag2963
ag2969
ag2985
ag3001
ag3027
ag3033
ag3049
ag3065
ag3081
ag3097
ag3113
ag3129
ag3145
ag3161
ag3177
ag3193
ag3209
ag3225
ag3251
ag3257
ag3273
ag3289
ag3305
ag3321
ag3347
ag3353
ag3369
ag3385
ag3401
ag3417
ag3433
ag3459
ag3465
ag3481
ag3497
ag3513
ag3539
ag3555
ag3561
ag3577
ag3593
ag3609
ag3625
ag3641
ag3657
ag3673
ag3689
ag3705
ag3721
ag3737
ag3753
ag3769
ag3785
ag3801
ag3817
ag3833
ag3849
ag3875
ag3881
ag3897
ag3913
ag3939
ag3945
ag3961
ag3977
ag3993
ag4009
ag4025
ag4051
ag4057
ag4073
atbstRp11476
(dp11477
g11197
(dp11478
g11184
I01
sg33
I00
sg11193
I01
sg34
I01
sg30
I00
ssg11199
g11463
sg11200
(lp11479
g11184
ag11193
ag33
ag34
ag30
asg11202
(lp11480
I200
aI1
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp11481
(I1
(I200
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00(\x00\x00\x00)\x00\x00\x00*\x00\x00\x00+\x00\x00\x00,\x00\x00\x00-\x00\x00\x00.\x00\x00\x00/\x00\x00\x000\x00\x00\x001\x00\x00\x002\x00\x00\x003\x00\x00\x004\x00\x00\x005\x00\x00\x006\x00\x00\x007\x00\x00\x008\x00\x00\x009\x00\x00\x00:\x00\x00\x00;\x00\x00\x00<\x00\x00\x00=\x00\x00\x00>\x00\x00\x00?\x00\x00\x00@\x00\x00\x00A\x00\x00\x00B\x00\x00\x00C\x00\x00\x00D\x00\x00\x00E\x00\x00\x00F\x00\x00\x00G\x00\x00\x00H\x00\x00\x00I\x00\x00\x00J\x00\x00\x00K\x00\x00\x00L\x00\x00\x00M\x00\x00\x00N\x00\x00\x00O\x00\x00\x00P\x00\x00\x00Q\x00\x00\x00R\x00\x00\x00S\x00\x00\x00T\x00\x00\x00U\x00\x00\x00V\x00\x00\x00W\x00\x00\x00X\x00\x00\x00Y\x00\x00\x00Z\x00\x00\x00[\x00\x00\x00\\\x00\x00\x00]\x00\x00\x00^\x00\x00\x00_\x00\x00\x00`\x00\x00\x00a\x00\x00\x00b\x00\x00\x00c\x00\x00\x00d\x00\x00\x00e\x00\x00\x00f\x00\x00\x00g\x00\x00\x00h\x00\x00\x00i\x00\x00\x00j\x00\x00\x00k\x00\x00\x00l\x00\x00\x00m\x00\x00\x00n\x00\x00\x00o\x00\x00\x00p\x00\x00\x00q\x00\x00\x00r\x00\x00\x00s\x00\x00\x00t\x00\x00\x00u\x00\x00\x00v\x00\x00\x00w\x00\x00\x00x\x00\x00\x00y\x00\x00\x00z\x00\x00\x00{\x00\x00\x00|\x00\x00\x00}\x00\x00\x00~\x00\x00\x00\x7f\x00\x00\x00\x80\x00\x00\x00\x81\x00\x00\x00\x82\x00\x00\x00\x83\x00\x00\x00\x84\x00\x00\x00\x85\x00\x00\x00\x86\x00\x00\x00\x87\x00\x00\x00\x88\x00\x00\x00\x89\x00\x00\x00\x8a\x00\x00\x00\x8b\x00\x00\x00\x8c\x00\x00\x00\x8d\x00\x00\x00\x8e\x00\x00\x00\x8f\x00\x00\x00\x90\x00\x00\x00\x91\x00\x00\x00\x92\x00\x00\x00\x93\x00\x00\x00\x94\x00\x00\x00\x95\x00\x00\x00\x96\x00\x00\x00\x97\x00\x00\x00\x98\x00\x00\x00\x99\x00\x00\x00\x9a\x00\x00\x00\x9b\x00\x00\x00\x9c\x00\x00\x00\x9d\x00\x00\x00\x9e\x00\x00\x00\x9f\x00\x00\x00\xa0\x00\x00\x00\xa1\x00\x00\x00\xa2\x00\x00\x00\xa3\x00\x00\x00\xa4\x00\x00\x00\xa5\x00\x00\x00\xa6\x00\x00\x00\xa7\x00\x00\x00\xa8\x00\x00\x00\xa9\x00\x00\x00\xaa\x00\x00\x00\xab\x00\x00\x00\xac\x00\x00\x00\xad\x00\x00\x00\xae\x00\x00\x00\xaf\x00\x00\x00\xb0\x00\x00\x00\xb1\x00\x00\x00\xb2\x00\x00\x00\xb3\x00\x00\x00\xb4\x00\x00\x00\xb5\x00\x00\x00\xb6\x00\x00\x00\xb7\x00\x00\x00\xb8\x00\x00\x00\xb9\x00\x00\x00\xba\x00\x00\x00\xbb\x00\x00\x00\xbc\x00\x00\x00\xbd\x00\x00\x00\xbe\x00\x00\x00\xbf\x00\x00\x00\xc0\x00\x00\x00\xc1\x00\x00\x00\xc2\x00\x00\x00\xc3\x00\x00\x00\xc4\x00\x00\x00\xc5\x00\x00\x00\xc6\x00\x00\x00\xc7\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp11482
g1
(g11214
g11182
(dp11483
g884
g885
sg886
g887
sg897
g898
sg901
g902
stRp11484
ag1
(g11214
g11182
(dp11485
g884
g905
sg886
g906
sg897
g915
sg901
g918
stRp11486
ag1
(g11214
g11182
(dp11487
g884
g921
sg886
g922
sg897
g931
sg901
g934
stRp11488
ag1
(g11214
g11182
(dp11489
g884
g937
sg886
g938
sg897
g947
sg901
g950
stRp11490
ag1
(g11214
g11182
(dp11491
g884
g953
sg886
g954
sg897
g963
sg901
g966
stRp11492
ag1
(g11214
g11182
(dp11493
g884
g969
sg886
g970
sg897
g979
sg901
g982
stRp11494
ag1
(g11214
g11182
(dp11495
g884
g985
sg886
g986
sg897
g995
sg901
g998
stRp11496
ag1
(g11214
g11182
(dp11497
g884
g1001
sg886
g1002
sg897
g1011
sg901
g1014
stRp11498
ag1
(g11214
g11182
(dp11499
g884
g1017
sg886
g1018
sg897
g1027
sg901
g1030
stRp11500
ag1
(g11214
g11182
(dp11501
g884
g1033
sg886
g1034
sg897
g1043
sg901
g1046
stRp11502
ag1
(g11214
g11182
(dp11503
g884
g1049
sg886
g1050
sg897
g1059
sg901
g1062
stRp11504
ag1
(g11214
g11182
(dp11505
g884
g1065
sg886
g1066
sg897
g1075
sg901
g1078
stRp11506
ag1
(g11214
g11182
(dp11507
g884
g1081
sg886
g1082
sg897
g1091
sg901
g1094
stRp11508
ag1
(g11214
g11182
(dp11509
g884
g1097
sg886
g1098
sg897
g1107
sg901
g1110
stRp11510
ag1
(g11214
g11182
(dp11511
g884
g1113
sg886
g1114
sg897
g1123
sg901
g1126
stRp11512
ag1
(g11214
g11182
(dp11513
g884
g1129
sg886
g1130
sg897
g1139
sg901
g1142
stRp11514
ag1
(g11214
g11182
(dp11515
g884
g1145
sg886
g1146
sg897
g1155
sg901
g1158
stRp11516
ag1
(g11214
g11182
(dp11517
g884
g1161
sg886
g1162
sg897
g1171
sg901
g1174
stRp11518
ag1
(g11214
g11182
(dp11519
g884
g1177
sg886
g1178
sg897
g1187
sg901
g1190
stRp11520
ag1
(g11214
g11182
(dp11521
g884
g1193
sg886
g1194
sg897
g1203
sg901
g1206
stRp11522
ag1
(g11214
g11182
(dp11523
g884
g1209
sg886
g1210
sg897
g1219
sg901
g1222
stRp11524
ag1
(g11214
g11182
(dp11525
g884
g1225
sg886
g1226
sg897
g1235
sg901
g1238
stRp11526
ag1
(g11214
g11182
(dp11527
g884
g1241
sg886
g1242
sg897
g1251
sg901
g1254
stRp11528
ag1
(g11214
g11182
(dp11529
g884
g1257
sg886
g1258
sg897
g1267
sg901
g1270
stRp11530
ag1
(g11214
g11182
(dp11531
g884
g1273
sg886
g1274
sg897
g1283
sg901
g1286
stRp11532
ag1
(g11214
g11182
(dp11533
g884
g1289
sg886
g1290
sg897
g1299
sg901
g1302
stRp11534
ag1
(g11214
g11182
(dp11535
g884
g1305
sg886
g1306
sg897
g1315
sg901
g1318
stRp11536
ag1
(g11214
g11182
(dp11537
g884
g1321
sg886
g1322
sg897
g1331
sg901
g1334
stRp11538
ag1
(g11214
g11182
(dp11539
g884
g1337
sg886
g1338
sg897
g1347
sg901
g1350
stRp11540
ag1
(g11214
g11182
(dp11541
g884
g1353
sg886
g1354
sg897
g1363
sg901
g1366
stRp11542
ag1
(g11214
g11182
(dp11543
g884
g1369
sg886
g1370
sg897
g1379
sg901
g1382
stRp11544
ag1
(g11214
g11182
(dp11545
g884
g1385
sg886
g1386
sg897
g1395
sg901
g1398
stRp11546
ag1
(g11214
g11182
(dp11547
g884
g1401
sg886
g1402
sg897
g1411
sg901
g1414
stRp11548
ag1
(g11214
g11182
(dp11549
g884
g1417
sg886
g1418
sg897
g1427
sg901
g1430
stRp11550
ag1
(g11214
g11182
(dp11551
g884
g1433
sg886
g1434
sg897
g1443
sg901
g1446
stRp11552
ag1
(g11214
g11182
(dp11553
g884
g1449
sg886
g1450
sg897
g1459
sg901
g1462
stRp11554
ag1
(g11214
g11182
(dp11555
g884
g1465
sg886
g1466
sg897
g1475
sg901
g1478
stRp11556
ag1
(g11214
g11182
(dp11557
g884
g1481
sg886
g1482
sg897
g1491
sg901
g1494
stRp11558
ag1
(g11214
g11182
(dp11559
g884
g1497
sg886
g1498
sg897
g1507
sg901
g1510
stRp11560
ag1
(g11214
g11182
(dp11561
g884
g1513
sg886
g1514
sg897
g1523
sg901
g1526
stRp11562
ag1
(g11214
g11182
(dp11563
g884
g1529
sg886
g1530
sg897
g1539
sg901
g1542
stRp11564
ag1
(g11214
g11182
(dp11565
g884
g1545
sg886
g1546
sg897
g1555
sg901
g1558
stRp11566
ag1
(g11214
g11182
(dp11567
g884
g1561
sg886
g1562
sg897
g1571
sg901
g1574
stRp11568
ag1
(g11214
g11182
(dp11569
g884
g1577
sg886
g1578
sg897
g1587
sg901
g1590
stRp11570
ag1
(g11214
g11182
(dp11571
g884
g1593
sg886
g1594
sg897
g1603
sg901
g1606
stRp11572
ag1
(g11214
g11182
(dp11573
g884
g1609
sg886
g1610
sg897
g1619
sg901
g1622
stRp11574
ag1
(g11214
g11182
(dp11575
g884
g1625
sg886
g1626
sg897
g1635
sg901
g1638
stRp11576
ag1
(g11214
g11182
(dp11577
g884
g1641
sg886
g1642
sg897
g1651
sg901
g1654
stRp11578
ag1
(g11214
g11182
(dp11579
g884
g1657
sg886
g1658
sg897
g1667
sg901
g1670
stRp11580
ag1
(g11214
g11182
(dp11581
g884
g1673
sg886
g1674
sg897
g1683
sg901
g1686
stRp11582
ag1
(g11214
g11182
(dp11583
g884
g1689
sg886
g1690
sg897
g1699
sg901
g1702
stRp11584
ag1
(g11214
g11182
(dp11585
g884
g1705
sg886
g1706
sg897
g1715
sg901
g1718
stRp11586
ag1
(g11214
g11182
(dp11587
g884
g1721
sg886
g1722
sg897
g1731
sg901
g1734
stRp11588
ag1
(g11214
g11182
(dp11589
g884
g1737
sg886
g1738
sg897
g1747
sg901
g1750
stRp11590
ag1
(g11214
g11182
(dp11591
g884
g1753
sg886
g1754
sg897
g1763
sg901
g1766
stRp11592
ag1
(g11214
g11182
(dp11593
g884
g1769
sg886
g1770
sg897
g1779
sg901
g1782
stRp11594
ag1
(g11214
g11182
(dp11595
g884
g1785
sg886
g1786
sg897
g1795
sg901
g1798
stRp11596
ag1
(g11214
g11182
(dp11597
g884
g1801
sg886
g1802
sg897
g1811
sg901
g1814
stRp11598
ag1
(g11214
g11182
(dp11599
g884
g1817
sg886
g1818
sg897
g1827
sg901
g1830
stRp11600
ag1
(g11214
g11182
(dp11601
g884
g1833
sg886
g1834
sg897
g1843
sg901
g1846
stRp11602
ag1
(g11214
g11182
(dp11603
g884
g1849
sg886
g1850
sg897
g1859
sg901
g1862
stRp11604
ag1
(g11214
g11182
(dp11605
g884
g1865
sg886
g1866
sg897
g1875
sg901
g1878
stRp11606
ag1
(g11214
g11182
(dp11607
g884
g1881
sg886
g1882
sg897
g1891
sg901
g1894
stRp11608
ag1
(g11214
g11182
(dp11609
g884
g1897
sg886
g1898
sg897
g1907
sg901
g1910
stRp11610
ag1
(g11214
g11182
(dp11611
g884
g1913
sg886
g1914
sg897
g1923
sg901
g1926
stRp11612
ag1
(g11214
g11182
(dp11613
g884
g1929
sg886
g1930
sg897
g1939
sg901
g1942
stRp11614
ag1
(g11214
g11182
(dp11615
g884
g1945
sg886
g1946
sg897
g1955
sg901
g1958
stRp11616
ag1
(g11214
g11182
(dp11617
g884
g1961
sg886
g1962
sg897
g1971
sg901
g1974
stRp11618
ag1
(g11214
g11182
(dp11619
g884
g1977
sg886
g1978
sg897
g1987
sg901
g1990
stRp11620
ag1
(g11214
g11182
(dp11621
g884
g1993
sg886
g1994
sg897
g2003
sg901
g2006
stRp11622
ag1
(g11214
g11182
(dp11623
g884
g2009
sg886
g2010
sg897
g2019
sg901
g2022
stRp11624
ag1
(g11214
g11182
(dp11625
g884
g2025
sg886
g2026
sg897
g2035
sg901
g2038
stRp11626
ag1
(g11214
g11182
(dp11627
g884
g2041
sg886
g2042
sg897
g2051
sg901
g2054
stRp11628
ag1
(g11214
g11182
(dp11629
g884
g2057
sg886
g2058
sg897
g2067
sg901
g2070
stRp11630
ag1
(g11214
g11182
(dp11631
g884
g2073
sg886
g2074
sg897
g2083
sg901
g2086
stRp11632
ag1
(g11214
g11182
(dp11633
g884
g2089
sg886
g2090
sg897
g2099
sg901
g2102
stRp11634
ag1
(g11214
g11182
(dp11635
g884
g2105
sg886
g2106
sg897
g2115
sg901
g2118
stRp11636
ag1
(g11214
g11182
(dp11637
g884
g2121
sg886
g2122
sg897
g2131
sg901
g2134
stRp11638
ag1
(g11214
g11182
(dp11639
g884
g2137
sg886
g2138
sg897
g2147
sg901
g2150
stRp11640
ag1
(g11214
g11182
(dp11641
g884
g2153
sg886
g2154
sg897
g2163
sg901
g2166
stRp11642
ag1
(g11214
g11182
(dp11643
g884
g2169
sg886
g2170
sg897
g2179
sg901
g2182
stRp11644
ag1
(g11214
g11182
(dp11645
g884
g2185
sg886
g2186
sg897
g2195
sg901
g2198
stRp11646
ag1
(g11214
g11182
(dp11647
g884
g2201
sg886
g2202
sg897
g2211
sg901
g2214
stRp11648
ag1
(g11214
g11182
(dp11649
g884
g2217
sg886
g2218
sg897
g2227
sg901
g2230
stRp11650
ag1
(g11214
g11182
(dp11651
g884
g2233
sg886
g2234
sg897
g2243
sg901
g2246
stRp11652
ag1
(g11214
g11182
(dp11653
g884
g2249
sg886
g2250
sg897
g2259
sg901
g2262
stRp11654
ag1
(g11214
g11182
(dp11655
g884
g2265
sg886
g2266
sg897
g2275
sg901
g2278
stRp11656
ag1
(g11214
g11182
(dp11657
g884
g2281
sg886
g2282
sg897
g2291
sg901
g2294
stRp11658
ag1
(g11214
g11182
(dp11659
g884
g2297
sg886
g2298
sg897
g2307
sg901
g2310
stRp11660
ag1
(g11214
g11182
(dp11661
g884
g2313
sg886
g2314
sg897
g2323
sg901
g2326
stRp11662
ag1
(g11214
g11182
(dp11663
g884
g2329
sg886
g2330
sg897
g2339
sg901
g2342
stRp11664
ag1
(g11214
g11182
(dp11665
g884
g2345
sg886
g2346
sg897
g2355
sg901
g2358
stRp11666
ag1
(g11214
g11182
(dp11667
g884
g2361
sg886
g2362
sg897
g2371
sg901
g2374
stRp11668
ag1
(g11214
g11182
(dp11669
g884
g2377
sg886
g2378
sg897
g2387
sg901
g2390
stRp11670
ag1
(g11214
g11182
(dp11671
g884
g2393
sg886
g2394
sg897
g2403
sg901
g2406
stRp11672
ag1
(g11214
g11182
(dp11673
g884
g2409
sg886
g2410
sg897
g2419
sg901
g2422
stRp11674
ag1
(g11214
g11182
(dp11675
g884
g2425
sg886
g2426
sg897
g2435
sg901
g2438
stRp11676
ag1
(g11214
g11182
(dp11677
g884
g2441
sg886
g2442
sg897
g2451
sg901
g2454
stRp11678
ag1
(g11214
g11182
(dp11679
g884
g2457
sg886
g2458
sg897
g2467
sg901
g2470
stRp11680
ag1
(g11214
g11182
(dp11681
g884
g2473
sg886
g2474
sg897
g2483
sg901
g2486
stRp11682
ag1
(g11214
g11182
(dp11683
g884
g2489
sg886
g2490
sg897
g2499
sg901
g2502
stRp11684
ag1
(g11214
g11182
(dp11685
g884
g2505
sg886
g2506
sg897
g2515
sg901
g2518
stRp11686
ag1
(g11214
g11182
(dp11687
g884
g2521
sg886
g2522
sg897
g2531
sg901
g2534
stRp11688
ag1
(g11214
g11182
(dp11689
g884
g2537
sg886
g2538
sg897
g2547
sg901
g2550
stRp11690
ag1
(g11214
g11182
(dp11691
g884
g2553
sg886
g2554
sg897
g2563
sg901
g2566
stRp11692
ag1
(g11214
g11182
(dp11693
g884
g2569
sg886
g2570
sg897
g2579
sg901
g2582
stRp11694
ag1
(g11214
g11182
(dp11695
g884
g2585
sg886
g2586
sg897
g2595
sg901
g2598
stRp11696
ag1
(g11214
g11182
(dp11697
g884
g2601
sg886
g2602
sg897
g2611
sg901
g2614
stRp11698
ag1
(g11214
g11182
(dp11699
g884
g2617
sg886
g2618
sg897
g2627
sg901
g2630
stRp11700
ag1
(g11214
g11182
(dp11701
g884
g2633
sg886
g2634
sg897
g2643
sg901
g2646
stRp11702
ag1
(g11214
g11182
(dp11703
g884
g2649
sg886
g2650
sg897
g2659
sg901
g2662
stRp11704
ag1
(g11214
g11182
(dp11705
g884
g2665
sg886
g2666
sg897
g2675
sg901
g2678
stRp11706
ag1
(g11214
g11182
(dp11707
g884
g2681
sg886
g2682
sg897
g2691
sg901
g2694
stRp11708
ag1
(g11214
g11182
(dp11709
g884
g2697
sg886
g2698
sg897
g2707
sg901
g2710
stRp11710
ag1
(g11214
g11182
(dp11711
g884
g2713
sg886
g2714
sg897
g2723
sg901
g2726
stRp11712
ag1
(g11214
g11182
(dp11713
g884
g2729
sg886
g2730
sg897
g2739
sg901
g2742
stRp11714
ag1
(g11214
g11182
(dp11715
g884
g2745
sg886
g2746
sg897
g2755
sg901
g2758
stRp11716
ag1
(g11214
g11182
(dp11717
g884
g2761
sg886
g2762
sg897
g2771
sg901
g2774
stRp11718
ag1
(g11214
g11182
(dp11719
g884
g2777
sg886
g2778
sg897
g2787
sg901
g2790
stRp11720
ag1
(g11214
g11182
(dp11721
g884
g2793
sg886
g2794
sg897
g2803
sg901
g2806
stRp11722
ag1
(g11214
g11182
(dp11723
g884
g2809
sg886
g2810
sg897
g2819
sg901
g2822
stRp11724
ag1
(g11214
g11182
(dp11725
g884
g2825
sg886
g2826
sg897
g2835
sg901
g2838
stRp11726
ag1
(g11214
g11182
(dp11727
g884
g2841
sg886
g2842
sg897
g2851
sg901
g2854
stRp11728
ag1
(g11214
g11182
(dp11729
g884
g2857
sg886
g2858
sg897
g2867
sg901
g2870
stRp11730
ag1
(g11214
g11182
(dp11731
g884
g2873
sg886
g2874
sg897
g2883
sg901
g2886
stRp11732
ag1
(g11214
g11182
(dp11733
g884
g2889
sg886
g2890
sg897
g2899
sg901
g2902
stRp11734
ag1
(g11214
g11182
(dp11735
g884
g2905
sg886
g2906
sg897
g2915
sg901
g2918
stRp11736
ag1
(g11214
g11182
(dp11737
g884
g2921
sg886
g2922
sg897
g2931
sg901
g2934
stRp11738
ag1
(g11214
g11182
(dp11739
g884
g2937
sg886
g2938
sg897
g2947
sg901
g2950
stRp11740
ag1
(g11214
g11182
(dp11741
g884
g2953
sg886
g2954
sg897
g2963
sg901
g2966
stRp11742
ag1
(g11214
g11182
(dp11743
g884
g2969
sg886
g2970
sg897
g2979
sg901
g2982
stRp11744
ag1
(g11214
g11182
(dp11745
g884
g2985
sg886
g2986
sg897
g2995
sg901
g2998
stRp11746
ag1
(g11214
g11182
(dp11747
g884
g3001
sg886
g3002
sg897
g3011
sg901
g3014
stRp11748
ag1
(g11214
g11182
(dp11749
g884
g3017
sg886
g3018
sg897
g3027
sg901
g3030
stRp11750
ag1
(g11214
g11182
(dp11751
g884
g3033
sg886
g3034
sg897
g3043
sg901
g3046
stRp11752
ag1
(g11214
g11182
(dp11753
g884
g3049
sg886
g3050
sg897
g3059
sg901
g3062
stRp11754
ag1
(g11214
g11182
(dp11755
g884
g3065
sg886
g3066
sg897
g3075
sg901
g3078
stRp11756
ag1
(g11214
g11182
(dp11757
g884
g3081
sg886
g3082
sg897
g3091
sg901
g3094
stRp11758
ag1
(g11214
g11182
(dp11759
g884
g3097
sg886
g3098
sg897
g3107
sg901
g3110
stRp11760
ag1
(g11214
g11182
(dp11761
g884
g3113
sg886
g3114
sg897
g3123
sg901
g3126
stRp11762
ag1
(g11214
g11182
(dp11763
g884
g3129
sg886
g3130
sg897
g3139
sg901
g3142
stRp11764
ag1
(g11214
g11182
(dp11765
g884
g3145
sg886
g3146
sg897
g3155
sg901
g3158
stRp11766
ag1
(g11214
g11182
(dp11767
g884
g3161
sg886
g3162
sg897
g3171
sg901
g3174
stRp11768
ag1
(g11214
g11182
(dp11769
g884
g3177
sg886
g3178
sg897
g3187
sg901
g3190
stRp11770
ag1
(g11214
g11182
(dp11771
g884
g3193
sg886
g3194
sg897
g3203
sg901
g3206
stRp11772
ag1
(g11214
g11182
(dp11773
g884
g3209
sg886
g3210
sg897
g3219
sg901
g3222
stRp11774
ag1
(g11214
g11182
(dp11775
g884
g3225
sg886
g3226
sg897
g3235
sg901
g3238
stRp11776
ag1
(g11214
g11182
(dp11777
g884
g3241
sg886
g3242
sg897
g3251
sg901
g3254
stRp11778
ag1
(g11214
g11182
(dp11779
g884
g3257
sg886
g3258
sg897
g3267
sg901
g3270
stRp11780
ag1
(g11214
g11182
(dp11781
g884
g3273
sg886
g3274
sg897
g3283
sg901
g3286
stRp11782
ag1
(g11214
g11182
(dp11783
g884
g3289
sg886
g3290
sg897
g3299
sg901
g3302
stRp11784
ag1
(g11214
g11182
(dp11785
g884
g3305
sg886
g3306
sg897
g3315
sg901
g3318
stRp11786
ag1
(g11214
g11182
(dp11787
g884
g3321
sg886
g3322
sg897
g3331
sg901
g3334
stRp11788
ag1
(g11214
g11182
(dp11789
g884
g3337
sg886
g3338
sg897
g3347
sg901
g3350
stRp11790
ag1
(g11214
g11182
(dp11791
g884
g3353
sg886
g3354
sg897
g3363
sg901
g3366
stRp11792
ag1
(g11214
g11182
(dp11793
g884
g3369
sg886
g3370
sg897
g3379
sg901
g3382
stRp11794
ag1
(g11214
g11182
(dp11795
g884
g3385
sg886
g3386
sg897
g3395
sg901
g3398
stRp11796
ag1
(g11214
g11182
(dp11797
g884
g3401
sg886
g3402
sg897
g3411
sg901
g3414
stRp11798
ag1
(g11214
g11182
(dp11799
g884
g3417
sg886
g3418
sg897
g3427
sg901
g3430
stRp11800
ag1
(g11214
g11182
(dp11801
g884
g3433
sg886
g3434
sg897
g3443
sg901
g3446
stRp11802
ag1
(g11214
g11182
(dp11803
g884
g3449
sg886
g3450
sg897
g3459
sg901
g3462
stRp11804
ag1
(g11214
g11182
(dp11805
g884
g3465
sg886
g3466
sg897
g3475
sg901
g3478
stRp11806
ag1
(g11214
g11182
(dp11807
g884
g3481
sg886
g3482
sg897
g3491
sg901
g3494
stRp11808
ag1
(g11214
g11182
(dp11809
g884
g3497
sg886
g3498
sg897
g3507
sg901
g3510
stRp11810
ag1
(g11214
g11182
(dp11811
g884
g3513
sg886
g3514
sg897
g3523
sg901
g3526
stRp11812
ag1
(g11214
g11182
(dp11813
g884
g3529
sg886
g3530
sg897
g3539
sg901
g3542
stRp11814
ag1
(g11214
g11182
(dp11815
g884
g3545
sg886
g3546
sg897
g3555
sg901
g3558
stRp11816
ag1
(g11214
g11182
(dp11817
g884
g3561
sg886
g3562
sg897
g3571
sg901
g3574
stRp11818
ag1
(g11214
g11182
(dp11819
g884
g3577
sg886
g3578
sg897
g3587
sg901
g3590
stRp11820
ag1
(g11214
g11182
(dp11821
g884
g3593
sg886
g3594
sg897
g3603
sg901
g3606
stRp11822
ag1
(g11214
g11182
(dp11823
g884
g3609
sg886
g3610
sg897
g3619
sg901
g3622
stRp11824
ag1
(g11214
g11182
(dp11825
g884
g3625
sg886
g3626
sg897
g3635
sg901
g3638
stRp11826
ag1
(g11214
g11182
(dp11827
g884
g3641
sg886
g3642
sg897
g3651
sg901
g3654
stRp11828
ag1
(g11214
g11182
(dp11829
g884
g3657
sg886
g3658
sg897
g3667
sg901
g3670
stRp11830
ag1
(g11214
g11182
(dp11831
g884
g3673
sg886
g3674
sg897
g3683
sg901
g3686
stRp11832
ag1
(g11214
g11182
(dp11833
g884
g3689
sg886
g3690
sg897
g3699
sg901
g3702
stRp11834
ag1
(g11214
g11182
(dp11835
g884
g3705
sg886
g3706
sg897
g3715
sg901
g3718
stRp11836
ag1
(g11214
g11182
(dp11837
g884
g3721
sg886
g3722
sg897
g3731
sg901
g3734
stRp11838
ag1
(g11214
g11182
(dp11839
g884
g3737
sg886
g3738
sg897
g3747
sg901
g3750
stRp11840
ag1
(g11214
g11182
(dp11841
g884
g3753
sg886
g3754
sg897
g3763
sg901
g3766
stRp11842
ag1
(g11214
g11182
(dp11843
g884
g3769
sg886
g3770
sg897
g3779
sg901
g3782
stRp11844
ag1
(g11214
g11182
(dp11845
g884
g3785
sg886
g3786
sg897
g3795
sg901
g3798
stRp11846
ag1
(g11214
g11182
(dp11847
g884
g3801
sg886
g3802
sg897
g3811
sg901
g3814
stRp11848
ag1
(g11214
g11182
(dp11849
g884
g3817
sg886
g3818
sg897
g3827
sg901
g3830
stRp11850
ag1
(g11214
g11182
(dp11851
g884
g3833
sg886
g3834
sg897
g3843
sg901
g3846
stRp11852
ag1
(g11214
g11182
(dp11853
g884
g3849
sg886
g3850
sg897
g3859
sg901
g3862
stRp11854
ag1
(g11214
g11182
(dp11855
g884
g3865
sg886
g3866
sg897
g3875
sg901
g3878
stRp11856
ag1
(g11214
g11182
(dp11857
g884
g3881
sg886
g3882
sg897
g3891
sg901
g3894
stRp11858
ag1
(g11214
g11182
(dp11859
g884
g3897
sg886
g3898
sg897
g3907
sg901
g3910
stRp11860
ag1
(g11214
g11182
(dp11861
g884
g3913
sg886
g3914
sg897
g3923
sg901
g3926
stRp11862
ag1
(g11214
g11182
(dp11863
g884
g3929
sg886
g3930
sg897
g3939
sg901
g3942
stRp11864
ag1
(g11214
g11182
(dp11865
g884
g3945
sg886
g3946
sg897
g3955
sg901
g3958
stRp11866
ag1
(g11214
g11182
(dp11867
g884
g3961
sg886
g3962
sg897
g3971
sg901
g3974
stRp11868
ag1
(g11214
g11182
(dp11869
g884
g3977
sg886
g3978
sg897
g3987
sg901
g3990
stRp11870
ag1
(g11214
g11182
(dp11871
g884
g3993
sg886
g3994
sg897
g4003
sg901
g4006
stRp11872
ag1
(g11214
g11182
(dp11873
g884
g4009
sg886
g4010
sg897
g4019
sg901
g4022
stRp11874
ag1
(g11214
g11182
(dp11875
g884
g4025
sg886
g4026
sg897
g4035
sg901
g4038
stRp11876
ag1
(g11214
g11182
(dp11877
g884
g4041
sg886
g4042
sg897
g4051
sg901
g4054
stRp11878
ag1
(g11214
g11182
(dp11879
g884
g4057
sg886
g4058
sg897
g4067
sg901
g4070
stRp11880
ag1
(g11214
g11182
(dp11881
g884
g4073
sg886
g4074
sg897
g4083
sg901
g4086
stRp11882
asg11295
Nsg11296
g4082
sg11297
I200
sg11298
I0
sg11299
I200
sg11300
I01
sbag1
(g11169
g3
NtRp11883
(dp11884
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p11885
sg11174
(lp11886
sg11176
I89576816
sg10
g11467
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp11887
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp11888
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg33
g11207
(g11187
(I0
tS'b'
tRp11889
(I1
(I200
I1
tg11308
I00
(lp11890
g4105
ag4123
ag4139
ag4155
ag4171
ag4187
ag4203
ag4219
ag4235
ag4251
ag4267
ag4283
ag4299
ag4315
ag4331
ag4347
ag4363
ag4379
ag4395
ag4411
ag4427
ag4443
ag4459
ag4475
ag4491
ag4507
ag4523
ag4539
ag4555
ag4571
ag4587
ag4603
ag4619
ag4635
ag4651
ag4667
ag4683
ag4699
ag4715
ag4731
ag4747
ag4763
ag4779
ag4795
ag4811
ag4827
ag4843
ag4859
ag4875
ag4891
ag4907
ag4923
ag4939
ag4955
ag4971
ag4987
ag5003
ag5019
ag5035
ag5051
ag5067
ag5083
ag5099
ag5115
ag5131
ag5147
ag5163
ag5179
ag5195
ag5211
ag5227
ag5243
ag5259
ag5275
ag5291
ag5307
ag5323
ag5339
ag5355
ag5371
ag5387
ag5403
ag5419
ag5435
ag5451
ag5467
ag5483
ag5499
ag5515
ag5531
ag5547
ag5563
ag5579
ag5595
ag5611
ag5627
ag5643
ag5659
ag5675
ag5691
ag5707
ag5723
ag5739
ag5755
ag5771
ag5787
ag5803
ag5819
ag5835
ag5851
ag5867
ag5883
ag5899
ag5915
ag5931
ag5947
ag5963
ag5979
ag5995
ag6011
ag6027
ag6043
ag6059
ag6075
ag6091
ag6107
ag6123
ag6139
ag6155
ag6171
ag6187
ag6203
ag6219
ag6235
ag6251
ag6267
ag6283
ag6299
ag6315
ag6331
ag6347
ag6363
ag6379
ag6395
ag6411
ag6427
ag6443
ag6459
ag6475
ag6491
ag6507
ag6523
ag6539
ag6555
ag6571
ag6587
ag6603
ag6619
ag6635
ag6651
ag6667
ag6683
ag6699
ag6715
ag6731
ag6747
ag6763
ag6779
ag6795
ag6811
ag6827
ag6843
ag6859
ag6875
ag6891
ag6907
ag6923
ag6939
ag6955
ag6971
ag6987
ag7003
ag7019
ag7035
ag7051
ag7067
ag7083
ag7099
ag7115
ag7131
ag7147
ag7163
ag7179
ag7195
ag7211
ag7227
ag7243
ag7259
ag7275
ag7291
atbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp11891
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB\x00\x00 B\x00\x00$B\x00\x00(B\x00\x00,B\x00\x000B\x00\x004B\x00\x008B\x00\x00<B\x00\x00@B\x00\x00DB\x00\x00HB\x00\x00LB\x00\x00PB\x00\x00TB\x00\x00XB\x00\x00\\B\x00\x00`B\x00\x00dB\x00\x00hB\x00\x00lB\x00\x00pB\x00\x00tB\x00\x00xB\x00\x00|B\x00\x00\x80B\x00\x00\x82B\x00\x00\x84B\x00\x00\x86B\x00\x00\x88B\x00\x00\x8aB\x00\x00\x8cB\x00\x00\x8eB\x00\x00\x90B\x00\x00\x92B\x00\x00\x94B\x00\x00\x96B\x00\x00\x98B\x00\x00\x9aB\x00\x00\x9cB\x00\x00\x9eB\x00\x00\xa0B\x00\x00\xa2B\x00\x00\xa4B\x00\x00\xa6B\x00\x00\xa8B\x00\x00\xaaB\x00\x00\xacB\x00\x00\xaeB\x00\x00\xb0B\x00\x00\xb2B\x00\x00\xb4B\x00\x00\xb6B\x00\x00\xb8B\x00\x00\xbaB\x00\x00\xbcB\x00\x00\xbeB\x00\x00\xc0B\x00\x00\xc2B\x00\x00\xc4B\x00\x00\xc6B\x00\x00\xc8B\x00\x00\xcaB\x00\x00\xccB\x00\x00\xceB\x00\x00\xd0B\x00\x00\xd2B\x00\x00\xd4B\x00\x00\xd6B\x00\x00\xd8B\x00\x00\xdaB\x00\x00\xdcB\x00\x00\xdeB\x00\x00\xe0B\x00\x00\xe2B\x00\x00\xe4B\x00\x00\xe6B\x00\x00\xe8B\x00\x00\xeaB\x00\x00\xecB\x00\x00\xeeB\x00\x00\xf0B\x00\x00\xf2B\x00\x00\xf4B\x00\x00\xf6B\x00\x00\xf8B\x00\x00\xfaB\x00\x00\xfcB\x00\x00\xfeB\x00\x00\x00C\x00\x00\x01C\x00\x00\x02C\x00\x00\x03C\x00\x00\x04C\x00\x00\x05C\x00\x00\x06C\x00\x00\x07C\x00\x00\x08C\x00\x00\tC\x00\x00\nC\x00\x00\x0bC\x00\x00\x0cC\x00\x00\rC\x00\x00\x0eC\x00\x00\x0fC\x00\x00\x10C\x00\x00\x11C\x00\x00\x12C\x00\x00\x13C\x00\x00\x14C\x00\x00\x15C\x00\x00\x16C\x00\x00\x17C\x00\x00\x18C\x00\x00\x19C\x00\x00\x1aC\x00\x00\x1bC\x00\x00\x1cC\x00\x00\x1dC\x00\x00\x1eC\x00\x00\x1fC\x00\x00 C\x00\x00!C\x00\x00"C\x00\x00#C\x00\x00$C\x00\x00%C\x00\x00&C\x00\x00\'C\x00\x00(C\x00\x00)C\x00\x00*C\x00\x00+C\x00\x00,C\x00\x00-C\x00\x00.C\x00\x00/C\x00\x000C\x00\x001C\x00\x002C\x00\x003C\x00\x004C\x00\x005C\x00\x006C\x00\x007C\x00\x008C\x00\x009C\x00\x00:C\x00\x00;C\x00\x00<C\x00\x00=C\x00\x00>C\x00\x00?C\x00\x00@C\x00\x00AC\x00\x00BC\x00\x00CC\x00\x00DC\x00\x00EC\x00\x00FC\x00\x00GC'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg34
g11185
(g11186
g11187
g11188
S'b'
tRp11892
(I1
(I200
I1
tg11190
I00
S'\xb2\xedx?\xcb\x0fa?\xc8\xb1\x86?\x84\xa4\x12?\x05\x1a\'?6\xd6V?\xe3v\x19?\xd3\xeb-?\xe4\x19\'?\x88;\x0f?\xca\x85u?\xf8\xd2\x0b?\xc7\xb0#?ulS?\xc5\xe2g?\x05\n\x96?l"\xb8?jkS?\xca\xeb-?\xf4\x04\xb3?\x9eH ?\x9b;\x0f?\xe2\r\x16?\xbf\xc9E?{\x03\xb3?D&8?\xd1\xc6E?\x13\x90;?\x0e@\xbd?\xba?Z?\xc3\xd6V?\x15\x1dr?%\xbc4?\xb2\x1a\'?-\xb2\x86?\xef\x85*?\x0f\n\x16?R\xec-?)\xa8]?\xc4a\xa5?\x95\x0ba?BKk?\xac\xb1\x86?i\xfd\x84?\xf0\r\x16?\xe8\xf7>?}H ?\xbc\x14a?9\xc9\xa8?\xdb\xc9E?\x16?Z?%\xf8>?\x87\xbe4?{3I?\xcaT1?\xf8\xb3n?\xb6\xc9E?\xb1yd?\xb7Kk?p\x82*?\xba\x98\x01?\xdev\x19?\xa1\xf7>?4\x9bL?\xa6\xfb\x04@k\x01\x05?\x01T1?@$8?bU\x94?\xb5\xd6V?\xb22I?7\xbe4?Q\xde\x1c?\xe8\xec-?a\x10a?\x86\x8f;?k\x98\x01?\xd5\x97\x01?\xc1u\x19?\xe0\xd2\x0b?\x96\xca\xa8?\xbd\r\x16?\xec\x1dr?\xdf\x00\x05?\xe9\xa0\x92?\x16\xdf\x1c?bI\x83?c@Z?,\xbd4?F\xa8]?\xa0Kk?\xdd\xd5V?\x80\xbd4?n\xa5\x12?\xf3yd?\xc3l#?h#b?\xfd\x01\x05?@\xdf\x1c?\xd4T1?\x05\xeb-?\x04H ?-?\x0f?\xf1v\x19?\xe4\xdf\x1c?\x03\x8f;?M\xca\xa8?\xd6\x83\x8d?\xd0\xf7>?w\x1dr?\x9c<\x0f?\x97\x83*?cj\x08?\x01\xd3\x0b?t\x84u?%\xfc\x84?1mS?\xad2I?\x8c\xe2g?td\x08@.w\x19?\x9d"\xb8?\xa4\x01\x05?i \'?\xf8\x82*?\xfe\x0fa?\x06\xa5#?\xa4\xeb-?\x067\xf7?\'\xba#?\xe7>Z?Y\x1a\'?J2I?>T1?d\x9cL?\x08\xed-?\x0b\xf7>?\xcaT1?\xa6v\x19?\x1aU1?\x18\x9bL?\xc1\xb0\x1d@\xd7\xc6\x7f?2\x0e\x16?\x90H ?\xac\xf4\xbe?\xebd\xf0?,\x1dr?\xb4\x84;?4\xa9\xc0?\xbf\x19\'?\xb0v\x19?\x01\xcaE?\x9e\xe2\x1c?#\xec-?\xe0S1?\xe02Z?\xa6G ?\xb6\xc9E?2\xb2\x86?\xe9kS?X\x82*?\xc0wd?\x1dKk?S\x0e\x16?$\xdf\x1c?\x01\xa9]?q\xe8\xe7>\x1ev\x19?\x0fh\x08?N\xb0#?$\x8f;?\xd7yd?\xa7\x98\x01?2\xd7\x1c?(&8?\xfd\\\xc2?6\xdf\x1c?;\x9aL?\x9c\xeex?\x8fW|?\x07U1?\xb5\xb0#?a\x01\x16?\xc7\x00\x05?\xbe\xe4\x1c?k\xf8>?\xb8T1?\xa1G ?o\xdf\x1c?~\x01\x05?]8\x8f?\xfd2I?\x8av\x19?\xc2r\x99?\xa0j\x08?rd\x08@v\xa4\x12?r\xbd4?\xdd\xa4\x12?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg30
g11207
(g11187
(I0
tS'b'
tRp11893
(I1
(I200
I1
tg11308
I00
(lp11894
g4097
ag4117
ag4133
ag4149
ag4165
ag4181
ag4197
ag4213
ag4239
ag4245
ag4261
ag4277
ag4293
ag4309
ag4325
ag4341
ag4357
ag4383
ag4389
ag4405
ag4431
ag4437
ag4453
ag4469
ag4495
ag4501
ag4527
ag4533
ag4549
ag4565
ag4581
ag4597
ag4613
ag4629
ag4645
ag4661
ag4677
ag4693
ag4709
ag4735
ag4741
ag4757
ag4773
ag4789
ag4805
ag4821
ag4837
ag4853
ag4869
ag4885
ag4901
ag4917
ag4933
ag4959
ag4965
ag4981
ag4997
ag5013
ag5029
ag5045
ag5071
ag5087
ag5093
ag5109
ag5125
ag5141
ag5157
ag5173
ag5189
ag5215
ag5221
ag5247
ag5253
ag5279
ag5285
ag5301
ag5327
ag5333
ag5349
ag5365
ag5381
ag5397
ag5413
ag5439
ag5445
ag5461
ag5477
ag5493
ag5519
ag5535
ag5541
ag5557
ag5573
ag5589
ag5605
ag5621
ag5637
ag5663
ag5669
ag5685
ag5701
ag5727
ag5743
ag5749
ag5765
ag5781
ag5797
ag5813
ag5839
ag5845
ag5871
ag5877
ag5903
ag5919
ag5925
ag5941
ag5957
ag5973
ag5989
ag6005
ag6021
ag6037
ag6053
ag6069
ag6085
ag6101
ag6117
ag6133
ag6149
ag6165
ag6181
ag6197
ag6213
ag6229
ag6245
ag6261
ag6277
ag6293
ag6309
ag6325
ag6341
ag6367
ag6373
ag6389
ag6415
ag6431
ag6437
ag6453
ag6469
ag6485
ag6501
ag6517
ag6533
ag6559
ag6565
ag6581
ag6607
ag6613
ag6639
ag6645
ag6671
ag6677
ag6693
ag6709
ag6725
ag6741
ag6757
ag6773
ag6789
ag6805
ag6821
ag6837
ag6853
ag6869
ag6885
ag6901
ag6917
ag6943
ag6949
ag6965
ag6981
ag6997
ag7023
ag7029
ag7045
ag7061
ag7077
ag7093
ag7119
ag7125
ag7141
ag7157
ag7173
ag7189
ag7205
ag7221
ag7237
ag7253
ag7269
ag7285
atbstRp11895
(dp11896
g11197
(dp11897
g11184
I01
sg33
I00
sg11193
I01
sg34
I01
sg30
I00
ssg11199
g11883
sg11200
(lp11898
g11184
ag11193
ag33
ag34
ag30
asg11202
(lp11899
I200
aI1
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp11900
(I1
(I200
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00(\x00\x00\x00)\x00\x00\x00*\x00\x00\x00+\x00\x00\x00,\x00\x00\x00-\x00\x00\x00.\x00\x00\x00/\x00\x00\x000\x00\x00\x001\x00\x00\x002\x00\x00\x003\x00\x00\x004\x00\x00\x005\x00\x00\x006\x00\x00\x007\x00\x00\x008\x00\x00\x009\x00\x00\x00:\x00\x00\x00;\x00\x00\x00<\x00\x00\x00=\x00\x00\x00>\x00\x00\x00?\x00\x00\x00@\x00\x00\x00A\x00\x00\x00B\x00\x00\x00C\x00\x00\x00D\x00\x00\x00E\x00\x00\x00F\x00\x00\x00G\x00\x00\x00H\x00\x00\x00I\x00\x00\x00J\x00\x00\x00K\x00\x00\x00L\x00\x00\x00M\x00\x00\x00N\x00\x00\x00O\x00\x00\x00P\x00\x00\x00Q\x00\x00\x00R\x00\x00\x00S\x00\x00\x00T\x00\x00\x00U\x00\x00\x00V\x00\x00\x00W\x00\x00\x00X\x00\x00\x00Y\x00\x00\x00Z\x00\x00\x00[\x00\x00\x00\\\x00\x00\x00]\x00\x00\x00^\x00\x00\x00_\x00\x00\x00`\x00\x00\x00a\x00\x00\x00b\x00\x00\x00c\x00\x00\x00d\x00\x00\x00e\x00\x00\x00f\x00\x00\x00g\x00\x00\x00h\x00\x00\x00i\x00\x00\x00j\x00\x00\x00k\x00\x00\x00l\x00\x00\x00m\x00\x00\x00n\x00\x00\x00o\x00\x00\x00p\x00\x00\x00q\x00\x00\x00r\x00\x00\x00s\x00\x00\x00t\x00\x00\x00u\x00\x00\x00v\x00\x00\x00w\x00\x00\x00x\x00\x00\x00y\x00\x00\x00z\x00\x00\x00{\x00\x00\x00|\x00\x00\x00}\x00\x00\x00~\x00\x00\x00\x7f\x00\x00\x00\x80\x00\x00\x00\x81\x00\x00\x00\x82\x00\x00\x00\x83\x00\x00\x00\x84\x00\x00\x00\x85\x00\x00\x00\x86\x00\x00\x00\x87\x00\x00\x00\x88\x00\x00\x00\x89\x00\x00\x00\x8a\x00\x00\x00\x8b\x00\x00\x00\x8c\x00\x00\x00\x8d\x00\x00\x00\x8e\x00\x00\x00\x8f\x00\x00\x00\x90\x00\x00\x00\x91\x00\x00\x00\x92\x00\x00\x00\x93\x00\x00\x00\x94\x00\x00\x00\x95\x00\x00\x00\x96\x00\x00\x00\x97\x00\x00\x00\x98\x00\x00\x00\x99\x00\x00\x00\x9a\x00\x00\x00\x9b\x00\x00\x00\x9c\x00\x00\x00\x9d\x00\x00\x00\x9e\x00\x00\x00\x9f\x00\x00\x00\xa0\x00\x00\x00\xa1\x00\x00\x00\xa2\x00\x00\x00\xa3\x00\x00\x00\xa4\x00\x00\x00\xa5\x00\x00\x00\xa6\x00\x00\x00\xa7\x00\x00\x00\xa8\x00\x00\x00\xa9\x00\x00\x00\xaa\x00\x00\x00\xab\x00\x00\x00\xac\x00\x00\x00\xad\x00\x00\x00\xae\x00\x00\x00\xaf\x00\x00\x00\xb0\x00\x00\x00\xb1\x00\x00\x00\xb2\x00\x00\x00\xb3\x00\x00\x00\xb4\x00\x00\x00\xb5\x00\x00\x00\xb6\x00\x00\x00\xb7\x00\x00\x00\xb8\x00\x00\x00\xb9\x00\x00\x00\xba\x00\x00\x00\xbb\x00\x00\x00\xbc\x00\x00\x00\xbd\x00\x00\x00\xbe\x00\x00\x00\xbf\x00\x00\x00\xc0\x00\x00\x00\xc1\x00\x00\x00\xc2\x00\x00\x00\xc3\x00\x00\x00\xc4\x00\x00\x00\xc5\x00\x00\x00\xc6\x00\x00\x00\xc7\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp11901
g1
(g11214
g11182
(dp11902
g4096
g4097
sg4098
g4099
sg4109
g4110
sg4113
g4114
stRp11903
ag1
(g11214
g11182
(dp11904
g4096
g4117
sg4098
g4118
sg4109
g4127
sg4113
g4130
stRp11905
ag1
(g11214
g11182
(dp11906
g4096
g4133
sg4098
g4134
sg4109
g4143
sg4113
g4146
stRp11907
ag1
(g11214
g11182
(dp11908
g4096
g4149
sg4098
g4150
sg4109
g4159
sg4113
g4162
stRp11909
ag1
(g11214
g11182
(dp11910
g4096
g4165
sg4098
g4166
sg4109
g4175
sg4113
g4178
stRp11911
ag1
(g11214
g11182
(dp11912
g4096
g4181
sg4098
g4182
sg4109
g4191
sg4113
g4194
stRp11913
ag1
(g11214
g11182
(dp11914
g4096
g4197
sg4098
g4198
sg4109
g4207
sg4113
g4210
stRp11915
ag1
(g11214
g11182
(dp11916
g4096
g4213
sg4098
g4214
sg4109
g4223
sg4113
g4226
stRp11917
ag1
(g11214
g11182
(dp11918
g4096
g4229
sg4098
g4230
sg4109
g4239
sg4113
g4242
stRp11919
ag1
(g11214
g11182
(dp11920
g4096
g4245
sg4098
g4246
sg4109
g4255
sg4113
g4258
stRp11921
ag1
(g11214
g11182
(dp11922
g4096
g4261
sg4098
g4262
sg4109
g4271
sg4113
g4274
stRp11923
ag1
(g11214
g11182
(dp11924
g4096
g4277
sg4098
g4278
sg4109
g4287
sg4113
g4290
stRp11925
ag1
(g11214
g11182
(dp11926
g4096
g4293
sg4098
g4294
sg4109
g4303
sg4113
g4306
stRp11927
ag1
(g11214
g11182
(dp11928
g4096
g4309
sg4098
g4310
sg4109
g4319
sg4113
g4322
stRp11929
ag1
(g11214
g11182
(dp11930
g4096
g4325
sg4098
g4326
sg4109
g4335
sg4113
g4338
stRp11931
ag1
(g11214
g11182
(dp11932
g4096
g4341
sg4098
g4342
sg4109
g4351
sg4113
g4354
stRp11933
ag1
(g11214
g11182
(dp11934
g4096
g4357
sg4098
g4358
sg4109
g4367
sg4113
g4370
stRp11935
ag1
(g11214
g11182
(dp11936
g4096
g4373
sg4098
g4374
sg4109
g4383
sg4113
g4386
stRp11937
ag1
(g11214
g11182
(dp11938
g4096
g4389
sg4098
g4390
sg4109
g4399
sg4113
g4402
stRp11939
ag1
(g11214
g11182
(dp11940
g4096
g4405
sg4098
g4406
sg4109
g4415
sg4113
g4418
stRp11941
ag1
(g11214
g11182
(dp11942
g4096
g4421
sg4098
g4422
sg4109
g4431
sg4113
g4434
stRp11943
ag1
(g11214
g11182
(dp11944
g4096
g4437
sg4098
g4438
sg4109
g4447
sg4113
g4450
stRp11945
ag1
(g11214
g11182
(dp11946
g4096
g4453
sg4098
g4454
sg4109
g4463
sg4113
g4466
stRp11947
ag1
(g11214
g11182
(dp11948
g4096
g4469
sg4098
g4470
sg4109
g4479
sg4113
g4482
stRp11949
ag1
(g11214
g11182
(dp11950
g4096
g4485
sg4098
g4486
sg4109
g4495
sg4113
g4498
stRp11951
ag1
(g11214
g11182
(dp11952
g4096
g4501
sg4098
g4502
sg4109
g4511
sg4113
g4514
stRp11953
ag1
(g11214
g11182
(dp11954
g4096
g4517
sg4098
g4518
sg4109
g4527
sg4113
g4530
stRp11955
ag1
(g11214
g11182
(dp11956
g4096
g4533
sg4098
g4534
sg4109
g4543
sg4113
g4546
stRp11957
ag1
(g11214
g11182
(dp11958
g4096
g4549
sg4098
g4550
sg4109
g4559
sg4113
g4562
stRp11959
ag1
(g11214
g11182
(dp11960
g4096
g4565
sg4098
g4566
sg4109
g4575
sg4113
g4578
stRp11961
ag1
(g11214
g11182
(dp11962
g4096
g4581
sg4098
g4582
sg4109
g4591
sg4113
g4594
stRp11963
ag1
(g11214
g11182
(dp11964
g4096
g4597
sg4098
g4598
sg4109
g4607
sg4113
g4610
stRp11965
ag1
(g11214
g11182
(dp11966
g4096
g4613
sg4098
g4614
sg4109
g4623
sg4113
g4626
stRp11967
ag1
(g11214
g11182
(dp11968
g4096
g4629
sg4098
g4630
sg4109
g4639
sg4113
g4642
stRp11969
ag1
(g11214
g11182
(dp11970
g4096
g4645
sg4098
g4646
sg4109
g4655
sg4113
g4658
stRp11971
ag1
(g11214
g11182
(dp11972
g4096
g4661
sg4098
g4662
sg4109
g4671
sg4113
g4674
stRp11973
ag1
(g11214
g11182
(dp11974
g4096
g4677
sg4098
g4678
sg4109
g4687
sg4113
g4690
stRp11975
ag1
(g11214
g11182
(dp11976
g4096
g4693
sg4098
g4694
sg4109
g4703
sg4113
g4706
stRp11977
ag1
(g11214
g11182
(dp11978
g4096
g4709
sg4098
g4710
sg4109
g4719
sg4113
g4722
stRp11979
ag1
(g11214
g11182
(dp11980
g4096
g4725
sg4098
g4726
sg4109
g4735
sg4113
g4738
stRp11981
ag1
(g11214
g11182
(dp11982
g4096
g4741
sg4098
g4742
sg4109
g4751
sg4113
g4754
stRp11983
ag1
(g11214
g11182
(dp11984
g4096
g4757
sg4098
g4758
sg4109
g4767
sg4113
g4770
stRp11985
ag1
(g11214
g11182
(dp11986
g4096
g4773
sg4098
g4774
sg4109
g4783
sg4113
g4786
stRp11987
ag1
(g11214
g11182
(dp11988
g4096
g4789
sg4098
g4790
sg4109
g4799
sg4113
g4802
stRp11989
ag1
(g11214
g11182
(dp11990
g4096
g4805
sg4098
g4806
sg4109
g4815
sg4113
g4818
stRp11991
ag1
(g11214
g11182
(dp11992
g4096
g4821
sg4098
g4822
sg4109
g4831
sg4113
g4834
stRp11993
ag1
(g11214
g11182
(dp11994
g4096
g4837
sg4098
g4838
sg4109
g4847
sg4113
g4850
stRp11995
ag1
(g11214
g11182
(dp11996
g4096
g4853
sg4098
g4854
sg4109
g4863
sg4113
g4866
stRp11997
ag1
(g11214
g11182
(dp11998
g4096
g4869
sg4098
g4870
sg4109
g4879
sg4113
g4882
stRp11999
ag1
(g11214
g11182
(dp12000
g4096
g4885
sg4098
g4886
sg4109
g4895
sg4113
g4898
stRp12001
ag1
(g11214
g11182
(dp12002
g4096
g4901
sg4098
g4902
sg4109
g4911
sg4113
g4914
stRp12003
ag1
(g11214
g11182
(dp12004
g4096
g4917
sg4098
g4918
sg4109
g4927
sg4113
g4930
stRp12005
ag1
(g11214
g11182
(dp12006
g4096
g4933
sg4098
g4934
sg4109
g4943
sg4113
g4946
stRp12007
ag1
(g11214
g11182
(dp12008
g4096
g4949
sg4098
g4950
sg4109
g4959
sg4113
g4962
stRp12009
ag1
(g11214
g11182
(dp12010
g4096
g4965
sg4098
g4966
sg4109
g4975
sg4113
g4978
stRp12011
ag1
(g11214
g11182
(dp12012
g4096
g4981
sg4098
g4982
sg4109
g4991
sg4113
g4994
stRp12013
ag1
(g11214
g11182
(dp12014
g4096
g4997
sg4098
g4998
sg4109
g5007
sg4113
g5010
stRp12015
ag1
(g11214
g11182
(dp12016
g4096
g5013
sg4098
g5014
sg4109
g5023
sg4113
g5026
stRp12017
ag1
(g11214
g11182
(dp12018
g4096
g5029
sg4098
g5030
sg4109
g5039
sg4113
g5042
stRp12019
ag1
(g11214
g11182
(dp12020
g4096
g5045
sg4098
g5046
sg4109
g5055
sg4113
g5058
stRp12021
ag1
(g11214
g11182
(dp12022
g4096
g5061
sg4098
g5062
sg4109
g5071
sg4113
g5074
stRp12023
ag1
(g11214
g11182
(dp12024
g4096
g5077
sg4098
g5078
sg4109
g5087
sg4113
g5090
stRp12025
ag1
(g11214
g11182
(dp12026
g4096
g5093
sg4098
g5094
sg4109
g5103
sg4113
g5106
stRp12027
ag1
(g11214
g11182
(dp12028
g4096
g5109
sg4098
g5110
sg4109
g5119
sg4113
g5122
stRp12029
ag1
(g11214
g11182
(dp12030
g4096
g5125
sg4098
g5126
sg4109
g5135
sg4113
g5138
stRp12031
ag1
(g11214
g11182
(dp12032
g4096
g5141
sg4098
g5142
sg4109
g5151
sg4113
g5154
stRp12033
ag1
(g11214
g11182
(dp12034
g4096
g5157
sg4098
g5158
sg4109
g5167
sg4113
g5170
stRp12035
ag1
(g11214
g11182
(dp12036
g4096
g5173
sg4098
g5174
sg4109
g5183
sg4113
g5186
stRp12037
ag1
(g11214
g11182
(dp12038
g4096
g5189
sg4098
g5190
sg4109
g5199
sg4113
g5202
stRp12039
ag1
(g11214
g11182
(dp12040
g4096
g5205
sg4098
g5206
sg4109
g5215
sg4113
g5218
stRp12041
ag1
(g11214
g11182
(dp12042
g4096
g5221
sg4098
g5222
sg4109
g5231
sg4113
g5234
stRp12043
ag1
(g11214
g11182
(dp12044
g4096
g5237
sg4098
g5238
sg4109
g5247
sg4113
g5250
stRp12045
ag1
(g11214
g11182
(dp12046
g4096
g5253
sg4098
g5254
sg4109
g5263
sg4113
g5266
stRp12047
ag1
(g11214
g11182
(dp12048
g4096
g5269
sg4098
g5270
sg4109
g5279
sg4113
g5282
stRp12049
ag1
(g11214
g11182
(dp12050
g4096
g5285
sg4098
g5286
sg4109
g5295
sg4113
g5298
stRp12051
ag1
(g11214
g11182
(dp12052
g4096
g5301
sg4098
g5302
sg4109
g5311
sg4113
g5314
stRp12053
ag1
(g11214
g11182
(dp12054
g4096
g5317
sg4098
g5318
sg4109
g5327
sg4113
g5330
stRp12055
ag1
(g11214
g11182
(dp12056
g4096
g5333
sg4098
g5334
sg4109
g5343
sg4113
g5346
stRp12057
ag1
(g11214
g11182
(dp12058
g4096
g5349
sg4098
g5350
sg4109
g5359
sg4113
g5362
stRp12059
ag1
(g11214
g11182
(dp12060
g4096
g5365
sg4098
g5366
sg4109
g5375
sg4113
g5378
stRp12061
ag1
(g11214
g11182
(dp12062
g4096
g5381
sg4098
g5382
sg4109
g5391
sg4113
g5394
stRp12063
ag1
(g11214
g11182
(dp12064
g4096
g5397
sg4098
g5398
sg4109
g5407
sg4113
g5410
stRp12065
ag1
(g11214
g11182
(dp12066
g4096
g5413
sg4098
g5414
sg4109
g5423
sg4113
g5426
stRp12067
ag1
(g11214
g11182
(dp12068
g4096
g5429
sg4098
g5430
sg4109
g5439
sg4113
g5442
stRp12069
ag1
(g11214
g11182
(dp12070
g4096
g5445
sg4098
g5446
sg4109
g5455
sg4113
g5458
stRp12071
ag1
(g11214
g11182
(dp12072
g4096
g5461
sg4098
g5462
sg4109
g5471
sg4113
g5474
stRp12073
ag1
(g11214
g11182
(dp12074
g4096
g5477
sg4098
g5478
sg4109
g5487
sg4113
g5490
stRp12075
ag1
(g11214
g11182
(dp12076
g4096
g5493
sg4098
g5494
sg4109
g5503
sg4113
g5506
stRp12077
ag1
(g11214
g11182
(dp12078
g4096
g5509
sg4098
g5510
sg4109
g5519
sg4113
g5522
stRp12079
ag1
(g11214
g11182
(dp12080
g4096
g5525
sg4098
g5526
sg4109
g5535
sg4113
g5538
stRp12081
ag1
(g11214
g11182
(dp12082
g4096
g5541
sg4098
g5542
sg4109
g5551
sg4113
g5554
stRp12083
ag1
(g11214
g11182
(dp12084
g4096
g5557
sg4098
g5558
sg4109
g5567
sg4113
g5570
stRp12085
ag1
(g11214
g11182
(dp12086
g4096
g5573
sg4098
g5574
sg4109
g5583
sg4113
g5586
stRp12087
ag1
(g11214
g11182
(dp12088
g4096
g5589
sg4098
g5590
sg4109
g5599
sg4113
g5602
stRp12089
ag1
(g11214
g11182
(dp12090
g4096
g5605
sg4098
g5606
sg4109
g5615
sg4113
g5618
stRp12091
ag1
(g11214
g11182
(dp12092
g4096
g5621
sg4098
g5622
sg4109
g5631
sg4113
g5634
stRp12093
ag1
(g11214
g11182
(dp12094
g4096
g5637
sg4098
g5638
sg4109
g5647
sg4113
g5650
stRp12095
ag1
(g11214
g11182
(dp12096
g4096
g5653
sg4098
g5654
sg4109
g5663
sg4113
g5666
stRp12097
ag1
(g11214
g11182
(dp12098
g4096
g5669
sg4098
g5670
sg4109
g5679
sg4113
g5682
stRp12099
ag1
(g11214
g11182
(dp12100
g4096
g5685
sg4098
g5686
sg4109
g5695
sg4113
g5698
stRp12101
ag1
(g11214
g11182
(dp12102
g4096
g5701
sg4098
g5702
sg4109
g5711
sg4113
g5714
stRp12103
ag1
(g11214
g11182
(dp12104
g4096
g5717
sg4098
g5718
sg4109
g5727
sg4113
g5730
stRp12105
ag1
(g11214
g11182
(dp12106
g4096
g5733
sg4098
g5734
sg4109
g5743
sg4113
g5746
stRp12107
ag1
(g11214
g11182
(dp12108
g4096
g5749
sg4098
g5750
sg4109
g5759
sg4113
g5762
stRp12109
ag1
(g11214
g11182
(dp12110
g4096
g5765
sg4098
g5766
sg4109
g5775
sg4113
g5778
stRp12111
ag1
(g11214
g11182
(dp12112
g4096
g5781
sg4098
g5782
sg4109
g5791
sg4113
g5794
stRp12113
ag1
(g11214
g11182
(dp12114
g4096
g5797
sg4098
g5798
sg4109
g5807
sg4113
g5810
stRp12115
ag1
(g11214
g11182
(dp12116
g4096
g5813
sg4098
g5814
sg4109
g5823
sg4113
g5826
stRp12117
ag1
(g11214
g11182
(dp12118
g4096
g5829
sg4098
g5830
sg4109
g5839
sg4113
g5842
stRp12119
ag1
(g11214
g11182
(dp12120
g4096
g5845
sg4098
g5846
sg4109
g5855
sg4113
g5858
stRp12121
ag1
(g11214
g11182
(dp12122
g4096
g5861
sg4098
g5862
sg4109
g5871
sg4113
g5874
stRp12123
ag1
(g11214
g11182
(dp12124
g4096
g5877
sg4098
g5878
sg4109
g5887
sg4113
g5890
stRp12125
ag1
(g11214
g11182
(dp12126
g4096
g5893
sg4098
g5894
sg4109
g5903
sg4113
g5906
stRp12127
ag1
(g11214
g11182
(dp12128
g4096
g5909
sg4098
g5910
sg4109
g5919
sg4113
g5922
stRp12129
ag1
(g11214
g11182
(dp12130
g4096
g5925
sg4098
g5926
sg4109
g5935
sg4113
g5938
stRp12131
ag1
(g11214
g11182
(dp12132
g4096
g5941
sg4098
g5942
sg4109
g5951
sg4113
g5954
stRp12133
ag1
(g11214
g11182
(dp12134
g4096
g5957
sg4098
g5958
sg4109
g5967
sg4113
g5970
stRp12135
ag1
(g11214
g11182
(dp12136
g4096
g5973
sg4098
g5974
sg4109
g5983
sg4113
g5986
stRp12137
ag1
(g11214
g11182
(dp12138
g4096
g5989
sg4098
g5990
sg4109
g5999
sg4113
g6002
stRp12139
ag1
(g11214
g11182
(dp12140
g4096
g6005
sg4098
g6006
sg4109
g6015
sg4113
g6018
stRp12141
ag1
(g11214
g11182
(dp12142
g4096
g6021
sg4098
g6022
sg4109
g6031
sg4113
g6034
stRp12143
ag1
(g11214
g11182
(dp12144
g4096
g6037
sg4098
g6038
sg4109
g6047
sg4113
g6050
stRp12145
ag1
(g11214
g11182
(dp12146
g4096
g6053
sg4098
g6054
sg4109
g6063
sg4113
g6066
stRp12147
ag1
(g11214
g11182
(dp12148
g4096
g6069
sg4098
g6070
sg4109
g6079
sg4113
g6082
stRp12149
ag1
(g11214
g11182
(dp12150
g4096
g6085
sg4098
g6086
sg4109
g6095
sg4113
g6098
stRp12151
ag1
(g11214
g11182
(dp12152
g4096
g6101
sg4098
g6102
sg4109
g6111
sg4113
g6114
stRp12153
ag1
(g11214
g11182
(dp12154
g4096
g6117
sg4098
g6118
sg4109
g6127
sg4113
g6130
stRp12155
ag1
(g11214
g11182
(dp12156
g4096
g6133
sg4098
g6134
sg4109
g6143
sg4113
g6146
stRp12157
ag1
(g11214
g11182
(dp12158
g4096
g6149
sg4098
g6150
sg4109
g6159
sg4113
g6162
stRp12159
ag1
(g11214
g11182
(dp12160
g4096
g6165
sg4098
g6166
sg4109
g6175
sg4113
g6178
stRp12161
ag1
(g11214
g11182
(dp12162
g4096
g6181
sg4098
g6182
sg4109
g6191
sg4113
g6194
stRp12163
ag1
(g11214
g11182
(dp12164
g4096
g6197
sg4098
g6198
sg4109
g6207
sg4113
g6210
stRp12165
ag1
(g11214
g11182
(dp12166
g4096
g6213
sg4098
g6214
sg4109
g6223
sg4113
g6226
stRp12167
ag1
(g11214
g11182
(dp12168
g4096
g6229
sg4098
g6230
sg4109
g6239
sg4113
g6242
stRp12169
ag1
(g11214
g11182
(dp12170
g4096
g6245
sg4098
g6246
sg4109
g6255
sg4113
g6258
stRp12171
ag1
(g11214
g11182
(dp12172
g4096
g6261
sg4098
g6262
sg4109
g6271
sg4113
g6274
stRp12173
ag1
(g11214
g11182
(dp12174
g4096
g6277
sg4098
g6278
sg4109
g6287
sg4113
g6290
stRp12175
ag1
(g11214
g11182
(dp12176
g4096
g6293
sg4098
g6294
sg4109
g6303
sg4113
g6306
stRp12177
ag1
(g11214
g11182
(dp12178
g4096
g6309
sg4098
g6310
sg4109
g6319
sg4113
g6322
stRp12179
ag1
(g11214
g11182
(dp12180
g4096
g6325
sg4098
g6326
sg4109
g6335
sg4113
g6338
stRp12181
ag1
(g11214
g11182
(dp12182
g4096
g6341
sg4098
g6342
sg4109
g6351
sg4113
g6354
stRp12183
ag1
(g11214
g11182
(dp12184
g4096
g6357
sg4098
g6358
sg4109
g6367
sg4113
g6370
stRp12185
ag1
(g11214
g11182
(dp12186
g4096
g6373
sg4098
g6374
sg4109
g6383
sg4113
g6386
stRp12187
ag1
(g11214
g11182
(dp12188
g4096
g6389
sg4098
g6390
sg4109
g6399
sg4113
g6402
stRp12189
ag1
(g11214
g11182
(dp12190
g4096
g6405
sg4098
g6406
sg4109
g6415
sg4113
g6418
stRp12191
ag1
(g11214
g11182
(dp12192
g4096
g6421
sg4098
g6422
sg4109
g6431
sg4113
g6434
stRp12193
ag1
(g11214
g11182
(dp12194
g4096
g6437
sg4098
g6438
sg4109
g6447
sg4113
g6450
stRp12195
ag1
(g11214
g11182
(dp12196
g4096
g6453
sg4098
g6454
sg4109
g6463
sg4113
g6466
stRp12197
ag1
(g11214
g11182
(dp12198
g4096
g6469
sg4098
g6470
sg4109
g6479
sg4113
g6482
stRp12199
ag1
(g11214
g11182
(dp12200
g4096
g6485
sg4098
g6486
sg4109
g6495
sg4113
g6498
stRp12201
ag1
(g11214
g11182
(dp12202
g4096
g6501
sg4098
g6502
sg4109
g6511
sg4113
g6514
stRp12203
ag1
(g11214
g11182
(dp12204
g4096
g6517
sg4098
g6518
sg4109
g6527
sg4113
g6530
stRp12205
ag1
(g11214
g11182
(dp12206
g4096
g6533
sg4098
g6534
sg4109
g6543
sg4113
g6546
stRp12207
ag1
(g11214
g11182
(dp12208
g4096
g6549
sg4098
g6550
sg4109
g6559
sg4113
g6562
stRp12209
ag1
(g11214
g11182
(dp12210
g4096
g6565
sg4098
g6566
sg4109
g6575
sg4113
g6578
stRp12211
ag1
(g11214
g11182
(dp12212
g4096
g6581
sg4098
g6582
sg4109
g6591
sg4113
g6594
stRp12213
ag1
(g11214
g11182
(dp12214
g4096
g6597
sg4098
g6598
sg4109
g6607
sg4113
g6610
stRp12215
ag1
(g11214
g11182
(dp12216
g4096
g6613
sg4098
g6614
sg4109
g6623
sg4113
g6626
stRp12217
ag1
(g11214
g11182
(dp12218
g4096
g6629
sg4098
g6630
sg4109
g6639
sg4113
g6642
stRp12219
ag1
(g11214
g11182
(dp12220
g4096
g6645
sg4098
g6646
sg4109
g6655
sg4113
g6658
stRp12221
ag1
(g11214
g11182
(dp12222
g4096
g6661
sg4098
g6662
sg4109
g6671
sg4113
g6674
stRp12223
ag1
(g11214
g11182
(dp12224
g4096
g6677
sg4098
g6678
sg4109
g6687
sg4113
g6690
stRp12225
ag1
(g11214
g11182
(dp12226
g4096
g6693
sg4098
g6694
sg4109
g6703
sg4113
g6706
stRp12227
ag1
(g11214
g11182
(dp12228
g4096
g6709
sg4098
g6710
sg4109
g6719
sg4113
g6722
stRp12229
ag1
(g11214
g11182
(dp12230
g4096
g6725
sg4098
g6726
sg4109
g6735
sg4113
g6738
stRp12231
ag1
(g11214
g11182
(dp12232
g4096
g6741
sg4098
g6742
sg4109
g6751
sg4113
g6754
stRp12233
ag1
(g11214
g11182
(dp12234
g4096
g6757
sg4098
g6758
sg4109
g6767
sg4113
g6770
stRp12235
ag1
(g11214
g11182
(dp12236
g4096
g6773
sg4098
g6774
sg4109
g6783
sg4113
g6786
stRp12237
ag1
(g11214
g11182
(dp12238
g4096
g6789
sg4098
g6790
sg4109
g6799
sg4113
g6802
stRp12239
ag1
(g11214
g11182
(dp12240
g4096
g6805
sg4098
g6806
sg4109
g6815
sg4113
g6818
stRp12241
ag1
(g11214
g11182
(dp12242
g4096
g6821
sg4098
g6822
sg4109
g6831
sg4113
g6834
stRp12243
ag1
(g11214
g11182
(dp12244
g4096
g6837
sg4098
g6838
sg4109
g6847
sg4113
g6850
stRp12245
ag1
(g11214
g11182
(dp12246
g4096
g6853
sg4098
g6854
sg4109
g6863
sg4113
g6866
stRp12247
ag1
(g11214
g11182
(dp12248
g4096
g6869
sg4098
g6870
sg4109
g6879
sg4113
g6882
stRp12249
ag1
(g11214
g11182
(dp12250
g4096
g6885
sg4098
g6886
sg4109
g6895
sg4113
g6898
stRp12251
ag1
(g11214
g11182
(dp12252
g4096
g6901
sg4098
g6902
sg4109
g6911
sg4113
g6914
stRp12253
ag1
(g11214
g11182
(dp12254
g4096
g6917
sg4098
g6918
sg4109
g6927
sg4113
g6930
stRp12255
ag1
(g11214
g11182
(dp12256
g4096
g6933
sg4098
g6934
sg4109
g6943
sg4113
g6946
stRp12257
ag1
(g11214
g11182
(dp12258
g4096
g6949
sg4098
g6950
sg4109
g6959
sg4113
g6962
stRp12259
ag1
(g11214
g11182
(dp12260
g4096
g6965
sg4098
g6966
sg4109
g6975
sg4113
g6978
stRp12261
ag1
(g11214
g11182
(dp12262
g4096
g6981
sg4098
g6982
sg4109
g6991
sg4113
g6994
stRp12263
ag1
(g11214
g11182
(dp12264
g4096
g6997
sg4098
g6998
sg4109
g7007
sg4113
g7010
stRp12265
ag1
(g11214
g11182
(dp12266
g4096
g7013
sg4098
g7014
sg4109
g7023
sg4113
g7026
stRp12267
ag1
(g11214
g11182
(dp12268
g4096
g7029
sg4098
g7030
sg4109
g7039
sg4113
g7042
stRp12269
ag1
(g11214
g11182
(dp12270
g4096
g7045
sg4098
g7046
sg4109
g7055
sg4113
g7058
stRp12271
ag1
(g11214
g11182
(dp12272
g4096
g7061
sg4098
g7062
sg4109
g7071
sg4113
g7074
stRp12273
ag1
(g11214
g11182
(dp12274
g4096
g7077
sg4098
g7078
sg4109
g7087
sg4113
g7090
stRp12275
ag1
(g11214
g11182
(dp12276
g4096
g7093
sg4098
g7094
sg4109
g7103
sg4113
g7106
stRp12277
ag1
(g11214
g11182
(dp12278
g4096
g7109
sg4098
g7110
sg4109
g7119
sg4113
g7122
stRp12279
ag1
(g11214
g11182
(dp12280
g4096
g7125
sg4098
g7126
sg4109
g7135
sg4113
g7138
stRp12281
ag1
(g11214
g11182
(dp12282
g4096
g7141
sg4098
g7142
sg4109
g7151
sg4113
g7154
stRp12283
ag1
(g11214
g11182
(dp12284
g4096
g7157
sg4098
g7158
sg4109
g7167
sg4113
g7170
stRp12285
ag1
(g11214
g11182
(dp12286
g4096
g7173
sg4098
g7174
sg4109
g7183
sg4113
g7186
stRp12287
ag1
(g11214
g11182
(dp12288
g4096
g7189
sg4098
g7190
sg4109
g7199
sg4113
g7202
stRp12289
ag1
(g11214
g11182
(dp12290
g4096
g7205
sg4098
g7206
sg4109
g7215
sg4113
g7218
stRp12291
ag1
(g11214
g11182
(dp12292
g4096
g7221
sg4098
g7222
sg4109
g7231
sg4113
g7234
stRp12293
ag1
(g11214
g11182
(dp12294
g4096
g7237
sg4098
g7238
sg4109
g7247
sg4113
g7250
stRp12295
ag1
(g11214
g11182
(dp12296
g4096
g7253
sg4098
g7254
sg4109
g7263
sg4113
g7266
stRp12297
ag1
(g11214
g11182
(dp12298
g4096
g7269
sg4098
g7270
sg4109
g7279
sg4113
g7282
stRp12299
ag1
(g11214
g11182
(dp12300
g4096
g7285
sg4098
g7286
sg4109
g7295
sg4113
g7298
stRp12301
asg11295
Nsg11296
g7294
sg11297
I200
sg11298
I0
sg11299
I200
sg11300
I01
sbag1
(g11169
g3
NtRp12302
(dp12303
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p12304
sg11174
(lp12305
sg11176
I89576816
sg10
g11467
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp12306
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp12307
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg33
g11207
(g11187
(I0
tS'b'
tRp12308
(I1
(I200
I1
tg11308
I00
(lp12309
g7317
ag7335
ag7351
ag7367
ag7383
ag7399
ag7415
ag7431
ag7447
ag7463
ag7479
ag7495
ag7511
ag7527
ag7543
ag7559
ag7575
ag7591
ag7607
ag7623
ag7639
ag7655
ag7671
ag7687
ag7703
ag7719
ag7735
ag7751
ag7767
ag7783
ag7799
ag7815
ag7831
ag7847
ag7863
ag7879
ag7895
ag7911
ag7927
ag7943
ag7959
ag7975
ag7991
ag8007
ag8023
ag8039
ag8055
ag8071
ag8087
ag8103
ag8119
ag8135
ag8151
ag8167
ag8183
ag8199
ag8215
ag8231
ag8247
ag8263
ag8279
ag8295
ag8311
ag8327
ag8343
ag8359
ag8375
ag8391
ag8407
ag8423
ag8439
ag8455
ag8471
ag8487
ag8503
ag8519
ag8535
ag8551
ag8567
ag8583
ag8599
ag8615
ag8631
ag8647
ag8663
ag8679
ag8695
ag8711
ag8727
ag8743
ag8759
ag8775
ag8791
ag8807
ag8823
ag8839
ag8855
ag8871
ag8887
ag8903
ag8919
ag8935
ag8951
ag8967
ag8983
ag8999
ag9015
ag9031
ag9047
ag9063
ag9079
ag9095
ag9111
ag9127
ag9143
ag9159
ag9175
ag9191
ag9207
ag9223
ag9239
ag9255
ag9271
ag9287
ag9303
ag9319
ag9335
ag9351
ag9367
ag9383
ag9399
ag9415
ag9431
ag9447
ag9463
ag9479
ag9495
ag9511
ag9527
ag9543
ag9559
ag9575
ag9591
ag9607
ag9623
ag9639
ag9655
ag9671
ag9687
ag9703
ag9719
ag9735
ag9751
ag9767
ag9783
ag9799
ag9815
ag9831
ag9847
ag9863
ag9879
ag9895
ag9911
ag9927
ag9943
ag9959
ag9975
ag9991
ag10007
ag10023
ag10039
ag10055
ag10071
ag10087
ag10103
ag10119
ag10135
ag10151
ag10167
ag10183
ag10199
ag10215
ag10231
ag10247
ag10263
ag10279
ag10295
ag10311
ag10327
ag10343
ag10359
ag10375
ag10391
ag10407
ag10423
ag10439
ag10455
ag10471
ag10487
ag10503
atbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp12310
(I1
(I200
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB\x00\x00 B\x00\x00$B\x00\x00(B\x00\x00,B\x00\x000B\x00\x004B\x00\x008B\x00\x00<B\x00\x00@B\x00\x00DB\x00\x00HB\x00\x00LB\x00\x00PB\x00\x00TB\x00\x00XB\x00\x00\\B\x00\x00`B\x00\x00dB\x00\x00hB\x00\x00lB\x00\x00pB\x00\x00tB\x00\x00xB\x00\x00|B\x00\x00\x80B\x00\x00\x82B\x00\x00\x84B\x00\x00\x86B\x00\x00\x88B\x00\x00\x8aB\x00\x00\x8cB\x00\x00\x8eB\x00\x00\x90B\x00\x00\x92B\x00\x00\x94B\x00\x00\x96B\x00\x00\x98B\x00\x00\x9aB\x00\x00\x9cB\x00\x00\x9eB\x00\x00\xa0B\x00\x00\xa2B\x00\x00\xa4B\x00\x00\xa6B\x00\x00\xa8B\x00\x00\xaaB\x00\x00\xacB\x00\x00\xaeB\x00\x00\xb0B\x00\x00\xb2B\x00\x00\xb4B\x00\x00\xb6B\x00\x00\xb8B\x00\x00\xbaB\x00\x00\xbcB\x00\x00\xbeB\x00\x00\xc0B\x00\x00\xc2B\x00\x00\xc4B\x00\x00\xc6B\x00\x00\xc8B\x00\x00\xcaB\x00\x00\xccB\x00\x00\xceB\x00\x00\xd0B\x00\x00\xd2B\x00\x00\xd4B\x00\x00\xd6B\x00\x00\xd8B\x00\x00\xdaB\x00\x00\xdcB\x00\x00\xdeB\x00\x00\xe0B\x00\x00\xe2B\x00\x00\xe4B\x00\x00\xe6B\x00\x00\xe8B\x00\x00\xeaB\x00\x00\xecB\x00\x00\xeeB\x00\x00\xf0B\x00\x00\xf2B\x00\x00\xf4B\x00\x00\xf6B\x00\x00\xf8B\x00\x00\xfaB\x00\x00\xfcB\x00\x00\xfeB\x00\x00\x00C\x00\x00\x01C\x00\x00\x02C\x00\x00\x03C\x00\x00\x04C\x00\x00\x05C\x00\x00\x06C\x00\x00\x07C\x00\x00\x08C\x00\x00\tC\x00\x00\nC\x00\x00\x0bC\x00\x00\x0cC\x00\x00\rC\x00\x00\x0eC\x00\x00\x0fC\x00\x00\x10C\x00\x00\x11C\x00\x00\x12C\x00\x00\x13C\x00\x00\x14C\x00\x00\x15C\x00\x00\x16C\x00\x00\x17C\x00\x00\x18C\x00\x00\x19C\x00\x00\x1aC\x00\x00\x1bC\x00\x00\x1cC\x00\x00\x1dC\x00\x00\x1eC\x00\x00\x1fC\x00\x00 C\x00\x00!C\x00\x00"C\x00\x00#C\x00\x00$C\x00\x00%C\x00\x00&C\x00\x00\'C\x00\x00(C\x00\x00)C\x00\x00*C\x00\x00+C\x00\x00,C\x00\x00-C\x00\x00.C\x00\x00/C\x00\x000C\x00\x001C\x00\x002C\x00\x003C\x00\x004C\x00\x005C\x00\x006C\x00\x007C\x00\x008C\x00\x009C\x00\x00:C\x00\x00;C\x00\x00<C\x00\x00=C\x00\x00>C\x00\x00?C\x00\x00@C\x00\x00AC\x00\x00BC\x00\x00CC\x00\x00DC\x00\x00EC\x00\x00FC\x00\x00GC'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg34
g11185
(g11186
g11187
g11188
S'b'
tRp12311
(I1
(I200
I1
tg11190
I00
S'\x84\x04P?A7I?+%8?\x91\x0c\x16?\x10W|?\x8e\r\x16?\x92\xb4n?\x17\x1c\'?\xf8\x0c\x16?8\xe0\x1c?OH ?\xd5\xf7>?\xf9\x85u?Y\xad\xa3?7w\x19?\x95\xd2\x0b?\xa8w\x19?\x189\x0f?)\x0e\x16?\x9f\xbb\xee>\xd6`B?!\x11a?\x88\x9bL?B\x85u?\xd9\xec\x90?\xa1\r\x16?\xe2\xde\x1c?~\xd2\x0b?\x1f\xa5\x12?\xbf\xc1\x97?\x94\xd6V?t\xa3\x12?\xfd;\x0f?9\xd3\x0b?)w\x19?\x8e\x8d\xf5>\xba`B?\x19\x1dr?\x12w\x19?\xe0\xfd>?\xb9r\x99?\xaci\x08?\xe3_\xfc>\n\xd3\x0b?\x86\x8c;?S\x8e\xf5>\x19D ?X\x98\x01?\x1dT1?&\x1a\'?P\x9bL?4\x1a\'?t?Z?\xb3\xa4\x12?1\xd6V?\x9c\xbd4?Bj\x08?\xd5\xf7>?\x84%8?\xc0u*?\xc7\x16\'?\xa3\xc9E?\xd8;\x0f?\xe2\r\x16?}\xc9E?\xb4\xb9\xb4?laB?\nI ?\xa8H ?[\xfd\x84?|1I?\xe1S ?\x0bk\x08?cT1?9T1?\xbe\x00\x05?5G ?\xd4\r\x16?\x07\x05P?\xd72I?\x80\xde\x1c?\x87\x98\x01?\x03_\xfc>\x9a\x82*?\xa5\xd3\x0b?\xa7`B?\xdf\xbb4?\xfb\xb0#?\'\x83*?h\xb1\x86?\xf0T1?/\x1a\'?"s\x99?/\xeb-?\xe52I?\xc5\xeb-?_\xbd4?*\xb1#?\xc9\xd2\x0b?\xa6mS?L\xd3\x0b?\xd0v\x19?\x92\xa4\x12?\xa2\xa7]?s\x86u?\x1d\x8d\xf5>Z\xa4\x12?\xc1\x04P?\xfaG ?3\x01\x05?(\xdf\x1c?g\xb1#?\xa6\x80d?\xf7\xc9E?\x0e\x9bL?\xfe\xa9]?H\x1dr?\xd9\x04P?\x81\xdf\x1c?\x94\x81*?Hv\x19?\x16\xb5n?>\x83*?x\xdc\x0b?8\xcfE?\xed\x81*?\\\xd4\x0b?]2I?6\xa5\x12?\x8amS?\x90\x98\x01?9\xcf\x8b?V\x12a?\xcaKk?\x16r\xfc>\xd1_\xfc>\\\x03\x05?\x1d\x99\x01?aH ?/\xb1#?\x1cz\x19?o\x0e\x16?\x97\xd3\x0b?\xfbv\x19?\x96\xcfE?]\x01\x05?;\xd2\x1c?\x04\xed-?\x8b\xc9E?\x0c\xa5\x12?\r\x0e\x16?v\x04P?]\xa8]?\xf8u*?%\xb1#?cT1?\t\xa8]?\xc9\xcd\x0b?wv\x19?Z\xd3\x0b?\xec\xa9L?\xb1\x82*?\xd22I?%aB?J]\xfc>\xc9\x82*?\x99X1?L\xd5\x9c?\xa1\xfd\x84?\xaf\x8e;?\xceV1?\xc2\x1a\x8a?\xd4\xbd4?\xd9\\\xfc>\xca\xba4?\xacH ?\xfa\x8e;?(v\x19?\x04H ?\xa3\xc9E?\xe9i\x08?\x89s\x19?\x94\xdf\x1c?\x13\xe0\x1c?\xfe\x85u?\xe3\xa7]?L\x83*?\xe4\x19\'?\xe1\xe2g?P\xeb-?\xc8H ?\x9c\xd3\x0b?\xfci\x08?\x02\xa5\x12?&\x90;?S\x8e\xf5>\xf7S1?\x04H ?\xb8\xde\x1c?\x11\x84*?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg30
g11207
(g11187
(I0
tS'b'
tRp12312
(I1
(I200
I1
tg11308
I00
(lp12313
g7309
ag7339
ag7355
ag7361
ag7377
ag7403
ag7409
ag7425
ag7451
ag7457
ag7473
ag7489
ag7505
ag7521
ag7537
ag7563
ag7569
ag7585
ag7601
ag7617
ag7633
ag7649
ag7665
ag7681
ag7707
ag7723
ag7729
ag7745
ag7761
ag7787
ag7793
ag7819
ag7825
ag7841
ag7857
ag7873
ag7889
ag7915
ag7921
ag7937
ag7963
ag7969
ag7985
ag8001
ag8017
ag8033
ag8049
ag8065
ag8081
ag8097
ag8113
ag8129
ag8155
ag8161
ag8177
ag8193
ag8209
ag8225
ag8241
ag8257
ag8273
ag8289
ag8315
ag8321
ag8337
ag8353
ag8379
ag8385
ag8401
ag8417
ag8433
ag8449
ag8465
ag8481
ag8497
ag8513
ag8529
ag8545
ag8561
ag8577
ag8593
ag8609
ag8625
ag8651
ag8657
ag8683
ag8689
ag8705
ag8721
ag8747
ag8753
ag8769
ag8785
ag8801
ag8817
ag8833
ag8849
ag8865
ag8881
ag8897
ag8913
ag8929
ag8955
ag8971
ag8977
ag8993
ag9009
ag9035
ag9051
ag9057
ag9073
ag9089
ag9115
ag9121
ag9137
ag9163
ag9169
ag9185
ag9201
ag9217
ag9233
ag9249
ag9265
ag9281
ag9297
ag9313
ag9329
ag9345
ag9361
ag9377
ag9393
ag9409
ag9425
ag9441
ag9457
ag9473
ag9489
ag9505
ag9521
ag9547
ag9553
ag9569
ag9585
ag9601
ag9627
ag9633
ag9649
ag9665
ag9681
ag9697
ag9713
ag9729
ag9755
ag9761
ag9777
ag9793
ag9809
ag9835
ag9841
ag9867
ag9873
ag9889
ag9905
ag9931
ag9937
ag9953
ag9969
ag9985
ag10001
ag10027
ag10033
ag10049
ag10075
ag10091
ag10097
ag10113
ag10129
ag10145
ag10161
ag10177
ag10193
ag10209
ag10225
ag10241
ag10257
ag10273
ag10289
ag10305
ag10321
ag10337
ag10353
ag10369
ag10395
ag10411
ag10427
ag10433
ag10459
ag10465
ag10491
ag10507
atbstRp12314
(dp12315
g11197
(dp12316
g11184
I01
sg33
I00
sg11193
I01
sg34
I01
sg30
I00
ssg11199
g12302
sg11200
(lp12317
g11184
ag11193
ag33
ag34
ag30
asg11202
(lp12318
I200
aI1
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp12319
(I1
(I200
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00(\x00\x00\x00)\x00\x00\x00*\x00\x00\x00+\x00\x00\x00,\x00\x00\x00-\x00\x00\x00.\x00\x00\x00/\x00\x00\x000\x00\x00\x001\x00\x00\x002\x00\x00\x003\x00\x00\x004\x00\x00\x005\x00\x00\x006\x00\x00\x007\x00\x00\x008\x00\x00\x009\x00\x00\x00:\x00\x00\x00;\x00\x00\x00<\x00\x00\x00=\x00\x00\x00>\x00\x00\x00?\x00\x00\x00@\x00\x00\x00A\x00\x00\x00B\x00\x00\x00C\x00\x00\x00D\x00\x00\x00E\x00\x00\x00F\x00\x00\x00G\x00\x00\x00H\x00\x00\x00I\x00\x00\x00J\x00\x00\x00K\x00\x00\x00L\x00\x00\x00M\x00\x00\x00N\x00\x00\x00O\x00\x00\x00P\x00\x00\x00Q\x00\x00\x00R\x00\x00\x00S\x00\x00\x00T\x00\x00\x00U\x00\x00\x00V\x00\x00\x00W\x00\x00\x00X\x00\x00\x00Y\x00\x00\x00Z\x00\x00\x00[\x00\x00\x00\\\x00\x00\x00]\x00\x00\x00^\x00\x00\x00_\x00\x00\x00`\x00\x00\x00a\x00\x00\x00b\x00\x00\x00c\x00\x00\x00d\x00\x00\x00e\x00\x00\x00f\x00\x00\x00g\x00\x00\x00h\x00\x00\x00i\x00\x00\x00j\x00\x00\x00k\x00\x00\x00l\x00\x00\x00m\x00\x00\x00n\x00\x00\x00o\x00\x00\x00p\x00\x00\x00q\x00\x00\x00r\x00\x00\x00s\x00\x00\x00t\x00\x00\x00u\x00\x00\x00v\x00\x00\x00w\x00\x00\x00x\x00\x00\x00y\x00\x00\x00z\x00\x00\x00{\x00\x00\x00|\x00\x00\x00}\x00\x00\x00~\x00\x00\x00\x7f\x00\x00\x00\x80\x00\x00\x00\x81\x00\x00\x00\x82\x00\x00\x00\x83\x00\x00\x00\x84\x00\x00\x00\x85\x00\x00\x00\x86\x00\x00\x00\x87\x00\x00\x00\x88\x00\x00\x00\x89\x00\x00\x00\x8a\x00\x00\x00\x8b\x00\x00\x00\x8c\x00\x00\x00\x8d\x00\x00\x00\x8e\x00\x00\x00\x8f\x00\x00\x00\x90\x00\x00\x00\x91\x00\x00\x00\x92\x00\x00\x00\x93\x00\x00\x00\x94\x00\x00\x00\x95\x00\x00\x00\x96\x00\x00\x00\x97\x00\x00\x00\x98\x00\x00\x00\x99\x00\x00\x00\x9a\x00\x00\x00\x9b\x00\x00\x00\x9c\x00\x00\x00\x9d\x00\x00\x00\x9e\x00\x00\x00\x9f\x00\x00\x00\xa0\x00\x00\x00\xa1\x00\x00\x00\xa2\x00\x00\x00\xa3\x00\x00\x00\xa4\x00\x00\x00\xa5\x00\x00\x00\xa6\x00\x00\x00\xa7\x00\x00\x00\xa8\x00\x00\x00\xa9\x00\x00\x00\xaa\x00\x00\x00\xab\x00\x00\x00\xac\x00\x00\x00\xad\x00\x00\x00\xae\x00\x00\x00\xaf\x00\x00\x00\xb0\x00\x00\x00\xb1\x00\x00\x00\xb2\x00\x00\x00\xb3\x00\x00\x00\xb4\x00\x00\x00\xb5\x00\x00\x00\xb6\x00\x00\x00\xb7\x00\x00\x00\xb8\x00\x00\x00\xb9\x00\x00\x00\xba\x00\x00\x00\xbb\x00\x00\x00\xbc\x00\x00\x00\xbd\x00\x00\x00\xbe\x00\x00\x00\xbf\x00\x00\x00\xc0\x00\x00\x00\xc1\x00\x00\x00\xc2\x00\x00\x00\xc3\x00\x00\x00\xc4\x00\x00\x00\xc5\x00\x00\x00\xc6\x00\x00\x00\xc7\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp12320
g1
(g11214
g11182
(dp12321
g7308
g7309
sg7310
g7311
sg7321
g7322
sg7325
g7326
stRp12322
ag1
(g11214
g11182
(dp12323
g7308
g7329
sg7310
g7330
sg7321
g7339
sg7325
g7342
stRp12324
ag1
(g11214
g11182
(dp12325
g7308
g7345
sg7310
g7346
sg7321
g7355
sg7325
g7358
stRp12326
ag1
(g11214
g11182
(dp12327
g7308
g7361
sg7310
g7362
sg7321
g7371
sg7325
g7374
stRp12328
ag1
(g11214
g11182
(dp12329
g7308
g7377
sg7310
g7378
sg7321
g7387
sg7325
g7390
stRp12330
ag1
(g11214
g11182
(dp12331
g7308
g7393
sg7310
g7394
sg7321
g7403
sg7325
g7406
stRp12332
ag1
(g11214
g11182
(dp12333
g7308
g7409
sg7310
g7410
sg7321
g7419
sg7325
g7422
stRp12334
ag1
(g11214
g11182
(dp12335
g7308
g7425
sg7310
g7426
sg7321
g7435
sg7325
g7438
stRp12336
ag1
(g11214
g11182
(dp12337
g7308
g7441
sg7310
g7442
sg7321
g7451
sg7325
g7454
stRp12338
ag1
(g11214
g11182
(dp12339
g7308
g7457
sg7310
g7458
sg7321
g7467
sg7325
g7470
stRp12340
ag1
(g11214
g11182
(dp12341
g7308
g7473
sg7310
g7474
sg7321
g7483
sg7325
g7486
stRp12342
ag1
(g11214
g11182
(dp12343
g7308
g7489
sg7310
g7490
sg7321
g7499
sg7325
g7502
stRp12344
ag1
(g11214
g11182
(dp12345
g7308
g7505
sg7310
g7506
sg7321
g7515
sg7325
g7518
stRp12346
ag1
(g11214
g11182
(dp12347
g7308
g7521
sg7310
g7522
sg7321
g7531
sg7325
g7534
stRp12348
ag1
(g11214
g11182
(dp12349
g7308
g7537
sg7310
g7538
sg7321
g7547
sg7325
g7550
stRp12350
ag1
(g11214
g11182
(dp12351
g7308
g7553
sg7310
g7554
sg7321
g7563
sg7325
g7566
stRp12352
ag1
(g11214
g11182
(dp12353
g7308
g7569
sg7310
g7570
sg7321
g7579
sg7325
g7582
stRp12354
ag1
(g11214
g11182
(dp12355
g7308
g7585
sg7310
g7586
sg7321
g7595
sg7325
g7598
stRp12356
ag1
(g11214
g11182
(dp12357
g7308
g7601
sg7310
g7602
sg7321
g7611
sg7325
g7614
stRp12358
ag1
(g11214
g11182
(dp12359
g7308
g7617
sg7310
g7618
sg7321
g7627
sg7325
g7630
stRp12360
ag1
(g11214
g11182
(dp12361
g7308
g7633
sg7310
g7634
sg7321
g7643
sg7325
g7646
stRp12362
ag1
(g11214
g11182
(dp12363
g7308
g7649
sg7310
g7650
sg7321
g7659
sg7325
g7662
stRp12364
ag1
(g11214
g11182
(dp12365
g7308
g7665
sg7310
g7666
sg7321
g7675
sg7325
g7678
stRp12366
ag1
(g11214
g11182
(dp12367
g7308
g7681
sg7310
g7682
sg7321
g7691
sg7325
g7694
stRp12368
ag1
(g11214
g11182
(dp12369
g7308
g7697
sg7310
g7698
sg7321
g7707
sg7325
g7710
stRp12370
ag1
(g11214
g11182
(dp12371
g7308
g7713
sg7310
g7714
sg7321
g7723
sg7325
g7726
stRp12372
ag1
(g11214
g11182
(dp12373
g7308
g7729
sg7310
g7730
sg7321
g7739
sg7325
g7742
stRp12374
ag1
(g11214
g11182
(dp12375
g7308
g7745
sg7310
g7746
sg7321
g7755
sg7325
g7758
stRp12376
ag1
(g11214
g11182
(dp12377
g7308
g7761
sg7310
g7762
sg7321
g7771
sg7325
g7774
stRp12378
ag1
(g11214
g11182
(dp12379
g7308
g7777
sg7310
g7778
sg7321
g7787
sg7325
g7790
stRp12380
ag1
(g11214
g11182
(dp12381
g7308
g7793
sg7310
g7794
sg7321
g7803
sg7325
g7806
stRp12382
ag1
(g11214
g11182
(dp12383
g7308
g7809
sg7310
g7810
sg7321
g7819
sg7325
g7822
stRp12384
ag1
(g11214
g11182
(dp12385
g7308
g7825
sg7310
g7826
sg7321
g7835
sg7325
g7838
stRp12386
ag1
(g11214
g11182
(dp12387
g7308
g7841
sg7310
g7842
sg7321
g7851
sg7325
g7854
stRp12388
ag1
(g11214
g11182
(dp12389
g7308
g7857
sg7310
g7858
sg7321
g7867
sg7325
g7870
stRp12390
ag1
(g11214
g11182
(dp12391
g7308
g7873
sg7310
g7874
sg7321
g7883
sg7325
g7886
stRp12392
ag1
(g11214
g11182
(dp12393
g7308
g7889
sg7310
g7890
sg7321
g7899
sg7325
g7902
stRp12394
ag1
(g11214
g11182
(dp12395
g7308
g7905
sg7310
g7906
sg7321
g7915
sg7325
g7918
stRp12396
ag1
(g11214
g11182
(dp12397
g7308
g7921
sg7310
g7922
sg7321
g7931
sg7325
g7934
stRp12398
ag1
(g11214
g11182
(dp12399
g7308
g7937
sg7310
g7938
sg7321
g7947
sg7325
g7950
stRp12400
ag1
(g11214
g11182
(dp12401
g7308
g7953
sg7310
g7954
sg7321
g7963
sg7325
g7966
stRp12402
ag1
(g11214
g11182
(dp12403
g7308
g7969
sg7310
g7970
sg7321
g7979
sg7325
g7982
stRp12404
ag1
(g11214
g11182
(dp12405
g7308
g7985
sg7310
g7986
sg7321
g7995
sg7325
g7998
stRp12406
ag1
(g11214
g11182
(dp12407
g7308
g8001
sg7310
g8002
sg7321
g8011
sg7325
g8014
stRp12408
ag1
(g11214
g11182
(dp12409
g7308
g8017
sg7310
g8018
sg7321
g8027
sg7325
g8030
stRp12410
ag1
(g11214
g11182
(dp12411
g7308
g8033
sg7310
g8034
sg7321
g8043
sg7325
g8046
stRp12412
ag1
(g11214
g11182
(dp12413
g7308
g8049
sg7310
g8050
sg7321
g8059
sg7325
g8062
stRp12414
ag1
(g11214
g11182
(dp12415
g7308
g8065
sg7310
g8066
sg7321
g8075
sg7325
g8078
stRp12416
ag1
(g11214
g11182
(dp12417
g7308
g8081
sg7310
g8082
sg7321
g8091
sg7325
g8094
stRp12418
ag1
(g11214
g11182
(dp12419
g7308
g8097
sg7310
g8098
sg7321
g8107
sg7325
g8110
stRp12420
ag1
(g11214
g11182
(dp12421
g7308
g8113
sg7310
g8114
sg7321
g8123
sg7325
g8126
stRp12422
ag1
(g11214
g11182
(dp12423
g7308
g8129
sg7310
g8130
sg7321
g8139
sg7325
g8142
stRp12424
ag1
(g11214
g11182
(dp12425
g7308
g8145
sg7310
g8146
sg7321
g8155
sg7325
g8158
stRp12426
ag1
(g11214
g11182
(dp12427
g7308
g8161
sg7310
g8162
sg7321
g8171
sg7325
g8174
stRp12428
ag1
(g11214
g11182
(dp12429
g7308
g8177
sg7310
g8178
sg7321
g8187
sg7325
g8190
stRp12430
ag1
(g11214
g11182
(dp12431
g7308
g8193
sg7310
g8194
sg7321
g8203
sg7325
g8206
stRp12432
ag1
(g11214
g11182
(dp12433
g7308
g8209
sg7310
g8210
sg7321
g8219
sg7325
g8222
stRp12434
ag1
(g11214
g11182
(dp12435
g7308
g8225
sg7310
g8226
sg7321
g8235
sg7325
g8238
stRp12436
ag1
(g11214
g11182
(dp12437
g7308
g8241
sg7310
g8242
sg7321
g8251
sg7325
g8254
stRp12438
ag1
(g11214
g11182
(dp12439
g7308
g8257
sg7310
g8258
sg7321
g8267
sg7325
g8270
stRp12440
ag1
(g11214
g11182
(dp12441
g7308
g8273
sg7310
g8274
sg7321
g8283
sg7325
g8286
stRp12442
ag1
(g11214
g11182
(dp12443
g7308
g8289
sg7310
g8290
sg7321
g8299
sg7325
g8302
stRp12444
ag1
(g11214
g11182
(dp12445
g7308
g8305
sg7310
g8306
sg7321
g8315
sg7325
g8318
stRp12446
ag1
(g11214
g11182
(dp12447
g7308
g8321
sg7310
g8322
sg7321
g8331
sg7325
g8334
stRp12448
ag1
(g11214
g11182
(dp12449
g7308
g8337
sg7310
g8338
sg7321
g8347
sg7325
g8350
stRp12450
ag1
(g11214
g11182
(dp12451
g7308
g8353
sg7310
g8354
sg7321
g8363
sg7325
g8366
stRp12452
ag1
(g11214
g11182
(dp12453
g7308
g8369
sg7310
g8370
sg7321
g8379
sg7325
g8382
stRp12454
ag1
(g11214
g11182
(dp12455
g7308
g8385
sg7310
g8386
sg7321
g8395
sg7325
g8398
stRp12456
ag1
(g11214
g11182
(dp12457
g7308
g8401
sg7310
g8402
sg7321
g8411
sg7325
g8414
stRp12458
ag1
(g11214
g11182
(dp12459
g7308
g8417
sg7310
g8418
sg7321
g8427
sg7325
g8430
stRp12460
ag1
(g11214
g11182
(dp12461
g7308
g8433
sg7310
g8434
sg7321
g8443
sg7325
g8446
stRp12462
ag1
(g11214
g11182
(dp12463
g7308
g8449
sg7310
g8450
sg7321
g8459
sg7325
g8462
stRp12464
ag1
(g11214
g11182
(dp12465
g7308
g8465
sg7310
g8466
sg7321
g8475
sg7325
g8478
stRp12466
ag1
(g11214
g11182
(dp12467
g7308
g8481
sg7310
g8482
sg7321
g8491
sg7325
g8494
stRp12468
ag1
(g11214
g11182
(dp12469
g7308
g8497
sg7310
g8498
sg7321
g8507
sg7325
g8510
stRp12470
ag1
(g11214
g11182
(dp12471
g7308
g8513
sg7310
g8514
sg7321
g8523
sg7325
g8526
stRp12472
ag1
(g11214
g11182
(dp12473
g7308
g8529
sg7310
g8530
sg7321
g8539
sg7325
g8542
stRp12474
ag1
(g11214
g11182
(dp12475
g7308
g8545
sg7310
g8546
sg7321
g8555
sg7325
g8558
stRp12476
ag1
(g11214
g11182
(dp12477
g7308
g8561
sg7310
g8562
sg7321
g8571
sg7325
g8574
stRp12478
ag1
(g11214
g11182
(dp12479
g7308
g8577
sg7310
g8578
sg7321
g8587
sg7325
g8590
stRp12480
ag1
(g11214
g11182
(dp12481
g7308
g8593
sg7310
g8594
sg7321
g8603
sg7325
g8606
stRp12482
ag1
(g11214
g11182
(dp12483
g7308
g8609
sg7310
g8610
sg7321
g8619
sg7325
g8622
stRp12484
ag1
(g11214
g11182
(dp12485
g7308
g8625
sg7310
g8626
sg7321
g8635
sg7325
g8638
stRp12486
ag1
(g11214
g11182
(dp12487
g7308
g8641
sg7310
g8642
sg7321
g8651
sg7325
g8654
stRp12488
ag1
(g11214
g11182
(dp12489
g7308
g8657
sg7310
g8658
sg7321
g8667
sg7325
g8670
stRp12490
ag1
(g11214
g11182
(dp12491
g7308
g8673
sg7310
g8674
sg7321
g8683
sg7325
g8686
stRp12492
ag1
(g11214
g11182
(dp12493
g7308
g8689
sg7310
g8690
sg7321
g8699
sg7325
g8702
stRp12494
ag1
(g11214
g11182
(dp12495
g7308
g8705
sg7310
g8706
sg7321
g8715
sg7325
g8718
stRp12496
ag1
(g11214
g11182
(dp12497
g7308
g8721
sg7310
g8722
sg7321
g8731
sg7325
g8734
stRp12498
ag1
(g11214
g11182
(dp12499
g7308
g8737
sg7310
g8738
sg7321
g8747
sg7325
g8750
stRp12500
ag1
(g11214
g11182
(dp12501
g7308
g8753
sg7310
g8754
sg7321
g8763
sg7325
g8766
stRp12502
ag1
(g11214
g11182
(dp12503
g7308
g8769
sg7310
g8770
sg7321
g8779
sg7325
g8782
stRp12504
ag1
(g11214
g11182
(dp12505
g7308
g8785
sg7310
g8786
sg7321
g8795
sg7325
g8798
stRp12506
ag1
(g11214
g11182
(dp12507
g7308
g8801
sg7310
g8802
sg7321
g8811
sg7325
g8814
stRp12508
ag1
(g11214
g11182
(dp12509
g7308
g8817
sg7310
g8818
sg7321
g8827
sg7325
g8830
stRp12510
ag1
(g11214
g11182
(dp12511
g7308
g8833
sg7310
g8834
sg7321
g8843
sg7325
g8846
stRp12512
ag1
(g11214
g11182
(dp12513
g7308
g8849
sg7310
g8850
sg7321
g8859
sg7325
g8862
stRp12514
ag1
(g11214
g11182
(dp12515
g7308
g8865
sg7310
g8866
sg7321
g8875
sg7325
g8878
stRp12516
ag1
(g11214
g11182
(dp12517
g7308
g8881
sg7310
g8882
sg7321
g8891
sg7325
g8894
stRp12518
ag1
(g11214
g11182
(dp12519
g7308
g8897
sg7310
g8898
sg7321
g8907
sg7325
g8910
stRp12520
ag1
(g11214
g11182
(dp12521
g7308
g8913
sg7310
g8914
sg7321
g8923
sg7325
g8926
stRp12522
ag1
(g11214
g11182
(dp12523
g7308
g8929
sg7310
g8930
sg7321
g8939
sg7325
g8942
stRp12524
ag1
(g11214
g11182
(dp12525
g7308
g8945
sg7310
g8946
sg7321
g8955
sg7325
g8958
stRp12526
ag1
(g11214
g11182
(dp12527
g7308
g8961
sg7310
g8962
sg7321
g8971
sg7325
g8974
stRp12528
ag1
(g11214
g11182
(dp12529
g7308
g8977
sg7310
g8978
sg7321
g8987
sg7325
g8990
stRp12530
ag1
(g11214
g11182
(dp12531
g7308
g8993
sg7310
g8994
sg7321
g9003
sg7325
g9006
stRp12532
ag1
(g11214
g11182
(dp12533
g7308
g9009
sg7310
g9010
sg7321
g9019
sg7325
g9022
stRp12534
ag1
(g11214
g11182
(dp12535
g7308
g9025
sg7310
g9026
sg7321
g9035
sg7325
g9038
stRp12536
ag1
(g11214
g11182
(dp12537
g7308
g9041
sg7310
g9042
sg7321
g9051
sg7325
g9054
stRp12538
ag1
(g11214
g11182
(dp12539
g7308
g9057
sg7310
g9058
sg7321
g9067
sg7325
g9070
stRp12540
ag1
(g11214
g11182
(dp12541
g7308
g9073
sg7310
g9074
sg7321
g9083
sg7325
g9086
stRp12542
ag1
(g11214
g11182
(dp12543
g7308
g9089
sg7310
g9090
sg7321
g9099
sg7325
g9102
stRp12544
ag1
(g11214
g11182
(dp12545
g7308
g9105
sg7310
g9106
sg7321
g9115
sg7325
g9118
stRp12546
ag1
(g11214
g11182
(dp12547
g7308
g9121
sg7310
g9122
sg7321
g9131
sg7325
g9134
stRp12548
ag1
(g11214
g11182
(dp12549
g7308
g9137
sg7310
g9138
sg7321
g9147
sg7325
g9150
stRp12550
ag1
(g11214
g11182
(dp12551
g7308
g9153
sg7310
g9154
sg7321
g9163
sg7325
g9166
stRp12552
ag1
(g11214
g11182
(dp12553
g7308
g9169
sg7310
g9170
sg7321
g9179
sg7325
g9182
stRp12554
ag1
(g11214
g11182
(dp12555
g7308
g9185
sg7310
g9186
sg7321
g9195
sg7325
g9198
stRp12556
ag1
(g11214
g11182
(dp12557
g7308
g9201
sg7310
g9202
sg7321
g9211
sg7325
g9214
stRp12558
ag1
(g11214
g11182
(dp12559
g7308
g9217
sg7310
g9218
sg7321
g9227
sg7325
g9230
stRp12560
ag1
(g11214
g11182
(dp12561
g7308
g9233
sg7310
g9234
sg7321
g9243
sg7325
g9246
stRp12562
ag1
(g11214
g11182
(dp12563
g7308
g9249
sg7310
g9250
sg7321
g9259
sg7325
g9262
stRp12564
ag1
(g11214
g11182
(dp12565
g7308
g9265
sg7310
g9266
sg7321
g9275
sg7325
g9278
stRp12566
ag1
(g11214
g11182
(dp12567
g7308
g9281
sg7310
g9282
sg7321
g9291
sg7325
g9294
stRp12568
ag1
(g11214
g11182
(dp12569
g7308
g9297
sg7310
g9298
sg7321
g9307
sg7325
g9310
stRp12570
ag1
(g11214
g11182
(dp12571
g7308
g9313
sg7310
g9314
sg7321
g9323
sg7325
g9326
stRp12572
ag1
(g11214
g11182
(dp12573
g7308
g9329
sg7310
g9330
sg7321
g9339
sg7325
g9342
stRp12574
ag1
(g11214
g11182
(dp12575
g7308
g9345
sg7310
g9346
sg7321
g9355
sg7325
g9358
stRp12576
ag1
(g11214
g11182
(dp12577
g7308
g9361
sg7310
g9362
sg7321
g9371
sg7325
g9374
stRp12578
ag1
(g11214
g11182
(dp12579
g7308
g9377
sg7310
g9378
sg7321
g9387
sg7325
g9390
stRp12580
ag1
(g11214
g11182
(dp12581
g7308
g9393
sg7310
g9394
sg7321
g9403
sg7325
g9406
stRp12582
ag1
(g11214
g11182
(dp12583
g7308
g9409
sg7310
g9410
sg7321
g9419
sg7325
g9422
stRp12584
ag1
(g11214
g11182
(dp12585
g7308
g9425
sg7310
g9426
sg7321
g9435
sg7325
g9438
stRp12586
ag1
(g11214
g11182
(dp12587
g7308
g9441
sg7310
g9442
sg7321
g9451
sg7325
g9454
stRp12588
ag1
(g11214
g11182
(dp12589
g7308
g9457
sg7310
g9458
sg7321
g9467
sg7325
g9470
stRp12590
ag1
(g11214
g11182
(dp12591
g7308
g9473
sg7310
g9474
sg7321
g9483
sg7325
g9486
stRp12592
ag1
(g11214
g11182
(dp12593
g7308
g9489
sg7310
g9490
sg7321
g9499
sg7325
g9502
stRp12594
ag1
(g11214
g11182
(dp12595
g7308
g9505
sg7310
g9506
sg7321
g9515
sg7325
g9518
stRp12596
ag1
(g11214
g11182
(dp12597
g7308
g9521
sg7310
g9522
sg7321
g9531
sg7325
g9534
stRp12598
ag1
(g11214
g11182
(dp12599
g7308
g9537
sg7310
g9538
sg7321
g9547
sg7325
g9550
stRp12600
ag1
(g11214
g11182
(dp12601
g7308
g9553
sg7310
g9554
sg7321
g9563
sg7325
g9566
stRp12602
ag1
(g11214
g11182
(dp12603
g7308
g9569
sg7310
g9570
sg7321
g9579
sg7325
g9582
stRp12604
ag1
(g11214
g11182
(dp12605
g7308
g9585
sg7310
g9586
sg7321
g9595
sg7325
g9598
stRp12606
ag1
(g11214
g11182
(dp12607
g7308
g9601
sg7310
g9602
sg7321
g9611
sg7325
g9614
stRp12608
ag1
(g11214
g11182
(dp12609
g7308
g9617
sg7310
g9618
sg7321
g9627
sg7325
g9630
stRp12610
ag1
(g11214
g11182
(dp12611
g7308
g9633
sg7310
g9634
sg7321
g9643
sg7325
g9646
stRp12612
ag1
(g11214
g11182
(dp12613
g7308
g9649
sg7310
g9650
sg7321
g9659
sg7325
g9662
stRp12614
ag1
(g11214
g11182
(dp12615
g7308
g9665
sg7310
g9666
sg7321
g9675
sg7325
g9678
stRp12616
ag1
(g11214
g11182
(dp12617
g7308
g9681
sg7310
g9682
sg7321
g9691
sg7325
g9694
stRp12618
ag1
(g11214
g11182
(dp12619
g7308
g9697
sg7310
g9698
sg7321
g9707
sg7325
g9710
stRp12620
ag1
(g11214
g11182
(dp12621
g7308
g9713
sg7310
g9714
sg7321
g9723
sg7325
g9726
stRp12622
ag1
(g11214
g11182
(dp12623
g7308
g9729
sg7310
g9730
sg7321
g9739
sg7325
g9742
stRp12624
ag1
(g11214
g11182
(dp12625
g7308
g9745
sg7310
g9746
sg7321
g9755
sg7325
g9758
stRp12626
ag1
(g11214
g11182
(dp12627
g7308
g9761
sg7310
g9762
sg7321
g9771
sg7325
g9774
stRp12628
ag1
(g11214
g11182
(dp12629
g7308
g9777
sg7310
g9778
sg7321
g9787
sg7325
g9790
stRp12630
ag1
(g11214
g11182
(dp12631
g7308
g9793
sg7310
g9794
sg7321
g9803
sg7325
g9806
stRp12632
ag1
(g11214
g11182
(dp12633
g7308
g9809
sg7310
g9810
sg7321
g9819
sg7325
g9822
stRp12634
ag1
(g11214
g11182
(dp12635
g7308
g9825
sg7310
g9826
sg7321
g9835
sg7325
g9838
stRp12636
ag1
(g11214
g11182
(dp12637
g7308
g9841
sg7310
g9842
sg7321
g9851
sg7325
g9854
stRp12638
ag1
(g11214
g11182
(dp12639
g7308
g9857
sg7310
g9858
sg7321
g9867
sg7325
g9870
stRp12640
ag1
(g11214
g11182
(dp12641
g7308
g9873
sg7310
g9874
sg7321
g9883
sg7325
g9886
stRp12642
ag1
(g11214
g11182
(dp12643
g7308
g9889
sg7310
g9890
sg7321
g9899
sg7325
g9902
stRp12644
ag1
(g11214
g11182
(dp12645
g7308
g9905
sg7310
g9906
sg7321
g9915
sg7325
g9918
stRp12646
ag1
(g11214
g11182
(dp12647
g7308
g9921
sg7310
g9922
sg7321
g9931
sg7325
g9934
stRp12648
ag1
(g11214
g11182
(dp12649
g7308
g9937
sg7310
g9938
sg7321
g9947
sg7325
g9950
stRp12650
ag1
(g11214
g11182
(dp12651
g7308
g9953
sg7310
g9954
sg7321
g9963
sg7325
g9966
stRp12652
ag1
(g11214
g11182
(dp12653
g7308
g9969
sg7310
g9970
sg7321
g9979
sg7325
g9982
stRp12654
ag1
(g11214
g11182
(dp12655
g7308
g9985
sg7310
g9986
sg7321
g9995
sg7325
g9998
stRp12656
ag1
(g11214
g11182
(dp12657
g7308
g10001
sg7310
g10002
sg7321
g10011
sg7325
g10014
stRp12658
ag1
(g11214
g11182
(dp12659
g7308
g10017
sg7310
g10018
sg7321
g10027
sg7325
g10030
stRp12660
ag1
(g11214
g11182
(dp12661
g7308
g10033
sg7310
g10034
sg7321
g10043
sg7325
g10046
stRp12662
ag1
(g11214
g11182
(dp12663
g7308
g10049
sg7310
g10050
sg7321
g10059
sg7325
g10062
stRp12664
ag1
(g11214
g11182
(dp12665
g7308
g10065
sg7310
g10066
sg7321
g10075
sg7325
g10078
stRp12666
ag1
(g11214
g11182
(dp12667
g7308
g10081
sg7310
g10082
sg7321
g10091
sg7325
g10094
stRp12668
ag1
(g11214
g11182
(dp12669
g7308
g10097
sg7310
g10098
sg7321
g10107
sg7325
g10110
stRp12670
ag1
(g11214
g11182
(dp12671
g7308
g10113
sg7310
g10114
sg7321
g10123
sg7325
g10126
stRp12672
ag1
(g11214
g11182
(dp12673
g7308
g10129
sg7310
g10130
sg7321
g10139
sg7325
g10142
stRp12674
ag1
(g11214
g11182
(dp12675
g7308
g10145
sg7310
g10146
sg7321
g10155
sg7325
g10158
stRp12676
ag1
(g11214
g11182
(dp12677
g7308
g10161
sg7310
g10162
sg7321
g10171
sg7325
g10174
stRp12678
ag1
(g11214
g11182
(dp12679
g7308
g10177
sg7310
g10178
sg7321
g10187
sg7325
g10190
stRp12680
ag1
(g11214
g11182
(dp12681
g7308
g10193
sg7310
g10194
sg7321
g10203
sg7325
g10206
stRp12682
ag1
(g11214
g11182
(dp12683
g7308
g10209
sg7310
g10210
sg7321
g10219
sg7325
g10222
stRp12684
ag1
(g11214
g11182
(dp12685
g7308
g10225
sg7310
g10226
sg7321
g10235
sg7325
g10238
stRp12686
ag1
(g11214
g11182
(dp12687
g7308
g10241
sg7310
g10242
sg7321
g10251
sg7325
g10254
stRp12688
ag1
(g11214
g11182
(dp12689
g7308
g10257
sg7310
g10258
sg7321
g10267
sg7325
g10270
stRp12690
ag1
(g11214
g11182
(dp12691
g7308
g10273
sg7310
g10274
sg7321
g10283
sg7325
g10286
stRp12692
ag1
(g11214
g11182
(dp12693
g7308
g10289
sg7310
g10290
sg7321
g10299
sg7325
g10302
stRp12694
ag1
(g11214
g11182
(dp12695
g7308
g10305
sg7310
g10306
sg7321
g10315
sg7325
g10318
stRp12696
ag1
(g11214
g11182
(dp12697
g7308
g10321
sg7310
g10322
sg7321
g10331
sg7325
g10334
stRp12698
ag1
(g11214
g11182
(dp12699
g7308
g10337
sg7310
g10338
sg7321
g10347
sg7325
g10350
stRp12700
ag1
(g11214
g11182
(dp12701
g7308
g10353
sg7310
g10354
sg7321
g10363
sg7325
g10366
stRp12702
ag1
(g11214
g11182
(dp12703
g7308
g10369
sg7310
g10370
sg7321
g10379
sg7325
g10382
stRp12704
ag1
(g11214
g11182
(dp12705
g7308
g10385
sg7310
g10386
sg7321
g10395
sg7325
g10398
stRp12706
ag1
(g11214
g11182
(dp12707
g7308
g10401
sg7310
g10402
sg7321
g10411
sg7325
g10414
stRp12708
ag1
(g11214
g11182
(dp12709
g7308
g10417
sg7310
g10418
sg7321
g10427
sg7325
g10430
stRp12710
ag1
(g11214
g11182
(dp12711
g7308
g10433
sg7310
g10434
sg7321
g10443
sg7325
g10446
stRp12712
ag1
(g11214
g11182
(dp12713
g7308
g10449
sg7310
g10450
sg7321
g10459
sg7325
g10462
stRp12714
ag1
(g11214
g11182
(dp12715
g7308
g10465
sg7310
g10466
sg7321
g10475
sg7325
g10478
stRp12716
ag1
(g11214
g11182
(dp12717
g7308
g10481
sg7310
g10482
sg7321
g10491
sg7325
g10494
stRp12718
ag1
(g11214
g11182
(dp12719
g7308
g10497
sg7310
g10498
sg7321
g10507
sg7325
g10510
stRp12720
asg11295
Nsg11296
g10506
sg11297
I200
sg11298
I0
sg11299
I200
sg11300
I01
sbag1
(g11169
g3
NtRp12721
(dp12722
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p12723
sg11174
(lp12724
sg11176
I89576816
sg10
S'bdm_loop2'
p12725
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp12726
g11184
g11185
(g11186
g11187
g11188
S'b'
tRp12727
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp12728
(I1
(I40
I1
tg11190
I00
S'\x00\x00\xe8A\x00\x00\xe0@\x00\x00\x80?\x00\x00\x18B\x00\x00\xd8A\x00\x00\x00@\x00\x00\xb8A\x00\x00\x00\x00\x00\x00\x0cB\x00\x00\xe0A\x00\x00\xc0A\x00\x00\x04B\x00\x00`A\x00\x00\xc0@\x00\x00\xa8A\x00\x00\xf0A\x00\x00\x98A\x00\x00\xd0A\x00\x00@@\x00\x00\xa0@\x00\x00pA\x00\x00PA\x00\x00\x10B\x00\x00\xf8A\x00\x00\x14B\x00\x00\xc8A\x00\x00\x88A\x00\x00\x1cB\x00\x000A\x00\x00\x08B\x00\x00\x90A\x00\x00\x10A\x00\x00@A\x00\x00\x80A\x00\x00\x00A\x00\x00 A\x00\x00\x80@\x00\x00\x00B\x00\x00\xa0A\x00\x00\xb0A'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg42
g11185
(g11186
g11187
g11188
S'b'
tRp12729
(I1
(I40
I1
tg11190
I00
S'\x1f\x85\x9b?\xaa\xf1\x92?\x1dZ\xc4?=\n\x87?D\x8b\xac?h\x91M@\xaa\xf1\x92?\x19\x04\x06@j\xbc\x94?D\x8b\xac?`\xe5\x00@\xaa\xf1\x92??5\xae?d;\xbf?\x00\x00\xb0?;\xdf\xaf?\xb0r\xb8?\x00\x00\xb0?\x02+\xd7?d;\xbf?\x9a\x99\xc9?h\x91\xbd?\xb2\x9d\x8f?\x8d\x97\xce?\x81\x95\x83?\xf2\xd2\x8d?\xac\x1c\xba?\x85\xeb\x81?^\xba\x99?d;\xbf?\xfc\xa9\xb1?\x19\x04n@\x1b/\x9d?\xfc\xa9\xb1?\xf8S\xb3?\xac\x1c\xba?\xe3\xa5\xeb?\x91\xed\xcc?\xf4\xfd\xb4??5\xae?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg41
g11185
(g11186
g11187
g11188
S'b'
tRp12730
(I1
(I40
I1
tg11190
I00
S'R\xb8\x1e?\x8f\xc2\xf5>\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\n\xd7\xa3>\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xc3\xf5(?\n\xd7\xa3=\x9a\x99\x19?\n\xd7#=\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00?\x00\x00\x00\x00\n\xd7\xa3<\x00\x00\x00\x00\x8f\xc2\xf5>\x00\x00\x00\x00\x8f\xc2\xf5>\x00\x00\x00\x00q=\n?\x8f\xc2\xf5>\x00\x00\x00\x00\n\xd7\xa3<\x00\x00\x00\x00\n\xd7#?\x00\x00\x00\x00\n\xd7\xa3>\x00\x00\x00\x00)\\\x0f>\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
NtbstRp12731
(dp12732
g11197
(dp12733
g11184
I01
sg11193
I01
sg42
I01
sg41
I01
ssg11199
g12721
sg11200
(lp12734
g11184
ag11193
ag41
ag42
asg11202
(lp12735
I40
aI1
asbsg11204
g11205
sg11206
g11207
(g11187
(I0
tS'b'
tRp12736
(I1
(I40
I1
tg96
I01
S'\x07\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x12\x00\x00\x00$\x00\x00\x00\x13\x00\x00\x00\r\x00\x00\x00\x01\x00\x00\x00"\x00\x00\x00\x1f\x00\x00\x00#\x00\x00\x00\x1c\x00\x00\x00 \x00\x00\x00\x15\x00\x00\x00\x0c\x00\x00\x00\x14\x00\x00\x00!\x00\x00\x00\x1a\x00\x00\x00\x1e\x00\x00\x00\x10\x00\x00\x00&\x00\x00\x00\x0e\x00\x00\x00\'\x00\x00\x00\x06\x00\x00\x00\n\x00\x00\x00\x19\x00\x00\x00\x11\x00\x00\x00\x04\x00\x00\x00\t\x00\x00\x00\x00\x00\x00\x00\x0f\x00\x00\x00\x17\x00\x00\x00%\x00\x00\x00\x0b\x00\x00\x00\x1d\x00\x00\x00\x08\x00\x00\x00\x16\x00\x00\x00\x18\x00\x00\x00\x03\x00\x00\x00\x1b\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp12737
g1
(g11214
g11182
(dp12738
g10526
g10730
stRp12739
ag1
(g11214
g11182
(dp12740
g10526
g10576
stRp12741
ag1
(g11214
g11182
(dp12742
g10526
g10534
stRp12743
ag1
(g11214
g11182
(dp12744
g10526
g10793
stRp12745
ag1
(g11214
g11182
(dp12746
g10526
g10716
stRp12747
ag1
(g11214
g11182
(dp12748
g10526
g10541
stRp12749
ag1
(g11214
g11182
(dp12750
g10526
g10688
stRp12751
ag1
(g11214
g11182
(dp12752
g10526
g10527
stRp12753
ag1
(g11214
g11182
(dp12754
g10526
g10772
stRp12755
ag1
(g11214
g11182
(dp12756
g10526
g10723
stRp12757
ag1
(g11214
g11182
(dp12758
g10526
g10695
stRp12759
ag1
(g11214
g11182
(dp12760
g10526
g10758
stRp12761
ag1
(g11214
g11182
(dp12762
g10526
g10625
stRp12763
ag1
(g11214
g11182
(dp12764
g10526
g10569
stRp12765
ag1
(g11214
g11182
(dp12766
g10526
g10674
stRp12767
ag1
(g11214
g11182
(dp12768
g10526
g10737
stRp12769
ag1
(g11214
g11182
(dp12770
g10526
g10660
stRp12771
ag1
(g11214
g11182
(dp12772
g10526
g10709
stRp12773
ag1
(g11214
g11182
(dp12774
g10526
g10548
stRp12775
ag1
(g11214
g11182
(dp12776
g10526
g10562
stRp12777
ag1
(g11214
g11182
(dp12778
g10526
g10632
stRp12779
ag1
(g11214
g11182
(dp12780
g10526
g10618
stRp12781
ag1
(g11214
g11182
(dp12782
g10526
g10779
stRp12783
ag1
(g11214
g11182
(dp12784
g10526
g10744
stRp12785
ag1
(g11214
g11182
(dp12786
g10526
g10786
stRp12787
ag1
(g11214
g11182
(dp12788
g10526
g10702
stRp12789
ag1
(g11214
g11182
(dp12790
g10526
g10646
stRp12791
ag1
(g11214
g11182
(dp12792
g10526
g10800
stRp12793
ag1
(g11214
g11182
(dp12794
g10526
g10604
stRp12795
ag1
(g11214
g11182
(dp12796
g10526
g10765
stRp12797
ag1
(g11214
g11182
(dp12798
g10526
g10653
stRp12799
ag1
(g11214
g11182
(dp12800
g10526
g10590
stRp12801
ag1
(g11214
g11182
(dp12802
g10526
g10611
stRp12803
ag1
(g11214
g11182
(dp12804
g10526
g10639
stRp12805
ag1
(g11214
g11182
(dp12806
g10526
g10583
stRp12807
ag1
(g11214
g11182
(dp12808
g10526
g10597
stRp12809
ag1
(g11214
g11182
(dp12810
g10526
g10555
stRp12811
ag1
(g11214
g11182
(dp12812
g10526
g10751
stRp12813
ag1
(g11214
g11182
(dp12814
g10526
g10667
stRp12815
ag1
(g11214
g11182
(dp12816
g10526
g10681
stRp12817
asg11295
Nsg11296
g10798
sg11297
I40
sg11298
I0
sg11299
I40
sg11300
I01
sbag1
(g11169
g3
NtRp12818
(dp12819
g11172
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2014 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import gui, logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs, locale\u000aimport weakref\u000aimport re\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFilename : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo==None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a        """\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if os.path.exists(fileName) and writeFormat == 'w':\u000a            logging.warning('Data file, %s, will be overwritten' %fileName)\u000a\u000a        if fileName[-4:] in ['.csv', '.CSV']:\u000a            delim=','\u000a        else:\u000a            delim='\u005ct'\u000a\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.csv', '.CSV','.dlm','.DLM', '.tsv','.TSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        self.saveWideText=False\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        #no need to save again\u000a        self.savePickle=False\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp==None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod = 'rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        if os.path.exists(fileName):\u000a            fileName = handleFileCollision(fileName, fileCollisionMethod)\u000a\u000a        #create the file or print to stdout\u000a        f = open(fileName, 'wb')\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a    def saveAsText(self,fileName,\u000a                   stimOut=[],\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim==None:\u000a            if fileName[-4:] in ['.csv','.CSV']:\u000a                delim=','\u000a            else:\u000a                delim='\u005ct'\u000a\u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',':\u000a                f= codecs.open(fileName+'.csv',writeFormat, encoding = "utf-8")\u000a            else:\u000a                f=codecs.open(fileName+'.dlm',writeFormat, encoding = "utf-8")\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=[],\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[],\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                if self.autoLog:\u000a                    logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line==None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and it's contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath,"r", encoding = "utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0: n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                elif heading=='order_raw': heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str: dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go trhough standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew: dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew: dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.txt' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if appendFile:\u000a            writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.tsv', '.TSV', '.txt', '.TXT', '.csv', '.CSV']:\u000a            f = codecs.open(fileName,writeFormat, encoding = "utf-8")\u000a        else:\u000a            if delim==',': f = codecs.open(fileName+'.csv', writeFormat, encoding="utf-8")\u000a            else: f=codecs.open(fileName+'.txt',writeFormat, encoding = "utf-8")\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a                nextEntry["TrialNumber"] = trialCount\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef importConditions(fileName, returnFieldNames=False):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError, 'Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError, 'Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name)\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError, 'Conditions file not found: %s' %os.path.abspath(fileName)\u000a\u000a    if fileName.endswith('.csv'):\u000a        #use csv import library to fetch the fieldNames\u000a        f = open(fileName, 'rU')#the U converts line endings to os.linesep (not unicode!)\u000a        trialsArr = numpy.recfromcsv(f, case_sensitive=True)\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        f.close()\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a        try:\u000a            wb = load_workbook(filename = fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError, 'Could not open %s as conditions' % fileName\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``demo_trialHandler.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a    \u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size        \u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                logging.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' %f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest':\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        try:\u000a            self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a            if len(self.runningStaircases)==0: #If finished,set finished flag\u000a                self.finished=True\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed byt he user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError, "MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)"\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label,\u000a                matrixOnly=matrixOnly, appendFile=append)\u000a    def saveAsText(self,fileName,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.dlm` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim,\u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position==None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        raise "FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead"\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params==None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled<0]=0\u000a        xx = (yScaled*(c50)**n/(1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy aray of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p12820
sg11174
(lp12821
sg11176
I89576816
sg10
S'binary2'
p12822
sg6
g11178
sg11179
I1
sg57
I01
sg58
g59
sg11180
g1
(g11181
g11182
(dp12823
g48
g11185
(g11186
g11187
g11188
S'b'
tRp12824
(I1
(I40
I1
tg11190
I00
S'\xb0rh?w\xbe\xdf?\xf8S\xb3?\xb6\xf3\xfd>?5\xae?\xcb\xa1\x05?\x85\xeb1?\xb4\xc8\x16?\xb6\xf3\xfd>\xd5x\xe9>\xe3\xa5\xdb>\xd3M\xe2>\xb8\x1ee?\xc5 \xf0>\xc5 \xf0>\xb4\xc8\xf6>\xd3M\xe2>\xcb\xa1\x05?\xe3\xa5\xdb>\xd5x\xe9>\xd5x\xe9>\xd3M\xe2>\xd3M\x02?\xe3\xa5\xdb>\xa2Ev?\xb6\xf3\xfd>\xd3M\xe2>\xb8\x1ee?\xcb\xa1\x05?9\xb4\x88?\xd5x\xe9>\xd3M\x02?\xf4\xfd\xd4>\xf4\xfd\xd4>\xd3M\xe2>\xd5x\xe9>\xb6\xf3\xfd>\xc5 \xf0>\xd3M\x02?\xf4\xfd\xd4>'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg47
g11185
(g11186
g11187
g11188
S'b'
tRp12825
(I1
(I40
I1
tg11190
I00
S'\x00\x00\xc0@\x00\x00\xc0@\x9a\x99\x99@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@33\xa3@\x00\x00\xc0@\xcd\xcc\xac@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00`@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x9a\x99\xa9@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xb0@\x00\x00\xc0@\x00\x00\x80?\x00\x00\xc0@\x00\x00\x80?\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@33\xb3@\x00\x00\xc0@\x00\x00\xc0@\x00\x00\xc0@'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11184
g11185
(g11186
g11187
g11188
S'b'
tRp12826
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?\x00\x00\x80?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg11193
g11185
(g11186
g11187
g11188
S'b'
tRp12827
(I1
(I40
I1
tg11190
I00
S'\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@\x00\x00\xc0@\x00\x00\xe0@\x00\x00\x00A\x00\x00\x10A\x00\x00 A\x00\x000A\x00\x00@A\x00\x00PA\x00\x00`A\x00\x00pA\x00\x00\x80A\x00\x00\x88A\x00\x00\x90A\x00\x00\x98A\x00\x00\xa0A\x00\x00\xa8A\x00\x00\xb0A\x00\x00\xb8A\x00\x00\xc0A\x00\x00\xc8A\x00\x00\xd0A\x00\x00\xd8A\x00\x00\xe0A\x00\x00\xe8A\x00\x00\xf0A\x00\x00\xf8A\x00\x00\x00B\x00\x00\x04B\x00\x00\x08B\x00\x00\x0cB\x00\x00\x10B\x00\x00\x14B\x00\x00\x18B\x00\x00\x1cB'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg46
g11185
(g11186
g11187
g11188
S'b'
tRp12828
(I1
(I40
I1
tg11190
I00
S'\xf0\xd8P@\xb9\xd3\xd3@Gh\x1f@~\xd2\x0b?=\xea\xe7>\xad;\x0f?\x10W|?N\x0e\x16?\xabv\x19?\xc3\x10a?\\\x16\xa7?(\x11\xe1?\xfc\x82*?(\x05P?9\x95\x81?\xd6`B?^\xa4\x12?\x88\x83\x8d?\xbf\xc0\x7f?\xe1%8?t\x19\'?"\xd3\x0b?\x08\xf8>?\xcf\xaf#?Yj\x08?\xc6\xe8\xe7>9\xb4n?\x9a\x01\x05?T\xb1#?*aB?\x86)8?\xcfu\x19?\xae\x83\x8d?\xd2S1?\x19<\x0f?\xcb#8?\x8e\r\x16?\xccv\x19?\x1c\xa1\x92?l\x1a\'?'
S'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
Ntbsg45
g11207
(g11187
(I0
tS'b'
tRp12829
(I1
(I40
I1
tg11308
I00
(lp12830
g10806
ag10816
ag10825
ag10834
ag10843
ag10852
ag10861
ag10870
ag10879
ag10888
ag10897
ag10906
ag10915
ag10924
ag10933
ag10942
ag10951
ag10960
ag10969
ag10978
ag10987
ag10996
ag11005
ag11014
ag11023
ag11032
ag11041
ag11050
ag11059
ag11068
ag11077
ag11086
ag11095
ag11104
ag11113
ag11122
ag11131
ag11140
ag11149
ag11158
atbstRp12831
(dp12832
g11197
(dp12833
g47
I01
sg11184
I01
sg46
I01
sg45
I00
sg11193
I01
sg48
I01
ssg11199
g12818
sg11200
(lp12834
g11184
ag11193
ag45
ag46
ag47
ag48
asg11202
(lp12835
I40
aI1
asbsg11204
g11320
sg11206
g11207
(g11187
(I0
tS'b'
tRp12836
(I1
(I40
I1
tg96
I00
S'\x00\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\x03\x00\x00\x00\x04\x00\x00\x00\x05\x00\x00\x00\x06\x00\x00\x00\x07\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\n\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x00\r\x00\x00\x00\x0e\x00\x00\x00\x0f\x00\x00\x00\x10\x00\x00\x00\x11\x00\x00\x00\x12\x00\x00\x00\x13\x00\x00\x00\x14\x00\x00\x00\x15\x00\x00\x00\x16\x00\x00\x00\x17\x00\x00\x00\x18\x00\x00\x00\x19\x00\x00\x00\x1a\x00\x00\x00\x1b\x00\x00\x00\x1c\x00\x00\x00\x1d\x00\x00\x00\x1e\x00\x00\x00\x1f\x00\x00\x00 \x00\x00\x00!\x00\x00\x00"\x00\x00\x00#\x00\x00\x00$\x00\x00\x00%\x00\x00\x00&\x00\x00\x00\'\x00\x00\x00'
tbsg11209
I01
sg11210
I1
sg11211
I-1
sg11212
(lp12837
g1
(g11214
g11182
(dp12838
g10804
g10805
sg10807
g10808
stRp12839
ag1
(g11214
g11182
(dp12840
g10804
g10815
sg10807
g10817
stRp12841
ag1
(g11214
g11182
(dp12842
g10804
g10824
sg10807
g10826
stRp12843
ag1
(g11214
g11182
(dp12844
g10804
g10833
sg10807
g10835
stRp12845
ag1
(g11214
g11182
(dp12846
g10804
g10842
sg10807
g10844
stRp12847
ag1
(g11214
g11182
(dp12848
g10804
g10851
sg10807
g10853
stRp12849
ag1
(g11214
g11182
(dp12850
g10804
g10860
sg10807
g10862
stRp12851
ag1
(g11214
g11182
(dp12852
g10804
g10869
sg10807
g10871
stRp12853
ag1
(g11214
g11182
(dp12854
g10804
g10878
sg10807
g10880
stRp12855
ag1
(g11214
g11182
(dp12856
g10804
g10887
sg10807
g10889
stRp12857
ag1
(g11214
g11182
(dp12858
g10804
g10896
sg10807
g10898
stRp12859
ag1
(g11214
g11182
(dp12860
g10804
g10905
sg10807
g10907
stRp12861
ag1
(g11214
g11182
(dp12862
g10804
g10914
sg10807
g10916
stRp12863
ag1
(g11214
g11182
(dp12864
g10804
g10923
sg10807
g10925
stRp12865
ag1
(g11214
g11182
(dp12866
g10804
g10932
sg10807
g10934
stRp12867
ag1
(g11214
g11182
(dp12868
g10804
g10941
sg10807
g10943
stRp12869
ag1
(g11214
g11182
(dp12870
g10804
g10950
sg10807
g10952
stRp12871
ag1
(g11214
g11182
(dp12872
g10804
g10959
sg10807
g10961
stRp12873
ag1
(g11214
g11182
(dp12874
g10804
g10968
sg10807
g10970
stRp12875
ag1
(g11214
g11182
(dp12876
g10804
g10977
sg10807
g10979
stRp12877
ag1
(g11214
g11182
(dp12878
g10804
g10986
sg10807
g10988
stRp12879
ag1
(g11214
g11182
(dp12880
g10804
g10995
sg10807
g10997
stRp12881
ag1
(g11214
g11182
(dp12882
g10804
g11004
sg10807
g11006
stRp12883
ag1
(g11214
g11182
(dp12884
g10804
g11013
sg10807
g11015
stRp12885
ag1
(g11214
g11182
(dp12886
g10804
g11022
sg10807
g11024
stRp12887
ag1
(g11214
g11182
(dp12888
g10804
g11031
sg10807
g11033
stRp12889
ag1
(g11214
g11182
(dp12890
g10804
g11040
sg10807
g11042
stRp12891
ag1
(g11214
g11182
(dp12892
g10804
g11049
sg10807
g11051
stRp12893
ag1
(g11214
g11182
(dp12894
g10804
g11058
sg10807
g11060
stRp12895
ag1
(g11214
g11182
(dp12896
g10804
g11067
sg10807
g11069
stRp12897
ag1
(g11214
g11182
(dp12898
g10804
g11076
sg10807
g11078
stRp12899
ag1
(g11214
g11182
(dp12900
g10804
g11085
sg10807
g11087
stRp12901
ag1
(g11214
g11182
(dp12902
g10804
g11094
sg10807
g11096
stRp12903
ag1
(g11214
g11182
(dp12904
g10804
g11103
sg10807
g11105
stRp12905
ag1
(g11214
g11182
(dp12906
g10804
g11112
sg10807
g11114
stRp12907
ag1
(g11214
g11182
(dp12908
g10804
g11121
sg10807
g11123
stRp12909
ag1
(g11214
g11182
(dp12910
g10804
g11130
sg10807
g11132
stRp12911
ag1
(g11214
g11182
(dp12912
g10804
g11139
sg10807
g11141
stRp12913
ag1
(g11214
g11182
(dp12914
g10804
g11148
sg10807
g11150
stRp12915
ag1
(g11214
g11182
(dp12916
g10804
g11157
sg10807
g11159
stRp12917
asg11295
Nsg11296
g11162
sg11297
I40
sg11298
I0
sg11299
I40
sg11300
I01
sbasS'savePickle'
p12918
I01
sb.